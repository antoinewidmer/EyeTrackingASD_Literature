[
  {"id":"2022","abstract":"Virtual reality (VR) technologies are playing an increasingly important role in the diagnostics and treatment of mental disorders.To systematically re…","accessed":{"date-parts":[["2024",7,24]]},"citation-key":"2022","container-title":"Clinical Psychology Review","DOI":"10.1016/j.cpr.2022.102213","ISSN":"0272-7358","issued":{"date-parts":[["2022",12,1]]},"language":"en-US","page":"102213","publisher":"Pergamon","source":"www.sciencedirect.com","title":"Virtual reality in the diagnostic and therapy for mental disorders: A systematic review","title-short":"Virtual reality in the diagnostic and therapy for mental disorders","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0272735822000988","volume":"98"},
  {"id":"2022a","abstract":"In the Industry 4.0 era, the number and complexity of machine tools are both increased, which is prone to cause malfunctions and downtime in the manuf…","accessed":{"date-parts":[["2024",8,21]]},"citation-key":"2022a","container-title":"Robotics and Computer-Integrated Manufacturing","DOI":"10.1016/j.rcim.2022.102357","ISSN":"0736-5845","issued":{"date-parts":[["2022",10,1]]},"language":"en-US","page":"102357","publisher":"Pergamon","source":"www.sciencedirect.com","title":"Probing an intelligent predictive maintenance approach with deep learning and augmented reality for machine tools in IoT-enabled manufacturing","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S073658452200045X","volume":"77"},
  {"id":"2022b","abstract":"While the development of artificial intelligence (AI) and virtual reality (VR) technologies in medicine has been significant, their application to doc…","accessed":{"date-parts":[["2024",9,15]]},"citation-key":"2022b","container-title":"Patient Education and Counseling","DOI":"10.1016/j.pec.2022.06.006","ISSN":"0738-3991","issue":"10","issued":{"date-parts":[["2022",10,1]]},"language":"en-US","page":"3038-3050","publisher":"Elsevier","source":"www.sciencedirect.com","title":"The use of artificial intelligence and virtual reality in doctor-patient risk communication: A scoping review","title-short":"The use of artificial intelligence and virtual reality in doctor-patient risk communication","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0738399122002750","volume":"105"},
  {"id":"2022c","abstract":"The acquisition of 3D facial models is crucial in the gaming and film industries. In this study, we developed a facial acquisition system based on inf…","accessed":{"date-parts":[["2024",9,16]]},"citation-key":"2022c","container-title":"Computers & Graphics","DOI":"10.1016/j.cag.2022.03.007","ISSN":"0097-8493","issued":{"date-parts":[["2022",5,1]]},"language":"en-US","page":"46-58","publisher":"Pergamon","source":"www.sciencedirect.com","title":"High-fidelity 3D real-time facial animation using infrared structured light sensing system","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0097849322000395","volume":"104"},
  {"id":"2023","abstract":"Technology-mediated dance experiences, as a medium of entertainment, are a key element in both traditional and virtual reality-based gaming platforms.…","accessed":{"date-parts":[["2024",6,11]]},"citation-key":"2023","container-title":"Neurocomputing","DOI":"10.1016/j.neucom.2023.126388","ISSN":"0925-2312","issued":{"date-parts":[["2023",8,28]]},"language":"en-US","page":"126388","publisher":"Elsevier","source":"www.sciencedirect.com","title":"Neuromorphic high-frequency 3D dancing pose estimation in dynamic environment","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0925231223005118","volume":"547"},
  {"id":"2023a","abstract":"Virtual reality simulations are shown to be an effective approach for interprofessional nurse-physician communication training. However, its scalabili…","accessed":{"date-parts":[["2024",7,22]]},"citation-key":"2023a","container-title":"Nurse Education Today","DOI":"10.1016/j.nedt.2023.105718","ISSN":"0260-6917","issued":{"date-parts":[["2023",3,1]]},"language":"en-US","page":"105718","publisher":"Churchill Livingstone","source":"www.sciencedirect.com","title":"Artificial intelligence in virtual reality simulation for interprofessional communication training: Mixed method study","title-short":"Artificial intelligence in virtual reality simulation for interprofessional communication training","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0260691723000126","volume":"122"},
  {"id":"2023b","abstract":"Educational approaches proven to produce cultural competence among nurses, consistently and cost-effectively, are not yet widely available. This study…","accessed":{"date-parts":[["2024",7,22]]},"citation-key":"2023b","container-title":"Clinical Simulation in Nursing","DOI":"10.1016/j.ecns.2023.01.005","ISSN":"1876-1399","issued":{"date-parts":[["2023",4,1]]},"language":"en-US","page":"13-22","publisher":"Elsevier","source":"www.sciencedirect.com","title":"An Immersive Virtual Reality Simulation for Cross-Cultural Communication Skills: Development and Feasibility","title-short":"An Immersive Virtual Reality Simulation for Cross-Cultural Communication Skills","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1876139923000051","volume":"77"},
  {"id":"2024a","abstract":"We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Inte…","accessed":{"date-parts":[["2024",8,27]]},"citation-key":"2024a","container-title":"Cognitive Systems Research","DOI":"10.1016/j.cogsys.2023.101188","ISSN":"1389-0417","issued":{"date-parts":[["2024",3,1]]},"language":"en-US","page":"101188","publisher":"Elsevier","source":"www.sciencedirect.com","title":"Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning","title-short":"Improving deep learning with prior knowledge and cognitive models","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1389041723001225","volume":"84"},
  {"id":"2024b","abstract":"Explore the benefits of using Arbrea Face Simulator: optimize consultation time and enhance patient satisfaction.","accessed":{"date-parts":[["2024",9,15]]},"citation-key":"2024b","container-title":"Arbrea Labs","issued":{"date-parts":[["2024",10,30]]},"language":"en-US","title":"Face simulator","type":"post-weblog","URL":"https://arbrea-labs.com/face/"},
  {"id":"abadi2015","abstract":"In this work, we present DECAF-a multimodal data set for decoding user physiological responses to affective multimedia content. Different from data sets such as DEAP [15] and MAHNOB-HCI [31], DECAF contains (1) brain signals acquired using the Magnetoencephalogram (MEG) sensor, which requires little physical contact with the user's scalp and consequently facilitates naturalistic affective response, and (2) explicit and implicit emotional responses of 30 participants to 40 one-minute music video segments used in [15] and 36 movie clips, thereby enabling comparisons between the EEG versus MEG modalities as well as movie versus music stimuli for affect recognition. In addition to MEG data, DECAF comprises synchronously recorded near-infra-red (NIR) facial videos, horizontal Electrooculogram (hEOG), Electrocardiogram (ECG), and trapezius-Electromyogram (tEMG) peripheral physiological responses. To demonstrate DECAF's utility, we present (i) a detailed analysis of the correlations between participants' self-assessments and their physiological responses and (ii) single-trial classification results for valence, arousal and dominance, with performance evaluation against existing data sets. DECAF also contains time-continuous emotion annotations for movie clips from seven users, which we use to demonstrate dynamic emotion prediction.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Abadi","given":"Mojtaba Khomami"},{"family":"Subramanian","given":"Ramanathan"},{"family":"Kia","given":"Seyed Mostafa"},{"family":"Avesani","given":"Paolo"},{"family":"Patras","given":"Ioannis"},{"family":"Sebe","given":"Nicu"}],"citation-key":"abadi2015","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/TAFFC.2015.2392932","ISSN":"1949-3045","issue":"3","issued":{"date-parts":[["2015",7]]},"page":"209-222","source":"IEEE Xplore","title":"DECAF: MEG-Based Multimodal Database for Decoding Affective Physiological Responses","title-short":"DECAF","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/7010926","volume":"6"},
  {"id":"abbasi2021","abstract":"A prototype app reliably distinguished toddlers with autism from those with typical development in a National Institutes of Health–funded study. The app uses a tablet or smartphone’s camera to record eye-gaze patterns while children watch short videos on the device.The study involved 993 patients with an average age of about 21 months who were seen at 4 Duke Children’s Primary Care clinics. The kids watched custom-made videos of people in social situations—smiling, making eye contact, and having conversations. Computer vision analysis of the gaze patterns revealed quantifiable differences in how the children visually tracked the social cues, which predicted with high accuracy those who went on to receive an autism spectrum disorder (ASD) diagnosis after traditional screening.","accessed":{"date-parts":[["2025",2,7]]},"author":[{"family":"Abbasi","given":"Jennifer"}],"citation-key":"abbasi2021","container-title":"JAMA","container-title-short":"JAMA","DOI":"10.1001/jama.2021.8627","ISSN":"0098-7484","issue":"22","issued":{"date-parts":[["2021",6,8]]},"page":"2243","source":"Silverchair","title":"Mobile Device App Helps Distinguish Toddlers With Autism","type":"article-journal","URL":"https://doi.org/10.1001/jama.2021.8627","volume":"325"},
  {"id":"abbasi2023","abstract":"The presence of abnormal infant General Movements (GMs) is a strong predictor of progressive neurodevelopmental disorders, including cerebral palsy (CP). Automation of the assessment will overcome scalability barriers that limit its delivery to at-risk individuals. Here, we report a robust markerless pose-estimation scheme, based on advanced deep-learning technology, to track infant movements in consumer mobile device video recordings. Two deep neural network models, namely Efficientnet-b6 and resnet-152, were trained on manually annotated data across twelve anatomical locations (3 per limb) in 12 videos from 6 full-term infants (mean age = 17.33 (SD 2.9) wks, 4 male, 2 female), using the DeepLabCut™ framework. K-fold cross-validation indicates the generalization capability of the deep-nets for GM tracking on out-of-domain data with an overall performance of 95.52% (SD 2.43) from the best performing model (Efficientnet-b6) across all infants (performance range: 84.32–99.24% across all anatomical locations). The paper further introduces an automatic, unsupervised strategy for performance evaluation on extensive out-of-domain recordings through a fusion of likelihoods from a Kalman filter and the deep-net. Findings indicate the possibility of establishing an automated GM tracking platform, as a suitable alternative to, or support for, the current observational protocols for early diagnosis of neurodevelopmental disorders in early infancy.","accessed":{"date-parts":[["2025",1,22]]},"author":[{"family":"Abbasi","given":"H."},{"family":"Mollet","given":"S. R."},{"family":"Williams","given":"S. A."},{"family":"Lim","given":"L."},{"family":"Battin","given":"M. R."},{"family":"Besier","given":"T. F."},{"family":"McMorland","given":"A. J. C."}],"citation-key":"abbasi2023","container-title":"International Journal of Information Technology","container-title-short":"Int. j. inf. tecnol.","DOI":"10.1007/s41870-023-01497-z","ISSN":"2511-2112","issue":"8","issued":{"date-parts":[["2023",12,1]]},"language":"en","page":"4073-4083","source":"Springer Link","title":"Deep-learning for automated markerless tracking of infants general movements","type":"article-journal","URL":"https://doi.org/10.1007/s41870-023-01497-z","volume":"15"},
  {"id":"abbasi2023a","abstract":"Monitoring spontaneous General Movements (GM) of infants 6–20 weeks post-term age is a reliable tool to assess the quality of neurodevelopment in early infancy. Abnormal or absent GMs are reliable prognostic indicators of whether an infant is at risk of developing neurological impairments and disorders such as cerebral palsy (CP). Therapeutic interventions are most effective at improving neuromuscular outcomes if administered in early infancy. Current clinical protocols require trained assessors to rate videos of infant movements, a time-intensive task. This work proposes a simple, inexpensive, and broadly applicable markerless pose-estimation approach for automatic infant movement tracking using conventional video recordings from handheld devices (e.g., tablets and mobile phones). We leverage the enhanced capabilities of deep-learning technology in image processing to identify 12 anatomical locations (3 per limb) in each video frame, tracking a baby’s natural movement throughout the recordings. We validate the capability of resnet152 and a mobile-net-v2-1 to identify body-parts in unseen frames from a full-term male infant, using a novel automatic unsupervised approach that fuses likelihood outputs of a Kalman filter and the deep-nets. Both deep-net models were found to perform very well in the identification of anatomical locations in the unseen data with high average Percentage of Correct Keypoints (aPCK) performances of >99.65% across all locations.Clinical relevance—Results of this research confirm the feasibility of a low-cost and publicly accessible technology to automatically track infants’ GMs and diagnose those at higher risk of developing neurological conditions early, when clinical interventions are most effective.","accessed":{"date-parts":[["2025",1,22]]},"author":[{"family":"Abbasi","given":"Hamid"},{"family":"Mollet","given":"Sarah R."},{"family":"Williams","given":"Sîan A."},{"family":"Lim","given":"Lilian"},{"family":"Battin","given":"Malcolm R."},{"family":"Besier","given":"Thor F."},{"family":"McMorland","given":"Angus J.C."}],"citation-key":"abbasi2023a","container-title":"2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","DOI":"10.1109/EMBC40787.2023.10340116","event-title":"2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","ISSN":"2694-0604","issued":{"date-parts":[["2023",7]]},"page":"1-4","source":"IEEE Xplore","title":"Deep-Learning Markerless Tracking of Infant General Movements using Standard Video Recordings","type":"paper-conference","URL":"https://ieeexplore.ieee.org/abstract/document/10340116"},
  {"id":"achouch2022","abstract":"In the era of the fourth industrial revolution, several concepts have arisen in parallel with this new revolution, such as predictive maintenance, which today plays a key role in sustainable manufacturing and production systems by introducing a digital version of machine maintenance. The data extracted from production processes have increased exponentially due to the proliferation of sensing technologies. Even if Maintenance 4.0 faces organizational, financial, or even data source and machine repair challenges, it remains a strong point for the companies that use it. Indeed, it allows for minimizing machine downtime and associated costs, maximizing the life cycle of the machine, and improving the quality and cadence of production. This approach is generally characterized by a very precise workflow, starting with project understanding and data collection and ending with the decision-making phase. This paper presents an exhaustive literature review of methods and applied tools for intelligent predictive maintenance models in Industry 4.0 by identifying and categorizing the life cycle of maintenance projects and the challenges encountered, and presents the models associated with this type of maintenance: condition-based maintenance (CBM), prognostics and health management (PHM), and remaining useful life (RUL). Finally, a novel applied industrial workflow of predictive maintenance is presented including the decision support phase wherein a recommendation for a predictive maintenance platform is presented. This platform ensures the management and fluid data communication between equipment throughout their life cycle in the context of smart maintenance.","accessed":{"date-parts":[["2025",3,7]]},"author":[{"family":"Achouch","given":"Mounia"},{"family":"Dimitrova","given":"Mariya"},{"family":"Ziane","given":"Khaled"},{"family":"Sattarpanah Karganroudi","given":"Sasan"},{"family":"Dhouib","given":"Rizck"},{"family":"Ibrahim","given":"Hussein"},{"family":"Adda","given":"Mehdi"}],"citation-key":"achouch2022","container-title":"Applied Sciences","DOI":"10.3390/app12168081","ISSN":"2076-3417","issue":"16","issued":{"date-parts":[["2022",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"16","page":"8081","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"On Predictive Maintenance in Industry 4.0: Overview, Models, and Challenges","title-short":"On Predictive Maintenance in Industry 4.0","type":"article-journal","URL":"https://www.mdpi.com/2076-3417/12/16/8081","volume":"12"},
  {"id":"adesina","abstract":"BACKGROUND\n\nThe study argues that managing tacit knowledge (TKM) would reduce small-and medium-sized enterprises (SMEs) operational discontinuity and knowledge loss in KwaZulu-Natal (KZN) province, South Africa.\n\nOBJECTIVES\n\nThe article examined the strategies put in place by SMEs for tacit knowledge management (TKM) practices and to develop a framework that will promote TKM for SMEs.\n\nMETHOD\n\nThe study adopted a quantitative research method and targeted 326 SMEs using Google Forms. One hundred and eighty (180; 55.2%) useful responses were obtained and analysed using the Statistical Package for Social Sciences.\n\nRESULTS\n\nMost of the SME owners are aware and affirmed that there is a particular tacit knowledge that is of importance to business. The most common methods of capturing tacit knowledge among SMEs are monitoring, practical sessions, in-house training programmes, and brainstorming. Tacit knowledge is shared during meetings (such as project teams) and when dialoguing. The study also revealed that electronic files in computers are the major tools for storing the collected tacit knowledge.\n\nCONCLUSION\n\nThe study concluded that TKM among SMEs in KZN required improvement and recommended improving teams and informal networks and making information and communication technology tools available to preserve tacit knowledge. The SMEs that can afford it can consider employing the services of consultant knowledge management officers to conduct periodic knowledge audits to identify knowledge gaps for proactive solutions.\n\nCONTRIBUTION\n\nThe study contributed to knowledge management, tacit knowledge, explicit knowledge, and TKM.","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Adesina","given":"Aderonke O."},{"family":"Ocholla","given":"Dennis N."}],"citation-key":"adesina","container-title":"South African Journal of Information Management","DOI":"10.4102/sajim.v26i1.1711","issue":"1","page":"1711","publisher":"AOSIS","source":"journals.co.za (Atypon)","title":"Tacit knowledge management strategies of small- and medium-sized enterprises: An overview","title-short":"Tacit knowledge management strategies of small- and medium-sized enterprises","type":"article-journal","URL":"https://journals.co.za/doi/full/10.4102/sajim.v26i1.1711","volume":"26"},
  {"id":"adhanom2023","abstract":"Eye tracking is becoming increasingly available in head-mounted virtual reality displays with various headsets with integrated eye trackers already commercially available. The applications of eye tracking in virtual reality are highly diversified and span multiple disciplines. As a result, the number of peer-reviewed publications that study eye tracking applications has surged in recent years. We performed a broad review to comprehensively search academic literature databases with the aim of assessing the extent of published research dealing with applications of eye tracking in virtual reality, and highlighting challenges, limitations and areas for future research.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Adhanom","given":"Isayas Berhe"},{"family":"MacNeilage","given":"Paul"},{"family":"Folmer","given":"Eelke"}],"citation-key":"adhanom2023","container-title":"Virtual Reality","container-title-short":"Virtual Reality","DOI":"10.1007/s10055-022-00738-z","ISSN":"1434-9957","issue":"2","issued":{"date-parts":[["2023",6,1]]},"language":"en","page":"1481-1505","source":"Springer Link","title":"Eye Tracking in Virtual Reality: a Broad Review of Applications and Challenges","title-short":"Eye Tracking in Virtual Reality","type":"article-journal","URL":"https://doi.org/10.1007/s10055-022-00738-z","volume":"27"},
  {"id":"ahn","abstract":"Assessing and responding to risks to children’s safety is a primary concern of the child protection system (CPS), and decision-support tools have been developed to assist child welfare workers (CWW). Yet, a limited understanding of CWWs’ decision-making experiences impedes our efforts to effectively support them. This qualitative study examines the unique characteristics of decision-making in CPS through focus groups involving CWWs from an agency in California. Five themes emerged: CWWs’ responsibilities, decision-making characteristics, domain-specific complexities, and CWWs’ perspectives on fairness in decision-making. The findings highlight the need to incorporate CWWs’ experiences and insights in developing future decision-support tools.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Ahn","given":"Eunhye"},{"family":"Morstatter","given":"Fred"},{"family":"Waters-Roman","given":"Debra"},{"family":"Palmer","given":"Lindsey"},{"family":"McCroskey","given":"Jacquelyn"}],"citation-key":"ahn","container-title":"Journal of Public Child Welfare","DOI":"10.1080/15548732.2024.2312846","ISSN":"1554-8732","issue":"0","page":"1-24","publisher":"Routledge","source":"Taylor and Francis+NEJM","title":"Qualitative exploration of child welfare workers’ decision-making experiences and perspectives on fairness","type":"article-journal","URL":"https://doi.org/10.1080/15548732.2024.2312846","volume":"0"},
  {"id":"aikat2024","abstract":"The high prevalence of autism calls for accessible and scalable technology-assisted screening tools. This will aid in early detection allowing timely access to services and supports. SenseToKnow, a mobile digital phenotyping app, showed potential in eliciting autism-related behaviors that can be automatically captured via computer vision analysis (CVA) in toddlers. Here, we present the capability of SenseToKnow in characterizing autism in school age children and showcase the robustness of the CVA features in interpreting distinct and overlapping behaviors with attention-deficit/hyperactive disorder (ADHD).","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Aikat","given":"Vikram"},{"family":"Krishnappa Babu","given":"Pradeep Raj"},{"family":"Carpenter","given":"Kimberly L.H."},{"family":"Di Martino","given":"J. Matias"},{"family":"Espinosa","given":"Steven"},{"family":"Davis","given":"Naomi"},{"family":"Franz","given":"Lauren"},{"family":"Spanos","given":"Marina"},{"family":"Dawson","given":"Geraldine"},{"family":"Sapiro","given":"Guillermo"}],"citation-key":"aikat2024","collection-title":"UIST Adjunct '24","container-title":"Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology","DOI":"10.1145/3672539.3686323","event-place":"New York, NY, USA","ISBN":"979-8-4007-0718-6","issued":{"date-parts":[["2024",10,13]]},"page":"1–4","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Digital Phenotyping based on a Mobile App Identifies Distinct and Overlapping Features in Children Diagnosed with Autism versus ADHD","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3672539.3686323"},
  {"id":"akdere2021a","abstract":"Purpose As new technologies such as immersive and augmented platforms emerge, training approaches are also transforming. The virtual reality (VR) platform provides a completely immersive learning experience for simulated training. Despite increased prevalence of these technologies, the extent literature is lagging behind in terms of evaluating and assessing such innovative training models. The purpose of this paper is to address this gap through exploring the traditional approaches of quantitative, qualitative and mixed methods as well as the cutting-edge biometric approach in the evaluation and assessment of the VR-based simulated training and discuss implications for simulated training based on immersive technologies. Design/methodology/approach Evaluation and assessment is one of the most critical components of training and development. Inaccurate or ineffective approaches to evaluate and assess training programs not only risk the successful attainment of training goals and outcomes, but they also harm trainees by misleading them about their training performances and experiences. This paper uses a review of existing literature to explore effective approaches for the evaluation and assessment of VR-based simulated training and conceptually discusses new capacities in capturing involuntary trainee reaction toward stimuli, in addition to traditional evaluation and assessment methods. Findings Immersive VR-based simulated training is uncharted territory for trainers and human resource development professionals. The findings indicate that existing approaches are still viable options for the evaluation and assessment of this new training technology. However, biometrics presents new frontiers in this arena through its capacity for obtaining trainee emotional responses to stimuli during training, as well as providing a venue free of personal bias and external influences in determining trainee perceptions. Originality/value This paper addresses an important gap in the field of training and development by studying the affordances of the latest biometric technology for evaluation and assessment in VR-based simulated training. The existing literature is very limited in its focus on immersive training technologies such as VR in general and evaluation and assessment in particular. The paper presents new insights to both researchers and practitioners in the field of training and development.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Akdere","given":"Mesut"},{"family":"Jiang","given":"Yeling"},{"family":"Lobo","given":"Flavio Destri"}],"citation-key":"akdere2021a","container-title":"European Journal of Training and Development","DOI":"10.1108/EJTD-12-2020-0178","ISSN":"2046-9012","issue":"5/6","issued":{"date-parts":[["2021",1,1]]},"page":"434-449","publisher":"Emerald Publishing Limited","source":"Emerald Insight","title":"Evaluation and assessment of virtual reality-based simulated training: exploring the human–technology frontier","title-short":"Evaluation and assessment of virtual reality-based simulated training","type":"article-journal","URL":"https://doi.org/10.1108/EJTD-12-2020-0178","volume":"46"},
  {"id":"alcaniz2022","abstract":"The core symptoms of autism spectrum disorder (ASD) mainly relate to social communication and interactions. ASD assessment involves expert observations in neutral settings, which introduces limitations and biases related to lack of objectivity and does not capture performance in real-world settings. To overcome these limitations, advances in technologies (e.g., virtual reality) and sensors (e.g., eye-tracking tools) have been used to create realistic simulated environments and track eye movements, enriching assessments with more objective data than can be obtained via traditional measures. This study aimed to distinguish between autistic and typically developing children using visual attention behaviors through an eye-tracking paradigm in a virtual environment as a measure of attunement to and extraction of socially relevant information. The 55 children participated. Autistic children presented a higher number of frames, both overall and per scenario, and showed higher visual preferences for adults over children, as well as specific preferences for adults' rather than children's faces on which looked more at bodies. A set of multivariate supervised machine learning models were developed using recursive feature selection to recognize ASD based on extracted eye gaze features. The models achieved up to 86% accuracy (sensitivity = 91%) in recognizing autistic children. Our results should be taken as preliminary due to the relatively small sample size and the lack of an external replication dataset. However, to our knowledge, this constitutes a first proof of concept in the combined use of virtual reality, eye-tracking tools, and machine learning for ASD recognition. Lay Summary Core symptoms in children with ASD involve social communication and interaction. ASD assessment includes expert observations in neutral settings, which show limitations and biases related to lack of objectivity and do not capture performance in real settings. To overcome these limitations, this work aimed to distinguish between autistic and typically developing children in visual attention behaviors through an eye-tracking paradigm in a virtual environment as a measure of attunement to, and extraction of, socially relevant information.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Alcañiz","given":"Mariano"},{"family":"Chicchi-Giglioli","given":"Irene Alice"},{"family":"Carrasco-Ribelles","given":"Lucía A."},{"family":"Marín-Morales","given":"Javier"},{"family":"Minissi","given":"Maria Eleonora"},{"family":"Teruel-García","given":"Gonzalo"},{"family":"Sirera","given":"Marian"},{"family":"Abad","given":"Luis"}],"citation-key":"alcaniz2022","container-title":"Autism Research","DOI":"10.1002/aur.2636","ISSN":"1939-3806","issue":"1","issued":{"date-parts":[["2022"]]},"language":"en","license":"© 2021 The Authors. Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.","page":"131-145","source":"Wiley Online Library","title":"Eye gaze as a biomarker in the recognition of autism spectrum disorder using virtual reality and machine learning: A proof of concept for diagnosis","title-short":"Eye gaze as a biomarker in the recognition of autism spectrum disorder using virtual reality and machine learning","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/aur.2636","volume":"15"},
  {"id":"alcanizraya2020","abstract":"<sec><title>Objective</title><p>Sensory processing is the ability to capture, elaborate, and integrate information through the five senses and is impaired in over 90% of children with autism spectrum disorder (ASD). The ASD population shows hyper–hypo sensitiveness to sensory stimuli that can generate alteration in information processing, affecting cognitive and social responses to daily life situations. Structured and semi-structured interviews are generally used for ASD assessment, and the evaluation relies on the examiner’s subjectivity and expertise, which can lead to misleading outcomes. Recently, there has been a growing need for more objective, reliable, and valid diagnostic measures, such as biomarkers, to distinguish typical from atypical functioning and to reliably track the progression of the illness, helping to diagnose ASD. Implicit measures and ecological valid settings have been showing high accuracy on predicting outcomes and correctly classifying populations in categories.</p></sec><sec><title>Methods</title><p>Two experiments investigated whether sensory processing can discriminate between ASD and typical development (TD) populations using electrodermal activity (EDA) in two multimodal virtual environments (VE): forest VE and city VE. In the first experiment, 24 children with ASD diagnosis and 30 TDs participated in both virtual experiences, and changes in EDA have been recorded before and during the presentation of visual, auditive, and olfactive stimuli. In the second experiment, 40 children have been added to test the model of experiment 1.</p></sec><sec><title>Results</title><p>The first exploratory results on EDA comparison models showed that the integration of visual, auditive, and olfactive stimuli in the forest environment provided higher accuracy (90.3%) on sensory dysfunction discrimination than specific stimuli. In the second experiment, 92 subjects experienced the forest VE, and results on 72 subjects showed that stimuli integration achieved an accuracy of 83.33%. The final confirmatory test set (<italic>n</italic> = 20) achieved 85% accuracy, simulating a real application of the models. Further relevant result concerns the visual stimuli condition in the first experiment, which achieved 84.6% of accuracy in recognizing ASD sensory dysfunction.</p></sec><sec><title>Conclusion</title><p>According to our studies’ results, implicit measures, such as EDA, and ecological valid settings can represent valid quantitative methods, along with traditional assessment measures, to classify ASD population, enhancing knowledge on the development of relevant specific treatments.</p></sec>","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Alcañiz Raya","given":"Mariano"},{"family":"Chicchi Giglioli","given":"Irene Alice"},{"family":"Marín-Morales","given":"Javier"},{"family":"Higuera-Trujillo","given":"Juan L."},{"family":"Olmos","given":"Elena"},{"family":"Minissi","given":"Maria E."},{"family":"Teruel Garcia","given":"Gonzalo"},{"family":"Sirera","given":"Marian"},{"family":"Abad","given":"Luis"}],"citation-key":"alcanizraya2020","container-title":"Frontiers in Human Neuroscience","container-title-short":"Front. Hum. Neurosci.","DOI":"10.3389/fnhum.2020.00090","ISSN":"1662-5161","issued":{"date-parts":[["2020",4,3]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Application of Supervised Machine Learning for Behavioral Biomarkers of Autism Spectrum Disorder Based on Electrodermal Activity and Virtual Reality","type":"article-journal","URL":"https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2020.00090/full","volume":"14"},
  {"id":"altin2025","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder that is characterized by limitations in social communication and interaction, self-repetitive behaviors, and the presence of limited interests. The prevalence of ASD, which typically emerges in the first years of life, is increasing at an alarming rate due to multiple factors, including the broadening of diagnostic criteria, heightened public awareness, and more frequent diagnoses among women and adults. Over the years, experts have invested considerable time and effort in developing educational scenarios for children with ASD. However, they have faced challenges replicating certain scenarios—such as emergencies, crowded public transportation, or restaurant environments—because recreating these exact conditions in real-world settings is difficult or cost-prohibitive. This has consequently compelled experts to seek out supplementary intervention methods that are more suitable and accessible. Virtual reality (VR), which has the capacity to integrate the physical and virtual realms, represents one such alternative intervention method. In this study, a systematic review of studies employing VR technology in social skills interventions for individuals with ASD was conducted, and 31 studies were included. The findings indicate the potential benefits of VR applications focusing on the social skills of individuals with ASD. Additionally, this research elucidates the limitations of the studies and offers suggestions for future research.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Altın","given":"Yücel"},{"family":"Boşnak","given":"Özge"},{"family":"Turhan","given":"Ceyda"}],"citation-key":"altin2025","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-025-06741-y","ISSN":"1573-3432","issued":{"date-parts":[["2025",2,5]]},"language":"en","source":"Springer Link","title":"Examining Virtual Reality Interventions for Social Skills in Children with Autism Spectrum Disorder: A Systematic Review","title-short":"Examining Virtual Reality Interventions for Social Skills in Children with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s10803-025-06741-y"},
  {"id":"alvari2024","abstract":"Virtual Reality (VR) has emerged as a promising tool for enhancing social skills and emotional well-being in individuals with Autism Spectrum Disorder (ASD). Through a technical exploration, this study employs a multiplayer serious gaming environment within VR, engaging 34 individuals diagnosed with ASD and employing high-precision biosensors for a comprehensive view of the participants' arousal and responses during the VR sessions. Participants were subjected to a series of 3 virtual scenarios designed in collaboration with stakeholders and clinical experts to promote socio-cognitive skills and emotional regulation in a controlled and structured virtual environment. We combined the framework with wearable non-invasive sensors for bio-signal acquisition, focusing on the collection of heart rate variability, and respiratory patterns to monitor participants behaviors. Further, behavioral assessments were conducted using observation and semi-structured interviews, with the data analyzed in conjunction with physiological measures to identify correlations and explore digital-intervention efficacy. Preliminary analysis revealed significant correlations between physiological responses and behavioral outcomes, indicating the potential of physiological feedback to enhance VR-based interventions for ASD. The study demonstrated the feasibility of using real-time data to adapt virtual scenarios, suggesting a promising avenue to support personalized therapy. The integration of quantitative physiological feedback into digital platforms represents a forward step in the personalized intervention for ASD. By leveraging real-time data to adjust therapeutic content, this approach promises to enhance the efficacy and engagement of digital-based therapies.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Alvari","given":"Gianpaolo"},{"family":"Vallefuoco","given":"Ersilia"},{"family":"Cristofolini","given":"Melanie"},{"family":"Salvadori","given":"Elio"},{"family":"Dianti","given":"Marco"},{"family":"Moltani","given":"Alessia"},{"family":"Castello","given":"Davide Dal"},{"family":"Venuti","given":"Paola"},{"family":"Furlanello","given":"Cesare"}],"citation-key":"alvari2024","DOI":"10.48550/arXiv.2404.07159","issued":{"date-parts":[["2024",4,10]]},"number":"arXiv:2404.07159","publisher":"arXiv","source":"arXiv.org","title":"Exploring Physiological Responses in Virtual Reality-based Interventions for Autism Spectrum Disorder: A Data-Driven Investigation","title-short":"Exploring Physiological Responses in Virtual Reality-based Interventions for Autism Spectrum Disorder","type":"article","URL":"http://arxiv.org/abs/2404.07159"},
  {"id":"americanpsychiatricassociation2022","accessed":{"date-parts":[["2025",3,11]]},"author":[{"literal":"American Psychiatric Association"}],"citation-key":"americanpsychiatricassociation2022","DOI":"10.1176/appi.books.9780890425787","edition":"DSM-5-TR","ISBN":"978-0-89042-575-6","issued":{"date-parts":[["2022",3,18]]},"language":"en","publisher":"American Psychiatric Association Publishing","source":"DOI.org (Crossref)","title":"Diagnostic and Statistical Manual of Mental Disorders","type":"book","URL":"https://psychiatryonline.org/doi/book/10.1176/appi.books.9780890425787"},
  {"id":"angelopoulos2021","abstract":"The cameras in modern gaze-tracking systems suffer from fundamental bandwidth and power limitations, constraining data acquisition speed to 300 Hz realistically. This obstructs the use of mobile eye trackers to perform, e.g., low latency predictive rendering, or to study quick and subtle eye motions like microsaccades using head-mounted devices in the wild. Here, we propose a hybrid frame-event-based near-eye gaze tracking system offering update rates beyond 10,000 Hz with an accuracy that matches that of high-end desktop-mounted commercial trackers when evaluated in the same conditions. Our system, previewed in Figure 1, builds on emerging event cameras that simultaneously acquire regularly sampled frames and adaptively sampled events. We develop an online 2D pupil fitting method that updates a parametric model every one or few events. Moreover, we propose a polynomial regressor for estimating the point of gaze from the parametric pupil model in real time. Using the first event-based gaze dataset, we demonstrate that our system achieves accuracies of 0.45°-1.75° for fields of view from 45° to 98°. With this technology, we hope to enable a new generation of ultra-low-latency gaze-contingent rendering and display techniques for virtual and augmented reality.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Angelopoulos","given":"Anastasios N."},{"family":"Martel","given":"Julien N.P."},{"family":"Kohli","given":"Amit P."},{"family":"Conradt","given":"Jörg"},{"family":"Wetzstein","given":"Gordon"}],"citation-key":"angelopoulos2021","container-title":"IEEE Transactions on Visualization and Computer Graphics","DOI":"10.1109/TVCG.2021.3067784","ISSN":"1941-0506","issue":"5","issued":{"date-parts":[["2021",5]]},"page":"2577-2586","source":"IEEE Xplore","title":"Event-Based Near-Eye Gaze Tracking Beyond 10,000 Hz","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9389490","volume":"27"},
  {"id":"antshel2019","abstract":"Autism spectrum disorder (ASD) and attention deficit/hyperactivity disorder (ADHD) are both increasing in prevalence and commonly co-occur with each other. The goal of this review is to outline what has been published recently on the topics of ASD, ADHD, and the comorbid state (ASD+ADHD) with a particular focus on shared phenomenology, differential diagnosis, and treatment considerations.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Antshel","given":"Kevin M."},{"family":"Russo","given":"Natalie"}],"citation-key":"antshel2019","container-title":"Current Psychiatry Reports","container-title-short":"Curr Psychiatry Rep","DOI":"10.1007/s11920-019-1020-5","ISSN":"1535-1645","issue":"5","issued":{"date-parts":[["2019",3,22]]},"language":"en","page":"34","source":"Springer Link","title":"Autism Spectrum Disorders and ADHD: Overlapping Phenomenology, Diagnostic Issues, and Treatment Considerations","title-short":"Autism Spectrum Disorders and ADHD","type":"article-journal","URL":"https://doi.org/10.1007/s11920-019-1020-5","volume":"21"},
  {"id":"ardalan2019","abstract":"Individuals with autism spectrum disorder struggle with motor difficulties throughout the life span, and these motor difficulties may affect independent living skills and quality of life. Yet, we know little about how whole-body movement may distinguish individuals with autism spectrum disorder from individuals with typical development. In this study, kinematic and postural sway data were collected during multiple sessions of videogame play in 39 youth with autism spectrum disorder and 23 age-matched youth with typical development (ages 7–17 years). The youth on the autism spectrum exhibited more variability and more entropy in their movements. Machine learning analysis of the youths’ motor patterns distinguished between the autism spectrum and typically developing groups with high aggregate accuracy (up to 89%), with no single region of the body seeming to drive group differences. Moreover, the machine learning results corresponded to individual differences in performance on standardized motor tasks and measures of autism symptom severity. The machine learning algorithm was also sensitive to age, suggesting that motor challenges in autism may be best characterized as a developmental motor delay rather than an autism-distinct motor profile. Overall, these results reveal that whole-body movement is a distinguishing feature in autism spectrum disorder and that movement atypicalities in autism are present across the body.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Ardalan","given":"Adel"},{"family":"Assadi","given":"Amir H."},{"family":"Surgent","given":"Olivia J."},{"family":"Travers","given":"Brittany G."}],"citation-key":"ardalan2019","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-019-56362-6","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2019",12,27]]},"language":"en","license":"2019 The Author(s)","page":"20094","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Whole-Body Movement during Videogame Play Distinguishes Youth with Autism from Youth with Typical Development","type":"article-journal","URL":"https://www.nature.com/articles/s41598-019-56362-6","volume":"9"},
  {"id":"armengol-urpi2024","abstract":"This work-in-progress innovative practice paper presents a novel approach to 1) extract tacit knowledge from expert trainers while they perform a task demo, 2) decrease the learner's cognitive load via the use of instructional videos portraying the variables at play during a task demonstration, and 3) define quantifiable metrics of expertise by extracting features that differentiate experts from novice practitioners. Implicit or tacit knowledge is know-how that experts develop with experience and is difficult to verbalize, formalize or explicitly transfer to others. For this reason, knowledge transfer from expert to apprentice is usually slow and inefficient. Our approach seeks to support knowledge transfer using technology-enhanced approaches. Here, we focus on extracting and describing exper-tise. We do so by instrumenting experts, trainees and their tools with sensors that can help structure and formalize knowledge. Our first application of this framework is on the knowledge transfer between an expert and novice glassblower. Glassblowing is well known for its crucial expert/apprentice relation and its slow learning rate due in part to the difficulties in verbal transfer of skills. Our framework seeks to capture relevant data while an expert glassblower demonstrates basic actions in a beginners glass blowing course. Our sensors collect eye-tracking activity, verbal demo instructions, pipe accelerometry, air infusion, scene video and muscle activity (EMG), which continuously monitor the expert, their explanations, the tools, and the glass piece. We bring together all the sensed data into instructional videos to be used by novice learners as supportive training material. We present preliminary results related to metrics of expertise and future steps towards gathering similar data from novices. This will help develop AI-based models to extract data-driven differences between experts and apprentices, which can be used as further instructional material. We will also present plans to test the instructional effectiveness of the developed videos and how our approach can be used in other training settings involving tacit knowledge transfer.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Armengol-Urpi","given":"Alexandre"},{"family":"Salazar-Gomez","given":"Andres F."},{"family":"Sarma","given":"Sanjay E."}],"citation-key":"armengol-urpi2024","container-title":"2024 IEEE Frontiers in Education Conference (FIE)","DOI":"10.1109/FIE61694.2024.10893143","event-title":"2024 IEEE Frontiers in Education Conference (FIE)","ISSN":"2377-634X","issued":{"date-parts":[["2024",10]]},"page":"1-5","source":"IEEE Xplore","title":"WIP: Making Implicit Knowledge Explicit - A Data-Driven Approach to Improve Knowledge Transfer in a Glassblowing Beginners Class","title-short":"WIP","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10893143"},
  {"id":"armengolurpi2023","abstract":"Tacit or implicit knowledge is know-how that humans cannot convey explicitly; it is difficult to verbalize, and hence, it is challenging to transfer to others in words. Tacit knowledge is usually gained from experience and internalized unconsciously through implicit learning. Since tacit knowledge is not consciously accessible, it is commonly seen as a “mysterious\" part of expertise that can only be transferred from one person to another through close interaction, coaching, mentoring, and observation of expert behavior. Examples of daily activities based on tacit knowledge include riding a bike, recognizing a face, writing a persuasive thesis or speaking a native language. This thesis explores new methods for tacit knowledge extraction using visual attention-based human-computer interfaces.\nEarlier studies suggest that eye gaze is particularly suited for studying the unconscious component of expertise. For this reason, this research focuses on developing new interfaces that track the visual attention of experts while performing tasks in which they excel. This thesis is divided into two main sections. In the first part, we develop novel human-computer interfaces suited to track visual attention and that enhance existing interfaces based on gaze tracking alone. We do this by exploiting brain activity in addition to eye gaze. First, we leverage neural mechanisms of visual attention to improve the accuracy of a commercial eye tracker through the analysis of electroencephalography (EEG) waves. Our hybrid system combines EEG and eye-tracking modalities to overcome the accuracy limitations of the gaze tracker alone. We integrate EEG and gaze data to efficiently exploit their complementary strengths by driving a Bayesian probabilistic decoder that estimates the region in the visual field gazed at by the user. This demonstrates that the intrinsic accuracy limitations of camera-based eye trackers can be corrected with the integration of EEG data. Then, we show why visual attention and gaze can be decoupled by developing an interface that tracks peripheral attention using EEG waves. Our novel approach can detect peripheral (or covert) spatial attention by using single-frequency phase-coded stimuli that elicit the corresponding Steady-State Visually Evoked Potentials (SSVEPs). This opens opportunities for attention-tracking applications with largely increased number of targets in the visual field.\nIn the second part of this thesis, we exploit our previously developed interfaces to track the visual attention of experts performing image classification tasks. First, we create images with a hidden asymmetry that is not consciously (or explicitly) recognized by the experts. However, their visual attention patterns reveal that the asymmetry is unconsciously internalized because the attention metrics are skewed towards the image regions most relevant for categorization. This demonstrates that we can capture insights about experts' tacit knowledge by tracking their visual attention. We then show that the expertise of subjects who receive feedback extracted from their own attention patterns is significantly enhanced compared to subjects who did not. We refer to this as cognitive reinforcement. This research opens the door to new ways in which human expertise can be enhanced, exploited, and transferred. Finally, we utilize human attention maps captured during image exploration and labeling to feed a CNN-based image classification model. We demonstrate that when few images are available for training, the model fed with human attention maps, in addition to images and labels, significantly outperforms the baseline model. These results illustrate that experts' tacit knowledge can be exploited to enhance the performance of human experts as well as AI systems.","accessed":{"date-parts":[["2024",8,21]]},"author":[{"family":"Armengol Urpí","given":"Àlex"}],"citation-key":"armengolurpi2023","event-place":"United States -- Massachusetts","genre":"Ph.D.","ISBN":"9798381955170","issued":{"date-parts":[["2023"]]},"license":"Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.","number-of-pages":"187","publisher":"Massachusetts Institute of Technology","publisher-place":"United States -- Massachusetts","source":"ProQuest","title":"Capturing Tacit Knowledge of Experts Through the Study of Visual Attention: Applications for Human Expertise and AI","title-short":"Capturing Tacit Knowledge of Experts Through the Study of Visual Attention","type":"thesis","URL":"https://www.proquest.com/docview/3031006792/abstract/137F0EAC92FA48A9PQ/1"},
  {"id":"aromaa2016","abstract":"Industrial maintenance is an increasingly complex and knowledge intensive field. Although new technologies in maintenance have been studied extensively, their usage is still lacking in the industry. We have studied knowledge-sharing solutions using augmented reality (AR) and wearable technologies in actual industry cases to find out if maintenance technicians find them useful and usable in their everyday work. Two test cases were included: the use of a wearable system consisting of three devices in the crane industry, and the use of AR guidance in the marine industry. In both cases two maintenance technicians tested the technologies and data were collected using questionnaires, interviews and observation. The maintenance technicians were positive towards the use of these technologies in their work. However, some practical issues were raised concerning the simultaneous use of multiple devices and the placement of the devices. A more system-level approach to designing wearable and AR technologies could be applied to ensure their utility in the field. Findings from this study can be used when designing and implementing wearable and AR technologies in maintenance, but also in other industry domains like the manufacturing industry.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Aromaa","given":"Susanna"},{"family":"Aaltonen","given":"Iina"},{"family":"Kaasinen","given":"Eija"},{"family":"Elo","given":"Joona"},{"family":"Parkkinen","given":"Ilari"}],"citation-key":"aromaa2016","collection-title":"AcademicMindtrek '16","container-title":"Proceedings of the 20th International Academic Mindtrek Conference","DOI":"10.1145/2994310.2994321","event-place":"New York, NY, USA","ISBN":"978-1-4503-4367-1","issued":{"date-parts":[["2016",10,17]]},"page":"235–242","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Use of wearable and augmented reality technologies in industrial maintenance work","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/2994310.2994321"},
  {"id":"arthur2021","abstract":"The integration of prior expectations, sensory information, and environmental volatility is proposed to be atypical in Autism Spectrum Disorder, yet few studies have tested these predictive processes in active movement tasks. To address this gap in the research, we used an immersive virtual-reality racquetball paradigm to explore how visual sampling behaviours and movement kinematics are adjusted in relation to unexpected, uncertain, and volatile changes in environmental statistics. We found that prior expectations concerning ball ‘bounciness’ affected sensorimotor control in both autistic and neurotypical participants, with all individuals using prediction-driven gaze strategies to track the virtual ball. However, autistic participants showed substantial differences in visuomotor behaviour when environmental conditions were more volatile. Specifically, uncertainty-related performance difficulties in these conditions were accompanied by atypical movement kinematics and visual sampling responses. Results support proposals that autistic people overestimate the volatility of sensory environments, and suggest that context-sensitive differences in active inference could explain a range of movement-related difficulties in autism.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Arthur","given":"Tom"},{"family":"Harris","given":"David"},{"family":"Buckingham","given":"Gavin"},{"family":"Brosnan","given":"Mark"},{"family":"Wilson","given":"Mark"},{"family":"Williams","given":"Genevieve"},{"family":"Vine","given":"Sam"}],"citation-key":"arthur2021","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-021-99864-y","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2021",10,13]]},"language":"en","license":"2021 The Author(s)","page":"20377","publisher":"Nature Publishing Group","source":"www.nature.com","title":"An examination of active inference in autistic adults using immersive virtual reality","type":"article-journal","URL":"https://www.nature.com/articles/s41598-021-99864-y","volume":"11"},
  {"id":"asmethajeyarani2023","abstract":"Eye tracking is a promising tool for Autism Spectrum Disorder (ASD) detection in both children and adults. An important aspect of social communication is keeping eye contact, which is something that people with ASD frequently struggle with. Eye tracking can assess the duration of eye contact and the frequency and direction of gaze movements, offering quantifiable indicators of social communication deficits. People with ASD may also demonstrate other abnormalities in visual processing, such as an increased concentration on detail, sensory sensitivity, and trouble with complicated visual activities. These variations can be measured via Eye tracking, which offers critical information for the planning of therapy and diagnosis. The primary objective of this work is to provide a thorough description of the most recent studies that use Eye tracking combined with various Machine Learning (ML) and Deep Learning (DL) models for the detection of ASD. This will provide insights into the identification, and behavioral assessment, and distinguish between autistic people and those who are Typically Developing (TD). A detailed review of the various ML and DL models with their datasets and performance criteria is presented. Different types of eye movement datasets with diagnostic standards and eye tracker devices are also discussed. Finally, the study addresses the potential of gaze prediction in ASD patients for the design of interventions.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Asmetha Jeyarani","given":"R."},{"family":"Senthilkumar","given":"Radha"}],"citation-key":"asmethajeyarani2023","container-title":"Research in Autism Spectrum Disorders","container-title-short":"Research in Autism Spectrum Disorders","DOI":"10.1016/j.rasd.2023.102228","ISSN":"1750-9467","issued":{"date-parts":[["2023",10,1]]},"page":"102228","source":"ScienceDirect","title":"Eye Tracking Biomarkers for Autism Spectrum Disorder Detection using Machine Learning and Deep Learning Techniques: Review","title-short":"Eye Tracking Biomarkers for Autism Spectrum Disorder Detection using Machine Learning and Deep Learning Techniques","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1750946723001289","volume":"108"},
  {"id":"azu2024","abstract":"Clinician and caregiver reports of autism features are both integral to receiving an autism diagnosis and appropriate intervention, yet informant discrepancies are present in clinical practice and may differ by demographic characteristics of the child and family. The present study examined how clinician–caregiver discrepancies in ratings of a child’s autism-related behaviors relate to a child’s sex at birth, age at first diagnosis, and amount of intervention received. Participants were 280 children (76.8% male, 67.9% White), 6–11 years old (M = 8.5 ± 1.6), with a diagnosis of autism spectrum disorder. Variable-centered and person-centered approaches were used to examine relationships between standardized clinician–caregiver discrepancy and participant characteristics. Both analytic approaches indicated that clinicians rated autism-related behaviors lower than caregivers for females and higher than caregivers for males. In addition, lower clinician ratings of autism features, relative to caregiver ratings, were associated with older age at diagnosis and fewer hours of intervention. Findings underscore the importance of incorporating multiple informants, especially caregivers, in the diagnostic process and developing diagnostic procedures sensitive to the female autism phenotype to facilitate diagnosis, intervention, and subsequent development.\nLay abstract\nIn some cases, a clinician’s perceptions of a child’s autism-related behaviors are not the same as the child’s caregiver’s perceptions. Identifying how these discrepancies relate to the characteristics of the child is critical for ensuring that diagnosis procedures are unbiased and suitable for all children. This study examined whether discrepancies between clinician and caregiver reports of autism features related to the child’s sex at birth. We also explored how the discrepancies related to the age at which the child received their autism diagnosis and how much intervention they received. We found that clinicians rated autism features higher than caregivers for boys and rated autism features lower than caregivers for girls. In addition, lower clinician relative to parent ratings was related to being diagnosed at an older age and receiving less intervention. These findings suggest that there is more to learn about the presentation of autism-related behaviors in girls. When caregiver and clinician ratings of autism features do not align, it may be important to consider caregivers’ ratings to obtain a more accurate picture of the child’s autism features and the support they may need.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Azu","given":"Margaret A."},{"family":"Han","given":"Gloria T."},{"family":"Wolf","given":"Julie M."},{"family":"Naples","given":"Adam J."},{"family":"Chawarska","given":"Katarzyna"},{"family":"Dawson","given":"Geraldine"},{"family":"Bernier","given":"Raphael A."},{"family":"Jeste","given":"Shafali S."},{"family":"Dziura","given":"James D."},{"family":"Webb","given":"Sara J."},{"family":"Sugar","given":"Catherine A."},{"family":"Shic","given":"Frederick"},{"family":"McPartland","given":"James C."}],"citation-key":"azu2024","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/13623613241279999","ISSN":"1362-3613","issued":{"date-parts":[["2024",9,30]]},"language":"en","page":"13623613241279999","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Clinician–caregiver informant discrepancy is associated with sex, diagnosis age, and intervention use among autistic children","type":"article-journal","URL":"https://doi.org/10.1177/13623613241279999"},
  {"id":"bailey2022","abstract":"This review investigated virtual reality and augmented reality (VR/AR) communication interventions for children, adolescents, and adults with communication disability and neurodevelopmental disorders, as well the feasibility of these technologies. A search of five scientific databases yielded 5385 potentially relevant records of which 69 met inclusion criteria. Studies reported on a wide range of VR/AR devices, platforms, and applications for people with autism spectrum disorder, communication disorders, and intellectual disability. Some VR/AR systems hosted effective communication interventions; however, participant outcomes varied across the included studies. Most participants with neurodevelopmental disorders and their supporters were able to access learning experiences using VR/AR and few adverse effects were reported. Directions for future research are discussed.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Bailey","given":"Benjamin"},{"family":"Bryant","given":"Lucy"},{"family":"Hemsley","given":"Bronwyn"}],"citation-key":"bailey2022","container-title":"Review Journal of Autism and Developmental Disorders","container-title-short":"Rev J Autism Dev Disord","DOI":"10.1007/s40489-020-00230-x","ISSN":"2195-7185","issue":"2","issued":{"date-parts":[["2022",6,1]]},"language":"en","page":"160-183","source":"Springer Link","title":"Virtual Reality and Augmented Reality for Children, Adolescents, and Adults with Communication Disability and Neurodevelopmental Disorders: a Systematic Review","title-short":"Virtual Reality and Augmented Reality for Children, Adolescents, and Adults with Communication Disability and Neurodevelopmental Disorders","type":"article-journal","URL":"https://doi.org/10.1007/s40489-020-00230-x","volume":"9"},
  {"id":"baldwin2023","abstract":"Event cameras are an exciting, new sensor modality enabling high-speed imaging with extremely low-latency and wide dynamic range. Unfortunately, most machine learning architectures are not designed to directly handle sparse data, like that generated from event cameras. Many state-of-the-art algorithms for event cameras rely on interpolated event representations—obscuring crucial timing information, increasing the data volume, and limiting overall network performance. This paper details an event representation called Time-Ordered Recent Event (TORE) volumes. TORE volumes are designed to compactly store raw spike timing information with minimal information loss. This bio-inspired design is memory efficient, computationally fast, avoids time-blocking (i.e., fixed and predefined frame rates), and contains “local memory” from past data. The design is evaluated on a wide range of challenging tasks (e.g., event denoising, image reconstruction, classification, and human pose estimation) and is shown to dramatically improve state-of-the-art performance. TORE volumes are an easy-to-implement replacement for any algorithm currently utilizing event representations.","accessed":{"date-parts":[["2024",6,11]]},"author":[{"family":"Baldwin","given":"R. Wes"},{"family":"Liu","given":"Ruixu"},{"family":"Almatrafi","given":"Mohammed"},{"family":"Asari","given":"Vijayan"},{"family":"Hirakawa","given":"Keigo"}],"citation-key":"baldwin2023","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","DOI":"10.1109/TPAMI.2022.3172212","ISSN":"1939-3539","issue":"2","issued":{"date-parts":[["2023",2]]},"page":"2519-2532","source":"IEEE Xplore","title":"Time-Ordered Recent Event (TORE) Volumes for Event Cameras","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9767613","volume":"45"},
  {"id":"baltrusaitis2024","abstract":"OpenFace – a state-of-the art tool intended for facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.","accessed":{"date-parts":[["2024",9,16]]},"author":[{"family":"Baltrusaitis","given":"Tadas"}],"citation-key":"baltrusaitis2024","genre":"MATLAB","issued":{"date-parts":[["2024",9,14]]},"original-date":{"date-parts":[["2016",3,5]]},"source":"GitHub","title":"TadasBaltrusaitis/OpenFace","type":"software","URL":"https://github.com/TadasBaltrusaitis/OpenFace"},
  {"id":"bargiela2016","abstract":"We used Framework Analysis to investigate the female autism phenotype and its impact upon the under-recognition of autism spectrum conditions (ASC) in girls and women. Fourteen women with ASC (aged 22–30 years) diagnosed in late adolescence or adulthood gave in-depth accounts of: ‘pretending to be normal’; of how their gender led various professionals to miss their ASC; and of conflicts between ASC and a traditional feminine identity. Experiences of sexual abuse were widespread in this sample, partially reflecting specific vulnerabilities from being a female with undiagnosed ASC. Training would improve teachers’ and clinicians’ recognition of ASC in females, so that timely identification can mitigate risks and promote wellbeing of girls and women on the autism spectrum.","accessed":{"date-parts":[["2024",6,19]]},"author":[{"family":"Bargiela","given":"Sarah"},{"family":"Steward","given":"Robyn"},{"family":"Mandy","given":"William"}],"citation-key":"bargiela2016","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-016-2872-8","ISSN":"1573-3432","issue":"10","issued":{"date-parts":[["2016",10,1]]},"language":"en","page":"3281-3294","source":"Springer Link","title":"The Experiences of Late-diagnosed Women with Autism Spectrum Conditions: An Investigation of the Female Autism Phenotype","title-short":"The Experiences of Late-diagnosed Women with Autism Spectrum Conditions","type":"article-journal","URL":"https://doi.org/10.1007/s10803-016-2872-8","volume":"46"},
  {"id":"barthel2024","abstract":"NeRF-based 3D-aware Generative Adversarial Networks (GANs) like EG3D or GIRAFFE have shown very high rendering quality under large representational variety. However, rendering with Neural Radiance Fields poses challenges for 3D applications: First, the significant computational demands of NeRF rendering preclude its use on low-power devices, such as mobiles and VR/AR headsets. Second, implicit representations based on neural networks are difficult to incorporate into explicit 3D scenes, such as VR environments or video games. 3D Gaussian Splatting (3DGS) overcomes these limitations by providing an explicit 3D representation that can be rendered efficiently at high frame rates. In this work, we present a novel approach that combines the high rendering quality of NeRF-based 3D-aware GANs with the flexibility and computational advantages of 3DGS. By training a decoder that maps implicit NeRF representations to explicit 3D Gaussian Splatting attributes, we can integrate the representational diversity and quality of 3D GANs into the ecosystem of 3D Gaussian Splatting for the first time. Additionally, our approach allows for a high resolution GAN inversion and real-time GAN editing with 3D Gaussian Splatting scenes. Project page: florian-barthel.github.io/gaussian_decoder","accessed":{"date-parts":[["2024",12,12]]},"author":[{"family":"Barthel","given":"Florian"},{"family":"Beckmann","given":"Arian"},{"family":"Morgenstern","given":"Wieland"},{"family":"Hilsmann","given":"Anna"},{"family":"Eisert","given":"Peter"}],"citation-key":"barthel2024","container-title":"2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","DOI":"10.1109/CVPRW63382.2024.00794","issued":{"date-parts":[["2024",6,17]]},"page":"7963-7972","source":"arXiv.org","title":"Gaussian Splatting Decoder for 3D-aware Generative Adversarial Networks","type":"paper-conference","URL":"http://arxiv.org/abs/2404.10625"},
  {"id":"barua2022","abstract":"Mental disorders (MDs) with onset in childhood or adolescence include neurodevelopmental disorders (NDDs) (intellectual disability and specific learning disabilities, such as dyslexia, attention deficit disorder (ADHD), and autism spectrum disorders (ASD)), as well as a broad range of mental health disorders (MHDs), including anxiety, depressive, stress-related and psychotic disorders. There is a high co-morbidity of NDDs and MHDs. Globally, there have been dramatic increases in the diagnosis of childhood-onset mental disorders, with a 2- to 3-fold rise in prevalence for several MHDs in the US over the past 20 years. Depending on the type of MD, children often grapple with social and communication deficits and difficulties adapting to changes in their environment, which can impact their ability to learn effectively. To improve outcomes for children, it is important to provide timely and effective interventions. This review summarises the range and effectiveness of AI-assisted tools, developed using machine learning models, which have been applied to address learning challenges in students with a range of NDDs. Our review summarises the evidence that AI tools can be successfully used to improve social interaction and supportive education. Based on the limitations of existing AI tools, we provide recommendations for the development of future AI tools with a focus on providing personalised learning for individuals with NDDs.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Barua","given":"Prabal Datta"},{"family":"Vicnesh","given":"Jahmunah"},{"family":"Gururajan","given":"Raj"},{"family":"Oh","given":"Shu Lih"},{"family":"Palmer","given":"Elizabeth"},{"family":"Azizan","given":"Muhammad Mokhzaini"},{"family":"Kadri","given":"Nahrizul Adib"},{"family":"Acharya","given":"U. Rajendra"}],"citation-key":"barua2022","container-title":"International Journal of Environmental Research and Public Health","DOI":"10.3390/ijerph19031192","ISSN":"1660-4601","issue":"3","issued":{"date-parts":[["2022",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"3","page":"1192","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Artificial Intelligence Enabled Personalised Assistive Tools to Enhance Education of Children with Neurodevelopmental Disorders—A Review","type":"article-journal","URL":"https://www.mdpi.com/1660-4601/19/3/1192","volume":"19"},
  {"id":"basdogan2024","abstract":"In virtual/augmented/mixed reality (VR/AR/MR) applications, rendering soft virtual objects using a hand-held haptic device is challenging due to the anatomical restrictions of the hand and the ungrounded nature of the design, which affect the selection of actuators and sensors and hence limit the resolution and range of forces displayed by the device. We developed a cable-driven haptic device for rendering the net forces involved in grasping and squeezing 3D virtual compliant (soft) objects being held between the index finger and thumb only. Using the proposed device, we investigate the perception of soft objects in virtual environments. We show that the range of object stiffness that can be effectively conveyed to a user in virtual environments (VEs) can be significantly expanded by controlling the relationship between the visual and haptic cues. We propose that a single variable, named Apparent Stiffness Difference, can predict the pattern of human stiffness perception under manipulated conflict, which can be used for rendering a range of soft objects in VEs larger than what is achievable by a haptic device alone due to its physical limits.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Basdogan","given":"Cagatay"},{"family":"Ataseven","given":"Berke"},{"family":"Srinivasan","given":"Mandayam A."}],"citation-key":"basdogan2024","container-title":"IEEE Transactions on Haptics","DOI":"10.1109/TOH.2023.3322189","ISSN":"2329-4051","issue":"2","issued":{"date-parts":[["2024",4]]},"page":"227-236","source":"IEEE Xplore","title":"Perception of Soft Objects in Virtual Environments Under Conflicting Visual and Haptic Cues","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/10272716","volume":"17"},
  {"id":"bast2023","abstract":"Attenuated social attention is a key marker of autism spectrum disorder (ASD). Recent neuroimaging findings also emphasize an altered processing of sensory salience in ASD. The locus coeruleus–norepinephrine system (LC-NE) has been established as a modulator of this sensory salience processing (SSP). We tested the hypothesis that altered LC-NE functioning contributes to different SSP and results in diverging social attention in ASD.","accessed":{"date-parts":[["2025",2,18]]},"author":[{"family":"Bast","given":"Nico"},{"family":"Mason","given":"Luke"},{"family":"Ecker","given":"Christine"},{"family":"Baumeister","given":"Sarah"},{"family":"Banaschewski","given":"Tobias"},{"family":"Jones","given":"Emily J. H."},{"family":"Murphy","given":"Declan G. M."},{"family":"Buitelaar","given":"Jan K."},{"family":"Loth","given":"Eva"},{"family":"Pandina","given":"Gahan"},{"family":"Ahmad","given":"Jumana"},{"family":"Ambrosino","given":"Sara"},{"family":"Auyeung","given":"Bonnie"},{"family":"Banaschewski","given":"Tobias"},{"family":"Baron-Cohen","given":"Simon"},{"family":"Bast","given":"Nico"},{"family":"Baumeister","given":"Sarah"},{"family":"Beckmann","given":"Christian F."},{"family":"Bölte","given":"Sven"},{"family":"Bourgeron","given":"Thomas"},{"family":"Bours","given":"Carsten"},{"family":"Brammer","given":"Michael"},{"family":"Brandeis","given":"Daniel"},{"family":"Brogna","given":"Claudia"},{"family":"Bruijn","given":"Yvette","non-dropping-particle":"de"},{"family":"Buitelaar","given":"Jan K."},{"family":"Chakrabarti","given":"Bhismadev"},{"family":"Charman","given":"Tony"},{"family":"Cornelissen","given":"Ineke"},{"family":"Crawley","given":"Daisy"},{"family":"Dell’Acqua","given":"Flavio"},{"family":"Dumas","given":"Guillaume"},{"family":"Durston","given":"Sarah"},{"family":"Ecker","given":"Christine"},{"family":"Faulkner","given":"Jessica"},{"family":"Frouin","given":"Vincent"},{"family":"Garcés","given":"Pilar"},{"family":"Goyard","given":"David"},{"family":"Ham","given":"Lindsay"},{"family":"Hayward","given":"Hannah"},{"family":"Hipp","given":"Joerg"},{"family":"Holt","given":"Rosemary"},{"family":"Johnson","given":"Mark"},{"family":"Jones","given":"Emily J. H."},{"family":"Kundu","given":"Prantik"},{"family":"Lai","given":"Meng-Chuan"},{"family":"D’ardhuy","given":"Xavier Liogier"},{"family":"Lombardo","given":"Michael V."},{"family":"Loth","given":"Eva"},{"family":"Lythgoe","given":"David J."},{"family":"Mandl","given":"René"},{"family":"Marquand","given":"Andre"},{"family":"Mason","given":"Luke"},{"family":"Mennes","given":"Maarten"},{"family":"Meyer-Lindenberg","given":"Andreas"},{"family":"Moessnang","given":"Carolin"},{"family":"Murphy","given":"Declan G. M."},{"family":"Oakley","given":"Bethany"},{"family":"O’Dwyer","given":"Laurence"},{"family":"Oldehinkel","given":"Marianne"},{"family":"Oranje","given":"Bob"},{"family":"Pandina","given":"Gahan"},{"family":"Persico","given":"Antonio M."},{"family":"Ruggeri","given":"Barbara"},{"family":"Ruigrok","given":"Amber"},{"family":"Sabet","given":"Jessica"},{"family":"Sacco","given":"Roberto"},{"family":"Cáceres","given":"Antonia San José"},{"family":"Simonoff","given":"Emily"},{"family":"Spooren","given":"Will"},{"family":"Tillmann","given":"Julian"},{"family":"Toro","given":"Roberto"},{"family":"Tost","given":"Heike"},{"family":"Waldman","given":"Jack"},{"family":"Williams","given":"Steve C. R."},{"family":"Wooldridge","given":"Caroline"},{"family":"Zwiers","given":"Marcel P."},{"family":"Freitag","given":"Christine M."},{"literal":"the EU-AIMS LEAP Group"}],"citation-key":"bast2023","container-title":"Molecular Autism","container-title-short":"Molecular Autism","DOI":"10.1186/s13229-023-00537-6","ISSN":"2040-2392","issue":"1","issued":{"date-parts":[["2023",2,9]]},"page":"5","source":"BioMed Central","title":"Sensory salience processing moderates attenuated gazes on faces in autism spectrum disorder: a case–control study","title-short":"Sensory salience processing moderates attenuated gazes on faces in autism spectrum disorder","type":"article-journal","URL":"https://doi.org/10.1186/s13229-023-00537-6","volume":"14"},
  {"id":"bauer2021","abstract":"Extended Reality (XR) has already been used to support interventions for autistic children, but mainly focuses on training the socioemotional abilities of children requiring low support. To also consider children requiring substantial support, this paper examines how to design XR applications in order to expand clinic-based sensory strategies that are often used by practitioners to put them in a secure state, and how to maximize the acceptability of such applications among practitioners. To that respect, a \"Mixed Reality platform for Engagement and Relaxation of Autistic children\" was designed and developed, which allows to add audio, visual and haptic individualized or common stimuli onto reality. A first Augmented Reality freeplay use case called Magic Bubbles was created based on interviews with stakeholders and on a collaboration with three practitioners. A preliminary study with eleven practitioners confirmed its well-being potential and acceptability. XR design guidelines are finally derived.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Bauer","given":"Valentin"},{"family":"Bouchara","given":"Tifanie"},{"family":"Bourdot","given":"Patrick"}],"citation-key":"bauer2021","container-title":"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","DOI":"10.1109/ISMAR-Adjunct54149.2021.00059","event-title":"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","issued":{"date-parts":[["2021",10]]},"page":"254-259","source":"IEEE Xplore","title":"Designing an Extended Reality Application to Expand Clinic-Based Sensory Strategies for Autistic Children Requiring Substantial Support: Participation of Practitioners","title-short":"Designing an Extended Reality Application to Expand Clinic-Based Sensory Strategies for Autistic Children Requiring Substantial Support","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9585792"},
  {"id":"becattini2022","abstract":"With the establishment of Industry 4.0, machines are now required to interact with workers. By observing biometrics they can assess if humans are authorized, or mentally and physically fit to work. Understanding body language, makes human–machine interaction more natural, secure, and effective. Nonetheless, traditional cameras have limitations; low frame rate and dynamic range hinder a comprehensive human understanding. This poses a challenge, since faces undergo frequent instantaneous microexpressions. In addition, this is privacy-sensitive information that must be protected. We propose to model expressions with event cameras, bio-inspired vision sensors that have found application within the Industry 4.0 scope. They capture motion at millisecond rates and work under challenging conditions like low illumination and highly dynamic scenes. Such cameras are also privacy-preserving, making them extremely interesting for industry. We show that using event cameras, we can understand human reactions by only observing facial expressions. Comparison with red-green-blue (RGB)-based modeling demonstrates improved effectiveness and robustness.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Becattini","given":"Federico"},{"family":"Palai","given":"Federico"},{"family":"Bimbo","given":"Alberto Del"}],"citation-key":"becattini2022","container-title":"IEEE Transactions on Industrial Informatics","DOI":"10.1109/TII.2022.3195063","ISSN":"1941-0050","issue":"12","issued":{"date-parts":[["2022",12]]},"page":"9112-9121","source":"IEEE Xplore","title":"Understanding Human Reactions Looking at Facial Microexpressions With an Event Camera","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/9844855","volume":"18"},
  {"id":"becattini2022a","abstract":"With the establishment of Industry 4.0, machines are now required to interact with workers. By observing biometrics they can assess if humans are authorized, or mentally and physically fit to work. Understanding body language, makes human–machine interaction more natural, secure, and effective. Nonetheless, traditional cameras have limitations; low frame rate and dynamic range hinder a comprehensive human understanding. This poses a challenge, since faces undergo frequent instantaneous microexpressions. In addition, this is privacy-sensitive information that must be protected. We propose to model expressions with event cameras, bio-inspired vision sensors that have found application within the Industry 4.0 scope. They capture motion at millisecond rates and work under challenging conditions like low illumination and highly dynamic scenes. Such cameras are also privacy-preserving, making them extremely interesting for industry. We show that using event cameras, we can understand human reactions by only observing facial expressions. Comparison with red-green-blue (RGB)-based modeling demonstrates improved effectiveness and robustness.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Becattini","given":"Federico"},{"family":"Palai","given":"Federico"},{"family":"Bimbo","given":"Alberto Del"}],"citation-key":"becattini2022a","container-title":"IEEE Transactions on Industrial Informatics","DOI":"10.1109/TII.2022.3195063","ISSN":"1941-0050","issue":"12","issued":{"date-parts":[["2022",12]]},"page":"9112-9121","source":"IEEE Xplore","title":"Understanding Human Reactions Looking at Facial Microexpressions With an Event Camera","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/9844855","volume":"18"},
  {"id":"bell2024","abstract":"Virtual reality (VR) has emerged as a promising tool in the field of mental health. Central to this technology are immersive environments, which enable exposure to highly controlled virtual experiences that feel real. In this Review, we elaborate on the active elements of immersive experiences and how VR-based treatments work. We provide an overview of developments in the use of VR to treat mental health conditions (anxiety, psychotic symptoms, post-traumatic stress, eating disorders, depression and stress management) with a focus on the core mechanisms that drive effective interventions. Artificial intelligence, biofeedback and gamification are emerging areas of development, and we discuss how they might enhance the accessibility, engagement and effectiveness of psychological treatments. Conducting rigorous studies with user-centred designs in diverse populations is a key research priority. As the use of VR in mental health continues to evolve, addressing ethical and implementation considerations is critical for ensuring ongoing treatment improvements.","accessed":{"date-parts":[["2024",8,19]]},"author":[{"family":"Bell","given":"Imogen H."},{"family":"Pot-Kolder","given":"Roos"},{"family":"Rizzo","given":"Albert"},{"family":"Rus-Calafell","given":"Mar"},{"family":"Cardi","given":"Valentina"},{"family":"Cella","given":"Matteo"},{"family":"Ward","given":"Thomas"},{"family":"Riches","given":"Simon"},{"family":"Reinoso","given":"Martin"},{"family":"Thompson","given":"Andrew"},{"family":"Alvarez-Jimenez","given":"Mario"},{"family":"Valmaggia","given":"Lucia"}],"citation-key":"bell2024","container-title":"Nature Reviews Psychology","container-title-short":"Nat Rev Psychol","DOI":"10.1038/s44159-024-00334-9","ISSN":"2731-0574","issue":"8","issued":{"date-parts":[["2024",8]]},"language":"en","license":"2024 Springer Nature America, Inc.","page":"552-567","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Advances in the use of virtual reality to treat mental health conditions","type":"article-journal","URL":"https://www.nature.com/articles/s44159-024-00334-9","volume":"3"},
  {"id":"ben2022","abstract":"Unlike the conventional facial expressions, micro-expressions are involuntary and transient facial expressions capable of revealing the genuine emotions that people attempt to hide. Therefore, they can provide important information in a broad range of applications such as lie detection, criminal detection, etc. Since micro-expressions are transient and of low intensity, however, their detection and recognition is difficult and relies heavily on expert experiences. Due to its intrinsic particularity and complexity, video-based micro-expression analysis is attractive but challenging, and has recently become an active area of research. Although there have been numerous developments in this area, thus far there has been no comprehensive survey that provides researchers with a systematic overview of these developments with a unified evaluation. Accordingly, in this survey paper, we first highlight the key differences between macro- and micro-expressions, then use these differences to guide our research survey of video-based micro-expression analysis in a cascaded structure, encompassing the neuropsychological basis, datasets, features, spotting algorithms, recognition algorithms, applications and evaluation of state-of-the-art approaches. For each aspect, the basic techniques, advanced developments and major challenges are addressed and discussed. Furthermore, after considering the limitations of existing micro-expression datasets, we present and release a new dataset — called micro-and-macro expression warehouse (MMEW) — containing more video samples and more labeled emotion types. We then perform a unified comparison of representative methods on CAS(ME)^22 for spotting, and on MMEW and SAMM for recognition, respectively. Finally, some potential future research directions are explored and outlined.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Ben","given":"Xianye"},{"family":"Ren","given":"Yi"},{"family":"Zhang","given":"Junping"},{"family":"Wang","given":"Su-Jing"},{"family":"Kpalma","given":"Kidiyo"},{"family":"Meng","given":"Weixiao"},{"family":"Liu","given":"Yong-Jin"}],"citation-key":"ben2022","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","DOI":"10.1109/TPAMI.2021.3067464","ISSN":"1939-3539","issue":"9","issued":{"date-parts":[["2022",9]]},"page":"5826-5846","source":"IEEE Xplore","title":"Video-Based Facial Micro-Expression Analysis: A Survey of Datasets, Features and Algorithms","title-short":"Video-Based Facial Micro-Expression Analysis","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9382112","volume":"44"},
  {"id":"bensch2024","abstract":"This paper describes the capabilities and potential of the intelligent personal assistant (IPA) CORE (Checklist Organizer for Research and Exploration), designed to support astronauts during procedures onboard the International Space Station (ISS), the Lunar Gateway station, and beyond. We reflect on the importance of a reliable and flexible assistant capable of offline operation and highlight the usefulness of audiovisual interaction using augmented reality elements to intuitively display checklist information. We argue that current approaches to the design of IPAs in space operations fall short of meeting these criteria. Therefore, we propose CORE as an assistant that combines Knowledge Graphs (KGs), Retrieval-Augmented Generation (RAG) for a Generative Pre-Trained Transformer (GPT), and Augmented Reality (AR) elements to ensure an intuitive understanding of procedure steps, reliability, offline availability, and flexibility in terms of response style and procedure updates.","accessed":{"date-parts":[["2025",1,10]]},"author":[{"family":"Bensch","given":"Oliver"},{"family":"Bensch","given":"Leonie"},{"family":"Nilsson","given":"Tommy"},{"family":"Saling","given":"Florian"},{"family":"Bewer","given":"Bernd"},{"family":"Jentzsch","given":"Sophie"},{"family":"Hecking","given":"Tobias"},{"family":"Kutz","given":"J. Nathan"}],"citation-key":"bensch2024","DOI":"10.48550/arXiv.2409.14206","issued":{"date-parts":[["2024",9,21]]},"number":"arXiv:2409.14206","publisher":"arXiv","source":"arXiv.org","title":"AI Assistants for Spaceflight Procedures: Combining Generative Pre-Trained Transformer and Retrieval-Augmented Generation on Knowledge Graphs With Augmented Reality Cues","title-short":"AI Assistants for Spaceflight Procedures","type":"article","URL":"http://arxiv.org/abs/2409.14206"},
  {"id":"berenguer2020","abstract":"Autistic Spectrum Disorder (ASD) is a neurodevelopmental condition characterized by persistent difficulties in communication and social interaction along with a restriction in interests and the presence of repetitive behaviors. The development and use of augmented reality technology for autism has increased in recent years. However, little is known about the impact of these virtual reality technologies on clinical health symptoms. The aim of this systematic review was to investigate the impact of augmented reality through social, cognitive, and behavioral domains in children and adolescents with autism. This study is the first contribution that has carried out an evidence-based systematic review including relevant science databases about the effectiveness of augmented reality-based intervention in ASD. The initial search identified a total of 387 records. After the exclusion of papers that are not research studies and are duplicated articles and after screening the abstract and full text, 20 articles were selected for analysis. The studies examined suggest promising findings about the effectiveness of augmented reality-based treatments for the promotion, support, and protection of health and wellbeing in children and adolescents with autism. Finally, possible directions for future work are discussed.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Berenguer","given":"Carmen"},{"family":"Baixauli","given":"Inmaculada"},{"family":"Gómez","given":"Soledad"},{"family":"Andrés","given":"María de El Puig"},{"family":"De Stasio","given":"Simona"}],"citation-key":"berenguer2020","container-title":"International Journal of Environmental Research and Public Health","container-title-short":"Int J Environ Res Public Health","DOI":"10.3390/ijerph17176143","ISSN":"1661-7827","issue":"17","issued":{"date-parts":[["2020",9]]},"page":"6143","PMCID":"PMC7504463","PMID":"32847074","source":"PubMed Central","title":"Exploring the Impact of Augmented Reality in Children and Adolescents with Autism Spectrum Disorder: A Systematic Review","title-short":"Exploring the Impact of Augmented Reality in Children and Adolescents with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7504463/","volume":"17"},
  {"id":"berlincioni2023","abstract":"Recently, event cameras have shown large applicability in several computer vision fields especially concerning tasks that require high temporal resolution. In this work, we investigate the usage of such kind of data for emotion recognition by presenting NEFER, a dataset for Neuromorphic Event-based Facial Expression Recognition. NEFER is composed of paired RGB and event videos representing human faces labeled with the respective emotions and also annotated with face bounding boxes and facial landmarks. We detail the data acquisition process as well as providing a baseline method for RGB and event data. The collected data captures subtle micro-expressions, which are hard to spot with RGB data, yet emerge in the event domain. We report a double recognition accuracy for the event-based approach, proving the effectiveness of a neuromorphic approach for analyzing fast and hardly detectable expressions and the emotions they conceal.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Berlincioni","given":"Lorenzo"},{"family":"Cultrera","given":"Luca"},{"family":"Albisani","given":"Chiara"},{"family":"Cresti","given":"Lisa"},{"family":"Leonardo","given":"Andrea"},{"family":"Picchioni","given":"Sara"},{"family":"Becattini","given":"Federico"},{"family":"Del Bimbo","given":"Alberto"}],"citation-key":"berlincioni2023","container-title":"2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","DOI":"10.1109/CVPRW59228.2023.00432","event-title":"2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","ISSN":"2160-7516","issued":{"date-parts":[["2023",6]]},"page":"4109-4119","source":"IEEE Xplore","title":"Neuromorphic Event-based Facial Expression Recognition","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10208675"},
  {"id":"bey2024","abstract":"Objective, quantitative measures of caregiver-child interaction during play are needed to complement caregiver or examiner ratings for clinical assessment and tracking intervention responses. In this exploratory study, we examined the feasibility of using automated video tracking, Noldus EthoVision XT, to measure 159 2-to-7-year-old autistic children’s patterns of movement during play-based, caregiver-child interactions and examined their associations with standard clinical measures and human observational coding of caregiver-child joint engagement. Results revealed that autistic children who exhibited higher durations and velocity of movement were, on average, younger, had lower cognitive abilities, greater autism-related features, spent less time attending to the caregiver, and showed lower levels of joint engagement. After adjusting for age and nonverbal cognitive abilities, we found that children who remained in close proximity to their caregiver were more likely to engage in joint engagement that required support from the caregiver. These findings suggest that video tracking offers promise as a scalable, quantitative, and relevant measure of autism-related behaviors.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Bey","given":"Alexandra L."},{"family":"Sabatos-DeVito","given":"Maura"},{"family":"Carpenter","given":"Kimberly L.H."},{"family":"Franz","given":"Lauren"},{"family":"Howard","given":"Jill"},{"family":"Vermeer","given":"Saritha"},{"family":"Simmons","given":"Ryan"},{"family":"Troy","given":"Jesse D."},{"family":"Dawson","given":"Geraldine"}],"citation-key":"bey2024","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-06107-2","ISSN":"1573-3432","issue":"10","issued":{"date-parts":[["2024",10,1]]},"language":"en","page":"3706-3718","source":"Springer Link","title":"Automated Video Tracking of Autistic Children’s Movement During Caregiver-Child Interaction: An Exploratory Study","title-short":"Automated Video Tracking of Autistic Children’s Movement During Caregiver-Child Interaction","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-06107-2","volume":"54"},
  {"id":"bhatti2024","abstract":"Remote working has brought forward many challenges for employees as the phenomenon is still new for most employees across the globe. Some of these challenges may be addressed by the recent adoption of digital technologies by organizations. In this vein, our study explores the impact of digital platform capability on the creativity of employees through the mediating mechanism of explicit and tacit knowledge sharing.,The data were gathered from higher education institutes (HEIs) in a developing country, Pakistan which recently saw a major disruption during the Covid-19 pandemic. The proposed hypotheses were tested through Structural Equational Modeling (SEM) and the results confirmed our hypotheses.,The findings confirmed that the digital platform capabilities impact both tacit and explicit knowledge sharing among these remote employees. Likewise, the results also supported the mediating role of both explicit and tacit knowledge sharing on the creativity of these remote workers.,Our results are significant as they confirm the impact of digitalization on remote workers’ creativity predisposition. We thus advance the academic debate on the problems of knowledge sharing in remote working. We prove that digital capabilities outweigh the challenges created due to new forms of work driven by the pandemic. It further highlights the important areas to focus on while planning human resource policies in the new normal.","accessed":{"date-parts":[["2025",3,5]]},"archive_location":"world","author":[{"family":"Bhatti","given":"Sabeen Hussain"},{"family":"Gavurova","given":"Beata"},{"family":"Ahmed","given":"Adeel"},{"family":"Marcone","given":"Maria Rosaria"},{"family":"Santoro","given":"Gabriele"}],"citation-key":"bhatti2024","container-title":"Journal of Knowledge Management","DOI":"10.1108/JKM-08-2023-0682","ISSN":"1367-3270","issue":"8","issued":{"date-parts":[["2024",5,6]]},"language":"en","page":"2433-2459","publisher":"Emerald Publishing Limited","source":"www.emerald.com","title":"The impact of digital platforms on the creativity of remote workers through the mediating role of explicit and tacit knowledge sharing","type":"article-journal","URL":"https://www.emerald.com/insight/content/doi/10.1108/jkm-08-2023-0682/full/html","volume":"28"},
  {"id":"birawo2022","abstract":"Eye tracking is a technology aimed at understanding the direction of the human gaze. Event detection is a process of detecting and classifying eye movements that are divided into several types. Nowadays, event detection is almost exclusively done by applying a detection algorithm to the raw recorded eye-tracking data. However, due to the lack of a standard procedure for how to perform evaluations, evaluating and comparing various detection algorithms in eye-tracking signals is very challenging. In this paper, we used data from a high-speed eye-tracker SMI HiSpeed 1250 system and compared event detection performance. The evaluation focused on fixations, saccades and post-saccadic oscillation classification. It used sample-by-sample comparisons to compare the algorithms and inter-agreement between algorithms and human coders. The impact of varying threshold values on threshold-based algorithms was examined and the optimum threshold values were determined. This evaluation differed from previous evaluations by using the same dataset to evaluate the event detection algorithms and human coders. We evaluated and compared the different algorithms from threshold-based, machine learning-based and deep learning event detection algorithms. The evaluation results show that all methods perform well for fixation and saccade detection; however, there are substantial differences in classification results. Generally, CNN (Convolutional Neural Network) and RF (Random Forest) algorithms outperform threshold-based methods.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Birawo","given":"Birtukan"},{"family":"Kasprowski","given":"Pawel"}],"citation-key":"birawo2022","container-title":"Sensors","DOI":"10.3390/s22228810","ISSN":"1424-8220","issue":"22","issued":{"date-parts":[["2022",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"22","page":"8810","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Review and Evaluation of Eye Movement Event Detection Algorithms","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/22/22/8810","volume":"22"},
  {"id":"black2024","abstract":"Introduction Advancing research and support for neurologically diverse populations requires novel data harmonisation methods that are capable of aligning with contemporary approaches to understanding health and disability.\nObjectives We present the International Classification of Functioning, Disability and Health (ICF) as a conceptual framework to support harmonisation of mental health data and present a proof of principle within the Risk and Resilience in Developmental Diversity and Mental Health (R2D2-MH) consortium.\nMethod 138 measures from various mental health datasets were linked to the ICF following the WHO’s established linking rules.\nFindings Findings support the notion that the ICF can assist in the harmonisation of mental health data. The high level of shared ICF codes provides indications of where items may be readily harmonised to develop datasets that may align more readily with contemporary approaches to understanding health and disability. Although the linking process necessarily entails an element of subjectivity, the application of established rules can increase rigour and transparency of the harmonisation process.\nConclusions We present the first steps towards data harmonisation in mental health that is compatible with contemporary approaches in psychiatry, being more capable of capturing diversity and aligning with more transdiagnostic and neurodiversity-affirmative ways of understanding data.\nClinical implications Our findings show promise, but future work is needed to address quantitative harmonisation. Similarly, issues related to the traditionally ‘pathophysiological’ frameworks that existing datasets are often embedded in can hinder the full potential of harmonisation based on the ICF.","accessed":{"date-parts":[["2025",2,18]]},"author":[{"family":"Black","given":"Melissa H."},{"family":"Buitelaar","given":"Jan"},{"family":"Charman","given":"Tony"},{"family":"Ecker","given":"Christine"},{"family":"Gallagher","given":"Louise"},{"family":"Hens","given":"Kristien"},{"family":"Jones","given":"Emily"},{"family":"Murphy","given":"Declan"},{"family":"Sadaka","given":"Yair"},{"family":"Schaer","given":"Marie"},{"family":"Pourcain","given":"Beate St"},{"family":"Wolke","given":"Dieter"},{"family":"Bonnot-Briey","given":"Stef"},{"family":"Bourgeron","given":"Thomas"},{"family":"Bölte","given":"Sven"}],"citation-key":"black2024","container-title":"BMJ Ment Health","DOI":"10.1136/bmjment-2024-301283","ISSN":"2755-9734","issue":"1","issued":{"date-parts":[["2024",11,1]]},"language":"en","license":"© Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY. Published by BMJ.. https://creativecommons.org/licenses/by/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution 4.0 Unported (CC BY 4.0) license, which permits others to copy, redistribute, remix, transform and build upon this work for any purpose, provided the original work is properly cited, a link to the licence is given, and indication of whether changes were made. See: https://creativecommons.org/licenses/by/4.0/.","PMID":"39608798","publisher":"Royal College of Psychiatrists","section":"Statistics","source":"mentalhealth.bmj.com","title":"Conceptual framework for data harmonisation in mental health using the International Classification of Functioning, Disability and Health: an example with the R2D2-MH consortium","title-short":"Conceptual framework for data harmonisation in mental health using the International Classification of Functioning, Disability and Health","type":"article-journal","URL":"https://mentalhealth.bmj.com/content/27/1/e301283","volume":"27"},
  {"id":"black2025","abstract":"A considerable number of screening and diagnostic tools for autism exist, but variability in these measures presents challenges to data harmonization and the comparability and generalizability of findings. At the same time, there is a movement away from autism symptomatology to stances that capture heterogeneity and appreciate diversity. The International Classification of Functioning, Disability and Health (ICF) provides a classification system that can support content harmonization of different screening and diagnostic tools for autism while enabling the translation of diagnostic information into functioning.","accessed":{"date-parts":[["2025",2,20]]},"author":[{"family":"Black","given":"Melissa H."},{"family":"Remnélius","given":"Karl Lundin"},{"family":"Alehagen","given":"Lovisa"},{"family":"Bourgeron","given":"Thomas"},{"family":"Bölte","given":"Sven"}],"citation-key":"black2025","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-06204-2","ISSN":"1573-3432","issue":"1","issued":{"date-parts":[["2025",1,1]]},"language":"en","page":"114-129","source":"Springer Link","title":"From Symptomatology to Functioning - Applying the ICF to Autism Measures to Facilitate Neurodiversity-Affirmative Data Harmonization","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-06204-2","volume":"55"},
  {"id":"bohus2021","abstract":"We introduce Platform for Situated Intelligence, an open-source framework created to support the rapid development and study of multimodal, integrative-AI systems. The framework provides infrastructure for sensing, fusing, and making inferences from temporal streams of data across different modalities, a set of tools that enable visualization and debugging, and an ecosystem of components that encapsulate a variety of perception and processing technologies. These assets jointly provide the means for rapidly constructing and refining multimodal, integrative-AI systems, while retaining the efficiency and performance characteristics required for deployment in open-world settings.","accessed":{"date-parts":[["2024",8,29]]},"author":[{"family":"Bohus","given":"Dan"},{"family":"Andrist","given":"Sean"},{"family":"Feniello","given":"Ashley"},{"family":"Saw","given":"Nick"},{"family":"Jalobeanu","given":"Mihai"},{"family":"Sweeney","given":"Patrick"},{"family":"Thompson","given":"Anne Loomis"},{"family":"Horvitz","given":"Eric"}],"citation-key":"bohus2021","DOI":"10.48550/arXiv.2103.15975","issued":{"date-parts":[["2021",3,29]]},"number":"arXiv:2103.15975","publisher":"arXiv","source":"arXiv.org","title":"Platform for Situated Intelligence","type":"article","URL":"http://arxiv.org/abs/2103.15975"},
  {"id":"bolte2011","abstract":"Research indicates that autism is the extreme end of a continuously distributed trait. The Social Responsiveness Scale (SRS) and the Social and Communication Disorders Checklist (SCDC) aim to assess autistic traits. The objective of this study was to compare their clinical validity. The SRS showed sensitivities of .74 to .80 and specificities of .69 to 1.00 for autism. Sensitivities were .85 to .90 and specificities .28 to.82 for the SCDC. Correlations with the ADI-R, ADOS and SCQ were higher for the SRS than for the SCDC. The SCDC seems superior to the SRS to screen for unspecific social and communicative deficits including autism. The SRS appears more suitable than the SCDC in clinical settings and for specific autism screening.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Bölte","given":"Sven"},{"family":"Westerwald","given":"Eva"},{"family":"Holtmann","given":"Martin"},{"family":"Freitag","given":"Christine"},{"family":"Poustka","given":"Fritz"}],"citation-key":"bolte2011","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-010-1024-9","ISSN":"1573-3432","issue":"1","issued":{"date-parts":[["2011",1,1]]},"language":"en","page":"66-72","source":"Springer Link","title":"Autistic Traits and Autism Spectrum Disorders: The Clinical Validity of Two Measures Presuming a Continuum of Social Communication Skills","title-short":"Autistic Traits and Autism Spectrum Disorders","type":"article-journal","URL":"https://doi.org/10.1007/s10803-010-1024-9","volume":"41"},
  {"id":"bolte2025","abstract":"Social cognition is a crucial capacity for social functioning. The last decades have seen a plethora of social cognition research in neurodevelopmental conditions, foremost autism and, to a lesser extent, ADHD, both characterized by social challenges. Social cognition is a multifaceted construct comprising various overlapping subdomains, such as Theory of Mind/mentalizing, emotion recognition, and social perception. Mechanisms underpinning social cognition are complex, including implicit and explicit, cognitive and affective, and hyper- and hypo-social information processing. This review explores the intricacies of social cognition in the context of autism and ADHD. Research indicates altered performance on social cognition tests in autism, compared to neurotypical groups, with social cognition alterations having a small but robust effect on the defining features of autism. The nature of such alterations in autism appears primarily in relation to implicit processing. ADHD groups show intermediate social cognition performance, appearing to be influenced by executive function difficulties. Social cognition varies with intellectual and verbal abilities and seems to improve with age in autism and ADHD. Social skills interventions in autism, and stimulant medication in ADHD have been shown to improve social cognition test performance, while mentalizing training effects in autism are less conclusive. A limitation of the field is that social cognition constructs and tests are not well delineated. Further, most research has been embedded in a nativist approach rather than a constructivist approach. The former has been questioned for ignoring environmental contributions, especially the dimension of mutual miscommunication between neurodivergent and neurotypical individuals.","accessed":{"date-parts":[["2025",2,20]]},"author":[{"family":"Bölte","given":"Sven"}],"citation-key":"bolte2025","container-title":"Neuroscience & Biobehavioral Reviews","container-title-short":"Neuroscience & Biobehavioral Reviews","DOI":"10.1016/j.neubiorev.2025.106022","ISSN":"0149-7634","issued":{"date-parts":[["2025",2,1]]},"page":"106022","source":"ScienceDirect","title":"Social cognition in autism and ADHD","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0149763425000223","volume":"169"},
  {"id":"bouchouras2025","abstract":"This paper presents a systematic review of the emerging applications of artificial intelligence (AI), Internet of Things (IoT), and sensor-based technologies in the diagnosis of autism spectrum disorder (ASD). The integration of these technologies has led to promising advances in identifying unique behavioral, physiological, and neuroanatomical markers associated with ASD. Through an examination of recent studies, we explore how technologies such as wearable sensors, eye-tracking systems, virtual reality environments, neuroimaging, and microbiome analysis contribute to a holistic approach to ASD diagnostics. The analysis reveals how these technologies facilitate non-invasive, real-time assessments across diverse settings, enhancing both diagnostic accuracy and accessibility. The findings underscore the transformative potential of AI, IoT, and sensor-based driven tools in providing personalized and continuous ASD detection, advocating for data-driven approaches that extend beyond traditional methodologies. Ultimately, this review emphasizes the role of technology in improving ASD diagnostic processes, paving the way for targeted and individualized assessments.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Bouchouras","given":"Georgios"},{"family":"Kotis","given":"Konstantinos"}],"citation-key":"bouchouras2025","container-title":"Algorithms","DOI":"10.3390/a18010034","ISSN":"1999-4893","issue":"1","issued":{"date-parts":[["2025",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"1","page":"34","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Integrating Artificial Intelligence, Internet of Things, and Sensor-Based Technologies: A Systematic Review of Methodologies in Autism Spectrum Disorder Detection","title-short":"Integrating Artificial Intelligence, Internet of Things, and Sensor-Based Technologies","type":"article-journal","URL":"https://www.mdpi.com/1999-4893/18/1/34","volume":"18"},
  {"id":"bourson2024","abstract":"The existence of a female phenotype profile in autistic spectrum disorder is one of the current hypotheses to explain the diagnostic discrepancy between men and women. In this context, an international literature review was carried out to evidence and describe the characteristics of restricted interests found in girls with autistic spectrum disorder. A documentary search was conducted on PubMed and a systematic literature review was carried out based on the PRISMA methodology. We selected studies with a population of boys and girls diagnosed as autistic according to the DSM-IV or the DSM-5, in which quantitative and descriptive comparisons of restricted interests, according to gender were carried out. Nineteen studies were found to be relevant. Fifteen enabled a refining of the characteristics of restricted interests among females: fewer restricted interests were identified in comparison with boys, and the autistic girls’ interests seem to be closer to those of neurotypical girls than to those of autistic boys, which thus led to more complex screening. Age and Intelligence quotient seem to be two factors that trigger variations in restricted interests differently according to gender. Representations among professionals also have an impact on diagnoses among girls. For future research, one of the perspectives could be a comparison between girls with autism and neurotypical girls to limit gender bias. The present results contribute to potentially extending knowledge of a female phenotypical profile in autism and show the need to improve the general population’s awareness, to improve health professionals’ training and possibly to revise the diagnostic tools.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Bourson","given":"Lise"},{"family":"Prevost","given":"Camille"}],"citation-key":"bourson2024","container-title":"European Child & Adolescent Psychiatry","container-title-short":"Eur Child Adolesc Psychiatry","DOI":"10.1007/s00787-022-01998-5","ISSN":"1435-165X","issue":"4","issued":{"date-parts":[["2024",4,1]]},"language":"en","page":"987-1004","source":"Springer Link","title":"Characteristics of restricted interests in girls with ASD compared to boys: a systematic review of the literature","title-short":"Characteristics of restricted interests in girls with ASD compared to boys","type":"article-journal","URL":"https://doi.org/10.1007/s00787-022-01998-5","volume":"33"},
  {"id":"bouzbib2022","abstract":"Haptic feedback has become crucial to enhance the user experiences in Virtual Reality (VR). This justifies the sudden burst of novel haptic solutions proposed these past years in the HCI community. This article is a survey of Virtual Reality interactions, relying on haptic devices. We propose two dimensions to describe and compare the current haptic solutions: their degree of physicality, as well as their degree of actuation. We depict a compromise between the user and the designer, highlighting how the range of required or proposed stimulation in VR is opposed to the haptic interfaces flexibility and their deployment in real-life use-cases. This paper (1) outlines the variety of haptic solutions and provides a novel perspective for analysing their associated interactions, (2) highlights the limits of the current evaluation criteria regarding these interactions, and finally (3) reflects the interaction, operation and conception potentials of ”encountered-type of haptic devices”.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Bouzbib","given":"Elodie"},{"family":"Bailly","given":"Gilles"},{"family":"Haliyo","given":"Sinan"},{"family":"Frey","given":"Pascal"}],"citation-key":"bouzbib2022","collection-title":"IHM '21","container-title":"Proceedings of the 32nd Conference on l'Interaction Homme-Machine","DOI":"10.1145/3450522.3451323","event-place":"New York, NY, USA","ISBN":"978-1-4503-8362-2","issued":{"date-parts":[["2022",1,13]]},"page":"1–16","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"“Can I Touch This?”: Survey of Virtual Reality Interactions via Haptic Solutions: Revue de Littérature des Interactions en Réalité Virtuelle par le biais de Solutions Haptiques","title-short":"“Can I Touch This?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3450522.3451323"},
  {"id":"brepohl2023","abstract":"Technological innovations have enabled physiotherapy to apply new possibilities in the rehabilitation of patients, especially in the use of virtual reality (VR). Although the literature provides several examples of VR applications, benefits, and barriers in physiotherapy, scholars obverse that there is still a dearth of studies that discuss and unify the results and impacts of this emerging technology on patients and physiotherapists. Thus, the aim of this study is to analyze the use of VR within physiotherapy and its impact on rehabilitation outcomes. A systematic literature review based on the PRISMA protocol was applied in this study. After searching on databases, such as Bireme, Cochrane, Emerald, Google Scholar, Lilacs, Medline, PEDro, PubMed, and Science Direct, we found 152 articles that complied with our protocol. The initial period of the search was open up to June 2020. Our results show an increased use of VR in neurology with elderly patients. We have identified underlying barriers (issues implementing VR, lack of protocols, and influence of patients) and benefits (effectiveness of treatment, motor development, and patient independence) of VR implementation. Finally, our study provides implications for VR in physiotherapy: a prominent increase in the use of VR in rehabilitation; value co-creation: interactions between patients and physiotherapists are crucial in the use of VR in physiotherapy; barriers related to technology, applicability, and the patient’s influence need to be overcome for VR practice to be used as a ‘business as usual’ modality in physiotherapy; the benefits of VR treatment can overcome the barriers faced by its use in rehabilitation.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Brepohl","given":"Polyana Cristina Alves"},{"family":"Leite","given":"Higor"}],"citation-key":"brepohl2023","container-title":"Virtual Reality","container-title-short":"Virtual Reality","DOI":"10.1007/s10055-022-00654-2","ISSN":"1434-9957","issue":"1","issued":{"date-parts":[["2023",3,1]]},"language":"en","page":"71-95","source":"Springer Link","title":"Virtual reality applied to physiotherapy: a review of current knowledge","title-short":"Virtual reality applied to physiotherapy","type":"article-journal","URL":"https://doi.org/10.1007/s10055-022-00654-2","volume":"27"},
  {"id":"brunetti2022","abstract":"In this survey paper, we focus on smart interactive technologies and providing a picture of the current state of the art, exploring the way new discoveries and recent technologies changed workers’ operations and activities on the factory floor. We focus in particular on the Industry 4.0 and 5.0 visions, wherein smart interactive technologies can bring benefits to the intelligent behavior machines can expose in a human-centric AI perspective. We consider smart technologies wherein the intelligence may be in and/or behind the user interfaces, and for both groups we try to highlight the importance of designing them with a human-centric approach, framed in the smart factory context. We review relevant work in the field with the aim of highlighting the pros and cons of each technology and its adoption in the industry. Furthermore, we try to collect guidelines for the human-centric integration of smart interactive technologies in the smart factory. In this wa y, we hope to provide the future designers and adopters of such technologies with concrete help in choosing among different options and implementing them in a user-centric manner. To this aim, surveyed works have been also classified based on the supported task(s) and production process phases/activities: access to knowledge, logistics, maintenance, planning, production, security, workers’ wellbeing, and warehousing.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Brunetti","given":"Davide"},{"family":"Gena","given":"Cristina"},{"family":"Vernero","given":"Fabiana"}],"citation-key":"brunetti2022","container-title":"Applied Sciences","DOI":"10.3390/app12167965","ISSN":"2076-3417","issue":"16","issued":{"date-parts":[["2022",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"16","page":"7965","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Smart Interactive Technologies in the Human-Centric Factory 5.0: A Survey","title-short":"Smart Interactive Technologies in the Human-Centric Factory 5.0","type":"article-journal","URL":"https://www.mdpi.com/2076-3417/12/16/7965","volume":"12"},
  {"id":"bucci2024","abstract":"Autism (ASD), attention deficit/hyperactive disorders (ADHD), and dyslexia (DYS) are defined in DSM-5 as neurodevelopment disorders (NDDs) and several times they are comorbid disorders. Several studies have reported poor oculomotor performance and postural instability in this population of children confirming the cerebellar deficit hypothesis in subjects with NDDs. In this paper, we summarized oculomotor and posture findings collected over the last decade, in order to find out biomarkers for children with NDDs; To our knowledge, such issue has never been studied before; the present study is designed to fill this gap. Oculomotor parameters (the number of express and anticipate saccades, the number of saccades during fixations and the number of catch-up saccades during pursuits), and the postural instability index measured in two viewing conditions (eyes open and eyes closed, on stable and unstable platform) were compared in four groups of 40 children. One-way ANOVA reported significant differences in oculomotor parameters between the three groups of children with NDDs with respect to a typical developing (TD) children group: the number of anticipatory saccades was found to be significantly (p < 0.001) higher in the ADHD (32.4 ± 5.9) and the DYS (34.7 ± 5.3) groups; the occurrence of express saccades and catch-up saccades was significantly (p < 0.001) more frequent in the ASD group (26.8 ± 1.8 and 55.3 ± 4.2, respectively); unwanted saccades occurred more in ADHD (8.5 ± 0.7) and DYS (7.3 ± 1.1) groups. In the fixation with distractor task, the number of saccades was significantly (p < 0.001) higher in the ADHD group (36.3 ± 3.9). In addition, the mixed repeated ANOVA on the postural instability index (measured under eyes open and eyes closed conditions, on stable and unstable platforms) reported a significant difference (p < 0.001) in such parameters in children with NDDs (ASD: 2.8 ± 0.6; DYS: 2.6 ± 0.5; ADHD: 2.7 ± 0.5, respectively) with respect to the TD group (1.9 ± 0.3); however, the postural instability index failed to distinguish between the different neurodevelopmental deficits. Such abnormal oculomotor and postural performances are in line with poor cerebellar activity; oculomotor measures only could be used as phenotype biomarkers for children with NDDs. Finally, these results could be useful to clinicians looking to develop specific oculomotor and/or postural training programs based on visual fixations and body stability exercises designed to reinforce motor ability in children with NDDs.","accessed":{"date-parts":[["2025",2,9]]},"author":[{"family":"Bucci","given":"Maria Pia"},{"family":"Moscoso","given":"Ana"},{"family":"Acquaviva","given":"Eric"},{"family":"Humeau","given":"Elise"},{"family":"Delorme","given":"Richard"}],"citation-key":"bucci2024","container-title":"Journal of Pediatric Neuropsychology","container-title-short":"J Pediatr Neuropsychol","DOI":"10.1007/s40817-024-00172-w","ISSN":"2199-2673","issue":"3","issued":{"date-parts":[["2024",9,1]]},"language":"en","page":"231-242","source":"Springer Link","title":"Eye Movements and Postural Control in Children; Biomarkers of Neurodevelopmental Disorders: Evidences Toward New Forms of Therapeutic Intervention?","title-short":"Eye Movements and Postural Control in Children; Biomarkers of Neurodevelopmental Disorders","type":"article-journal","URL":"https://doi.org/10.1007/s40817-024-00172-w","volume":"10"},
  {"id":"bui2022","abstract":"BACKGROUND: Chatbots have been increasingly considered for applications in the health care field. However, it remains unclear how a chatbot can assist users with complex health needs, such as parents of children with neurodevelopmental disorders (NDDs) who need ongoing support. Often, this population must deal with complex and overwhelming health information, which can make parents less likely to use a software that may be very helpful. An approach to enhance user engagement is incorporating game elements in nongame contexts, known as gamification. Gamification needs to be tailored to users; however, there has been no previous assessment of gamification use in chatbots for NDDs.\nOBJECTIVE: We sought to examine how gamification elements are perceived and whether their implementation in chatbots will be well received among parents of children with NDDs. We have discussed some elements in detail as the initial step of the project.\nMETHODS: We performed a narrative literature review of gamification elements, specifically those used in health and education. Among the elements identified in the literature, our health and social science experts in NDDs prioritized five elements for in-depth discussion: goal setting, customization, rewards, social networking, and unlockable content. We used a qualitative approach, which included focus groups and interviews with parents of children with NDDs (N=21), to assess the acceptability of the potential implementation of these elements in an NDD-focused chatbot. Parents were asked about their opinions on the 5 elements and to rate them. Video and audio recordings were transcribed and summarized for emerging themes, using deductive and inductive thematic approaches.\nRESULTS: From the responses obtained from 21 participants, we identified three main themes: parents of children with NDDs were familiar with and had positive experiences with gamification; a specific element (goal setting) was important to all parents, whereas others (customization, rewards, and unlockable content) received mixed opinions; and the social networking element received positive feedback, but concerns about information accuracy were raised.\nCONCLUSIONS: We showed for the first time that parents of children with NDDs support gamification use in a chatbot for NDDs. Our study illustrates the need for a user-centered design in the medical domain and provides a foundation for researchers interested in developing chatbots for populations that are medically vulnerable. Future studies exploring wide range of gamification elements with large number of potential users are needed to understand the impact of gamification elements in enhancing knowledge mobilization.","author":[{"family":"Bui","given":"Truong An"},{"family":"Pohl","given":"Megan"},{"family":"Rosenfelt","given":"Cory"},{"family":"Ogourtsova","given":"Tatiana"},{"family":"Yousef","given":"Mahdieh"},{"family":"Whitlock","given":"Kerri"},{"family":"Majnemer","given":"Annette"},{"family":"Nicholas","given":"David"},{"family":"Demmans Epp","given":"Carrie"},{"family":"Zaiane","given":"Osmar"},{"family":"Bolduc","given":"François V."}],"citation-key":"bui2022","container-title":"JMIR human factors","container-title-short":"JMIR Hum Factors","DOI":"10.2196/31991","ISSN":"2292-9495","issue":"3","issued":{"date-parts":[["2022",8,19]]},"language":"eng","page":"e31991","PMCID":"PMC9440405","PMID":"35984679","source":"PubMed","title":"Identifying Potential Gamification Elements for A New Chatbot for Families With Neurodevelopmental Disorders: User-Centered Design Approach","title-short":"Identifying Potential Gamification Elements for A New Chatbot for Families With Neurodevelopmental Disorders","type":"article-journal","volume":"9"},
  {"id":"bustos-valenzuela2022","abstract":"Background\nFacial expression of emotion is fundamental to human social interactions. Attention to relevant cues in ADHD and ASD patients are believed to underlie difficulties in recognizing emotions. Cognitive vergence eye movements during gaze fixation have a role in attention. Here we evaluate a possible role of cognitive vergence in facial emotion recognition.\nMethods\nWe recorded eye vergence from children with ADHD (n ​= ​27), ASD (n ​= ​18) or ADHD&ASD (n ​= ​15) and from neurotypical (NT; n ​= ​31) children during a facial emotion recognition task.\nResults\nVergence responses to relevant stimuli were stronger than those to distractor stimuli. ADHD and ADHD&ASD children showed shorter gaze fixation duration and weaker cognitive vergence responses to the eye regions of the face stimuli compared to neurotypically developing children. In contrast, gaze behavior and vergence responses of ASD children resembled that of neurotypically developing children.\nConclusion\nThese results provide evidence for the idea that impaired recognition of facial expression of emotion is a problem of attending the relevant cues to adequately recognize facial expressions. As ASD patients resembled that of NT, cognitive vergence represents an etiological difference between ADHD and ASD.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Bustos-Valenzuela","given":"Patricia"},{"family":"Romeo","given":"August"},{"family":"Boxhoorn","given":"Sara"},{"family":"Helfer","given":"Bartosz"},{"family":"Freitag","given":"Christine M."},{"family":"Asherson","given":"Phil"},{"family":"Supèr","given":"Hans"}],"citation-key":"bustos-valenzuela2022","container-title":"Psychiatry Research Communications","container-title-short":"Psychiatry Research Communications","DOI":"10.1016/j.psycom.2022.100045","ISSN":"2772-5987","issue":"2","issued":{"date-parts":[["2022",6,1]]},"page":"100045","source":"ScienceDirect","title":"Atypical cognitive vergence responses in children with attention deficit hyperactivity disorder but not with autism spectrum disorder in a facial emotion recognition task","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S2772598722000265","volume":"2"},
  {"id":"cabibihan2016","abstract":"This paper reviews the state-of-the-art in sensing technologies that are relevant for Autism Spectrum Disorder (ASD) screening and therapy. This disorder is characterized by difficulties in social communication, social interactions, and repetitive behaviors. It is diagnosed during the first three years of life. Early and intensive interventions have been shown to improve the developmental trajectory of the affected children. The earlier the diagnosis, the sooner the intervention therapy can begin, thus, making early diagnosis an important research goal. Technological innovations have tremendous potential to assist with early diagnosis and improve intervention programs. The need for careful and methodological evaluation of such emerging technologies becomes important in order to assist not only the therapists and clinicians in their selection of suitable tools, but to also guide the developers of the technologies in improving hardware and software. In this paper, we survey the literatures on sensing technologies for ASD and we categorize them into eye trackers, movement trackers, electrodermal activity monitors, tactile sensors, vocal prosody and speech detectors, and sleep quality assessment devices. We assess their effectiveness and study their limitations. We also examine the challenges faced by this growing field that need to be addressed before these technologies can perform up to their theoretical potential.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Cabibihan","given":"John-John"},{"family":"Javed","given":"Hifza"},{"family":"Aldosari","given":"Mohammed"},{"family":"Frazier","given":"Thomas W"},{"family":"Elbashir","given":"Haitham"}],"citation-key":"cabibihan2016","container-title":"Sensors (Basel, Switzerland)","container-title-short":"Sensors (Basel)","DOI":"10.3390/s17010046","ISSN":"1424-8220","issue":"1","issued":{"date-parts":[["2016",12,1]]},"language":"eng","license":"cc by","page":"E46","PMCID":"PMC5298619","PMID":"28036004","source":"Europe PMC","title":"Sensing Technologies for Autism Spectrum Disorder Screening and Intervention","type":"article-journal","URL":"https://europepmc.org/articles/PMC5298619","volume":"17"},
  {"id":"calabrese2019","abstract":"Human pose estimation has dramatically improved thanks to the continuous developments in deep learning. However, marker-free human pose estimation based on standard frame-based cameras is still slow and power hungry for real-time feedback interaction because of the huge number of operations necessary for large Convolutional Neural Network (CNN) inference. Event-based cameras such as the Dynamic Vision Sensor (DVS) quickly output sparse moving-edge information. Their sparse and rapid output is ideal for driving low-latency CNNs, thus potentially allowing real-time interaction for human pose estimators. Although the application of CNNs to standard frame-based cameras for human pose estimation is well established, their application to event-based cameras is still under study. This paper proposes a novel benchmark dataset of human body movements, the Dynamic Vision Sensor Human Pose dataset (DHP19). It consists of recordings from 4 synchronized 346x260 pixel DVS cameras, for a set of 33 movements with 17 subjects. DHP19 also includes a 3D pose estimation model that achieves an average 3D pose estimation error of about 8 cm, despite the sparse and reduced input data from the DVS.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Calabrese","given":"Enrico"},{"family":"Taverni","given":"Gemma"},{"family":"Easthope","given":"Christopher Awai"},{"family":"Skriabine","given":"Sophie"},{"family":"Corradi","given":"Federico"},{"family":"Longinotti","given":"Luca"},{"family":"Eng","given":"Kynan"},{"family":"Delbruck","given":"Tobi"}],"citation-key":"calabrese2019","container-title":"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","DOI":"10.1109/CVPRW.2019.00217","event-title":"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","ISSN":"2160-7516","issued":{"date-parts":[["2019",6]]},"page":"1695-1704","source":"IEEE Xplore","title":"DHP19: Dynamic Vision Sensor 3D Human Pose Dataset","title-short":"DHP19","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9025364"},
  {"id":"carta2020","abstract":"<p>Comorbidity between attention deficit/hyperactivity disorder (ADHD) and autism spectrum disorder (ASD) is a frequently reported condition. However, the clinical overlaps between the two disorders are not well characterized. The Child Behavior Checklist (CBCL) is a well-documented measure of emotional and behavioral problems in children and adolescents. The aim of the present study was to evaluate whether CBCL scales were able to detect psychopathological comorbidities as well as emotional and behavioral profiles across three groups of children with ASD, ADHD, and with the co-occurrence of both disorders. The results show that around 30% of participants with ASD exhibited internalizing problems, which was in line with previous findings. Co-occurrence condition showed a clinical intermediate phenotype: relative to ADHD and ASD, youths with co-occurrence of ADHD and ASD phenotype showed respectively lower (<italic>p</italic> &lt; 0.000) and higher externalizing problems (<italic>p</italic> &lt; 0.000). No differences emerged in internalizing problems (<italic>p</italic> &gt; 0.05) across groups. CBCL is a useful measure to study the psychopathological conditions as well as emotional and behavioral profiles associated with ASD, ADHD, and the co-occurrence of ADHD and ASD. The identification of psychopathological and behavioral profiles associated with ASD and ADHD is crucial to perform specific and individualized treatments. Our preliminary findings suggested the existence of an intermediate and independent phenotype between ADHD and ASD that seems to be defined by the externalizing problems. Internalizing problems do not significantly differ between the combined phenotype and the two groups.</p>","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Carta","given":"Alessandra"},{"family":"Fucà","given":"Elisa"},{"family":"Guerrera","given":"Silvia"},{"family":"Napoli","given":"Eleonora"},{"family":"Valeri","given":"Giovanni"},{"family":"Vicari","given":"Stefano"}],"citation-key":"carta2020","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2020.00861","ISSN":"1664-1078","issued":{"date-parts":[["2020",5,15]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Characterization of Clinical Manifestations in the Co-occurring Phenotype of Attention Deficit/Hyperactivity Disorder and Autism Spectrum Disorder","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.00861/full","volume":"11"},
  {"id":"cerasa2022","abstract":"Since Mark Zuckerberg’s announcement about the development of new three-dimensional virtual worlds for social communication, a great debate has been raised about the promise of such a technology. The metaverse, a term formed by combining meta and universe, could open a new era in mental health, mainly in psychological disorders, where the creation of a full-body illusion via digital avatar could promote healthcare and personal well-being. Patients affected by body dysmorphism symptoms (i.e., eating disorders), social deficits (i.e. autism) could greatly benefit from this kind of technology. However, it is not clear which advantage the metaverse would have in treating psychological disorders with respect to the well-known and effective virtual reality (VR) exposure therapy. Indeed, in the last twenty years, a plethora of studies have demonstrated the effectiveness of VR technology in reducing symptoms of pain, anxiety, stress, as well as, in improving cognitive and social skills. We hypothesize that the metaverse will offer more opportunities, such as a more complex, virtual realm where sensory inputs, and recurrent feedback, mediated by a “federation” of multiple technologies - e.g., artificial intelligence, tangible interfaces, Internet of Things and blockchain, can be reinterpreted for facilitating a new kind of communication overcoming self-body representation. However, nowadays a clear starting point does not exist. For this reason, it is worth defining a theoretical framework for applying this new kind of technology in a social neuroscience context for developing accurate solutions to mental health in the future.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Cerasa","given":"Antonio"},{"family":"Gaggioli","given":"Andrea"},{"family":"Marino","given":"Flavia"},{"family":"Riva","given":"Giuseppe"},{"family":"Pioggia","given":"Giovanni"}],"citation-key":"cerasa2022","container-title":"Heliyon","container-title-short":"Heliyon","DOI":"10.1016/j.heliyon.2022.e11762","ISSN":"2405-8440","issue":"11","issued":{"date-parts":[["2022",11,1]]},"page":"e11762","source":"ScienceDirect","title":"The promise of the metaverse in mental health: the new era of MEDverse","title-short":"The promise of the metaverse in mental health","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S240584402203050X","volume":"8"},
  {"id":"cerasa2024","abstract":"We review the first pilot studies applying metaverse-related technologies in psychiatric patients and discuss the rationale for using this complex federation of technologies to treat mental diseases. Concerning previous virtual-reality applications in medical care, metaverse technologies provide the unique opportunity to define, control, and shape virtual scenarios shared by multi-users to exploit the “synchronized brains” potential exacerbated by social interactions.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Cerasa","given":"Antonio"},{"family":"Gaggioli","given":"Andrea"},{"family":"Pioggia","given":"Giovanni"},{"family":"Riva","given":"Giuseppe"}],"citation-key":"cerasa2024","container-title":"Current Psychiatry Reports","container-title-short":"Curr Psychiatry Rep","DOI":"10.1007/s11920-024-01501-8","ISSN":"1535-1645","issue":"6","issued":{"date-parts":[["2024",6,1]]},"language":"en","page":"294-303","source":"Springer Link","title":"Metaverse in Mental Health: The Beginning of a Long History","title-short":"Metaverse in Mental Health","type":"article-journal","URL":"https://doi.org/10.1007/s11920-024-01501-8","volume":"26"},
  {"id":"cerasuolo2025","abstract":"While studies examining the effectiveness of virtual reality (VR) systems in autism spectrum disorder (ASD) intervention have seen significant growth, research on their application as tools to improve assessment and diagnosis remains limited. This systematic review explores the potential of VR systems in speeding-up and enhancing the assessment process for ASD.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Cerasuolo","given":"Mariangela"},{"family":"De Marco","given":"Stefania"},{"family":"Nappo","given":"Raffaele"},{"family":"Simeoli","given":"Roberta"},{"family":"Rega","given":"Angelo"}],"citation-key":"cerasuolo2025","container-title":"Advances in Neurodevelopmental Disorders","container-title-short":"Adv Neurodev Disord","DOI":"10.1007/s41252-024-00413-1","ISSN":"2366-7540","issue":"1","issued":{"date-parts":[["2025",3,1]]},"language":"en","page":"1-22","source":"Springer Link","title":"The Potential of Virtual Reality to Improve Diagnostic Assessment by Boosting Autism Spectrum Disorder Traits: A Systematic Review","title-short":"The Potential of Virtual Reality to Improve Diagnostic Assessment by Boosting Autism Spectrum Disorder Traits","type":"article-journal","URL":"https://doi.org/10.1007/s41252-024-00413-1","volume":"9"},
  {"id":"chang2021a","abstract":"Atypical eye gaze is an early-emerging symptom of autism spectrum disorder (ASD) and holds promise for autism screening. Current eye-tracking methods are expensive and require special equipment and calibration. There is a need for scalable, feasible methods for measuring eye gaze.Using computational methods based on computer vision analysis, we evaluated whether an app deployed on an iPhone or iPad that displayed strategically designed brief movies could elicit and quantify differences in eye-gaze patterns of toddlers with ASD vs typical development.A prospective study in pediatric primary care clinics was conducted from December 2018 to March 2020, comparing toddlers with and without ASD. Caregivers of 1564 toddlers were invited to participate during a well-child visit. A total of 993 toddlers (63%) completed study measures. Enrollment criteria were aged 16 to 38 months, healthy, English- or Spanish-speaking caregiver, and toddler able to sit and view the app. Participants were screened with the Modified Checklist for Autism in Toddlers–Revised With Follow-up during routine care. Children were referred by their pediatrician for diagnostic evaluation based on results of the checklist or if the caregiver or pediatrician was concerned. Forty toddlers subsequently were diagnosed with ASD.A mobile app displayed on a smartphone or tablet.Computer vision analysis quantified eye-gaze patterns elicited by the app, which were compared between toddlers with ASD vs typical development.Mean age of the sample was 21.1 months (range, 17.1-36.9 months), and 50.6% were boys, 59.8% White individuals, 16.5% Black individuals, 23.7% other race, and 16.9% Hispanic/Latino individuals. Distinctive eye-gaze patterns were detected in toddlers with ASD, characterized by reduced gaze to social stimuli and to salient social moments during the movies, and previously unknown deficits in coordination of gaze with speech sounds. The area under the receiver operating characteristic curve discriminating ASD vs non-ASD using multiple gaze features was 0.90 (95% CI, 0.82-0.97).The app reliably measured both known and new gaze biomarkers that distinguished toddlers with ASD vs typical development. These novel results may have potential for developing scalable autism screening tools, exportable to natural settings, and enabling data sets amenable to machine learning.","accessed":{"date-parts":[["2025",2,7]]},"author":[{"family":"Chang","given":"Zhuoqing"},{"family":"Di Martino","given":"J. Matias"},{"family":"Aiello","given":"Rachel"},{"family":"Baker","given":"Jeffrey"},{"family":"Carpenter","given":"Kimberly"},{"family":"Compton","given":"Scott"},{"family":"Davis","given":"Naomi"},{"family":"Eichner","given":"Brian"},{"family":"Espinosa","given":"Steven"},{"family":"Flowers","given":"Jacqueline"},{"family":"Franz","given":"Lauren"},{"family":"Harris","given":"Adrianne"},{"family":"Howard","given":"Jill"},{"family":"Perochon","given":"Sam"},{"family":"Perrin","given":"Eliana M."},{"family":"Krishnappa Babu","given":"Pradeep Raj"},{"family":"Spanos","given":"Marina"},{"family":"Sullivan","given":"Connor"},{"family":"Walter","given":"Barbara K."},{"family":"Kollins","given":"Scott H."},{"family":"Dawson","given":"Geraldine"},{"family":"Sapiro","given":"Guillermo"}],"citation-key":"chang2021a","container-title":"JAMA Pediatrics","container-title-short":"JAMA Pediatrics","DOI":"10.1001/jamapediatrics.2021.0530","ISSN":"2168-6203","issue":"8","issued":{"date-parts":[["2021",8,1]]},"page":"827-836","source":"Silverchair","title":"Computational Methods to Measure Patterns of Gaze in Toddlers With Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1001/jamapediatrics.2021.0530","volume":"175"},
  {"id":"chantiluke2014","abstract":"Attention Deficit Hyperactivity Disorder (ADHD) and Autism Spectrum Disorder (ASD) are often comorbid and share cognitive abnormalities in temporal foresight. A key question is whether shared cognitive phenotypes are based on common or different underlying pathophysiologies and whether comorbid patients have additive neurofunctional deficits, resemble one of the disorders or have a different pathophysiology. We compared age- and IQ-matched boys with non-comorbid ADHD (18), non-comorbid ASD (15), comorbid ADHD and ASD (13) and healthy controls (18) using functional magnetic resonance imaging (fMRI) during a temporal discounting task. Only the ASD and the comorbid groups discounted delayed rewards more steeply. The fMRI data showed both shared and disorder-specific abnormalities in the three groups relative to controls in their brain-behaviour associations. The comorbid group showed both unique and more severe brain-discounting associations than controls and the non-comorbid patient groups in temporal discounting areas of ventromedial and lateral prefrontal cortex, ventral striatum and anterior cingulate, suggesting that comorbidity is neither an endophenocopy of the two pure disorders nor an additive pathology.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Chantiluke","given":"Kaylita"},{"family":"Christakou","given":"Anastasia"},{"family":"Murphy","given":"Clodagh M."},{"family":"Giampietro","given":"Vincent"},{"family":"Daly","given":"Eileen M."},{"family":"Ecker","given":"Christina"},{"family":"Brammer","given":"Michael"},{"family":"Murphy","given":"Declan G."},{"family":"Rubia","given":"Katya"}],"citation-key":"chantiluke2014","container-title":"Psychiatry Research: Neuroimaging","container-title-short":"Psychiatry Research: Neuroimaging","DOI":"10.1016/j.pscychresns.2014.04.006","ISSN":"0925-4927","issue":"2","issued":{"date-parts":[["2014",8,30]]},"page":"113-120","source":"ScienceDirect","title":"Disorder-specific functional abnormalities during temporal discounting in youth with Attention Deficit Hyperactivity Disorder (ADHD), Autism and comorbid ADHD and Autism","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0925492714000936","volume":"223"},
  {"id":"cheng2024","abstract":"Human gaze provides valuable information on human focus and intentions, making it a crucial area of research. Recently, deep learning has revolutionized appearance-based gaze estimation. However, due to the unique features of gaze estimation research, such as the unfair comparison between 2D gaze positions and 3D gaze vectors and the different pre-processing and post-processing methods, there is a lack of a definitive guideline for developing deep learning-based gaze estimation algorithms. In this paper, we present a systematic review of the appearance-based gaze estimation methods using deep learning. Firstly, we survey the existing gaze estimation algorithms along the typical gaze estimation pipeline: deep feature extraction, deep learning model design, personal calibration and platforms. Secondly, to fairly compare the performance of different approaches, we summarize the data pre-processing and post-processing methods, including face/eye detection, data rectification, 2D/3D gaze conversion and gaze origin conversion. Finally, we set up a comprehensive benchmark for deep learning-based gaze estimation. We characterize all the public datasets and provide the source code of typical gaze estimation algorithms. This paper serves not only as a reference to develop deep learning-based gaze estimation methods, but also a guideline for future gaze estimation research. The project web page can be found at https://phi-ai.buaa.edu.cn/Gazehub.","accessed":{"date-parts":[["2025",2,7]]},"author":[{"family":"Cheng","given":"Yihua"},{"family":"Wang","given":"Haofei"},{"family":"Bao","given":"Yiwei"},{"family":"Lu","given":"Feng"}],"citation-key":"cheng2024","DOI":"10.48550/arXiv.2104.12668","issued":{"date-parts":[["2024",4,24]]},"number":"arXiv:2104.12668","publisher":"arXiv","source":"arXiv.org","title":"Appearance-based Gaze Estimation With Deep Learning: A Review and Benchmark","title-short":"Appearance-based Gaze Estimation With Deep Learning","type":"article","URL":"http://arxiv.org/abs/2104.12668"},
  {"id":"chetcuti2024","abstract":"We tested the potential for Gazefinder eye-tracking to support early autism identification, including feasible use with infants, and preliminary concurrent validity of trial-level gaze data against clinical assessment scores. We embedded the ~ 2-min ‘Scene 1S4’ protocol within a comprehensive clinical assessment for 54 consecutively-referred, clinically-indicated infants (prematurity-corrected age 9–14 months). Alongside % tracking rate as a broad indicator of feasible assessment/data capture, we report infant gaze data to pre-specified regions of interest (ROI) across four trial types and associations with scores on established clinical/behavioural tools. Most infants tolerated Gazefinder eye-tracking well, returning high overall % tracking rate. As a group, infants directed more gaze towards social vs. non-social (or more vs. less socially-salient) ROIs within trials. Behavioural autism features were correlated with increased gaze towards non-social/geometry (vs. social/people) scenes. No associations were found for gaze directed to ROIs within other stimulus types. Notably, there were no associations between developmental/cognitive ability or adaptive behaviour with gaze towards any ROI. Gazefinder assessment seems highly feasible with clinically-indicated infants, and the people vs. geometry stimuli show concurrent predictive validity for behavioural autism features. Aggregating data across the ~ 2-min autism identification protocol might plausibly offer greater utility than stimulus-level analysis alone.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Chetcuti","given":"Lacey"},{"family":"Varcin","given":"Kandice J."},{"family":"Boutrus","given":"Maryam"},{"family":"Smith","given":"Jodie"},{"family":"Bent","given":"Catherine A."},{"family":"Whitehouse","given":"Andrew J. O."},{"family":"Hudry","given":"Kristelle"}],"citation-key":"chetcuti2024","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-024-55643-z","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2024",3,1]]},"language":"en","license":"2024 The Author(s)","page":"5117","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Feasibility of a 2-minute eye-tracking protocol to support the early identification of autism","type":"article-journal","URL":"https://www.nature.com/articles/s41598-024-55643-z","volume":"14"},
  {"id":"chicchigiglioli2017","abstract":"<p>Virtual reality (VR) technology represents a novel and powerful tool for behavioral research in psychological assessment. VR provides simulated experiences able to create the sensation of undergoing real situations. Users become active participants in the virtual environment seeing, hearing, feeling, and actuating as if they were in the real world. Currently, the most psychological VR applications concern the treatment of various mental disorders but not the assessment, that it is mainly based on paper and pencil tests. The observation of behaviors is costly, labor-intensive, and it is hard to create social situations in laboratory settings, even if the observation of actual behaviors could be particularly informative. In this framework, social stressful experiences can activate various behaviors of attachment for a significant person that can help to control and soothe them to promote individual’s well-being. Social support seeking, physical proximity, and positive and negative behaviors represent the main attachment behaviors that people can carry out during experiences of distress. We proposed VR as a novel integrating approach to measure real attachment behaviors. The first studies on attachment behavioral system by VR showed the potentiality of this approach. To improve the assessment during the VR experience, we proposed virtual stealth assessment (VSA) as a new method. VSA could represent a valid and novel technique to measure various psychological attributes in real-time during the virtual experience. The possible use of this method in psychology could be to generate a more complete, exhaustive, and accurate individual’s psychological evaluation.</p>","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Chicchi Giglioli","given":"Irene Alice"},{"family":"Pravettoni","given":"Gabriella"},{"family":"Sutil Martín","given":"Dolores Lucia"},{"family":"Parra","given":"Elena"},{"family":"Raya","given":"Mariano A."}],"citation-key":"chicchigiglioli2017","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2017.00959","ISSN":"1664-1078","issued":{"date-parts":[["2017",6,28]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"A Novel Integrating Virtual Reality Approach for the Assessment of the Attachment Behavioral System","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2017.00959/full","volume":"8"},
  {"id":"chien2023","abstract":"The design goals of recently developed serious games are to improve attention, affective recognition, and social interactions among individuals with autism. However, most previous studies on serious games used behavioral questionnaires to evaluate their effectiveness. The cognitive assessment of individuals with autism after behavioral intervention or drug treatment has become important because it provides promising biomarkers to assess improvement after cognitive intervention. In this study, we developed a game-based social interaction platform incorporating an eye-tracking system for children and preadolescents with autism. Three modules (focusing on gaze following, facial emotion recognition, and social interaction skills) are included in the platform; participants with autism learn these according to their cognitive abilities. The eye-tracking results showed decreased fixation durations when autistic children looked at positive emotional expressions and focused on multiple targets. Prolonged saccade durations and shorter fixation times for social-related facial emotion expressions were also found in preadolescents and teenagers with autism. Our findings suggest that these atypical gaze patterns are reliable biomarkers for evaluating the social and cognitive functions of autistic individuals while playing serious games. The proposed platform’s game-based modules and the findings regarding aberrant gaze patterns in autistic individuals demonstrate the possibility of evaluating cognitive functions and intervention effectiveness by using eye-tracking signals in a serious game or real-life environment.","accessed":{"date-parts":[["2025",2,4]]},"author":[{"family":"Chien","given":"Yi-Ling"},{"family":"Lee","given":"Chia-Hsin"},{"family":"Chiu","given":"Yen-Nan"},{"family":"Tsai","given":"Wen-Che"},{"family":"Min","given":"Yuan-Che"},{"family":"Lin","given":"Yang-Min"},{"family":"Wong","given":"Jui-Shen"},{"family":"Tseng","given":"Yi-Li"}],"citation-key":"chien2023","container-title":"IEEE Transactions on Neural Systems and Rehabilitation Engineering","DOI":"10.1109/TNSRE.2022.3232369","ISSN":"1558-0210","issued":{"date-parts":[["2023"]]},"page":"749-758","source":"IEEE Xplore","title":"Game-Based Social Interaction Platform for Cognitive Assessment of Autism Using Eye Tracking","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/10000269","volume":"31"},
  {"id":"chinski2022","abstract":"During rhinoplasty consultations, surgeons typically create a computer simulation of the expected result. An artificial intelligence model (AIM) can learn a surgeon's style and criteria and generate the simulation automatically. The objective of this study is to determine if an AIM is capable of imitating a surgeon's criteria to generate simulated images of an aesthetic rhinoplasty surgery. This is a cross-sectional survey study of resident and specialist doctors in otolaryngology conducted in the month of November 2019 during a rhinoplasty conference. Sequential images of rhinoplasty simulations created by a surgeon and by an AIM were shown at random. Participants used a seven-point Likert scale to evaluate their level of agreement with the simulation images they were shown, with 1 indicating total disagreement and 7 total agreement. Ninety-seven of 122 doctors agreed to participate in the survey. The median level of agreement between the participant and the surgeon was 6 (interquartile range or IQR 5-7); between the participant and the AIM it was 5 (IQR 4-6), p-value < 0.0001. The evaluators were in total or partial agreement with the results of the AIM's simulation 68.4% of the time (95% confidence interval or CI 64.9-71.7). They were in total or partial agreement with the surgeon's simulation 77.3% of the time (95% CI 74.2-80.3). An AIM can emulate a surgeon's aesthetic criteria to generate a computer-simulated image of rhinoplasty. This can allow patients to have a realistic approximation of the possible results of a rhinoplasty ahead of an in-person consultation. The level of evidence of the study is 4.","author":[{"family":"Chinski","given":"Hernan"},{"family":"Lerch","given":"Ricardo"},{"family":"Tournour","given":"Damián"},{"family":"Chinski","given":"Luis"},{"family":"Caruso","given":"Diego"}],"citation-key":"chinski2022","container-title":"Facial plastic surgery: FPS","container-title-short":"Facial Plast Surg","DOI":"10.1055/s-0041-1729911","ISSN":"1098-8793","issue":"2","issued":{"date-parts":[["2022",4]]},"language":"eng","page":"201-206","PMID":"34051703","source":"PubMed","title":"An Artificial Intelligence Tool for Image Simulation in Rhinoplasty","type":"article-journal","volume":"38"},
  {"id":"chita-tegmark2016","abstract":"Determining whether social attention is reduced in Autism Spectrum Disorder (ASD) and what factors influence social attention is important to our theoretical understanding of developmental trajectories of ASD and to designing targeted interventions for ASD. This meta-analysis examines data from 38 articles that used eye-tracking methods to compare individuals with ASD and TD controls. In this paper, the impact of eight factors on the size of the effect for the difference in social attention between these two groups are evaluated: age, non-verbal IQ matching, verbal IQ matching, motion, social content, ecological validity, audio input and attention bids. Results show that individuals with ASD spend less time attending to social stimuli than typically developing (TD) controls, with a mean effect size of 0.55. Social attention in ASD was most impacted when stimuli had a high social content (showed more than one person). This meta-analysis provides an opportunity to survey the eye-tracking research on social attention in ASD and to outline potential future research directions, more specifically research of social attention in the context of stimuli with high social content.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Chita-Tegmark","given":"Meia"}],"citation-key":"chita-tegmark2016","container-title":"Research in Developmental Disabilities","container-title-short":"Research in Developmental Disabilities","DOI":"10.1016/j.ridd.2015.10.011","ISSN":"0891-4222","issued":{"date-parts":[["2016",1,1]]},"page":"79-93","source":"ScienceDirect","title":"Social attention in ASD: A review and meta-analysis of eye-tracking studies","title-short":"Social attention in ASD","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0891422215001821","volume":"48"},
  {"id":"cilia2022","abstract":"Semantic Scholar extracted view of \"Eye-tracking Dataset to Support the Research on Autism Spectrum Disorder\" by Federica Cilia et al.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Cilia","given":"Federica"},{"family":"Carette","given":"Romuald"},{"family":"Elbattah","given":"Mahmoud"},{"family":"Guérin","given":"Jean-Luc"},{"family":"Dequen","given":"Gilles"}],"citation-key":"cilia2022","container-title":"Proceedings of the 1st Workshop on Scarce Data in Artificial Intelligence for Healthcare","DOI":"10.5220/0011540900003523","event-place":"Vienna, Austria","ISBN":"9789897586293","issued":{"date-parts":[["2022"]]},"page":"59-64","publisher":"SCITEPRESS - Science and Technology Publications","publisher-place":"Vienna, Austria","source":"Semantic Scholar","title":"Eye-tracking Dataset to Support the Research on Autism Spectrum Disorder:","title-short":"Eye-tracking Dataset to Support the Research on Autism Spectrum Disorder","type":"article-journal","URL":"https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0011540900003523"},
  {"id":"clemente2024","abstract":"Musculoskeletal conditions affect millions of people globally; however, conventional treatments pose challenges concerning price, accessibility, and convenience. Many telerehabilitation solutions offer an engaging alternative but rely on complex hardware for body tracking. This work explores the feasibility of a model for 3D Human Pose Estimation (HPE) from monocular 2D videos (MediaPipe Pose) in a physiotherapy context, by comparing its performance to ground truth measurements. MediaPipe Pose was investigated in eight exercises typically performed in musculoskeletal physiotherapy sessions, where the Range of Motion (ROM) of the human joints was the evaluated parameter. This model showed the best performance for shoulder abduction, shoulder press, elbow flexion, and squat exercises. Results have shown a MAPE ranging between 14.9% and 25.0%, Pearson’s coefficient ranging between 0.963 and 0.996, and cosine similarity ranging between 0.987 and 0.999. Some exercises (e.g., seated knee extension and shoulder flexion) posed challenges due to unusual poses, occlusions, and depth ambiguities, possibly related to a lack of training data. This study demonstrates the potential of HPE from monocular 2D videos, as a markerless, affordable, and accessible solution for musculoskeletal telerehabilitation approaches. Future work should focus on exploring variations of the 3D HPE models trained on physiotherapy-related datasets, such as the Fit3D dataset, and post-preprocessing techniques to enhance the model’s performance.","accessed":{"date-parts":[["2024",11,13]]},"author":[{"family":"Clemente","given":"Carolina"},{"family":"Chambel","given":"Gonçalo"},{"family":"Silva","given":"Diogo C. F."},{"family":"Montes","given":"António Mesquita"},{"family":"Pinto","given":"Joana F."},{"family":"Silva","given":"Hugo Plácido","dropping-particle":"da"}],"citation-key":"clemente2024","container-title":"Sensors","DOI":"10.3390/s24010206","ISSN":"1424-8220","issue":"1","issued":{"date-parts":[["2024",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"1","page":"206","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Feasibility of 3D Body Tracking from Monocular 2D Video Feeds in Musculoskeletal Telerehabilitation","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/24/1/206","volume":"24"},
  {"id":"coffman2023","abstract":"Early behavioral markers for autism include differences in social attention and orienting in response to one's name when called, and differences in body movements and motor abilities. More efficient, scalable, objective, and reliable measures of these behaviors could improve early screening for autism. This study evaluated whether objective and quantitative measures of autism-related behaviors elicited from an app (SenseToKnow) administered on a smartphone or tablet and measured via computer vision analysis (CVA) are correlated with standardized caregiver-report and clinician administered measures of autism-related behaviors and cognitive, language, and motor abilities. This is an essential step in establishing the concurrent validity of a digital phenotyping approach. In a sample of 485 toddlers, 43 of whom were diagnosed with autism, we found that CVA-based gaze variables related to social attention were associated with the level of autism-related behaviors. Two language-related behaviors measured via the app, attention to people during a conversation and responding to one's name being called, were associated with children's language skills. Finally, performance during a bubble popping game was associated with fine motor skills. These findings provide initial support for the concurrent validity of the SenseToKnow app and its potential utility in identifying clinical profiles associated with autism. Future research is needed to determine whether the app can be used as an autism screening tool, can reliably stratify autism-related behaviors, and measure changes in autism-related behaviors over time.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Coffman","given":"Marika"},{"family":"Di Martino","given":"J. Matias"},{"family":"Aiello","given":"Rachel"},{"family":"Carpenter","given":"Kimberly L. H."},{"family":"Chang","given":"Zhuoqing"},{"family":"Compton","given":"Scott"},{"family":"Eichner","given":"Brian"},{"family":"Espinosa","given":"Steve"},{"family":"Flowers","given":"Jacqueline"},{"family":"Franz","given":"Lauren"},{"family":"Perochon","given":"Sam"},{"family":"Krishnappa Babu","given":"Pradeep Raj"},{"family":"Sapiro","given":"Guillermo"},{"family":"Dawson","given":"Geraldine"}],"citation-key":"coffman2023","container-title":"Autism Research","DOI":"10.1002/aur.2955","ISSN":"1939-3806","issue":"7","issued":{"date-parts":[["2023"]]},"language":"en","license":"© 2023 International Society for Autism Research and Wiley Periodicals LLC.","page":"1360-1374","source":"Wiley Online Library","title":"Relationship between quantitative digital behavioral features and clinical profiles in young autistic children","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/aur.2955","volume":"16"},
  {"id":"coll2020a","abstract":"Background: Sensorimotor skills are often reported as atypical in individuals with autism spectrum disorder (ASD). Little is known about how sensorimotor skills in ASD may vary across development and with symptom severity. The main objective of this study was to conduct a comprehensive quantitative meta-analysis of sensorimotor skills in ASD. The speciﬁc aims were: to assess impairment of gross and ﬁne sensorimotor skills in ASD, to examine the eﬀect of age on sensorimotor skills in ASD and to examine the relationship between sensorimotor skills and ASD symptom severity.\nMethod: An exhaustive search was conducted in Psycnet, PubMed, Web of Science and Cochrane Database to identify studies in ASD from 1980 to 2018 that involved quantitative evaluations of motor coordination, motor impairments, arm movement, gait, postural stability, visuomotor or auditory motor integration. A total of 139 studies were included and this represent 3436 individuals with ASD.\nResults: Results strongly support the presence of deﬁcits in overall sensorimotor abilities in ASD (Hedges’ g = 1.22, p < 0.001) and these atypicalities extended to ﬁne and gross sensorimotor abilities. Sensorimotor abilities increased with age, but did not appear to covary with symptom severity.\nConclusions: These results highlight the importance to target these deﬁcits in future interventions and consider the impact of sensorimotor impairments across research, therapy, and educational settings.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Coll","given":"Sarah-Maude"},{"family":"Foster","given":"Nicholas E.V."},{"family":"Meilleur","given":"Alexa"},{"family":"Brambati","given":"Simona M."},{"family":"Hyde","given":"Krista L."}],"citation-key":"coll2020a","container-title":"Research in Autism Spectrum Disorders","container-title-short":"Research in Autism Spectrum Disorders","DOI":"10.1016/j.rasd.2020.101570","ISSN":"17509467","issued":{"date-parts":[["2020",8]]},"language":"en","page":"101570","source":"DOI.org (Crossref)","title":"Sensorimotor skills in autism spectrum disorder: A meta-analysis","title-short":"Sensorimotor skills in autism spectrum disorder","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S175094672030060X","volume":"76"},
  {"id":"cook2021","abstract":"Some autistic people employ strategies and behaviours to cope with the everyday social world, thereby ‘camouflaging’ their autistic differences and difficulties. This review aimed to systematically appraise and synthesise the current evidence base pertaining to autistic camouflaging. Following a systematic search of eight databases, 29 studies quantifying camouflaging in children and adults with autism diagnoses or high levels of autistic traits were reviewed. The multiple methods used to measure camouflaging broadly fell under two different approaches: internal-external discrepancy or self-report. These approaches appear to relate to two distinct but potentially connected elements of camouflaging: observable behavioural presentations and self-perceived camouflaging efforts. While significant variation was noted across individual study findings, much of the existing literature supported three preliminary findings about the nature of autistic camouflaging: (1) adults with more self-reported autistic traits report greater engagement in camouflaging; (2) sex and gender differences exist in camouflaging; and (3) higher self-reported camouflaging is associated with worse mental health outcomes. However, the research base was limited regarding participant characterisation and representativeness, which suggests that conclusions cannot be applied to the autistic community as a whole. We propose priorities for future research in refining the current understanding of camouflaging and improving measurement methods.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Cook","given":"Julia"},{"family":"Hull","given":"Laura"},{"family":"Crane","given":"Laura"},{"family":"Mandy","given":"William"}],"citation-key":"cook2021","container-title":"Clinical Psychology Review","container-title-short":"Clinical Psychology Review","DOI":"10.1016/j.cpr.2021.102080","ISSN":"0272-7358","issued":{"date-parts":[["2021",11,1]]},"page":"102080","source":"ScienceDirect","title":"Camouflaging in autism: A systematic review","title-short":"Camouflaging in autism","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0272735821001239","volume":"89"},
  {"id":"corona2024","abstract":"Purpose: Telemedicine approaches to autism (ASD) assessment have become increasingly common, yet few validated tools exist for this purpose. This study presents results from a clinical trial investigating two approaches to tele-assessment for ASD in toddlers. Methods: 144 children (29% female) between 17 and 36 months of age (mean = 2.5 years, SD = 0.33 years) completed tele-assessment using either the TELE-ASD-PEDS (TAP) or an experimental remote administration of the Screening Tool for Autism in Toddlers (STAT). All children then completed traditional in-person assessment with a blinded clinician, using the Mullen Scales of Early Learning (MSEL), Vineland Adaptive Behavior Scales, 3rd Edition (VABS-3), and Autism Diagnostic Observation Schedule (ADOS-2). Both tele-assessment and in-person assessment included a clinical interview with caregivers. Results: Results indicated diagnostic agreement for 92% of participants. Children diagnosed with ASD following in-person assessment who were missed by tele-assessment (n = 8) had lower scores on tele- and in-person ASD assessment tools. Children inaccurately identified as having ASD by tele-assessment (n = 3) were younger than other children and had higher developmental and adaptive behavior scores than children accurately diagnosed with ASD by tele-assessment. Diagnostic certainty was highest for children correctly identified as having ASD via tele-assessment. Clinicians and caregivers reported satisfaction with tele-assessment procedures. Conclusion: This work provides additional support for the use of tele-assessment for identification of ASD in toddlers, with both clinicians and families reporting broad acceptability. Continued development and refinement of tele-assessment procedures is recommended to optimize this approach for the needs of varying clinicians, families, and circumstances.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Corona","given":"Laura L."},{"family":"Wagner","given":"Liliana"},{"family":"Hooper","given":"Madison"},{"family":"Weitlauf","given":"Amy"},{"family":"Foster","given":"Tori E."},{"family":"Hine","given":"Jeffrey"},{"family":"Miceli","given":"Alexandra"},{"family":"Nicholson","given":"Amy"},{"family":"Stone","given":"Caitlin"},{"family":"Vehorn","given":"Alison"},{"family":"Warren","given":"Zachary"}],"citation-key":"corona2024","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-05908-9","ISSN":"1573-3432","issue":"6","issued":{"date-parts":[["2024",6,1]]},"language":"en","page":"2069-2080","source":"Springer Link","title":"A Randomized Trial of the Accuracy of Novel Telehealth Instruments for the Assessment of Autism in Toddlers","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-05908-9","volume":"54"},
  {"id":"cotton2023","abstract":"Easy access to precise 3D tracking of movement could benefit many aspects of rehabilitation. A challenge to achieving this goal is that while there are many datasets and pretrained algorithms for able-bodied adults, algorithms trained on these datasets often fail to generalize to clinical populations including people with disabilities, infants, and neonates. Reliable movement analysis of infants and neonates is important as spontaneous movement behavior is an important indicator of neurological function and neurodevelopmental disability, which can help guide early interventions. We explored the application of dynamic Gaussian splatting to sparse markerless motion capture (MMC) data. Our approach leverages semantic segmentation masks to focus on the infant, significantly improving the initialization of the scene. Our results demonstrate the potential of this method in rendering novel views of scenes and tracking infant movements. This work paves the way for advanced movement analysis tools that can be applied to diverse clinical populations, with a particular emphasis on early detection in infants.","accessed":{"date-parts":[["2025",1,22]]},"author":[{"family":"Cotton","given":"R. James"},{"family":"Peyton","given":"Colleen"}],"citation-key":"cotton2023","DOI":"10.48550/arXiv.2310.19441","issued":{"date-parts":[["2023",10,30]]},"number":"arXiv:2310.19441","publisher":"arXiv","source":"arXiv.org","title":"Dynamic Gaussian Splatting from Markerless Motion Capture can Reconstruct Infants Movements","type":"article","URL":"http://arxiv.org/abs/2310.19441"},
  {"id":"cronin2024","abstract":"<p>This study tested the performance of OpenPose on footage collected by two cameras at 200 Hz from a real-life competitive setting by comparing it with manually analyzed data in SIMI motion. The same take-off recording from the men's Long Jump finals at the 2017 World Athletics Championships was used for both approaches (markerless and manual) to reconstruct the 3D coordinates from each of the camera's 2D coordinates. Joint angle and Centre of Mass (COM) variables during the final step and take-off phase of the jump were determined. Coefficients of Multiple Determinations (CMD) for joint angle waveforms showed large variation between athletes with the knee angle values typically being higher (take-off leg: 0.727 ± 0.242; swing leg: 0.729 ± 0.190) than those for hip (take-off leg: 0.388 ± 0.193; swing leg: 0.370 ± 0.227) and ankle angle (take-off leg: 0.247 ± 0.172; swing leg: 0.155 ± 0.228). COM data also showed considerable variation between athletes and parameters, with position (0.600 ± 0.322) and projection angle (0.658 ± 0.273) waveforms generally showing better agreement than COM velocity (0.217 ± 0.241). Agreement for discrete data was generally poor with high random error for joint kinematics and COM parameters at take-off and an average ICC across variables of 0.17. The poor agreement statistics and a range of unrealistic values returned by the pose estimation underline that OpenPose is not suitable for in-competition performance analysis in events such as the long jump, something that manual analysis still achieves with high levels of accuracy and reliability.</p>","accessed":{"date-parts":[["2024",7,30]]},"author":[{"family":"Cronin","given":"Neil J."},{"family":"Walker","given":"Josh"},{"family":"Tucker","given":"Catherine B."},{"family":"Nicholson","given":"Gareth"},{"family":"Cooke","given":"Mark"},{"family":"Merlino","given":"Stéphane"},{"family":"Bissas","given":"Athanassios"}],"citation-key":"cronin2024","container-title":"Frontiers in Sports and Active Living","container-title-short":"Front. Sports Act. Living","DOI":"10.3389/fspor.2023.1298003","ISSN":"2624-9367","issued":{"date-parts":[["2024",1,5]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Feasibility of OpenPose markerless motion analysis in a real athletics competition","type":"article-journal","URL":"https://www.frontiersin.org/journals/sports-and-active-living/articles/10.3389/fspor.2023.1298003/full","volume":"5"},
  {"id":"cruz2024","abstract":"Autism is more frequently diagnosed in males, with evidence suggesting that females are more likely to be misdiagnosed or underdiagnosed. Possibly, the male/female ratio imbalance relates to phenotypic and camouflaging differences between genders. Here, we performed a comprehensive approach to phenotypic and camouflaging research in autism addressed in two studies. First (Study 1 – Phenotypic Differences in Autism), we conducted a systematic review and meta-analysis of gender differences in autism phenotype. The electronic datasets Pubmed, Scopus, Web of Science, and PsychInfo were searched. We included 67 articles that compared females and males in autism core symptoms, and in cognitive, socioemotional, and behavioural phenotypes. Autistic males exhibited more severe symptoms and social interaction difficulties on standard clinical measures than females, who, in turn, exhibited more cognitive and behavioural difficulties. Considering the hypothesis of camouflaging possibly underlying these differences, we then conducted a meta-analysis of gender differences in camouflaging (Study 2 – Camouflaging Differences in Autism). The same datasets as the first study were searched. Ten studies were included. Females used more compensation and masking camouflage strategies than males. The results support the argument of a bias in clinical procedures towards males and the importance of considering a ‘female autism phenotype’—potentially involving camouflaging—in the diagnostic process.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Cruz","given":"Sara"},{"family":"Zubizarreta","given":"Sabela Conde-Pumpido"},{"family":"Costa","given":"Ana Daniela"},{"family":"Araújo","given":"Rita"},{"family":"Martinho","given":"Júlia"},{"family":"Tubío-Fungueiriño","given":"María"},{"family":"Sampaio","given":"Adriana"},{"family":"Cruz","given":"Raquel"},{"family":"Carracedo","given":"Angel"},{"family":"Fernández-Prieto","given":"Montse"}],"citation-key":"cruz2024","container-title":"Neuropsychology Review","container-title-short":"Neuropsychol Rev","DOI":"10.1007/s11065-023-09630-2","ISSN":"1573-6660","issued":{"date-parts":[["2024",1,29]]},"language":"en","source":"Springer Link","title":"Is There a Bias Towards Males in the Diagnosis of Autism? A Systematic Review and Meta-Analysis","title-short":"Is There a Bias Towards Males in the Diagnosis of Autism?","type":"article-journal","URL":"https://doi.org/10.1007/s11065-023-09630-2"},
  {"id":"daling2024","abstract":"ObjectiveThe present scoping review aims to transform the diverse field of research on the effects of mixed reality-based training on performance in manual assembly tasks into comprehensive statements about industrial needs for and effects of mixed reality-based training.BackgroundTechnologies such as augmented and virtual reality, referred to as mixed reality, are seen as promising media for training manual assembly tasks. Nevertheless, current literature shows partly contradictory results, which is due to the diversity of the hardware used, manual assembly tasks as well as methodological approaches to investigate the effects of mixed reality-based training.MethodFollowing the methodological approach of a scoping review, we selected 24 articles according to predefined criteria and analyzed them concerning five key aspects: (1) the needs in the industry for mixed reality-based training, (2) the actual use and classification of mixed reality technologies, (3) defined measures for evaluating the outcomes of mixed reality-based training, (4) findings on objectively measured performance and subjective evaluations, as well as (5) identified research gaps.ResultsRegarding the improvement of performance and effectiveness through mixed reality-based training, promising results were found particularly for augmented reality-based training, while virtual reality-based training is mostly—but not consistently—as good as traditional training.ApplicationMixed reality-based training is still not consistently better, but mostly at least as good as traditional training. However, depending on the use case and technology used, the training outcomes in terms of assembly performance and subjective evaluations show promising results of mixed reality-based training.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Daling","given":"Lea M."},{"family":"Schlittmeier","given":"Sabine J."}],"citation-key":"daling2024","container-title":"Human Factors","container-title-short":"Hum Factors","DOI":"10.1177/00187208221105135","ISSN":"0018-7208","issue":"2","issued":{"date-parts":[["2024",2,1]]},"language":"en","page":"589-626","publisher":"SAGE Publications Inc","source":"SAGE Journals","title":"Effects of Augmented Reality-, Virtual Reality-, and Mixed Reality–Based Training on Objective Performance Measures and Subjective Evaluations in Manual Assembly Tasks: A Scoping Review","title-short":"Effects of Augmented Reality-, Virtual Reality-, and Mixed Reality–Based Training on Objective Performance Measures and Subjective Evaluations in Manual Assembly Tasks","type":"article-journal","URL":"https://doi.org/10.1177/00187208221105135","volume":"66"},
  {"id":"damgrave2023","abstract":"Organisations often rely, implicitly, on the tacit knowledge of their employees, especially in non-conforming operations. These activities include (dis)assembly tasks, manual machining, troubleshooting, and tailored adjustments. While a traditional master-apprentice approach is a proven way to transfer tacit knowledge between employees, this approach is not feasible in current industrial situations. This research proposes a contemporary master-apprentice approach to support and improve non-conforming operations in situations that cannot rely on all parties being present at the same time, in the same location, while co-operating on the same task. The approach demonstrates the use of augmented reality as an implicit and discreet tool that purposefully addresses both capturing tacit knowledge, as well as employing it during operations - without disruptive interference in the primary processes.","accessed":{"date-parts":[["2025",3,7]]},"author":[{"family":"Damgrave","given":"Roy"},{"family":"Scheffer","given":"Sara"},{"family":"Lutters","given":"Eric"}],"citation-key":"damgrave2023","collection-title":"56th CIRP International Conference on Manufacturing Systems 2023","container-title":"Procedia CIRP","container-title-short":"Procedia CIRP","DOI":"10.1016/j.procir.2023.09.196","ISSN":"2212-8271","issued":{"date-parts":[["2023",1,1]]},"page":"1475-1480","source":"ScienceDirect","title":"Augmented reality support to employ tacit knowledge in non-conforming operations","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S2212827123009289","volume":"120"},
  {"id":"davis2025","abstract":"Background Autism commonly co-occurs with attention-deficit/hyperactivity disorder (ADHD), but less is known regarding how ADHD symptoms impact the early presentation of autism. This study examined early behavioral characteristics of a community sample of toddlers later identified with autism diagnosis, ADHD symptoms, combined autism and ADHD symptoms, or neither condition. Methods Participants were 506 toddlers who were part of a longitudinal study of children's behavioral development. Parents completed questionnaires about their children's behavior at two time points. Four groups were identified based on study measures or medical record: autism diagnosis (n = 45), elevated ADHD symptoms (n = 70), autism and ADHD symptoms (n = 30), or neurotypical development (n = 361). Relationships between early parent report of autism- and ADHD-related behaviors, social–emotional and behavioral functioning, and caregiver experience and subsequent group designation were evaluated with adjusted linear regression models controlling for sex. Results Significant group differences were found in measures of autism-related behaviors, ADHD-related behaviors, externalizing and internalizing behaviors, and parent support needs (p < .0001). Pairwise comparisons indicated toddlers later identified with combined autism diagnosis and ADHD symptoms had higher levels of autism-related behaviors, externalizing and internalizing behaviors, and autism-related parent support needs compared to the other groups. Toddlers with subsequent elevated ADHD symptoms or combined autism diagnosis and ADHD symptoms exhibited similar levels of ADHD-related behaviors, while both groups displayed more ADHD-related behaviors than toddlers subsequently identified with autism or those with neither condition. Conclusions In this community sample, toddlers for whom combined autism diagnosis and ADHD symptoms were subsequently identified showed a distinct presentation characterized by higher early autism-related behaviors, broader behavioral concerns, and higher parent support needs. Presence of ADHD symptoms (alone or in combination with autism) was associated with higher parent-reported ADHD-related behaviors during toddlerhood. Results indicate that ADHD-related behaviors are manifest by toddlerhood, supporting screening for both autism and ADHD during early childhood.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Davis","given":"Naomi O."},{"family":"Lerebours","given":"Reginald"},{"family":"Aiello","given":"Rachel E."},{"family":"Carpenter","given":"Kimberly L.H."},{"family":"Compton","given":"Scott"},{"family":"Franz","given":"Lauren"},{"family":"Kollins","given":"Scott H."},{"family":"Sabatos-DeVito","given":"Maura"},{"family":"Spanos","given":"Marina"},{"family":"Dawson","given":"Geraldine"}],"citation-key":"davis2025","container-title":"Journal of Child Psychology and Psychiatry","DOI":"10.1111/jcpp.14050","ISSN":"1469-7610","issue":"2","issued":{"date-parts":[["2025"]]},"language":"en","license":"© 2024 Association for Child and Adolescent Mental Health.","page":"214-224","source":"Wiley Online Library","title":"Behavioral characteristics of toddlers later identified with an autism diagnosis, ADHD symptoms, or combined autism and ADHD symptoms","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.14050","volume":"66"},
  {"id":"dawson2008","abstract":"Advances in the fields of cognitive and affective developmental neuroscience, developmental psychopathology, neurobiology, genetics, and applied behavior analysis have contributed to a more optimistic outcome for individuals with autism spectrum disorder (ASD). These advances have led to new methods for early detection and more effective treatments. For the first time, prevention of ASD is plausible. Prevention will entail detecting infants at risk before the full syndrome is present and implementing treatments designed to alter the course of early behavioral and brain development. This article describes a developmental model of risk, risk processes, symptom emergence, and adaptation in ASD that offers a framework for understanding early brain plasticity in ASD and its role in prevention of the disorder.","author":[{"family":"Dawson","given":"Geraldine"}],"citation-key":"dawson2008","container-title":"Development and Psychopathology","container-title-short":"Dev Psychopathol","DOI":"10.1017/S0954579408000370","ISSN":"1469-2198","issue":"3","issued":{"date-parts":[["2008"]]},"language":"eng","page":"775-803","PMID":"18606031","source":"PubMed","title":"Early behavioral intervention, brain plasticity, and the prevention of autism spectrum disorder","type":"article-journal","volume":"20"},
  {"id":"debelen2024","abstract":"Atypical visual attention in individuals with autism spectrum disorders (ASD) has been utilised as a unique diagnosis criterion in previous research. This paper presents a novel approach to the automatic and quantitative screening of ASD as well as symptom severity prediction in preschool children. We develop a novel computational pipeline that extracts learned features from a dynamic visual stimulus to classify ASD children and predict the level of ASD-related symptoms. Experimental results demonstrate promising performance that is superior to using handcrafted features and machine learning algorithms, in terms of evaluation metrics used in diagnostic tests. Using a leave-one-out cross-validation approach, we obtained an accuracy of 94.59%, a sensitivity of 100%, a specificity of 76.47% and an area under the receiver operating characteristic curve (AUC) of 96% for ASD classification. In addition, we obtained an accuracy of 94.74%, a sensitivity of 87.50%, a specificity of 100% and an AUC of 99% for ASD symptom severity prediction.","author":[{"family":"Belen","given":"Ryan Anthony J.","non-dropping-particle":"de"},{"family":"Eapen","given":"Valsamma"},{"family":"Bednarz","given":"Tomasz"},{"family":"Sowmya","given":"Arcot"}],"citation-key":"debelen2024","container-title":"PloS One","container-title-short":"PLoS One","DOI":"10.1371/journal.pone.0282818","ISSN":"1932-6203","issue":"2","issued":{"date-parts":[["2024"]]},"language":"eng","page":"e0282818","PMCID":"PMC10861059","PMID":"38346053","source":"PubMed","title":"Using visual attention estimation on videos for automated prediction of autism spectrum disorder and symptom severity in preschool children","type":"article-journal","volume":"19"},
  {"id":"dechsling2021","abstract":"Background\nNaturalistic Developmental Behavioral Interventions (NDBI) have been evaluated as the most promising interventions for children with autism spectrum disorder. In recent years, a growing body of literature suggests that technological advancements such as Virtual Reality (VR) are promising intervention tools. However, to the best of our knowledge no studies have combined evidence-based practice with such tools.\nAim\nThis article aims to review the current literature combining NDBI and VR, and provide suggestions on merging NDBI-approaches with VR.\nMethods\nThis article is divided into two parts, where we first conduct a review mapping the research applying NDBI-approaches in VR. In the second part we argue how to apply the common features of NDBI into VR-technology.\nResults\nOur findings show that no VR-studies explicitly rely on NDBI-approaches, but some utilize elements in their interventions that are considered to be common features to NDBI.\nConclusions and implications\nAs the results show, to date, no VR-based studies have utilized NDBI in their intervention. We therefore, in the second part of this article, suggests ways to merge VR and NDBI and introduce the term Virtual Naturalistic Developmental Behavioral Interventions (VNDBI). VNDBI is an innovative way of implementing NDBI which will contribute in making interventions more accessible in central as well as remote locations, while reducing unwanted variation between service sites. VNDBI will advance the possibilities of individually tailoring and widen the area of interventions. In addition, VNDBI can provide the field with new knowledge on effective components enhancing the accuracy in the intervention packages and thus move forward the research field and clinical practice.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Dechsling","given":"Anders"},{"family":"Shic","given":"Frederick"},{"family":"Zhang","given":"Dajie"},{"family":"Marschik","given":"Peter B."},{"family":"Esposito","given":"Gianluca"},{"family":"Orm","given":"Stian"},{"family":"Sütterlin","given":"Stefan"},{"family":"Kalandadze","given":"Tamara"},{"family":"Øien","given":"Roald A."},{"family":"Nordahl-Hansen","given":"Anders"}],"citation-key":"dechsling2021","container-title":"Research in Developmental Disabilities","container-title-short":"Research in Developmental Disabilities","DOI":"10.1016/j.ridd.2021.103885","ISSN":"0891-4222","issued":{"date-parts":[["2021",4,1]]},"page":"103885","source":"ScienceDirect","title":"Virtual reality and naturalistic developmental behavioral interventions for children with autism spectrum disorder","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0891422221000342","volume":"111"},
  {"id":"dechsling2022","abstract":"In the last decade, there has been an increase in publications on technology-based interventions for autism spectrum disorder (ASD). Virtual reality based assessments and intervention tools are promising and have shown to be acceptable amongst individuals with ASD. This scoping review reports on 49 studies utilizing virtual reality and augmented reality technology in social skills interventions for individuals with ASD. The included studies mostly targeted children and adolescents, but few targeted very young children or adults. Our findings show that the mode number of participants with ASD is low, and that female participants are underrepresented. Our review suggests that there is need for studies that apply virtual and augmented realty with more rigorous designs involving established and evidenced-based intervention strategies.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Dechsling","given":"Anders"},{"family":"Orm","given":"Stian"},{"family":"Kalandadze","given":"Tamara"},{"family":"Sütterlin","given":"Stefan"},{"family":"Øien","given":"Roald A."},{"family":"Shic","given":"Frederick"},{"family":"Nordahl-Hansen","given":"Anders"}],"citation-key":"dechsling2022","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-021-05338-5","ISSN":"1573-3432","issue":"11","issued":{"date-parts":[["2022",11,1]]},"language":"en","page":"4692-4707","source":"Springer Link","title":"Virtual and Augmented Reality in Social Skills Interventions for Individuals with Autism Spectrum Disorder: A Scoping Review","title-short":"Virtual and Augmented Reality in Social Skills Interventions for Individuals with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s10803-021-05338-5","volume":"52"},
  {"id":"degiorgi2022","abstract":"Immersive Virtual Reality applications have been proven to be effective in training soft skills and in managing anxiety. Many studies on this technology have focused on public speaking and on the treatment of phobias. Apparently, there is an interesting domain represented by job interviews that has not been fully considered yet. In fact, most of the work done in this context leveraged desktop-based Virtual Reality, a configuration which does not enable to take full advantage of the potential of immersive technologies. Training before having a job interview, however, could be a precious asset for students who are about to finish their studies and need to apply for job positions, especially if they have never experienced one. This training could indeed be done with traditional methods; by means of Virtual Reality, though, an individual can see him or herself from the outside and better assess his or her performance. Compared with, e.g., practicing while watching in the mirror, there is so much more that can be done in immersive Virtual Reality. This technology offers the possibility to observe the whole scene where the job interview takes place, both from an external viewpoint as an observer without a direct involvement, as well as from another person’s perspective as if his or her virtual body was that of the individual being interviewed. Based on the above premises, this thesis work explores the two configurations above, aiming at disclosing which one could be more useful to self-assess an individual performance while answering questions in a job interview. Rather than actually developing a tool to support practicing in this scenario, the ultimate goal is to identify how such a tool could be most effective, i.e., whether observing the interview from an “objective” or “neutral” viewpoint or from the “subjective” viewpoint of the interviewer whose job is to carry out the evaluation.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"De Giorgi","given":"Chiara"}],"citation-key":"degiorgi2022","genre":"laurea","issued":{"date-parts":[["2022",12,20]]},"language":"it","license":"cc_by_nc_nd","number-of-pages":"86","publisher":"Politecnico di Torino","source":"webthesis.biblio.polito.it","title":"Virtual reality body swapping to improve the training of soft skills and self-assessment","type":"thesis","URL":"https://webthesis.biblio.polito.it/25575/"},
  {"id":"dehghani2023","abstract":"Emotion detection is a crucial component of Games User Research (GUR), as it allows game developers to gain insights into players’ emotional experiences and tailor their games accordingly. However, detecting emotions in Virtual Reality (VR) games is challenging due to the Head-Mounted Display (HMD) that covers the top part of the player’s face, namely, their eyes and eyebrows, which provide crucial information for recognizing the impression. To tackle this we used a Convolutional Neural Network (CNN) to train a model to predict emotions in full-face images where the eyes and eyebrows are covered. We used the FER2013 dataset, which we modified to cover eyes and eyebrows in images. The model in these images can accurately recognize seven different emotions which are anger, happiness, disgust, fear, impartiality, sadness and surprise.We assessed the model’s performance by testing it on two VR games and using it to detect players’ emotions. We collected self-reported emotion data from the players after the gameplay sessions. We analyzed the data collected from our experiment to understand which emotions players experience during the gameplay. We found that our approach has the potential to enhance gameplay analysis by enabling the detection of players’ emotions in VR games, which can help game developers create more engaging and immersive game experiences.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Dehghani","given":"Fatemeh"},{"family":"Zaman","given":"Loutfouz"}],"citation-key":"dehghani2023","container-title":"2023 IEEE Conference on Games (CoG)","DOI":"10.1109/CoG57401.2023.10333160","event-title":"2023 IEEE Conference on Games (CoG)","ISSN":"2325-4289","issued":{"date-parts":[["2023",8]]},"page":"1-4","source":"IEEE Xplore","title":"Facial Emotion Recognition in VR Games","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10333160"},
  {"id":"delbianco2024","abstract":"Face-processing timing differences may underlie visual social attention differences between autistic and non-autistic people, and males and females. This study investigates the timing of the effects of neurotype and sex on face-processing, and their dependence on age. We analysed EEG data during upright and inverted photographs of faces from 492 participants from the Longitudinal European Autism Project (141 neurotypical males, 76 neurotypical females, 202 autistic males, 73 autistic females; age 6–30 years). We detected timings of sex/diagnosis effects on event-related potential amplitudes at the posterior–temporal channel P8 with Bootstrapped Cluster-based Permutation Analysis and conducted Growth Curve Analysis (GCA) to investigate the timecourse and dependence on age of neural signals. The periods of influence of neurotype and sex overlapped but differed in onset (respectively, 260 and 310 ms post-stimulus), with sex effects lasting longer. GCA revealed a smaller and later amplitude peak in autistic female children compared to non-autistic female children; this difference decreased in adolescence and was not significant in adulthood. No age-dependent neurotype difference was significant in males. These findings indicate that sex and neurotype influence longer latency face processing and implicates cognitive rather than perceptual processing. Sex may have more overarching effects than neurotype on configural face processing.","accessed":{"date-parts":[["2025",2,18]]},"author":[{"family":"Del Bianco","given":"Teresa"},{"family":"Lai","given":"Meng-Chuan"},{"family":"Mason","given":"Luke"},{"family":"Johnson","given":"Mark H."},{"family":"Charman","given":"Tony"},{"family":"Loth","given":"Eva"},{"family":"Banaschewski","given":"Tobias"},{"family":"Buitelaar","given":"Jan"},{"family":"Murphy","given":"Declan G. M."},{"family":"Jones","given":"Emily J. H."}],"citation-key":"delbianco2024","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-024-64387-9","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2024",6,18]]},"language":"en","license":"2024 The Author(s)","page":"14038","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Sex differences in social brain neural responses in autism: temporal profiles of configural face-processing within data-driven time windows","title-short":"Sex differences in social brain neural responses in autism","type":"article-journal","URL":"https://www.nature.com/articles/s41598-024-64387-9","volume":"14"},
  {"id":"dellazizzo2020","abstract":"Background\nAmong all diseases globally, mental illnesses are one of the major causes of burden. As many people are resistant to conventional evidence-based treatments, there is an unmet need for the implementation of novel mental health treatments. Efforts to increase the effectiveness and benefits of evidence-based psychotherapy in psychiatry have led to the emergence of virtual reality (VR)–based interventions. These interventions have shown a wide range of advantages over conventional psychotherapies. Currently, VR-based interventions have been developed mainly for anxiety-related disorders; however, they are also used for developmental disorders, severe mental disorders, and neurocognitive disorders.\n\nObjective\nThis meta-review aims to summarize the current state of evidence on the efficacy of VR-based interventions for various psychiatric disorders by evaluating the quality of evidence provided by meta-analytical studies.\n\nMethods\nA systematic search was performed using the following electronic databases: PubMed, PsycINFO, Web of Science, and Google Scholar (any time until February 2020). Meta-analyses were included as long as they quantitatively examined the efficacy of VR-based interventions for symptoms of a psychiatric disorder. To avoid overlap among meta-analyses, for each subanalysis included within this meta-review, only one analysis provided from one meta-analysis was selected based on the best quality of evidence.\n\nResults\nThe search retrieved 11 eligible meta-analyses. The quality of evidence varied from very low to moderate quality. Several reasons account for the lower quality evidence, such as a limited number of randomized controlled trials, lack of follow-up analysis or control group, and the presence of heterogeneity and publication bias. Nonetheless, evidence has shown that VR-based interventions for anxiety-related disorders display overall medium-to-large effects when compared with inactive controls but no significant difference when compared with standard evidence-based approaches. Preliminary data have highlighted that such effects appear to be sustained in time, and subjects may fare better than active controls. Neurocognitive disorders also appear to improve with VR-based approaches, with small effects being found for various clinical outcomes (eg, cognition, emotion). Finally, there are insufficient data to classify VR-based interventions as an evidence-based practice for social skills training in neurodevelopmental disorders and compliance among patients with schizophrenia.\n\nConclusions\nVR provides unlimited opportunities by tailoring approaches to specific complex problems and individualizing the intervention. However, VR-based interventions have not shown superiority compared with usual evidence-based treatments. Future VR-based interventions should focus on developing innovative approaches for complex and treatment-resistant symptoms that are difficult to address with traditional treatments. Future research should also aim to gain a better understanding of the potential factors that may mediate VR outcomes to improve treatment.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Dellazizzo","given":"Laura"},{"family":"Potvin","given":"Stéphane"},{"family":"Luigi","given":"Mimosa"},{"family":"Dumais","given":"Alexandre"}],"citation-key":"dellazizzo2020","container-title":"Journal of Medical Internet Research","container-title-short":"J Med Internet Res","DOI":"10.2196/20889","ISSN":"1439-4456","issue":"8","issued":{"date-parts":[["2020",8,19]]},"page":"e20889","PMCID":"PMC7468638","PMID":"32812889","source":"PubMed Central","title":"Evidence on Virtual Reality–Based Therapies for Psychiatric Disorders: Meta-Review of Meta-Analyses","title-short":"Evidence on Virtual Reality–Based Therapies for Psychiatric Disorders","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7468638/","volume":"22"},
  {"id":"destefani2022","abstract":"Aim: Three-dimensional facial imaging systems are a useful tool that is gradually replacing two-dimensional imaging and traditional anthropometry with calipers. In this varied and growing landscape of new devices, Canfield (Canfield Scientific, Parsippany, NJ, USA) has proposed a series of static and portable 3D imaging systems. The aim of this systematic review was to evaluate the current literature regarding the validation of Canfield’s Vectra imaging systems. Materials and Methods: A search strategy was developed on electronic databases including PubMed, Web of Science and Scopus by using specific keywords. After the study selection phase, a total of 10 articles were included in the present review. Results: A total of 10 articles were finally included in the present review. For six articles, we conducted a validation of the Vectra static devices, focusing especially on the Vectra M5, Vectra M3 and Vectra XT. For four articles, we validated the Vectra H1 portable system. Conclusions: All of the reviewed articles concluded that Canfield’s Vectra 3D imaging systems are capable of capturing accurate and reproducible stereophotogrammetric images. Minor errors were reported, particularly in the acquisition of the perioral region, but all the evaluated devices are considered to be valid and accurate tools for clinicians.","accessed":{"date-parts":[["2024",9,15]]},"author":[{"family":"De Stefani","given":"Alberto"},{"family":"Barone","given":"Martina"},{"family":"Hatami Alamdari","given":"Sam"},{"family":"Barjami","given":"Arjola"},{"family":"Baciliero","given":"Ugo"},{"family":"Apolloni","given":"Federico"},{"family":"Gracco","given":"Antonio"},{"family":"Bruno","given":"Giovanni"}],"citation-key":"destefani2022","container-title":"International Journal of Environmental Research and Public Health","container-title-short":"Int J Environ Res Public Health","DOI":"10.3390/ijerph19148820","ISSN":"1661-7827","issue":"14","issued":{"date-parts":[["2022",7,20]]},"page":"8820","PMCID":"PMC9318949","PMID":"35886670","source":"PubMed Central","title":"Validation of Vectra 3D Imaging Systems: A Review","title-short":"Validation of Vectra 3D Imaging Systems","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9318949/","volume":"19"},
  {"id":"devries2021","abstract":"Pupillometry, measuring pupil size and reactivity, has been proposed as a measure of autonomic nervous system functioning, the latter which might be altered in individuals with autism spectrum disorder (ASD). This study aims to evaluate if pupillary responses differ in individuals with and without ASD. After performing a systematic literature search, we conducted a meta-analysis and constructed a qualitative synthesis. The meta-analysis shows a longer latency of the pupil response in the ASD-group as a substantial group difference, with a Hedges’ g of 1.03 (95% CI 0.49–1.56, p = 0.008). Evidence on baseline pupil size and amplitude change is conflicting. We used the framework method to perform a qualitative evaluation of these differences. Explanations for the group differences vary between studies and are inconclusive, but many authors point to involvement of the autonomous nervous system and more specifically the locus coeruleus-norepinephrine system. Pupillometry reveals differences between people with and without ASD, but the exact meaning of these differences remains unknown. Future studies should align research designs and investigate a possible effect of maturation.","accessed":{"date-parts":[["2025",1,14]]},"author":[{"family":"Vries","given":"Lyssa","non-dropping-particle":"de"},{"family":"Fouquaet","given":"Iris"},{"family":"Boets","given":"Bart"},{"family":"Naulaers","given":"Gunnar"},{"family":"Steyaert","given":"Jean"}],"citation-key":"devries2021","container-title":"Neuroscience & Biobehavioral Reviews","container-title-short":"Neuroscience & Biobehavioral Reviews","DOI":"10.1016/j.neubiorev.2020.09.032","ISSN":"0149-7634","issued":{"date-parts":[["2021",1,1]]},"page":"479-508","source":"ScienceDirect","title":"Autism spectrum disorder and pupillometry: A systematic review and meta-analysis","title-short":"Autism spectrum disorder and pupillometry","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S014976342030590X","volume":"120"},
  {"id":"dhiman2024","abstract":"Past research comparing augmented reality (AR) media such as in-situ projection and head-mounted devices (HMD) has usually considered simple manual activities. It is unknown whether previously reported differences between different AR media also apply to complex, skill-driven tasks. In this paper, we explore the feasibility and challenges in designing AR instructions for expertise-driven, skilled activities. We present findings from a real-world, between-subjects experiment in which novices were instructed to trim and bone sub-primal cuts of pork using two interactive AR prototypes, one utilizing in-situ projection and a second using the Hololens 2. The prototypes and instructions were designed in consultation with experts. We compared novices' task performance and subjective perceptions and gathered experts' feedback. Although both users and experts indicated a subjective preference for in-situ projection, results indicate that when tasks require knowledge, skill and expertise, the choice of the AR medium itself may not be consequential. Rather, in our experiment, the instruction quality influenced comprehension, knowledge retention and task performance. Hence, from an engineering perspective, emphasis ought to be laid on gathering and structuring expert performance and knowledge to create effective instructions, which could be delivered using any AR medium suited to the task and work environment.","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Dhiman","given":"Hitesh"},{"family":"Röcker","given":"Carsten"}],"citation-key":"dhiman2024","container-title":"Proc. ACM Hum.-Comput. Interact.","DOI":"10.1145/3660249","issue":"EICS","issued":{"date-parts":[["2024",6,17]]},"page":"249:1–249:28","source":"ACM Digital Library","title":"Does the Medium Matter? A Comparison of Augmented Reality Media in Instructing Novices to Perform Complex, Skill-Based Manual Tasks.","title-short":"Does the Medium Matter?","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/3660249","volume":"8"},
  {"id":"dinis2025","abstract":"Maintenance management is defined as “all management activities that determine the maintenance requirements, objectives, strategies and responsibilities, and implementation of them by such means as maintenance planning, maintenance control, and improvement of maintenance activities and economics”. The purpose of this research work is to present a brief review on key problems in maintenance management and on selected solutions to address these problems, particularly within aviation maintenance, framed within business analytics (BA), which comprises descriptive, predictive, and prescriptive perspectives. Unlike manufacturing, in which most activities are deterministic by nature, characterized by well-defined execution lead times and required resources, being it labor, tools, or parts and materials, maintenance presents an important stochastic component. Maintenance can be divided into preventive maintenance and corrective maintenance. The former refers to prespecified tasks, carried out at predetermined intervals, being its work essentially deterministic. The latter results from the probabilistic nature of failures, performed upon a fault is identified, being its work inherently stochastic. The workload resulting from corrective maintenance can be more than half of the total maintenance workload according to some studies, making it an important challenge for effective and efficient maintenance management. This research work is expected to be of interest for researchers and practitioners alike, by identifying the sources of uncertainty associated with maintenance management and by providing references on relevant methods to model and control such uncertainty.","accessed":{"date-parts":[["2025",3,7]]},"author":[{"family":"Dinis","given":"Duarte"}],"citation-key":"dinis2025","collection-title":"6th International Conference on Industry 4.0 and Smart Manufacturing","container-title":"Procedia Computer Science","container-title-short":"Procedia Computer Science","DOI":"10.1016/j.procs.2025.02.031","ISSN":"1877-0509","issued":{"date-parts":[["2025",1,1]]},"page":"3069-3077","source":"ScienceDirect","title":"Maintenance Management: A Review on Problems and Solutions","title-short":"Maintenance Management","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1877050925003746","volume":"253"},
  {"id":"dollion2022","abstract":"<p>Processing and recognizing facial expressions are key factors in human social interaction. Past research suggests that individuals with autism spectrum disorder (ASD) present difficulties to decode facial expressions. Those difficulties are notably attributed to altered strategies in the visual scanning of expressive faces. Numerous studies have demonstrated the multiple benefits of exposure to pet dogs and service dogs on the interaction skills and psychosocial development of children with ASD. However, no study has investigated if those benefits also extend to the processing of facial expressions. The aim of this study was to investigate if having a service dog had an influence on facial expression processing skills of children with ASD. Two groups of 15 children with ASD, with and without a service dog, were compared using a facial expression recognition computer task while their ocular movements were measured using an eye-tracker. While the two groups did not differ in their accuracy and reaction time, results highlighted that children with ASD owning a service dog directed less attention toward areas that were not relevant to facial expression processing. They also displayed a more differentiated scanning of relevant facial features according to the displayed emotion (i.e., they spent more time on the mouth for joy than for anger, and vice versa for the eyes area). Results from the present study suggest that having a service dog and interacting with it on a daily basis may promote the development of specific visual exploration strategies for the processing of human faces.</p>","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Dollion","given":"Nicolas"},{"family":"Grandgeorge","given":"Marine"},{"family":"Saint-Amour","given":"Dave"},{"family":"Hosein Poitras Loewen","given":"Anthony"},{"family":"François","given":"Nathe"},{"family":"Fontaine","given":"Nathalie M. G."},{"family":"Champagne","given":"Noël"},{"family":"Plusquellec","given":"Pierrich"}],"citation-key":"dollion2022","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2022.869452","ISSN":"1664-1078","issued":{"date-parts":[["2022",5,20]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Emotion Facial Processing in Children With Autism Spectrum Disorder: A Pilot Study of the Impact of Service Dogs","title-short":"Emotion Facial Processing in Children With Autism Spectrum Disorder","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.869452/full","volume":"13"},
  {"id":"donato2022","abstract":"Within Artificial Intelligence, Deep Learning (DL) represents a paradigm that has been showing unprecedented performance in image and audio processing by supporting or even replacing humans in defect and anomaly detection. The railway sector is expected to benefit from DL applications, especially in predictive maintenance applications, where smart audio and video sensors can be leveraged yet kept distinct from safety-critical functions. Such separation is crucial, as it allows for improving system dependability with no impact on its safety certification. This is further supported by the development of DL in other transportation domains, such as automotive and avionics, opening for knowledge transfer opportunities and highlighting the potential of such a paradigm in railways. In order to summarize the recent state-of-the-art while inquiring about future opportunities, this paper reviews DL approaches for the analysis of data generated by acoustic and visual sensors in railway maintenance applications that have been published until August 31st, 2021. In this paper, the current state of the research is investigated and evaluated using a structured and systematic method, in order to highlight promising approaches and successful applications, as well as to identify available datasets, current limitations, open issues, challenges, and recommendations about future research directions.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Donato","given":"Lorenzo De"},{"family":"Flammini","given":"Francesco"},{"family":"Marrone","given":"Stefano"},{"family":"Mazzariello","given":"Claudio"},{"family":"Nardone","given":"Roberto"},{"family":"Sansone","given":"Carlo"},{"family":"Vittorini","given":"Valeria"}],"citation-key":"donato2022","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2022.3183102","ISSN":"2169-3536","issued":{"date-parts":[["2022"]]},"page":"65376-65400","source":"IEEE Xplore","title":"A Survey on Audio-Video Based Defect Detection Through Deep Learning in Railway Maintenance","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/9795283","volume":"10"},
  {"id":"dong2021","abstract":"Facial expressions are a vital way for humans to show their perceived emotions. It is convenient for detecting and recognizing expressions or micro-expressions by annotating a lot of data in deep learning. However, the study of video-based expressions or micro-expressions requires that coders have professional knowledge and be familiar with action unit (AU) coding, leading to considerable difficulties. This paper aims to alleviate this situation. We deconstruct facial muscle movements from the motor cortex and systematically sort out the relationship among facial muscles, AU, and emotion to make more people understand coding from the basic principles: We derived the relationship between AU and emotion based on a data-driven analysis of 5,000 images from the RAF-AU database, along with the experience of professional coders.We discussed the complex facial motor cortical network system that generates facial movement properties, detailing the facial nucleus and the motor system associated with facial expressions.The supporting physiological theory for AU labeling of emotions is obtained by adding facial muscle movements patterns.We present the detailed process of emotion labeling and the detection and recognition of AU. Based on the above research, the video's coding of spontaneous expressions and micro-expressions is concluded and prospected.","author":[{"family":"Dong","given":"Zizhao"},{"family":"Wang","given":"Gang"},{"family":"Lu","given":"Shaoyuan"},{"family":"Li","given":"Jingting"},{"family":"Yan","given":"Wenjing"},{"family":"Wang","given":"Su-Jing"}],"citation-key":"dong2021","container-title":"Frontiers in Psychology","container-title-short":"Front Psychol","DOI":"10.3389/fpsyg.2021.784834","ISSN":"1664-1078","issued":{"date-parts":[["2021"]]},"language":"eng","page":"784834","PMCID":"PMC8763852","PMID":"35058850","source":"PubMed","title":"Spontaneous Facial Expressions and Micro-expressions Coding: From Brain to Face","title-short":"Spontaneous Facial Expressions and Micro-expressions Coding","type":"article-journal","volume":"12"},
  {"id":"dong2024","abstract":"The objective of human pose estimation (HPE) derived from deep learning aims to accurately estimate and predict the human body posture in images or videos via the utilization of deep neural networks. However, the accuracy of real-time HPE tasks is still to be improved due to factors such as partial occlusion of body parts and limited receptive field of the model. To alleviate the accuracy loss caused by these issues, this paper proposes a real-time HPE model called $${\\textbf {CCAM-Person}}$$based on the YOLOv8 framework. Specifically, we have improved the backbone and neck of the YOLOv8x-pose real-time HPE model to alleviate the feature loss and receptive field constraints. Secondly, we introduce the context coordinate attention module (CCAM) to augment the model’s focus on salient features, reduce background noise interference, alleviate key point regression failure caused by limb occlusion, and improve the accuracy of pose estimation. Our approach attains competitive results on multiple metrics of two open-source datasets, MS COCO 2017 and CrowdPose. Compared with the baseline model YOLOv8x-pose, CCAM-Person improves the average precision by 2.8% and 3.5% on the two datasets, respectively.","accessed":{"date-parts":[["2025",2,9]]},"author":[{"family":"Dong","given":"Chengang"},{"family":"Du","given":"Guodong"}],"citation-key":"dong2024","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-024-58146-z","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2024",4,5]]},"language":"en","license":"2024 The Author(s)","page":"8012","publisher":"Nature Publishing Group","source":"www.nature.com","title":"An enhanced real-time human pose estimation method based on modified YOLOv8 framework","type":"article-journal","URL":"https://www.nature.com/articles/s41598-024-58146-z","volume":"14"},
  {"id":"duong2024","abstract":"Artificial intelligence (AI) is revolutionizing plastic surgery through its remarkable advancements in various domains such as image analysis, robotic assistance, predictive analytics, and augmented reality. Predictive analytics, powered by AI, harnesses patient data to predict surgical outcomes, minimize risks, and tailor treatment plans, thereby optimizing patient care and safety. Augmented reality and virtual reality technology are also reshaping the cosmetic surgery landscape, providing immersive experiences for preoperative imaging, intraoperative guidance, and advanced skills through simulation. Looking ahead, the future of AI in plastic surgery holds great promise, including personalized medicine, bioprinting of tissues and organs, and continuous learning through iterative improvement algorithms based on real-world surgical experience. However, amid these transformational advances, ethical considerations and regulatory frameworks must evolve to ensure the responsible deployment of AI, protect patient privacy, minimize errors and algorithmic deviation, and uphold standards of fairness and transparency. Our study aims to explore the role of AI in the field of plastic surgery with the potential for the future in mind. In summary, AI is considered a beacon of innovation in plastic surgery, enhancing surgical precision, enhancing patient outcomes, and heralding a future where interventions rely on personalized technology that will redefine the boundaries of aesthetic and regenerative medicine.","accessed":{"date-parts":[["2024",9,15]]},"author":[{"family":"Duong","given":"Tran Van"},{"family":"Vy","given":"Vu Pham Thao"},{"family":"Hung","given":"Truong Nguyen Khanh"}],"citation-key":"duong2024","container-title":"Cosmetics","DOI":"10.3390/cosmetics11040109","event-place":"Basel, Switzerland","issue":"4","issued":{"date-parts":[["2024"]]},"language":"English","license":"© 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.","number-of-pages":"109","page":"109","publisher":"MDPI AG","publisher-place":"Basel, Switzerland","source":"ProQuest","title":"Artificial Intelligence in Plastic Surgery: Advancements, Applications, and Future","title-short":"Artificial Intelligence in Plastic Surgery","type":"article-journal","URL":"https://www.proquest.com/docview/3097884861/abstract/7BA7496DBBFA44C6PQ/1","volume":"11"},
  {"id":"duvekot2017","abstract":"In order to shed more light on why referred girls are less likely to be diagnosed with autism spectrum disorder than boys, this study examined whether behavioral characteristics influence the probability of an autism spectrum disorder diagnosis differently in girls versus boys derived from a multicenter sample of consecutively referred children aged 2.5–10 years. Based on information from the short version of the Developmental, Dimensional and Diagnostic Interview and the Autism Diagnostic Observation Schedule, 130 children (106 boys and 24 girls) received a diagnosis of autism spectrum disorder according to Diagnostic and Statistical Manual of Mental Disorders (4th ed., text rev.) criteria and 101 children (61 boys and 40 girls) did not. Higher overall levels of parent-reported repetitive and restricted behavior symptoms were less predictive of an autism spectrum disorder diagnosis in girls than in boys (odds ratio interaction = 0.41, 95% confidence interval = 0.18–0.92, p = 0.03). In contrast, higher overall levels of parent-reported emotional and behavioral problems increased the probability of an autism spectrum disorder diagnosis more in girls than in boys (odds ratio interaction = 2.44, 95% confidence interval = 1.13–5.29, p = 0.02). No differences were found between girls and boys in the prediction of an autism spectrum disorder diagnosis by overall autistic impairment, sensory symptoms, and cognitive functioning. These findings provide insight into possible explanations for the assumed underidentification of autism spectrum disorder in girls in the clinic.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Duvekot","given":"Jorieke"},{"family":"Ende","given":"Jan","non-dropping-particle":"van der"},{"family":"Verhulst","given":"Frank C"},{"family":"Slappendel","given":"Geerte"},{"family":"Daalen","given":"Emma","non-dropping-particle":"van"},{"family":"Maras","given":"Athanasios"},{"family":"Greaves-Lord","given":"Kirstin"}],"citation-key":"duvekot2017","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/1362361316672178","ISSN":"1362-3613","issue":"6","issued":{"date-parts":[["2017",8,1]]},"language":"en","page":"646-658","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Factors influencing the probability of a diagnosis of autism spectrum disorder in girls versus boys","type":"article-journal","URL":"https://doi.org/10.1177/1362361316672178","volume":"21"},
  {"id":"eack2015","abstract":"Facial emotion perception is significantly affected in autism spectrum disorder, yet little is known about how individuals with autism spectrum disorder misinterpret facial expressions that result in their difficulty in accurately recognizing emotion in faces. This study examined facial emotion perception in 45 verbal adults with autism spectrum disorder and 30 age- and gender-matched volunteers without autism spectrum disorder to identify patterns of emotion misinterpretation during face processing that contribute to emotion recognition impairments in autism. Results revealed that difficulty distinguishing emotional from neutral facial expressions characterized much of the emotion perception impairments exhibited by participants with autism spectrum disorder. In particular, adults with autism spectrum disorder uniquely misinterpreted happy faces as neutral, and were significantly more likely than typical volunteers to attribute negative valence to nonemotional faces. The over-attribution of emotions to neutral faces was significantly related to greater communication and emotional intelligence impairments in individuals with autism spectrum disorder. These findings suggest a potential negative bias toward the interpretation of facial expressions and may have implications for interventions designed to remediate emotion perception in autism spectrum disorder.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Eack","given":"Shaun M"},{"family":"Mazefsky","given":"Carla A"},{"family":"Minshew","given":"Nancy J"}],"citation-key":"eack2015","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/1362361314520755","ISSN":"1362-3613","issue":"3","issued":{"date-parts":[["2015",4,1]]},"language":"en","page":"308-315","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Misinterpretation of facial expressions of emotion in verbal adults with autism spectrum disorder","type":"article-journal","URL":"https://doi.org/10.1177/1362361314520755","volume":"19"},
  {"id":"eberhard2022","abstract":"“Missed” cases with neurodevelopmental disorders (NDDs) within adult psychiatry services have attracted increasing attention in the last decade. Key questions have been what the prevalence of NDDs (particularly attention-deficit/hyperactivity disorder/ADHD and autism spectrum disorder/ASD) is, and what the clinical and gender characteristics of those with NDD in adult psychiatry are. All first-time attenders at an adult psychiatry clinic serving 18–25 years old were invited to take part in the study regardless of cause of concern. Participation in the study included diagnostic in-depth evaluation performed by experienced adult psychiatrists. Clinical diagnoses (DSM-IV-TR and DSM-5 criteria) were based on all available information (clinical psychiatric interview, clinical observation, and self-rating questionnaires). Almost two thirds (63%) of the study group met criteria for ADHD or ASD. Most of the patients with NDD (particularly the \"NDD females\") had not been diagnosed in childhood. Twelve percent of the females included had been given an ADHD diagnosis in childhood. In the current study we found that 48% of the females had ADHD. The high male:female NDD ratio reported among children, was not obvious in our NDD group. The results underscore the importance of screening for NDD in adult psychiatric services regardless of referral reason.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Eberhard","given":"David"},{"family":"Billstedt","given":"Eva"},{"family":"Gillberg","given":"Christopher"}],"citation-key":"eberhard2022","container-title":"Psychiatry Research","container-title-short":"Psychiatry Research","DOI":"10.1016/j.psychres.2022.114638","ISSN":"0165-1781","issued":{"date-parts":[["2022",7,1]]},"page":"114638","source":"ScienceDirect","title":"Neurodevelopmental disorders and comorbidity in young adults attending a psychiatric outpatient clinic","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0165178122002384","volume":"313"},
  {"id":"edwards2024","abstract":"Background Evidence that autism often manifests differently between males and females is growing, particularly in terms of social interaction and communication, but it is unclear if there are sex differences in restricted and repetitive behaviours and interests (RRBIs) when rigorously focusing on the narrow construct level (i.e., stereotyped behaviour, restricted interests, insistence on sameness, and/or sensory experiences). Methods We conducted a systematic review and four random effects meta-analyses investigating sex differences in narrow construct measures of RRBIs in autistic children, adolescents, and adults (Prospero registration ID: CRD42021254221). Study quality was appraised using the Newcastle-Ottawa Quality Assessment Scale. Results Forty-six studies were narratively synthesised and 25 of these were included in four random effects meta-analyses. Results found that autistic males had significantly higher levels of stereotyped behaviours (SMD = 0.21, 95% confidence interval (CI) [0.09, 0.33], p < .001) and restricted interests (SMD = 0.18, 95% CI [0.07, 0.29], p < .001) compared to autistic females. In contrast, there were no significant sex differences for sensory experiences (SMD = −0.09, 95% CI [−0.27, 0.09], p = .32) and insistence on sameness (SMD = 0.01, 95% CI [−0.03, 0.05], p = .68). The findings from the narrative synthesis were generally consistent with those from the meta-analyses and also found qualitative sex differences in the way RRBIs manifest. Conclusions Our findings show significant differences in narrowly defined RRBIs in males and females. Practitioners need to be aware of such differences, which could be contributing to the under-recognition of autism in females and may not be captured by current diagnostic instruments.","accessed":{"date-parts":[["2024",6,19]]},"author":[{"family":"Edwards","given":"Hannah"},{"family":"Wright","given":"Sarah"},{"family":"Sargeant","given":"Cora"},{"family":"Cortese","given":"Samuele"},{"family":"Wood-Downie","given":"Henry"}],"citation-key":"edwards2024","container-title":"Journal of Child Psychology and Psychiatry","DOI":"10.1111/jcpp.13855","ISSN":"1469-7610","issue":"1","issued":{"date-parts":[["2024"]]},"language":"en","page":"4-17","source":"Wiley Online Library","title":"Research Review: A systematic review and meta-analysis of sex differences in narrow constructs of restricted and repetitive behaviours and interests in autistic children, adolescents, and adults","title-short":"Research Review","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.13855","volume":"65"},
  {"id":"edwards2024a","abstract":"Background Evidence that autism often manifests differently between males and females is growing, particularly in terms of social interaction and communication, but it is unclear if there are sex differences in restricted and repetitive behaviours and interests (RRBIs) when rigorously focusing on the narrow construct level (i.e., stereotyped behaviour, restricted interests, insistence on sameness, and/or sensory experiences). Methods We conducted a systematic review and four random effects meta-analyses investigating sex differences in narrow construct measures of RRBIs in autistic children, adolescents, and adults (Prospero registration ID: CRD42021254221). Study quality was appraised using the Newcastle-Ottawa Quality Assessment Scale. Results Forty-six studies were narratively synthesised and 25 of these were included in four random effects meta-analyses. Results found that autistic males had significantly higher levels of stereotyped behaviours (SMD = 0.21, 95% confidence interval (CI) [0.09, 0.33], p < .001) and restricted interests (SMD = 0.18, 95% CI [0.07, 0.29], p < .001) compared to autistic females. In contrast, there were no significant sex differences for sensory experiences (SMD = −0.09, 95% CI [−0.27, 0.09], p = .32) and insistence on sameness (SMD = 0.01, 95% CI [−0.03, 0.05], p = .68). The findings from the narrative synthesis were generally consistent with those from the meta-analyses and also found qualitative sex differences in the way RRBIs manifest. Conclusions Our findings show significant differences in narrowly defined RRBIs in males and females. Practitioners need to be aware of such differences, which could be contributing to the under-recognition of autism in females and may not be captured by current diagnostic instruments.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Edwards","given":"Hannah"},{"family":"Wright","given":"Sarah"},{"family":"Sargeant","given":"Cora"},{"family":"Cortese","given":"Samuele"},{"family":"Wood-Downie","given":"Henry"}],"citation-key":"edwards2024a","container-title":"Journal of Child Psychology and Psychiatry","DOI":"10.1111/jcpp.13855","ISSN":"1469-7610","issue":"1","issued":{"date-parts":[["2024"]]},"language":"en","license":"© 2023 The Authors. Journal of Child Psychology and Psychiatry published by John Wiley & Sons Ltd on behalf of Association for Child and Adolescent Mental Health.","page":"4-17","source":"Wiley Online Library","title":"Research Review: A systematic review and meta-analysis of sex differences in narrow constructs of restricted and repetitive behaviours and interests in autistic children, adolescents, and adults","title-short":"Research Review","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1111/jcpp.13855","volume":"65"},
  {"id":"ekman1986","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Ekman","given":"Paul"},{"family":"Friesen","given":"Wallace V."}],"citation-key":"ekman1986","container-title":"Motivation and Emotion","container-title-short":"Motiv Emot","DOI":"10.1007/BF00992253","ISSN":"0146-7239, 1573-6644","issue":"2","issued":{"date-parts":[["1986",6]]},"language":"en","license":"http://www.springer.com/tdm","page":"159-168","source":"DOI.org (Crossref)","title":"A new pan-cultural facial expression of emotion","type":"article-journal","URL":"http://link.springer.com/10.1007/BF00992253","volume":"10"},
  {"id":"ekman1999","abstract":"Research suggests that most people cannot tell from demeanor when others are lying. Such poor performance is typical not only of lay people but also of most professionals concerned with lying. In this study, three professional groups with special interest or skill in deception, two law-enforcement groups (made up of 23 federal officers [mean age 40.8 yrs], 43 sheriffs [mean age 40.7 yrs], 84 federal judges [mean age 52.4 yrs], and 36 mixed law-enforcement officers [mean age 34.9 yrs]) and a select group of clinical psychologists (made up of 107 deception- interested clinical psychologists [mean age 49.6 yrs], 209 regular clinical psychologists [mean age 49.1 yrs], and 125 academic psychologists [mean age 39.2 yrs]), obtained high accuracy in judging videotapes of people who were lying or telling the truth about their opinions. These findings strengthen earlier evidence that some professional lie catchers are highly accurate, and that behavioral clues to lying are detectable in real time. This study also provides the first evidence that some psychologists can achieve high accuracy in catching lies. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","author":[{"family":"Ekman","given":"Paul"},{"family":"O'Sullivan","given":"Maureen"},{"family":"Frank","given":"Mark G."}],"citation-key":"ekman1999","container-title":"Psychological Science","DOI":"10.1111/1467-9280.00147","event-place":"United Kingdom","ISSN":"1467-9280","issue":"3","issued":{"date-parts":[["1999"]]},"page":"263-266","publisher":"Blackwell Publishing","publisher-place":"United Kingdom","source":"APA PsycNet","title":"A few can catch a liar","type":"article-journal","volume":"10"},
  {"id":"ekman2003","abstract":"Ekman and Friesen’s breakthrough research on the facial expression of emotion is richly illustrated with photographs depicting surprise, fear, disgust, anger, happiness and sadness. The authors explain how to identify these basic emotions correctly and how to tell when people try to mask, simulate or neutralize them. The book features several practical exercises that can help actors, teachers, salesmen, counselors, nurses, law-enforcement personnel and physicians – and everyone else who deals with people – become adept, perceptive readers of the facial expressions of emotions.","author":[{"family":"Ekman","given":"Paul"},{"family":"Friesen","given":"Wallace V."}],"citation-key":"ekman2003","event-place":"Cambridge, Mass.","ISBN":"978-1-883536-36-7","issued":{"date-parts":[["2003",12,2]]},"language":"English","number-of-pages":"232","publisher":"Malor Books","publisher-place":"Cambridge, Mass.","source":"Amazon","title":"Unmasking the Face: A Guide to Recognizing Emotions From Facial Expressions","title-short":"Unmasking the Face","type":"book"},
  {"id":"elkin2022","abstract":"Children and youth with Autism Spectrum Disorder (ASD) display difficulties recognizing and interacting with behavioral expressions of emotion, a deficit that makes social interaction problematic. Social skills training is foundational to the treatment of ASD, yet this intervention is costly, time-consuming, lacks objectivity, and is difficult to deliver in real-world settings. This pilot project investigated the use of an immersive virtual reality (IVR) headset to simulate real-world social interactions for children/youth with ASD. The primary objective was to describe gaze fixation and visual search behaviors during the simulated activity. Ten participants were enrolled and completed one social-skills training session in the IVR. The results demonstrate differential patterns between participants with mild, moderate, and severe ASD in the location and duration of gaze fixation as well as the patterns of visual searching. Although the results are preliminary, these differences may shed light on phenotypes within the continuum of ASD. Additionally, there may be value in quantifying gaze and visual search behaviors as an objective metric of interventional effectiveness for social-skills training therapy.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Elkin","given":"Thomas David"},{"family":"Zhang","given":"Yunxi"},{"family":"Reneker","given":"Jennifer C."}],"citation-key":"elkin2022","container-title":"Brain Sciences","DOI":"10.3390/brainsci12111568","ISSN":"2076-3425","issue":"11","issued":{"date-parts":[["2022",11]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"11","page":"1568","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Gaze Fixation and Visual Searching Behaviors during an Immersive Virtual Reality Social Skills Training Experience for Children and Youth with Autism Spectrum Disorder: A Pilot Study","title-short":"Gaze Fixation and Visual Searching Behaviors during an Immersive Virtual Reality Social Skills Training Experience for Children and Youth with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.mdpi.com/2076-3425/12/11/1568","volume":"12"},
  {"id":"elsabbagh2013","abstract":"Background\nEarly emerging characteristics of visual orienting have been associated with a wide range of typical and atypical developmental outcomes. In the current study, we examined the development of visual disengagement in infants at risk for autism.\nMethods\nWe measured the efficiency of disengaging from a central visual stimulus to orient to a peripheral one in a cohort of 104 infants with and without familial risk for autism by virtue of having an older sibling with autism.\nResults\nAt 7 months of age, disengagement was not robustly associated with later diagnostic outcomes. However, by 14 months, longer latencies to disengage in the subset of the risk group later diagnosed with autism was observed relative to other infants at risk and the low-risk control group. Moreover, between 7 months and 14 months, infants who were later diagnosed with autism at 36 months showed no consistent increases in the speed and flexibility of visual orienting. However, the latter developmental effect also characterized those infants who exhibited some form of developmental concerns (but not meeting criteria for autism) at 36 months.\nConclusions\nInfants who develop autism or other developmental concerns show atypicality in the development of visual attention skills from the first year of life.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Elsabbagh","given":"Mayada"},{"family":"Fernandes","given":"Janice"},{"family":"Jane Webb","given":"Sara"},{"family":"Dawson","given":"Geraldine"},{"family":"Charman","given":"Tony"},{"family":"Johnson","given":"Mark H."}],"citation-key":"elsabbagh2013","collection-title":"Oxytocin and Autism","container-title":"Biological Psychiatry","container-title-short":"Biological Psychiatry","DOI":"10.1016/j.biopsych.2012.11.030","ISSN":"0006-3223","issue":"3","issued":{"date-parts":[["2013",8,1]]},"page":"189-194","source":"ScienceDirect","title":"Disengagement of Visual Attention in Infancy is Associated with Emerging Autism in Toddlerhood","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0006322312010864","volume":"74"},
  {"id":"facultyofsocialsciencemasterprogramofpsychomotricity-psycho-traumaandlectureratuniversiteanglicandebukavudrcandrudolphkwanueuniversity-liberia.2024","abstract":"This study is the preliminary research focused on psychomotor therapy and body schemas for the intellectually disabled, hence the motor dimension with a test of balance, coordination and jumping in the pre-test and post-test of a BPM measurement at 60, 90 and 120 (BPM) with the YO and YC. The cognitive dimension with, for example, the Berces and Lezine test of body control and latero-spatial organization, the Piaget and Head tests of gesture imitation and latero-spatial organization. The affective dimension revolving around self-esteem was measured with the self-perception profile for adults with intellectual disabilities (SPPD) on physical appearance, athletic competence and psychomotor competence. At the end of the verification of research question and using methodological approach adopted on the present study on the motor dimension, the cognitive dimension and the affective dimension; it was found that with the motor dimension on the balance test, a trend on the performance of our intellectually disabled patients from A.D.A.R-Tubahoze centre during the psychomotor therapy sessions was tested positive in the post-test compared to the pre-test (BYO and BYC).With regard to the coordination test (CYO and CYC) at post-test and pre-test, the statistical frequencies with overall averages show that our intellectually impaired patients tended to obtain better results at posttest than at pre-test; this shows a success in the applicability of motor therapy to coordination disorder in intellectually impaired patients. Similarly, a positive performance trend was shown in the results of the jumping test at post-test than at pre-test. The trend in the results of the jump test (JYO and JYC) in the post-test than in the pre-test would have shown a positive result after our therapeutic-motor sessions with the IDs of the A.D.A.R. centre. From the cognitive dimension, using the test of imitation of gestures and lateral-spatial on different movements, has a score of 10 points in the test of imitation of simple gestures of hand movements, it would have been observed in MID patients that the test proved positive; with the Piaget’s Head test of latero-spatial organization administered to MID which was evaluated at a score of 40 points, had as a positive performance to all patients who took this test. The results of our work on the affective dimension of the dominant modality “Rather true”, was observed on items 12, 16, 20 and 24 of self-esteem, with physical appearance vis-à-vis items (5,10,18 and 22) and items 5 and 9 and then items 17, 13 and 1 of athletic competence; from items with a “Rather positive” modality with items 11, 3 and 2 3, 7, 15 and 19 of our MID patients that a positive trend on positive appreciation was satisfactorily observable.","accessed":{"date-parts":[["2025",3,3]]},"author":[{"literal":"Faculty of social science master program of psychomotricity-Psycho-trauma and lecturer at Université Anglican de Bukavu (DRC) and Rudolph Kwanue University-Liberia."},{"family":"Dieudonné","given":"Safari"},{"family":"Alice","given":"Cyuzuzo"},{"literal":"Midwife at Kibirizi Hospital and College Saint Bernard Kansi as midwife teacher, south province of Rwanda."}],"citation-key":"facultyofsocialsciencemasterprogramofpsychomotricity-psycho-traumaandlectureratuniversiteanglicandebukavudrcandrudolphkwanueuniversity-liberia.2024","container-title":"International Journal of Current Science Research and Review","container-title-short":"ijcsrr","DOI":"10.47191/ijcsrr/V7-i3-08","ISSN":"25818341","issue":"03","issued":{"date-parts":[["2024",3,6]]},"language":"en","source":"DOI.org (Crossref)","title":"Psychomotor Therapy Using the Body Schema for the Intellectually Disabled at the A.D.A.R-Tubahoze Centre","type":"article-journal","URL":"https://ijcsrr.org/single-view/?id=15337&pid=15277","volume":"07"},
  {"id":"farkhondeh2024","abstract":"Hand-Object Interaction (HOI) is gaining significant attention, particularly with the creation of numerous egocentric datasets driven by AR/VR applications. However, third-person view HOI has received less attention, especially in terms of datasets. Most third-person view datasets are curated for action recognition tasks and feature pre-segmented clips of high-level daily activities, leaving a gap for in-the-wild datasets. To address this gap, we propose ChildPlay-Hand, a novel dataset that includes person and object bounding boxes, as well as manipulation actions. ChildPlay-Hand is unique in: (1) providing per-hand annotations; (2) featuring videos in uncontrolled settings with natural interactions, involving both adults and children; (3) including gaze labels from the ChildPlay-Gaze dataset for joint modeling of manipulations and gaze. The manipulation actions cover the main stages of an HOI cycle, such as grasping, holding or operating, and different types of releasing. To illustrate the interest of the dataset, we study two tasks: object in hand detection (OiH), i.e. if a person has an object in their hand, and manipulation stages (ManiS), which is more fine-grained and targets the main stages of manipulation. We benchmark various spatio-temporal and segmentation networks, exploring body vs. hand-region information and comparing pose and RGB modalities. Our findings suggest that ChildPlay-Hand is a challenging new benchmark for modeling HOI in the wild.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Farkhondeh","given":"Arya"},{"family":"Tafasca","given":"Samy"},{"family":"Odobez","given":"Jean-Marc"}],"citation-key":"farkhondeh2024","DOI":"10.48550/arXiv.2409.09319","issued":{"date-parts":[["2024",9,14]]},"number":"arXiv:2409.09319","publisher":"arXiv","source":"arXiv.org","title":"ChildPlay-Hand: A Dataset of Hand Manipulations in the Wild","title-short":"ChildPlay-Hand","type":"article","URL":"http://arxiv.org/abs/2409.09319"},
  {"id":"fears2023","abstract":"Autistic children have differences in their movements which impact their functional performance. Virtual-reality enables researchers to study movement in safe, engaging environments. We used motion-capture to measure how 7–13-year-old autistic and neurotypical children make whole-body movements in a virtual-reality task. Although children in both groups were successful, we observed differences in their movements. Autistic children were less efficient moving to the target. Autistic children did not appear to use a movement strategy. While neurotypical children were more likely to overshoot near targets and undershoot far targets, autistic children did not modulate their strategy. Using kinematic data from tasks in virtual-reality, we can begin to understand the pattern of movement challenges experienced by autistic children.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Fears","given":"Nicholas E."},{"family":"Templin","given":"Tylan N."},{"family":"Sherrod","given":"Gabriela M."},{"family":"Bugnariu","given":"Nicoleta L."},{"family":"Patterson","given":"Rita M."},{"family":"Miller","given":"Haylie L."}],"citation-key":"fears2023","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-022-05523-0","ISSN":"1573-3432","issue":"7","issued":{"date-parts":[["2023",7,1]]},"language":"en","page":"2806-2817","source":"Springer Link","title":"Autistic Children Use Less Efficient Goal-Directed Whole Body Movements Compared to Neurotypical Development","type":"article-journal","URL":"https://doi.org/10.1007/s10803-022-05523-0","volume":"53"},
  {"id":"feng2022","abstract":"Gaze tracking is increasingly becoming an essential component in Augmented and Virtual Reality. Modern gaze tracking algorithms are heavyweight; they operate at most 5 Hz on mobile processors despite that near-eye cameras comfortably operate at a real-time rate (> 30 Hz). This paper presents a real-time eye tracking algorithm that, on average, operates at 30 Hz on a mobile processor, achieves 0.1°–0.5° gaze accuracies, all the while requiring only 30K parameters, one to two orders of magnitude smaller than state-of-the-art eye tracking algorithms. The crux of our algorithm is an Auto ROI mode, which continuously predicts the Regions of Interest (ROIs) of near-eye images and judiciously processes only the ROIs for gaze estimation. To that end, we introduce a novel, lightweight ROI prediction algorithm by emulating an event camera. We discuss how a software emulation of events enables accurate ROI prediction without requiring special hardware. The code of our paper is available at https://github.com/horizon-research/edgaze.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Feng","given":"Yu"},{"family":"Goulding-Hotta","given":"Nathan"},{"family":"Khan","given":"Asif"},{"family":"Reyserhove","given":"Hans"},{"family":"Zhu","given":"Yuhao"}],"citation-key":"feng2022","container-title":"2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","DOI":"10.1109/VR51125.2022.00059","event-title":"2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","ISSN":"2642-5254","issued":{"date-parts":[["2022",3]]},"page":"399-408","source":"IEEE Xplore","title":"Real-Time Gaze Tracking with Event-Driven Eye Segmentation","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9756796"},
  {"id":"fenoglio2022","abstract":"Manufacturers migrate their processes to Industry 4.0, which includes new technologies for improving productivity and efficiency of operations. One of the issues is capturing, recreating, and documenting the tacit knowledge of the aging workers. However, there are no systematic procedures to incorporate this knowledge into Enterprise Resource Planning systems and maintain a competitive advantage. This paper describes a solution proposal for a tacit knowledge elicitation process for capturing operational best practices of experienced workers in industrial domains based on a mix of algorithmic techniques and a cooperative game. We use domain ontologies for Industry 4.0 and reasoning techniques to discover and integrate new facts from textual sources into an Operational Knowledge Graph. We describe a concepts formation iterative process in a role game played by human and virtual agents through socialization and externalization for knowledge graph refinement. Ethical and societal concerns are discussed as well.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Fenoglio","given":"Enzo"},{"family":"Kazim","given":"Emre"},{"family":"Latapie","given":"Hugo"},{"family":"Koshiyama","given":"Adriano"}],"citation-key":"fenoglio2022","container-title":"Discover Artificial Intelligence","container-title-short":"Discov Artif Intell","DOI":"10.1007/s44163-022-00020-w","ISSN":"2731-0809","issue":"1","issued":{"date-parts":[["2022",3,10]]},"language":"en","page":"6","source":"Springer Link","title":"Tacit knowledge elicitation process for industry 4.0","type":"article-journal","URL":"https://doi.org/10.1007/s44163-022-00020-w","volume":"2"},
  {"id":"fida2023","abstract":"Human behavior is deeply influenced by emotions. Detection of emotions plays a pivotal role in understanding how individuals respond to various stimuli, such as reading text, encompassing feelings of anger, anxiety, confusion, or nervousness. Real-time facial emotion detection during online text reading represents an innovative approach for receiving immediate feedback based on readers’ emotional responses. Real-time emotion detection finds applications in interactive displays and holds immense potential for online learning platforms, where it can be utilized to analyze students’ emotional states and gauge their level of comprehension. Despite vast existing literature on emotion detection, real-time emotion detection is not very well studied. This study demonstrates the design and implementation of face emotion detection for students while they are using online learning platforms. The primary objective is capturing human emotions and storing them in the database after five seconds while they are reading online text. The system is implemented using SSD based on VB.NetV1. The proposed system has strong relevance for integration with online web applications to detect learners’ real-time emotions. Experiments are performed using CK+ and JAFFE face datasets and results show 96.46% and 98.43% accuracy, respectively. The system not only provides accurate results but also enables high-quality, robust, and real-time feedback based on the facial expressions of readers, facilitating a deeper understanding of students’ emotional engagement during their online learning experiences.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Fida","given":"Alisha"},{"family":"Umer","given":"Muhammad"},{"family":"Saidani","given":"Oumaima"},{"family":"Hamdi","given":"Monia"},{"family":"Alnowaiser","given":"Khaled"},{"family":"Bisogni","given":"Carmen"},{"family":"Abate","given":"Andrea F."},{"family":"Ashraf","given":"Imran"}],"citation-key":"fida2023","container-title":"Multimedia Tools and Applications","container-title-short":"Multimed Tools Appl","DOI":"10.1007/s11042-023-16722-x","ISSN":"1573-7721","issued":{"date-parts":[["2023",9,22]]},"language":"en","source":"Springer Link","title":"Real time emotions recognition through facial expressions","type":"article-journal","URL":"https://doi.org/10.1007/s11042-023-16722-x"},
  {"id":"forbes2025","abstract":"Oculomotor characteristics, including accuracy, timing, and sensorimotor processing, are considered sensitive intermediate phenotypes for understanding the etiology of neurodevelopmental conditions, such as autism and ADHD. Oculomotor characteristics have predominantly been studied separately in autism and ADHD. Despite the high rates of co-occurrence between these conditions, only one study has investigated oculomotor processes among those with co-occurring autism + ADHD. Four hundred and five (n = 405; 226 males) Australian children and adolescents aged 4 to 18 years (M = 9.64 years; SD = 3.20 years) with ADHD (n = 64), autism (n = 66), autism + ADHD (n = 146), or neurotypical individuals (n = 129) were compared across four different oculomotor tasks: visually guided saccade, anti-saccade, sinusoidal pursuit and step-ramp pursuit. Confirmatory analyses were conducted using separate datasets acquired from the University of Nottingham UK (n = 17 autism, n = 22 ADHD, n = 32 autism + ADHD, n = 30 neurotypical) and University of Kansas USA (n = 29 autism, n = 41 neurotypical). Linear mixed effect models controlling for sex, age and family revealed that children and adolescents with autism + ADHD exhibited increased variability in the accuracy of the final saccadic eye position compared to neurotypical children and adolescents. Autistic children and adolescents demonstrated a greater number of catch-up saccades during step-ramp pursuit compared to neurotypical children and adolescents. These findings suggest that select differences in saccadic precision are unique to autistic individuals with co-occurring ADHD, indicating that measuring basic sensorimotor processes may be useful for parsing neurodevelopment and clinical heterogeneity in autism.","accessed":{"date-parts":[["2025",2,4]]},"author":[{"family":"Forbes","given":"Elana J."},{"family":"Tiego","given":"Jeggan"},{"family":"Langmead","given":"Joshua"},{"family":"Unruh","given":"Kathryn E."},{"family":"Mosconi","given":"Matthew W."},{"family":"Finlay","given":"Amy"},{"family":"Kallady","given":"Kathryn"},{"family":"Maclachlan","given":"Lydia"},{"family":"Moses","given":"Mia"},{"family":"Cappel","given":"Kai"},{"family":"Knott","given":"Rachael"},{"family":"Chau","given":"Tracey"},{"family":"Sindhu","given":"Vishnu Priya Mohanakumar"},{"family":"Bellato","given":"Alessio"},{"family":"Groom","given":"Madeleine J."},{"family":"Kerestes","given":"Rebecca"},{"family":"Bellgrove","given":"Mark A."},{"family":"Johnson","given":"Beth P."}],"citation-key":"forbes2025","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-024-06718-3","ISSN":"1573-3432","issued":{"date-parts":[["2025",1,24]]},"language":"en","source":"Springer Link","title":"Oculomotor Function in Children and Adolescents with Autism, ADHD or Co-occurring Autism and ADHD","type":"article-journal","URL":"https://doi.org/10.1007/s10803-024-06718-3"},
  {"id":"francis2021","abstract":"Autism Spectrum Disorder (ASD) is a complex highly heritable disorder, in which multiple environmental factors interact with the genes to increase its risk and lead to variable clinical presentations and outcomes. Furthermore, the inherent fundamental deficits of ASD in social attention and interaction critically diverge children from the typical pathways of learning, “creating” what we perceive as autism syndrome during the first three years of life. Later in life, training and education, the presence and management of comorbidities, as well as social and vocational support throughout the lifespan, will define the quality of life and the adaptation of an individual with ASD. Given the overall burden of ASD, prevention strategies seem like a cost-effective endeavour that we have to explore. In this paper, we take a life course approach to prevention. We will review the possibilities of the management of risk factors from preconception until the perinatal period, that of early intervention in the first three years of life and that of effective training and support from childhood until adulthood.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Francis","given":"Konstantinos"},{"family":"Karantanos","given":"Georgios"},{"family":"Al-Ozairi","given":"Abdullah"},{"family":"AlKhadhari","given":"Sulaiman"}],"citation-key":"francis2021","container-title":"Brain Sciences","container-title-short":"Brain Sci","DOI":"10.3390/brainsci11020151","ISSN":"2076-3425","issue":"2","issued":{"date-parts":[["2021",1,24]]},"page":"151","PMCID":"PMC7911370","PMID":"33498888","source":"PubMed Central","title":"Prevention in Autism Spectrum Disorder: A Lifelong Focused Approach","title-short":"Prevention in Autism Spectrum Disorder","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7911370/","volume":"11"},
  {"id":"frazier2017","abstract":"Objective\nNumerous studies have identified abnormal gaze in individuals with autism. However, only some findings have been replicated, the magnitude of effects is unclear, and the pattern of gaze differences across stimuli remains poorly understood. To address these gaps, a comprehensive meta-analysis of autism eye-tracking studies was conducted.\nMethod\nPubMed and a manual search of 1,132 publications were used to identify studies comparing looking behavior to social and/or nonsocial stimuli between individuals with autism and controls. Sample characteristics, eye-tracking methods, stimulus features, and regions of interest (ROIs) were coded for each comparison within each study. Multivariate mixed-effects meta-regression analyses examined the impact of study methodology, stimulus features, and ROI on effect sizes derived from comparisons using gaze-fixation metrics.\nResults\nThe search yielded 122 independent studies with 1,155 comparisons. Estimated effect sizes tended to be small to medium but varied substantially across stimuli and ROIs. Overall, nonsocial ROIs yielded larger effect sizes than social ROIs; however, eye and whole-face regions from stimuli with human interaction produced the largest effects (Hedges g = 0.47 and 0.50, respectively). Studies with weaker study designs or reporting yielded larger effects, but key effects remained significant and medium in size, even for high-rigor designs.\nConclusion\nIndividuals with autism show a reliable pattern of gaze abnormalities that suggests a basic problem with selecting socially relevant versus irrelevant information for attention and that persists across ages and worsens during perception of human interactions. Aggregation of gaze abnormalities across stimuli and ROIs could yield clinically useful risk assessment and quantitative, objective outcome measurements.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Frazier","given":"Thomas W."},{"family":"Strauss","given":"Mark"},{"family":"Klingemier","given":"Eric W."},{"family":"Zetzer","given":"Emily E."},{"family":"Hardan","given":"Antonio Y."},{"family":"Eng","given":"Charis"},{"family":"Youngstrom","given":"Eric A."}],"citation-key":"frazier2017","container-title":"Journal of the American Academy of Child & Adolescent Psychiatry","container-title-short":"Journal of the American Academy of Child & Adolescent Psychiatry","DOI":"10.1016/j.jaac.2017.05.005","ISSN":"0890-8567","issue":"7","issued":{"date-parts":[["2017",7,1]]},"page":"546-555","source":"ScienceDirect","title":"A Meta-Analysis of Gaze Differences to Social and Nonsocial Information Between Individuals With and Without Autism","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0890856717302071","volume":"56"},
  {"id":"freire2022","abstract":"Maintaining a complex system, such as a modern production line, is a knowledge-intensive task. Many firms use maintenance reports as a decision support tool. However, reports are often poor quality and tedious to compile. A Conversational User Interface (CUI) could streamline the reporting process by validating the user’s input, eliciting more valuable information, and reducing the time needed. In this paper, we use a Technology Probe to explore the potential of a CUI to create instructional maintenance reports. We conducted a between-groups study (N = 24) in which participants had to replace the inner tube of a bicycle tire. One group documented the procedure using a CUI while replacing the inner tube, whereas the other group compiled a paper report afterward. The CUI was enacted by a researcher according to a set of rules. Our results indicate that using a CUI for maintenance reports saves a significant amount of time, is no more cognitively demanding than writing a report, and results in maintenance reports of higher quality.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Freire","given":"Samuel Kernan"},{"family":"Niforatos","given":"Evangelos"},{"family":"Rusak","given":"Zoltan"},{"family":"Aschenbrenner","given":"Doris"},{"family":"Bozzon","given":"Alessandro"}],"citation-key":"freire2022","collection-title":"CUI '22","container-title":"Proceedings of the 4th Conference on Conversational User Interfaces","DOI":"10.1145/3543829.3544516","event-place":"New York, NY, USA","ISBN":"978-1-4503-9739-1","issued":{"date-parts":[["2022",9,15]]},"page":"1–6","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"A Conversational User Interface for Instructional Maintenance Reports","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3543829.3544516"},
  {"id":"freire2023","abstract":"As agile manufacturing expands and workforce mobility increases, the importance of efficient knowledge transfer among factory workers grows. Cognitive Assistants (CAs) with Large Language Models (LLMs), like GPT-3.5, can bridge knowledge gaps and improve worker performance in manufacturing settings. This study investigates the opportunities, risks, and user acceptance of LLM-powered CAs in two factory contexts: textile and detergent production. Several opportunities and risks are identified through a literature review, proof-of-concept implementation, and focus group sessions. Factory representatives raise concerns regarding data security, privacy, and the reliability of LLMs in high-stake environments. By following design guidelines regarding persistent memory, real-time data integration, security, privacy, and ethical concerns, LLM-powered CAs can become valuable assets in manufacturing settings and other industries.","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Freire","given":"Samuel Kernan"},{"family":"Foosherian","given":"Mina"},{"family":"Wang","given":"Chaofan"},{"family":"Niforatos","given":"Evangelos"}],"citation-key":"freire2023","collection-title":"CUI '23","container-title":"Proceedings of the 5th International Conference on Conversational User Interfaces","DOI":"10.1145/3571884.3604313","event-place":"New York, NY, USA","ISBN":"979-8-4007-0014-9","issued":{"date-parts":[["2023",7,19]]},"page":"1–6","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Harnessing Large Language Models for Cognitive Assistants in Factories","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3571884.3604313"},
  {"id":"freire2024","abstract":"In the shift towards human-centered manufacturing, our two-year longitudinal study investigates the real-world impact of deploying Cognitive Assistants (CAs) in factories. The CAs were designed to facilitate knowledge sharing among factory operators. Our investigation focused on smartphone-based voice assistants and LLM-powered chatbots, examining their usability and utility in a real-world factory setting. Based on the qualitative feedback we collected during the deployments of CAs at the factories, we conducted a thematic analysis to investigate the perceptions, challenges, and overall impact on workflow and knowledge sharing. Our results indicate that while CAs have the potential to significantly improve efficiency through knowledge sharing and quicker resolution of production issues, they also introduce concerns around workplace surveillance, the types of knowledge that can be shared, and shortcomings compared to human-to-human knowledge sharing. Additionally, our findings stress the importance of addressing privacy, knowledge contribution burdens, and tensions between factory operators and their managers.","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Freire","given":"Samuel Kernan"},{"family":"He","given":"Tianhao"},{"family":"Wang","given":"Chaofan"},{"family":"Niforatos","given":"Evangelos"},{"family":"Bozzon","given":"Alessandro"}],"citation-key":"freire2024","DOI":"10.48550/arXiv.2409.20192","issued":{"date-parts":[["2024",9,30]]},"number":"arXiv:2409.20192","publisher":"arXiv","source":"arXiv.org","title":"Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing: Challenges, Risks, and Impact on Work","title-short":"Factory Operators' Perspectives on Cognitive Assistants for Knowledge Sharing","type":"article","URL":"http://arxiv.org/abs/2409.20192"},
  {"id":"freire2024a","abstract":"Recent advances in natural language processing enable more intelligent ways to support knowledge sharing in factories. In manufacturing, operating production lines has become increasingly knowledge-intensive, putting strain on a factory's capacity to train and support new operators. This paper introduces a Large Language Model (LLM)-based system designed to retrieve information from the extensive knowledge contained in factory documentation and knowledge shared by expert operators. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. We conducted a user study at a factory to assess its potential impact and adoption, eliciting several perceived benefits, namely, enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several commercial and open-sourced LLMs for this system. The current state-of-the-art model, GPT-4, consistently outperformed its counterparts, with open-source models trailing closely, presenting an attractive option given their data privacy and customization benefits. In summary, this work offers preliminary insights and a system design for factories considering using LLM tools for knowledge management.","author":[{"family":"Freire","given":"Samuel Kernan"},{"family":"Wang","given":"Chaofan"},{"family":"Foosherian","given":"Mina"},{"family":"Wellsandt","given":"Stefan"},{"family":"Ruiz-Arenas","given":"Santiago"},{"family":"Niforatos","given":"Evangelos"}],"citation-key":"freire2024a","container-title":"Frontiers in Artificial Intelligence","container-title-short":"Front Artif Intell","DOI":"10.3389/frai.2024.1293084","ISSN":"2624-8212","issued":{"date-parts":[["2024"]]},"language":"eng","page":"1293084","PMCID":"PMC11004332","PMID":"38601111","source":"PubMed","title":"Knowledge sharing in manufacturing using LLM-powered tools: user study and model benchmarking","title-short":"Knowledge sharing in manufacturing using LLM-powered tools","type":"article-journal","volume":"7"},
  {"id":"freire2025","abstract":"Modern factories showlittle resemblance to the assembly lines froma century ago. Nowadays, a single human might be responsible for setting up, operating, and maintaining a complex chain of machines. This shift has made the work of factory operators more cognitively demanding, requiring constant monitoring and problem-solving. Key to tackling these challenges is the effective collaboration of human operators in exchanging ideas and knowledge, from high-level problem-solving strategies to solutions for emerging issues. Yet, the heightened productivity requirements and small shifts mean fewer opportunities to share this knowledge face-to-face and reporting practices are deprioritized. Thus, the manufacturing industry faces a knowledge management crisis.<br/>This dissertation investigates the integration of conversational AI assistants into manufacturing settings to facilitate knowledge sharing among factory operators. Capitalizing on recent advancements in Natural Language Processing (NLP), particularly in Large Language Models (LLMs), this research investigates the designing and evaluation of conversational AI tools that efficiently capture and share human knowledge on the factory floor while addressing operator needs and concerns. The introduction of conversational AI assistants for knowledge sharing—referred to as cognitive assistants (CA) in this work—in factory environments promises significant benefits but comes with numerous challenges....","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Freire","given":"Samuel Kernan"}],"citation-key":"freire2025","issued":{"date-parts":[["2025"]]},"language":"en","source":"repository.tudelft.nl","title":"LLM-Powered Cognitive Assistants for Knowledge Sharing among Factory Operators","type":"article-journal","URL":"https://repository.tudelft.nl/record/uuid:733e10e7-890c-48a7-86d3-fa782ffd65c8"},
  {"id":"frye2019","abstract":"Autism spectrum disorder (ASD) affects approximately 2% of children in the United States (US) yet its etiology is unclear and effective treatments are lacking. Therapeutic interventions are most effective if started early in life, yet diagnosis often remains delayed, partly because the diagnosis of ASD is based on identifying abnormal behaviors that may not emerge until the disorder is well established. Biomarkers that identify children at risk during the pre-symptomatic period, assist with early diagnosis, confirm behavioral observations, stratify patients into subgroups, and predict therapeutic response would be a great advance. Here we underwent a systematic review of the literature on ASD to identify promising biomarkers and rated the biomarkers in regards to a Level of Evidence and Grade of Recommendation using the Oxford Centre for Evidence-Based Medicine scale. Biomarkers identified by our review included physiological biomarkers that identify neuroimmune and metabolic abnormalities, neurological biomarkers including abnormalities in brain structure, function and neurophysiology, subtle behavioral biomarkers including atypical development of visual attention, genetic biomarkers and gastrointestinal biomarkers. Biomarkers of ASD may be found prior to birth and after diagnosis and some may predict response to specific treatments. Many promising biomarkers have been developed for ASD. However, many biomarkers are preliminary and need to be validated and their role in the diagnosis and treatment of ASD needs to be defined. It is likely that biomarkers will need to be combined to be effective to identify ASD early and guide treatment.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Frye","given":"Richard E."},{"family":"Vassall","given":"Sarah"},{"family":"Kaur","given":"Gurjot"},{"family":"Lewis","given":"Christina"},{"family":"Karim","given":"Mohammand"},{"family":"Rossignol","given":"Daniel"}],"citation-key":"frye2019","container-title":"Annals of Translational Medicine","container-title-short":"Ann Transl Med","DOI":"10.21037/atm.2019.11.53","ISSN":"2305-5839","issue":"23","issued":{"date-parts":[["2019",12]]},"page":"792","PMCID":"PMC6989979","PMID":"32042808","source":"PubMed Central","title":"Emerging biomarkers in autism spectrum disorder: a systematic review","title-short":"Emerging biomarkers in autism spectrum disorder","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6989979/","volume":"7"},
  {"id":"gallagher2022","abstract":"This edition of Irish Journal of Psychological Medicine is a Special Themed Issue on Autism Spectrum Disorders (ASD). Mental health services are not currently meeting the needs of autistic people across the lifespan. We have limited evidence based treatments for core symptoms and comorbidities and there is lack of awareness and under-recognition of ASD, particularly in adults and certain groups of individuals. The key themes in this edition focus on challenges with recognition and diagnosis and address these from both clinical and research perspectives. Co-occurring conditions also feature, which are also under-recognised and can contribute to less optimal outcomes. New and existing research developments in stratification for clinical trials and neuroimaging are also discussed. We hope this Issue highlights relevant current issues in ASD, and provides insights which can help address the challenges in providing evidence based pathways to better meet the needs of autistic people into the future.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Gallagher","given":"L."},{"family":"McGrath","given":"J."}],"citation-key":"gallagher2022","container-title":"Irish Journal of Psychological Medicine","DOI":"10.1017/ipm.2022.34","ISSN":"0790-9667, 2051-6967","issue":"3","issued":{"date-parts":[["2022",9]]},"language":"en","page":"237-239","source":"Cambridge University Press","title":"Autism spectrum disorders: current issues and future directions","title-short":"Autism spectrum disorders","type":"article-journal","URL":"https://www.cambridge.org/core/journals/irish-journal-of-psychological-medicine/article/autism-spectrum-disorders-current-issues-and-future-directions/ED00F8E8FA48910CD814968A9866DE46","volume":"39"},
  {"id":"ganai2025","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder diagnosed by clinicians and experts through questionnaires, observations, and interviews. Current diagnostic practices focus on social and communication impairments, which often emerge later in life. This delay in detection results in missed opportunities for early intervention. Gait, a motor behavior, has been previously shown to be aberrant in children with ASD and may be a biomarker for early detection and diagnosis of ASD. The current study assessed gait in children with ASD using a single RGB camera-based pose estimation method by MediaPipe (MP). Data from 32 children with ASD and 29 typically developing (TD) children were collected. The ASD group exhibited significantly reduced step length and right elbow° and increased right shoulder° relative to TD children. Four machine learning (ML) algorithms were employed to classify the ASD and TD children based on the statistically significant gait parameters. The binomial logistic regression (Logit) performed the best, with an accuracy of 0.82, in classifying the ASD and TD children. The present study demonstrates the use of gait analysis and ML techniques for the early detection of ASD.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Ganai","given":"Umer Jon"},{"family":"Ratne","given":"Aditya"},{"family":"Bhushan","given":"Braj"},{"family":"Venkatesh","given":"K. S."}],"citation-key":"ganai2025","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-025-85348-w","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2025",1,6]]},"language":"en","license":"2025 The Author(s)","page":"873","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Early detection of autism spectrum disorder: gait deviations and machine learning","title-short":"Early detection of autism spectrum disorder","type":"article-journal","URL":"https://www.nature.com/articles/s41598-025-85348-w","volume":"15"},
  {"id":"gehrig2021","abstract":"Once an academic venture, autonomous driving has received unparalleled corporate funding in the last decade. Still, operating conditions of current autonomous cars are mostly restricted to ideal scenarios. This means that driving in challenging illumination conditions such as night, sunrise, and sunset remains an open problem. In these cases, standard cameras are being pushed to their limits in terms of low light and high dynamic range performance. To address these challenges, we propose, DSEC, a new dataset that contains such demanding illumination conditions and provides a rich set of sensory data. DSEC offers data from a wide-baseline stereo setup of two color frame cameras and two high-resolution monochrome event cameras. In addition, we collect lidar data and RTK GPS measurements, both hardware synchronized with all camera data. One of the distinctive features of this dataset is the inclusion of high-resolution event cameras. Event cameras have received increasing attention for their high temporal resolution and high dynamic range performance. However, due to their novelty, event camera datasets in driving scenarios are rare. This work presents the first high resolution, large scale stereo dataset with event cameras. The dataset contains 53 sequences collected by driving in a variety of illumination conditions and provides ground truth disparity for the development and evaluation of event-based stereo algorithms.","accessed":{"date-parts":[["2024",6,11]]},"author":[{"family":"Gehrig","given":"Mathias"},{"family":"Aarents","given":"Willem"},{"family":"Gehrig","given":"Daniel"},{"family":"Scaramuzza","given":"Davide"}],"citation-key":"gehrig2021","container-title":"IEEE Robotics and Automation Letters","DOI":"10.1109/LRA.2021.3068942","ISSN":"2377-3766","issue":"3","issued":{"date-parts":[["2021",7]]},"page":"4947-4954","source":"IEEE Xplore","title":"DSEC: A Stereo Event Camera Dataset for Driving Scenarios","title-short":"DSEC","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9387069","volume":"6"},
  {"id":"gehrig2023","abstract":"We present Recurrent Vision Transformers (RVTs), a novel backbone for object detection with event cameras. Event cameras provide visual information with submillisecond latency at a high-dynamic range and with strong robustness against motion blur. These unique properties offer great potential for low-latency object detection and tracking in time-critical scenarios. Prior work in event-based vision has achieved outstanding detection performance but at the cost of substantial inference time, typically beyond 40 milliseconds. By revisiting the high-level design of recurrent vision backbones, we reduce inference time by a factor of 6 while retaining similar performance. To achieve this, we explore a multi-stage design that utilizes three key concepts in each stage: ﬁrst, a convolutional prior that can be regarded as a conditional positional embedding. Second, local and dilated global self-attention for spatial feature interaction. Third, recurrent temporal feature aggregation to minimize latency while retaining temporal information. RVTs can be trained from scratch to reach state-of-the-art performance on event-based object detection - achieving an mAP of 47.2% on the Gen1 automotive dataset. At the same time, RVTs offer fast inference (< 12 ms on a T4 GPU) and favorable parameter efﬁciency (5× fewer than prior art). Our study brings new insights into effective design choices that can be fruitful for research beyond event-based vision.","accessed":{"date-parts":[["2024",6,14]]},"author":[{"family":"Gehrig","given":"Mathias"},{"family":"Scaramuzza","given":"Davide"}],"citation-key":"gehrig2023","container-title":"2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","DOI":"10.1109/CVPR52729.2023.01334","event-place":"Vancouver, BC, Canada","event-title":"2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","ISBN":"979-8-3503-0129-8","issued":{"date-parts":[["2023",6]]},"language":"en","license":"https://doi.org/10.15223/policy-029","page":"13884-13893","publisher":"IEEE","publisher-place":"Vancouver, BC, Canada","source":"DOI.org (Crossref)","title":"Recurrent Vision Transformers for Object Detection with Event Cameras","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10204090/"},
  {"id":"gehrig2024","abstract":"The computer vision algorithms used currently in advanced driver assistance systems rely on image-based RGB cameras, leading to a critical bandwidth–latency trade-off for delivering safe driving experiences. To address this, event cameras have emerged as alternative vision sensors. Event cameras measure the changes in intensity asynchronously, offering high temporal resolution and sparsity, markedly reducing bandwidth and latency requirements1. Despite these advantages, event-camera-based algorithms are either highly efficient but lag behind image-based ones in terms of accuracy or sacrifice the sparsity and efficiency of events to achieve comparable results. To overcome this, here we propose a hybrid event- and frame-based object detector that preserves the advantages of each modality and thus does not suffer from this trade-off. Our method exploits the high temporal resolution and sparsity of events and the rich but low temporal resolution information in standard images to generate efficient, high-rate object detections, reducing perceptual and computational latency. We show that the use of a 20 frames per second (fps) RGB camera plus an event camera can achieve the same latency as a 5,000-fps camera with the bandwidth of a 45-fps camera without compromising accuracy. Our approach paves the way for efficient and robust perception in edge-case scenarios by uncovering the potential of event cameras2.","accessed":{"date-parts":[["2024",6,11]]},"author":[{"family":"Gehrig","given":"Daniel"},{"family":"Scaramuzza","given":"Davide"}],"citation-key":"gehrig2024","container-title":"Nature","DOI":"10.1038/s41586-024-07409-w","ISSN":"1476-4687","issue":"8014","issued":{"date-parts":[["2024",5]]},"language":"en","license":"2024 The Author(s)","page":"1034-1040","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Low-latency automotive vision with event cameras","type":"article-journal","URL":"https://www.nature.com/articles/s41586-024-07409-w","volume":"629"},
  {"id":"geraets2021","abstract":"Immersive virtual reality (VR) has been identified as a potentially revolutionary tool for psychological interventions. This study reviews current advances in immersive VR-based therapies for mental disorders. VR has the potential to make psychiatric treatments better and more cost-effective and to make them available to a larger group of patients. However, this may require a new generation of VR therapeutic techniques that use the full potential of VR, such as embodiment, and self-led interventions. VR-based interventions are promising, but further well-designed studies are needed that use novel techniques and investigate efficacy, efficiency, and cost-effectiveness of VR interventions compared with current treatments. This will be crucial for implementation and dissemination of VR in regular clinical practice.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Geraets","given":"Chris N. W."},{"family":"Stouwe","given":"Elisabeth C. D.","non-dropping-particle":"van der"},{"family":"Pot-Kolder","given":"Roos"},{"family":"Veling","given":"Wim"}],"citation-key":"geraets2021","collection-title":"Psychopathology","container-title":"Current Opinion in Psychology","container-title-short":"Current Opinion in Psychology","DOI":"10.1016/j.copsyc.2021.02.004","ISSN":"2352-250X","issued":{"date-parts":[["2021",10,1]]},"page":"40-45","source":"ScienceDirect","title":"Advances in immersive virtual reality interventions for mental disorders: A new reality?","title-short":"Advances in immersive virtual reality interventions for mental disorders","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S2352250X21000142","volume":"41"},
  {"id":"gjoreski2022","abstract":"Using a novel wearable surface electromyography (sEMG), we investigated induced affective states by measuring the activation of facial muscles traditionally associated with positive (left/right orbicularis and left/right zygomaticus) and negative expressions (the corrugator muscle). In a sample of 38 participants that watched 25 affective videos in a virtual reality environment, we found that each of the three variables examined—subjective valence, subjective arousal, and objective valence measured via the validated video types (positive, neutral, and negative)—sEMG amplitude varied significantly depending on video content. sEMG aptitude from “positive muscles” increased when participants were exposed to positively valenced stimuli compared with stimuli that was negatively valenced. In contrast, activation of “negative muscles” was elevated following exposure to negatively valenced stimuli compared with positively valenced stimuli. High arousal videos increased muscle activations compared to low arousal videos in all the measured muscles except the corrugator muscle. In line with previous research, the relationship between sEMG amplitude as a function of subjective valence was V-shaped.","accessed":{"date-parts":[["2024",8,21]]},"author":[{"family":"Gjoreski","given":"Martin"},{"family":"Kiprijanovska","given":"Ivana"},{"family":"Stankoski","given":"Simon"},{"family":"Mavridou","given":"Ifigeneia"},{"family":"Broulidakis","given":"M. John"},{"family":"Gjoreski","given":"Hristijan"},{"family":"Nduka","given":"Charles"}],"citation-key":"gjoreski2022","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-022-21456-1","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2022",10,7]]},"language":"en","license":"2022 The Author(s)","page":"16876","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Facial EMG sensing for monitoring affect using a wearable device","type":"article-journal","URL":"https://www.nature.com/articles/s41598-022-21456-1","volume":"12"},
  {"id":"goh2024","abstract":"Virtual Reality (VR) is revolutionizing healthcare research and practice by offering innovative methodologies across various clinical conditions. Advances in VR technology enable the creation of controllable, multisensory 3D environments, making it an appealing tool for capturing and quantifying behavior in realistic scenarios. This paper details the application of VR as a tool for neurocognitive evaluation, specifically in attention process assessment, an area of relevance for informing the diagnosis of childhood health conditions such as Attention Deficit Hyperactivity Disorder (ADHD). The data presented focuses on attention performance results from a large sample (n=837) of neurotypical male and female children (ages 6-13) tested on a visual continuous performance task, administered within an immersive VR classroom environment. The results indicate systematic improvements on most metrics across the age span and sex differences are noted on key variables thought to reflect differential measures of hyperactivity and inattention in children with ADHD. This data was collected to create a normative baseline database for use to inform comparisons with the performances of children with ADHD to support diagnostic decision-making in this area. The results indicate that VR technology can provide a safe and viable option for testing attention processes in children under stimulus conditions that closely mimic ecologically relevant challenges found in everyday life. In response to these stimulus conditions, VR can support advanced methods for capturing and quantifying users' behavioral responses. VR offers a more systematic and objective approach for clinical assessment and intervention, and provides conceptual support for its use in a wide variety of healthcare contexts.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Goh","given":"Crystal"},{"family":"Ma","given":"Yu"},{"family":"Rizzo","given":"Albert"}],"citation-key":"goh2024","container-title":"Frontiers in Virtual Reality","container-title-short":"Front. Virtual Real.","DOI":"10.3389/frvir.2024.1309176","ISSN":"2673-4192","issued":{"date-parts":[["2024",4,4]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Normative performance data on visual attention in neurotypical children: virtual reality assessment of cognitive and psychomotor development","title-short":"Normative performance data on visual attention in neurotypical children","type":"article-journal","URL":"https://www.frontiersin.org/articles/10.3389/frvir.2024.1309176","volume":"5"},
  {"id":"goldblum2023","archive_location":"UNC-Chapel Hill","author":[{"family":"Goldblum","given":""}],"citation-key":"goldblum2023","issued":{"date-parts":[["2023"]]},"language":"http://id.loc.gov/vocabulary/iso639-2/eng","title":"THE TODDLER REMOTE ASSESSMENT OF VIRTUAL EYE TRACKING AND LANGUAGE (TRAVEL) STUDY: AN EYE TRACKING AND BEHAVIORAL ASSESSMENT OF JOINT ATTENTION AT HOME","type":"Dissertation"},
  {"id":"gong2022","abstract":"With the recent development of microexpression recognition, deep learning (DL) has been widely applied in this ﬁeld. In this paper, we provide a comprehensive survey of the current DL-based microexpression (ME) recognition methods. In addition, we introduce a novel dataset based on fusing all the existing ME datasets. We also evaluate a baseline DL for the microexpression recognition task. Finally, we make the new dataset and the code publicly available to the community at https://github.com/wenjgong/microExpressionSurvey.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Gong","given":"Wenjuan"},{"family":"An","given":"Zhihong"},{"family":"Elfiky","given":"Noha M."}],"citation-key":"gong2022","container-title":"Neural Computing and Applications","container-title-short":"Neural Comput & Applic","DOI":"10.1007/s00521-022-07157-w","ISSN":"0941-0643, 1433-3058","issue":"12","issued":{"date-parts":[["2022",6]]},"language":"en","page":"9537-9560","source":"DOI.org (Crossref)","title":"Deep learning-based microexpression recognition: a survey","title-short":"Deep learning-based microexpression recognition","type":"article-journal","URL":"https://link.springer.com/10.1007/s00521-022-07157-w","volume":"34"},
  {"id":"gotham2009","abstract":"The aim of this study is to standardize Autism Diagnostic Observation Schedule (ADOS) scores within a large sample to approximate an autism severity metric. Using a dataset of 1415 individuals aged 2–16 years with autism spectrum disorders (ASD) or nonspectrum diagnoses, a subset of 1807 assessments from 1118 individuals with ASD were divided into narrow age- and language-cells. Within each cell, severity scores were based on percentiles of raw totals corresponding to each ADOS diagnostic classification. Calibrated severity scores had more uniform distributions across developmental groups and were less influenced by participant demographics than raw totals. This metric should be useful in comparing assessments across modules and time, and identifying trajectories of autism severity for clinical, genetic, and neurobiological research.","accessed":{"date-parts":[["2025",2,5]]},"author":[{"family":"Gotham","given":"Katherine"},{"family":"Pickles","given":"Andrew"},{"family":"Lord","given":"Catherine"}],"citation-key":"gotham2009","container-title":"Journal of autism and developmental disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-008-0674-3","ISSN":"0162-3257","issue":"5","issued":{"date-parts":[["2009",5]]},"page":"693-705","PMCID":"PMC2922918","PMID":"19082876","source":"PubMed Central","title":"Standardizing ADOS Scores for a Measure of Severity in Autism Spectrum Disorders","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2922918/","volume":"39"},
  {"id":"gowen2020","abstract":"This study investigated whether reduced visual attention to an observed action might account for altered imitation in autistic adults. A total of 22 autistic and 22 non-autistic adults observed and then imitated videos of a hand producing sequences of movements that differed in vertical elevation while their hand and eye movements were recorded. Participants first performed a block of imitation trials with general instructions to imitate the action. They then performed a second block with explicit instructions to attend closely to the characteristics of the movement. Imitation was quantified according to how much participants modulated their movement between the different heights of the observed movements. In the general instruction condition, the autistic group modulated their movements significantly less compared to the non-autistic group. However, following instructions to attend to the movement, the autistic group showed equivalent imitation modulation to the non-autistic group. Eye movement recording showed that the autistic group spent significantly less time looking at the hand movement for both instruction conditions. These findings show that visual attention contributes to altered voluntary imitation in autistic individuals and have implications for therapies involving imitation as well as for autistic people’s ability to understand the actions of others.","accessed":{"date-parts":[["2024",6,19]]},"author":[{"family":"Gowen","given":"Emma"},{"family":"Vabalas","given":"Andrius"},{"family":"Casson","given":"Alexander J"},{"family":"Poliakoff","given":"Ellen"}],"citation-key":"gowen2020","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/1362361319882810","ISSN":"1362-3613","issue":"3","issued":{"date-parts":[["2020",4,1]]},"language":"en","page":"730-743","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Instructions to attend to an observed action increase imitation in autistic adults","type":"article-journal","URL":"https://doi.org/10.1177/1362361319882810","volume":"24"},
  {"id":"green2019","abstract":"We review the recent literature regarding the implications of gender on the diagnosis and treatment of autism spectrum disorder (ASD) in women and adolescent females. We also discuss important clinical observations in treating this population.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Green","given":"Renée M."},{"family":"Travers","given":"Alyssa M."},{"family":"Howe","given":"Yamini"},{"family":"McDougle","given":"Christopher J."}],"citation-key":"green2019","container-title":"Current Psychiatry Reports","container-title-short":"Curr Psychiatry Rep","DOI":"10.1007/s11920-019-1006-3","ISSN":"1535-1645","issue":"4","issued":{"date-parts":[["2019",3,9]]},"language":"en","page":"22","source":"Springer Link","title":"Women and Autism Spectrum Disorder: Diagnosis and Implications for Treatment of Adolescents and Adults","title-short":"Women and Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s11920-019-1006-3","volume":"21"},
  {"id":"griffin2025","abstract":"Background\nReduced social attention—looking at faces—is one of the most common manifestations of social difficulty in autism that is central to social development. Although reduced social attention is well characterized in autism, qualitative differences in how social attention unfolds across time remains unknown.\nMethods\nWe used a computational modeling (i.e., hidden Markov modeling) approach to assess and compare the spatiotemporal dynamics of social attention in a large, well-characterized sample of children with autism (n = 280) and neurotypical children (n = 119) (ages 6–11) who completed 3 social eye-tracking assays at 3 longitudinal time points (baseline, 6 weeks, 24 weeks).\nResults\nOur analysis supported the existence of 2 common eye movement patterns that emerged across 3 eye-tracking assays. A focused pattern was characterized by small face regions of interest, which had high a probability of capturing fixations early in visual processing. In contrast, an exploratory pattern was characterized by larger face regions of interest, with a lower initial probability of fixation and more nonsocial regions of interest. In the context of social perception, children with autism showed significantly more exploratory eye movement patterns than neurotypical children across all social perception assays and all 3 longitudinal time points. Eye movement patterns were associated with clinical features of autism, including adaptive function, face recognition, and autism symptom severity.\nConclusions\nDecreased likelihood of precisely looking at faces early in social visual processing may be an important feature of autism that is associated with autism-related symptomology and may reflect less visual sensitivity to face information.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Griffin","given":"Jason W."},{"family":"Naples","given":"Adam"},{"family":"Bernier","given":"Raphael"},{"family":"Chawarska","given":"Katarzyna"},{"family":"Dawson","given":"Geraldine"},{"family":"Dziura","given":"James"},{"family":"Faja","given":"Susan"},{"family":"Jeste","given":"Shafali"},{"family":"Kleinhans","given":"Natalia"},{"family":"Sugar","given":"Catherine"},{"family":"Webb","given":"Sara Jane"},{"family":"Shic","given":"Frederick"},{"family":"McPartland","given":"James C."}],"citation-key":"griffin2025","container-title":"Biological Psychiatry: Cognitive Neuroscience and Neuroimaging","container-title-short":"Biological Psychiatry: Cognitive Neuroscience and Neuroimaging","DOI":"10.1016/j.bpsc.2024.08.017","ISSN":"2451-9022","issue":"1","issued":{"date-parts":[["2025",1,1]]},"page":"45-57","source":"ScienceDirect","title":"Spatiotemporal Eye Movement Dynamics Reveal Altered Face Prioritization in Early Visual Processing Among Autistic Children","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S2451902224002520","volume":"10"},
  {"id":"grzadzinski2016","abstract":"Psychometric properties and initial validity of the Brief Observation of Social Communication Change (BOSCC), a measure of treatment-response for social-communication behaviors, are described. The BOSCC coding scheme is applied to 177 video observations of 56 young children with ASD and minimal language abilities. The BOSCC has high to excellent inter-rater and test–retest reliability and shows convergent validity with measures of language and communication skills. The BOSCC Core total demonstrates statistically significant amounts of change over time compared to a no change alternative while the ADOS CSS over the same period of time did not. This work is a first step in the development of a novel outcome measure for social-communication behaviors with applications to clinical trials and longitudinal studies.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Grzadzinski","given":"Rebecca"},{"family":"Carr","given":"Themba"},{"family":"Colombi","given":"Costanza"},{"family":"McGuire","given":"Kelly"},{"family":"Dufek","given":"Sarah"},{"family":"Pickles","given":"Andrew"},{"family":"Lord","given":"Catherine"}],"citation-key":"grzadzinski2016","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-016-2782-9","ISSN":"1573-3432","issue":"7","issued":{"date-parts":[["2016",7,1]]},"language":"en","page":"2464-2479","source":"Springer Link","title":"Measuring Changes in Social Communication Behaviors: Preliminary Development of the Brief Observation of Social Communication Change (BOSCC)","title-short":"Measuring Changes in Social Communication Behaviors","type":"article-journal","URL":"https://doi.org/10.1007/s10803-016-2782-9","volume":"46"},
  {"id":"guo2023","abstract":"Micro-expressions are facial movements of short duration and low amplitude, which, upon analysis, can reveal genuine human emotions. However, the low frame rate of frame-based cameras hinders the further advancement of micro-expression recognition (MER). A novel technology, event-based cameras, boasting high frame rates and low latency, proves suitable for the MER task but remains challenging to obtain. In this article, a local event feature, namely the local count image, is proposed. This feature is calculated from up-sampled video using the SloMo method. Additionally, a global-local event feature fusion network is constructed, wherein the local count image and the global dense optical flow are merged to map deeper features and effectively address the MER task. Experimental results demonstrate that the proposed light-weighted method outperforms state-of-the-art approaches across multiple datasets. To our best knowledges that this work marks the first successful attempt to solve the MER task from an event perspective, thus facilitating the future promotion of event-based camera technology and providing inspiration for future research endeavors in related domains.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Guo","given":"Cunhan"},{"family":"Huang","given":"Heyan"}],"citation-key":"guo2023","collection-title":"FME '23","container-title":"Proceedings of the 3rd Workshop on Facial Micro-Expression: Advanced Techniques for Multi-Modal Facial Expression Analysis","DOI":"10.1145/3607829.3616446","event-place":"New York, NY, USA","ISBN":"979-8-4007-0285-3","issued":{"date-parts":[["2023",10,29]]},"page":"17–24","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"GLEFFN: A Global-Local Event Feature Fusion Network for Micro-Expression Recognition","title-short":"GLEFFN","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3607829.3616446"},
  {"id":"gupta2024","abstract":"There is little research on how Virtual Reality (VR) applications can identify and respond meaningfully to users' emotional changes. In this paper, we investigate the impact of Context-Aware Empathic VR (CAEVR) on the emotional and cognitive aspects of user experience in VR. We developed a real-time emotion prediction model using electroencephalography (EEG), electrodermal activity (EDA), and heart rate variability (HRV) and used this in personalized and generalized models for emotion recognition. We then explored the application of this model in a context-aware empathic (CAE) virtual agent and an emotion-adaptive (EA) VR environment. We found a significant increase in positive emotions, cognitive load, and empathy toward the CAE agent, suggesting the potential of CAEVR environments to refine user-agent interactions. We identify lessons learned from this study and directions for future work.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Gupta","given":"Kunal"},{"family":"Zhang","given":"Yuewei"},{"family":"Gunasekaran","given":"Tamil Selvan"},{"family":"Krishna","given":"Nanditha"},{"family":"Pai","given":"Yun Suen"},{"family":"Billinghurst","given":"Mark"}],"citation-key":"gupta2024","container-title":"IEEE Transactions on Visualization and Computer Graphics","DOI":"10.1109/TVCG.2024.3372130","ISSN":"1941-0506","issue":"5","issued":{"date-parts":[["2024",5]]},"page":"2671-2681","source":"IEEE Xplore","title":"CAEVR: Biosignals-Driven Context-Aware Empathy in Virtual Reality","title-short":"CAEVR","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/10458349","volume":"30"},
  {"id":"gupta2024a","abstract":"Human gaze plays a crucial role in communication and social interaction. Many recent studies have focused on predicting the 2D pixel location of a person's gaze target in an image. However, this approach has limitations when it comes to studying gaze for downstream applications that require analysis of higher-level social gaze behaviors. Previous works have post-processed the predicted 2D gaze target for social gaze prediction, however, we show that this approach is insufficient. Our proposed method jointly predicts the gaze target and social gaze behaviour, explicitly incorporating people interaction for state of the art results on three social gaze tasks - looking at heads, mutual gaze and shared attention. Additionally, we introduce evaluation protocols for these tasks, presenting a promising avenue for future research in gaze behavior analysis.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Gupta","given":"Anshul"},{"family":"Tafasca","given":"Samy"},{"family":"Chutisilp","given":"Naravich"},{"family":"Odobez","given":"Jean-Marc"}],"citation-key":"gupta2024a","container-title":"2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)","DOI":"10.1109/FG59268.2024.10581955","event-title":"2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)","ISSN":"2770-8330","issued":{"date-parts":[["2024",5]]},"page":"1-9","source":"IEEE Xplore","title":"A Unified Model for Gaze Following and Social Gaze Prediction","type":"paper-conference","URL":"https://ieeexplore.ieee.org/abstract/document/10581955"},
  {"id":"gupta2024b","abstract":"Contextual cues related to a person's pose and interactions with objects and other people in the scene can provide valuable information for gaze following. While existing methods have focused on dedicated cue extraction methods, in this work we investigate the zero-shot capabilities of Vision-Language Models (VLMs) for extracting a wide array of contextual cues to improve gaze following performance. We first evaluate various VLMs, prompting strategies, and in-context learning (ICL) techniques for zero-shot cue recognition performance. We then use these insights to extract contextual cues for gaze following, and investigate their impact when incorporated into a state of the art model for the task. Our analysis indicates that BLIP-2 is the overall top performing VLM and that ICL can improve performance. We also observe that VLMs are sensitive to the choice of the text prompt although ensembling over multiple text prompts can provide more robust performance. Additionally, we discover that using the entire image along with an ellipse drawn around the target person is the most effective strategy for visual prompting. For gaze following, incorporating the extracted cues results in better generalization performance, especially when considering a larger set of cues, highlighting the potential of this approach.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Gupta","given":"Anshul"},{"family":"Vuillecard","given":"Pierre"},{"family":"Farkhondeh","given":"Arya"},{"family":"Odobez","given":"Jean-Marc"}],"citation-key":"gupta2024b","DOI":"10.48550/arXiv.2406.03907","issued":{"date-parts":[["2024",6,6]]},"number":"arXiv:2406.03907","publisher":"arXiv","source":"arXiv.org","title":"Exploring the Zero-Shot Capabilities of Vision-Language Models for Improving Gaze Following","type":"article","URL":"http://arxiv.org/abs/2406.03907"},
  {"id":"haeyen2024","abstract":"Personality disorders (PD) are based not just on maladaptive ideas about self and others, they also are grounded on embodied patterns of behaviors and reactions to interpersonal stressors. There is growing interest in working with the body and through the body so to address automatisms that lead to suffering and dysfunctional social action. In this issue of the Journal of Clinical Psychology: In-Session the use of art and psychomotor therapies for these patients was explored by seven different clinical perspectives. Patients described presented with different PD and associated symptoms. The arts and psychomotor therapies deployed in personality disorder treatment are: (visual) art therapy, music therapy, drama therapy, dance (movement) therapy, and psychomotor therapy making psychotherapeutic use of the different modalities: art, music, play, role-play, performance, improvisation, dance, body awareness and movement. Interventions provide kinesthetic, sensory, perceptual, and symbolic opportunities to invite alternative modes of meaning-making, accessing own needs and wishes, and communicating them to others. In this commentary we summarize some of the different topics covered by the clinical-based papers, including working mechanisms of arts and psychomotor therapies, the importance of bottom-up emotion regulation processes, how to treat trauma in the presence of a PD, how to integrate art and psychomotor therapies in a fine-grained formulation and how to understand the process of change. Although there is a need for more empirical research, we hope this issue makes a solid case that clinicians can effectively include art and psychomotor therapies when treating the full range of PD.","accessed":{"date-parts":[["2025",3,3]]},"author":[{"family":"Haeyen","given":"Suzanne"},{"family":"Dimaggio","given":"Giancarlo"}],"citation-key":"haeyen2024","container-title":"Journal of Clinical Psychology","DOI":"10.1002/jclp.23730","ISSN":"1097-4679","issue":"11","issued":{"date-parts":[["2024"]]},"language":"en","license":"© 2024 The Author(s). Journal of Clinical Psychology published by Wiley Periodicals LLC.","page":"2303-2314","source":"Wiley Online Library","title":"Arts and psychomotor therapies in personality disorder treatment: An appropriate therapeutic entrance to personal development: A commentary","title-short":"Arts and psychomotor therapies in personality disorder treatment","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/jclp.23730","volume":"80"},
  {"id":"harris2023","abstract":"The aim of this work was to examine the fidelity and validity of an aviation simulation using eye tracking. Commercial head-mounted virtual reality (VR) systems offer a convenient and cost-effective alternative to existing aviation simulation (e.g., for refresher exercises). We performed pre-implementation testing of a novel aviation simulation, designed for head-mounted VR, to determine its fidelity and validity as a training device. Eighteen airline pilots, with varying levels of flight experience, completed a sequence of training ‘flows.’ Self-reported measures of presence and workload and users’ perceptions of fidelity were taken. Pilots’ eye movements and performance were recorded to determine whether more experienced pilots showed distinct performance and eye gaze profiles in the simulation, as they would in the real-world. Real-world expertise correlated with eye gaze patterns characterized by fewer, but longer, fixations and a scan path that was more structured and less random. Multidimensional scaling analyses also indicated differential clustering of strategies in more versus less experienced pilots. Subjective ratings of performance, however, showed little relationship with real-world expertise or eye movements. We adopted an evidence-based approach to assessing the fidelity and validity of a VR flight training tool. Pilot reports indicated the simulation was realistic and potentially useful for training, while direct measurement of eye movements was useful for establishing construct validity and psychological fidelity of the simulation.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Harris","given":"D. J."},{"family":"Arthur","given":"T."},{"family":"Burgh","given":"T.","non-dropping-particle":"de"},{"family":"Duxbury","given":"M."},{"family":"Lockett-Kirk","given":"R."},{"family":"McBarnett","given":"W."},{"family":"Vine","given":"S. J."}],"citation-key":"harris2023","container-title":"The International Journal of Aerospace Psychology","DOI":"10.1080/24721840.2023.2195428","ISSN":"2472-1840","issue":"3","issued":{"date-parts":[["2023",7,3]]},"page":"153-173","publisher":"Routledge","source":"Taylor and Francis+NEJM","title":"Assessing Expertise Using Eye Tracking in a Virtual Reality Flight Simulation","type":"article-journal","URL":"https://doi.org/10.1080/24721840.2023.2195428","volume":"33"},
  {"id":"hassan2024","abstract":"Nowadays, Autism Spectrum Disorder (ASD) is a compound neurodevelopmental disorder that affects millions of persons universally, impacting their communication, communal interaction, and behavior. ASD is a diverse condition that exhibits differently in each individual, from trivial complications with social cues to severe challenges with parallel communication. ASD has become a demanding concern for healthcare professionals, and educationalists, highlighting the need for early detection, effective intervention, and wide-ranging support systems. As a result, an approach has proposed for predicting ASD at early stages, as the existing models have overfitting, class imbalance and more complexity problems. To overcome these issues a hybrid model of eXtreme Gradient Boosting and Logistic Regression (XGBoost-LR) has proposed, which involves with preprocessing of Synthetic Minority Oversampling Technique (SMOTE) and Standard Scalar Standardization to balance class and to improve interpretability. Next, feature extraction is performed with Recursive Feature Elimination (RFE) and cross validation using 5foldCV to reduce overfitting and improve generalizability. The XGBoost-LR model gives a precise rate in predicting and classifying the stages of ASD. The proposed XGBoost-LR model gives the better results than the other existing methods Support Vector Machine (SVM) in terms of metrices accuracy, precision, recall, specificity and f1 score respectively.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Hassan","given":"Muntather Muhsin"},{"family":"Laxmi","given":"H. Bhagya"},{"family":"Sasikala","given":"M."},{"family":"Kumar","given":"S. Senthil"},{"family":"Alamelu","given":"M."}],"citation-key":"hassan2024","container-title":"2024 First International Conference on Software, Systems and Information Technology (SSITCON)","DOI":"10.1109/SSITCON62437.2024.10796968","event-title":"2024 First International Conference on Software, Systems and Information Technology (SSITCON)","issued":{"date-parts":[["2024",10]]},"page":"1-5","source":"IEEE Xplore","title":"A Machine Learning Approach for Early Prediction of Autism Spectrum Disorder using eXtreme Gradient Boosting and Logistic Regression Framework","type":"paper-conference","URL":"https://ieeexplore.ieee.org/abstract/document/10796968"},
  {"id":"hickson2019","abstract":"One of the main challenges of social interaction in virtual reality settings is that head-mounted displays occlude a large portion of the face, blocking facial expressions and thereby restricting social engagement cues among users. We present an algorithm to automatically infer expressions by analyzing only a partially occluded face while the user is engaged in a virtual reality experience. Specifically, we show that images of the user's eyes captured from an IR gaze-tracking camera within a VR headset are sufficient to infer a subset of facial expressions without the use of any fixed external camera. Using these inferences, we can generate dynamic avatars in real-time which function as an expressive surrogate for the user. We propose a novel data collection pipeline as well as a novel approach for increasing CNN accuracy via personalization. Our results show a mean accuracy of 74% (F1 of 0.73) among 5 'emotive' expressions and a mean accuracy of 70% (F1 of 0.68) among 10 distinct facial action units, outperforming human raters.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Hickson","given":"Steven"},{"family":"Dufour","given":"Nick"},{"family":"Sud","given":"Avneesh"},{"family":"Kwatra","given":"Vivek"},{"family":"Essa","given":"Irfan"}],"citation-key":"hickson2019","container-title":"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)","DOI":"10.1109/WACV.2019.00178","event-title":"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)","ISSN":"1550-5790","issued":{"date-parts":[["2019",1]]},"page":"1626-1635","source":"IEEE Xplore","title":"Eyemotion: Classifying Facial Expressions in VR Using Eye-Tracking Cameras","title-short":"Eyemotion","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/8658392"},
  {"id":"hou2024","abstract":"Gaze abnormalities are well documented in infants at elevated risk for autism spectrum disorder (ASD). However, variations in experimental design and stimuli across studies have led to mixed results. The current meta-analysis aimed to identify which type of eye tracking task and stimulus are most effective at differentiating high-risk infants (siblings of children with ASD) who later meet diagnosis criteria from low-risk infants without familial autism. We synthesized 35 studies that used eye tracking to investigate gaze behavior in infants at high genetic risk for autism before 2 years of age. We found that stimulus features, regions of interest (ROIs) and study quality moderated effect sizes across studies. Overall, dynamic stimuli and socially-relevant regions in the social stimuli (i.e. the target and activity of characters' shared focus) reliably detected high-risk infants who later develop ASD. Attention disengagement task and stimuli depicting interactions between human and nonhuman characters could identify high-risk infants who later develop ASD and those who have autism-related symptoms but do not meet the diagnostic criteria as well. These findings provide sensitive and reliable early markers of ASD, which is helpful to develop objective and quantitative early autism screening and intervention tools.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Hou","given":"Wenwen"},{"family":"Jiang","given":"Yingying"},{"family":"Yang","given":"Yunmei"},{"family":"Zhu","given":"Liqi"},{"family":"Li","given":"Jing"}],"citation-key":"hou2024","container-title":"Clinical Psychology Review","container-title-short":"Clinical Psychology Review","DOI":"10.1016/j.cpr.2024.102466","ISSN":"0272-7358","issued":{"date-parts":[["2024",8,1]]},"page":"102466","source":"ScienceDirect","title":"Evaluating the validity of eye-tracking tasks and stimuli in detecting high-risk infants later diagnosed with autism: A meta-analysis","title-short":"Evaluating the validity of eye-tracking tasks and stimuli in detecting high-risk infants later diagnosed with autism","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0272735824000874","volume":"112"},
  {"id":"howard2021","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Howard","given":"Matt C."},{"family":"Gutworth","given":"Melissa B."},{"family":"Jacobs","given":"Rick R."}],"citation-key":"howard2021","container-title":"Comput. Hum. Behav.","DOI":"10.1016/j.chb.2021.106808","ISSN":"0747-5632","issue":"C","issued":{"date-parts":[["2021",8,1]]},"source":"ACM Digital Library","title":"A meta-analysis of virtual reality training programs","type":"article-journal","URL":"https://doi.org/10.1016/j.chb.2021.106808","volume":"121"},
  {"id":"hu2024","abstract":"Diagnosing autism spectrum disorder (ASD) by identifying abnormal speech patterns from examiner-patient dialogues presents significant challenges due to the subtle and diverse manifestations of speech-related symptoms in affected individuals. This study presents a comprehensive approach to identify distinctive speech patterns through the analysis of examiner-patient dialogues. Utilizing a dataset of recorded dialogues, we extracted 40 speech-related features, categorized into frequency, zero-crossing rate, energy, spectral characteristics, Mel Frequency Cepstral Coefficients (MFCCs), and balance. These features encompass various aspects of speech such as intonation, volume, rhythm, and speech rate, reflecting the complex nature of communicative behaviors in ASD. We employed machine learning for both classification and regression tasks to analyze these speech features. The classification model aimed to differentiate between ASD and non-ASD cases, achieving an accuracy of 87.75%. Regression models were developed to predict speech pattern related variables and a composite score from all variables, facilitating a deeper understanding of the speech dynamics associated with ASD. The effectiveness of machine learning in interpreting intricate speech patterns and the high classification accuracy underscore the potential of computational methods in supporting the diagnostic processes for ASD. This approach not only aids in early detection but also contributes to personalized treatment planning by providing insights into the speech and communication profiles of individuals with ASD.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Hu","given":"Chuanbo"},{"family":"Thrasher","given":"Jacob"},{"family":"Li","given":"Wenqi"},{"family":"Ruan","given":"Mindi"},{"family":"Yu","given":"Xiangxu"},{"family":"Paul","given":"Lynn K"},{"family":"Wang","given":"Shuo"},{"family":"Li","given":"Xin"}],"citation-key":"hu2024","DOI":"10.48550/arXiv.2405.05126","issued":{"date-parts":[["2024",5,1]]},"note":"ADS Bibcode: 2024arXiv240505126H","source":"NASA ADS","title":"Exploring Speech Pattern Disorders in Autism using Machine Learning","type":"article","URL":"https://ui.adsabs.harvard.edu/abs/2024arXiv240505126H"},
  {"id":"hu2024a","abstract":"Diagnosing language disorders associated with autism is a complex challenge, often hampered by the subjective nature and variability of traditional assessment methods. Traditional diagnostic methods not only require intensive human effort but also often result in delayed interventions due to their lack of speed and precision. In this study, we explored the application of ChatGPT, a large language model, to overcome these obstacles by enhancing sensitivity and profiling linguistic features for autism diagnosis. This research utilizes ChatGPT natural language processing capabilities to simplify and improve the diagnostic process, focusing on identifying autism related language patterns. Specifically, we compared ChatGPT performance with that of conventional supervised learning models, including BERT, a model acclaimed for its effectiveness in various natural language processing tasks. We showed that ChatGPT substantially outperformed these models, achieving over 10% improvement in both sensitivity and positive predictive value, in a zero shot learning configuration. The findings underscore the model potential as a diagnostic tool, combining accuracy and applicability. We identified ten key features of autism associated language disorders across scenarios. Features such as echolalia, pronoun reversal, and atypical language usage play a critical role in diagnosing ASD and informing tailored treatment plans. Together, our findings advocate for adopting sophisticated AI tools like ChatGPT in clinical settings to assess and diagnose developmental disorders. Our approach promises enhanced diagnostic precision and supports personalized medicine, potentially transforming the evaluation landscape for autism and similar neurological conditions.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Hu","given":"Chuanbo"},{"family":"Li","given":"Wenqi"},{"family":"Ruan","given":"Mindi"},{"family":"Yu","given":"Xiangxu"},{"family":"Deshpande","given":"Shalaka"},{"family":"Paul","given":"Lynn K."},{"family":"Wang","given":"Shuo"},{"family":"Li","given":"Xin"}],"citation-key":"hu2024a","DOI":"10.48550/arXiv.2405.01799","issued":{"date-parts":[["2024",11,29]]},"number":"arXiv:2405.01799","publisher":"arXiv","source":"arXiv.org","title":"Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features","type":"article","URL":"http://arxiv.org/abs/2405.01799"},
  {"id":"hull2020","abstract":"Autism is more commonly diagnosed in males than females. One explanation is the ‘female protective effect’: there is something inherent in being female which reduces the likelihood of developing autism. However, evidence suggests that the condition is underdiagnosed in females, perhaps because females express their autism in ways which do not meet current diagnostic criteria. This review explores evidence for a female-typical autism presentation, the Female Autism Phenotype (FAP) and the component of camouflaging (compensating for and masking autistic characteristics) in particular. The evidence so far supports the existence of a female-typical autism presentation, although further examination of the characteristics and their impact across all genders and ages is needed.","accessed":{"date-parts":[["2025",2,13]]},"author":[{"family":"Hull","given":"Laura"},{"family":"Petrides","given":"K. V."},{"family":"Mandy","given":"William"}],"citation-key":"hull2020","container-title":"Review Journal of Autism and Developmental Disorders","container-title-short":"Rev J Autism Dev Disord","DOI":"10.1007/s40489-020-00197-9","ISSN":"2195-7185","issue":"4","issued":{"date-parts":[["2020",12,1]]},"language":"en","page":"306-317","source":"Springer Link","title":"The Female Autism Phenotype and Camouflaging: a Narrative Review","title-short":"The Female Autism Phenotype and Camouflaging","type":"article-journal","URL":"https://doi.org/10.1007/s40489-020-00197-9","volume":"7"},
  {"id":"illusioimaging2020","accessed":{"date-parts":[["2024",9,15]]},"citation-key":"illusioimaging2020","director":[{"literal":"Illusio Imaging"}],"issued":{"date-parts":[["2020",8,27]]},"source":"YouTube","title":"It's Time For ILLUSIO","type":"motion_picture","URL":"https://www.youtube.com/watch?v=bBM_IUQRbnE"},
  {"id":"ip2022","abstract":"Social-emotional deficits in school-aged children diagnosed with autism spectrum disorder (ASD) greatly hinder these children from fully participating in various school activities in the inclusive education setting. Previous studies have demonstrated evidence regarding the effectiveness of using virtual reality (VR) for enhancing the children’s affective expression and social reciprocity. However, considering the technical and logistical complexity of the enabling hardware and software systems, how such approaches can be effectively and sustainably delivered in the school setting remains underexplored. This paper presents a study that utilised VR headsets to enhance affective expression and social reciprocity for children with ASD and explored how the approach could be effectively and sustainably delivered at schools. A total of eight VR learning scenarios were designed based on Kolb’s experiential learning framework. 176 children aged 6–12 with a clinical diagnosis of ASD participated in the study. The statistical analyses showed that the participants who received the intervention significantly improved in affective expression and social reciprocity, compared to those who were in the control group. Moreover, the approaches to enhance long-term sustainability have also been presented and discussed in this paper.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Ip","given":"Horace H. S."},{"family":"Wong","given":"Simpson W. L."},{"family":"Chan","given":"Dorothy F. Y."},{"family":"Li","given":"Chen"},{"family":"Kon","given":"Lo Lo"},{"family":"Ma","given":"Po Ke"},{"family":"Lau","given":"Kate S. Y."},{"family":"Byrne","given":"Julia"}],"citation-key":"ip2022","container-title":"Interactive Learning Environments","DOI":"10.1080/10494820.2022.2107681","ISSN":"1049-4820","issue":"3","issued":{"date-parts":[["2022"]]},"page":"1012-1035","publisher":"Routledge","source":"Taylor and Francis+NEJM","title":"Enhance affective expression and social reciprocity for children with autism spectrum disorder: using virtual reality headsets at schools","title-short":"Enhance affective expression and social reciprocity for children with autism spectrum disorder","type":"article-journal","URL":"https://doi.org/10.1080/10494820.2022.2107681","volume":"32"},
  {"id":"isaev2024","abstract":"We report preliminary results of computer vision analysis of caregiver–child interactions during free play with children diagnosed with autism (N = 29, 41–91 months), attention-deficit/hyperactivity disorder (ADHD, N = 22, 48–100 months), or combined autism + ADHD (N = 20, 56–98 months), and neurotypical children (NT, N = 7, 55–95 months). We conducted micro-analytic analysis of ‘reaching to a toy,’ as a proxy for initiating or responding to a toy play bout. Dyadic analysis revealed two clusters of interaction patterns, which differed in frequency of ‘reaching to a toy’ and caregivers’ contingent responding to the child’s reach for a toy by also reaching for a toy. Children in dyads with higher caregiver responsiveness had less developed language, communication, and socialization skills. Clusters were not associated with diagnostic groups. These results hold promise for automated methods of characterizing caregiver responsiveness in dyadic interactions for assessment and outcome monitoring in clinical trials.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Isaev","given":"Dmitry Yu."},{"family":"Sabatos-DeVito","given":"Maura"},{"family":"Di Martino","given":"J. Matias"},{"family":"Carpenter","given":"Kimberly"},{"family":"Aiello","given":"Rachel"},{"family":"Compton","given":"Scott"},{"family":"Davis","given":"Naomi"},{"family":"Franz","given":"Lauren"},{"family":"Sullivan","given":"Connor"},{"family":"Dawson","given":"Geraldine"},{"family":"Sapiro","given":"Guillermo"}],"citation-key":"isaev2024","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-05973-0","ISSN":"1573-3432","issue":"6","issued":{"date-parts":[["2024",6,1]]},"language":"en","page":"2286-2297","source":"Springer Link","title":"Computer Vision Analysis of Caregiver–Child Interactions in Children with Neurodevelopmental Disorders: A Preliminary Report","title-short":"Computer Vision Analysis of Caregiver–Child Interactions in Children with Neurodevelopmental Disorders","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-05973-0","volume":"54"},
  {"id":"jalilifard2016","abstract":"Several studies have found evidence for corticolimbic Theta electroencephalographic (EEG) oscillation in the neural processing of visual stimuli perceived as fear or threatening scene. Recent studies showed that neural oscillations' patterns in Theta, Alpha, Beta and Gamma sub-bands play a main role in brain's emotional processing. The main goal of this study is to classify two different emotional states by means of EEG data recorded through a single-electrode EEG headset. Nineteen young subjects participated in an EEG experiment while watching a video clip that evoked three emotional states: neutral, relaxation and scary. Following each video clip, participants were asked to report on their subjective affect by giving a score between 0 to 10. First, recorded EEG data were preprocessed by stationary wavelet transform (SWT) based denoising to remove artifacts. Afterward, the distribution of power in time-frequency space was obtained using short-time Fourier transform (STFT) and then, the mean value of energy was calculated for each EEG sub-band. Finally, 46 features, as the mean energy of frequency bands between 4 and 50 Hz, containing 689 instances - for each subject -were collected in order to classify the emotional states. Our experimental results show that EEG dynamics induced by horror and relaxing movies can be classified with average classification rate of 92% using support vector machine (SVM) classifier. We also compared the performance of SVM to K-nearest neighbors (K-NN). The results show that K-NN achieves a better classification rate by 94% accuracy. The findings of this work are expected to pave the way to a new horizon in neuroscience by proving the point that only single-channel EEG data carry enough information for emotion classification.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Jalilifard","given":"Amir"},{"family":"Pizzolato","given":"Ednaldo Brigante"},{"family":"Islam","given":"Md Kafiul"}],"citation-key":"jalilifard2016","container-title":"2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","DOI":"10.1109/EMBC.2016.7590833","event-title":"2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","ISSN":"1558-4615","issued":{"date-parts":[["2016",8]]},"page":"845-849","source":"IEEE Xplore","title":"Emotion classification using single-channel scalp-EEG recording","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/7590833"},
  {"id":"jans2025","accessed":{"date-parts":[["2025",3,3]]},"author":[{"family":"Jans","given":"Nathalie"},{"family":"Wouters","given":"Hans"},{"family":"Kolijn","given":"Joep"},{"family":"Haeyen","given":"Suzanne"}],"citation-key":"jans2025","container-title":"Frontiers in Virtual Reality","container-title-short":"Front. Virtual Real.","DOI":"10.3389/frvir.2025.1462775","ISSN":"2673-4192","issued":{"date-parts":[["2025",1,22]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Developing a virtual reality application for online arts and psychomotor therapies using action research","type":"article-journal","URL":"https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2025.1462775/full","volume":"6"},
  {"id":"jensen2022","abstract":"Autism spectrum disorder is an increasingly prevalent neurodevelopmental disorder in the world today, with an estimated 2% of the population being affected in the USA. A major complicating factor in diagnosing, treating, and understanding autism spectrum disorder is that defining the disorder is solely based on the observation of behavior. Thus, recent research has focused on identifying specific biological abnormalities in autism spectrum disorder that can provide clues to diagnosis and treatment. Biomarkers are an objective way to identify and measure biological abnormalities for diagnostic purposes as well as to measure changes resulting from treatment. This current opinion paper discusses the state of research of various biomarkers currently in development for autism spectrum disorder. The types of biomarkers identified include prenatal history, genetics, neurological including neuroimaging, neurophysiologic, and visual attention, metabolic including abnormalities in mitochondrial, folate, trans-methylation, and trans-sulfuration pathways, immune including autoantibodies and cytokine dysregulation, autonomic nervous system, and nutritional. Many of these biomarkers have promising preliminary evidence for prenatal and post-natal pre-symptomatic risk assessment, confirmation of diagnosis, subtyping, and treatment response. However, most biomarkers have not undergone validation studies and most studies do not investigate biomarkers with clinically relevant comparison groups. Although the field of biomarker research in autism spectrum disorder is promising, it appears that it is currently in the early stages of development.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Jensen","given":"Amanda R."},{"family":"Lane","given":"Alison L."},{"family":"Werner","given":"Brianna A."},{"family":"McLees","given":"Sallie E."},{"family":"Fletcher","given":"Tessa S."},{"family":"Frye","given":"Richard E."}],"citation-key":"jensen2022","container-title":"Molecular Diagnosis & Therapy","container-title-short":"Mol Diagn Ther","DOI":"10.1007/s40291-022-00600-7","ISSN":"1177-1062","issue":"5","issued":{"date-parts":[["2022"]]},"page":"483-495","PMCID":"PMC9411091","PMID":"35759118","source":"PubMed Central","title":"Modern Biomarkers for Autism Spectrum Disorder: Future Directions","title-short":"Modern Biomarkers for Autism Spectrum Disorder","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9411091/","volume":"26"},
  {"id":"jiang2024","abstract":"As consumer Virtual Reality (VR) and Mixed Reality (MR) technologies gain momentum, there's a growing focus on the development of engagements with 3D virtual content. Unfortunately, traditional techniques for content creation, editing, and interaction within these virtual spaces are fraught with difficulties. They tend to be not only engineering-intensive but also require extensive expertise, which adds to the frustration and inefficiency in virtual object manipulation. Our proposed VR-GS system represents a leap forward in human-centered 3D content interaction, offering a seamless and intuitive user experience. By developing a physical dynamics-aware interactive Gaussian Splatting in a Virtual Reality setting, and constructing a highly efficient two-level embedding strategy alongside deformable body simulations, VR-GS ensures real-time execution with highly realistic dynamic responses. The components of our Virtual Reality system are designed for high efficiency and effectiveness, starting from detailed scene reconstruction and object segmentation, advancing through multi-view image in-painting, and extending to interactive physics-based editing. The system also incorporates real-time deformation embedding and dynamic shadow casting, ensuring a comprehensive and engaging virtual experience.Our project page is available at: https://yingjiang96.github.io/VR-GS/.","accessed":{"date-parts":[["2024",12,11]]},"author":[{"family":"Jiang","given":"Ying"},{"family":"Yu","given":"Chang"},{"family":"Xie","given":"Tianyi"},{"family":"Li","given":"Xuan"},{"family":"Feng","given":"Yutao"},{"family":"Wang","given":"Huamin"},{"family":"Li","given":"Minchen"},{"family":"Lau","given":"Henry"},{"family":"Gao","given":"Feng"},{"family":"Yang","given":"Yin"},{"family":"Jiang","given":"Chenfanfu"}],"citation-key":"jiang2024","DOI":"10.48550/arXiv.2401.16663","issued":{"date-parts":[["2024",5,4]]},"number":"arXiv:2401.16663","publisher":"arXiv","source":"arXiv.org","title":"VR-GS: A Physical Dynamics-Aware Interactive Gaussian Splatting System in Virtual Reality","title-short":"VR-GS","type":"article","URL":"http://arxiv.org/abs/2401.16663"},
  {"id":"jin2024","abstract":"Machine learning (ML) based on remote video has shown ideal diagnostic value in autism spectrum disorder (ASD). Here, we conducted a meta-analysis of the diagnostic value of home video–based ML in ASD. Relevant articles were systematically searched in PubMed, Cochrane, Embase, and Web of Science from inception to September 2023 with no language restriction, and the literature search was updated in September 2024. The overall risk of bias and suitability of the ML prediction models in the included studies were assessed using PROBAST. Nineteen articles involving 89 prediction models and 9959 subjects were included. The mean video duration was 5.63 ± 1.23 min, and the mean number of behavioral features during initial modeling was 23.53. Among the 19 included studies, 13 models had been trained. Seven of the 13 models were not cross-validated (c-index = 0.92, 95% CI 0.88–0.96), while 6 of the 13 models were tenfold cross-validated (c-index = 0.95, 95% CI 0.94–0.97). There were 8 validation cohorts (c-index = 0.83, 95% CI 0.77–0.89). The pooled sensitivity and specificity were 0.87 (95% CI 0.77–0.93) and 0.79 (95% CI 0.76–0.81) in the training cohort, 0.90 (95% CI 0.85–0.94) and 0.87 (95% CI 0.72–0.94) in the cross-validation, and 0.81 (95% CI 0.74–0.86) and 0.72 (95% CI 0.68–0.75) in the validation cohort, respectively. These results indicated that this model is a highly sensitive and user-friendly tool for early ASD diagnosis.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Jin","given":"Longjie"},{"family":"Cui","given":"Hualei"},{"family":"Zhang","given":"Peiyuan"},{"family":"Cai","given":"Chunquan"}],"citation-key":"jin2024","container-title":"European Journal of Pediatrics","container-title-short":"Eur J Pediatr","DOI":"10.1007/s00431-024-05837-4","ISSN":"1432-1076","issue":"1","issued":{"date-parts":[["2024",11,21]]},"language":"en","page":"37","source":"Springer Link","title":"Early diagnostic value of home video–based machine learning in autism spectrum disorder: a meta-analysis","title-short":"Early diagnostic value of home video–based machine learning in autism spectrum disorder","type":"article-journal","URL":"https://doi.org/10.1007/s00431-024-05837-4","volume":"184"},
  {"id":"jonassen2024","abstract":"Today, Computerized Maintenance Management Systems (CMMS) are widely used across various industries, particularly those with long-lived physical assets like the energy and transportation sectors. However, recent advancements in smart maintenance, especially within technology, have opened new opportunities. With tools such as artificial intelligence and machine learning, CMMS can extract higher value from assets. \n\nMaximizing the value derived from the CMMS is a multifaceted and challenging task. This challenge comes from among other things the diverse requirements and objectives across organizations and industries, necessitating a flexible, capable, and user-friendly software solution that serves as the centralized database for all maintenance activities. The thesis aims to answer the following research questions:\n\n  1. How can an asset owner or operator achieve full benefits of CMMS within recent industrial\n      trends, such as industry 4.0/5.0, IoT, data-driven technologies (AI/ML), etc?\n\n  2. How can an asset owner or operator implement CMMS to fulfill expectations from stake-\n      holders both internally in the enterprise and externally?\n\n  3. How can an asset owner or operator ensure data integrity, and what strategies can be used\n      to accurately collect data?\n\nTo address these questions, a mixed-method approach will be used, including a literature review and qualitative data obtained through interviews with relevant personnel who engage with CMMS on a daily basis. This data forms the foundation for subsequent analysis and answering of the research questions. \n\nThe interviews highlighted several key findings, including the widespread use of outdated CMMS software among many organizations. Additionally, there was limited focus on upgrading to newer versions with enhanced features like built-in visualization tools and artificial intelligence capabilities. Moreover, personnel training emerged as a crucial factor in maximizing the potential of CMMS, as the software was considered as challenging to use without extensive knowledge and experience. Similarly, data integrity was identified as a significant challenge, particularly regarding the quality of maintenance completion reports, which could also be attributed to personnel training and other factors. Improvements in these areas could significantly enhance\nthe value generated by the CMMS.","accessed":{"date-parts":[["2025",3,7]]},"author":[{"family":"Jonassen","given":"Gunnar Sveinsvoll"}],"citation-key":"jonassen2024","genre":"Master thesis","issued":{"date-parts":[["2024"]]},"language":"eng","note":"Accepted: 2024-09-13T15:51:41Z","publisher":"UIS","source":"uis.brage.unit.no","title":"Value of Computerized maintenance management system (CMMS) in smart Maintenance and Asset management decisions – cases and best practices","type":"thesis","URL":"https://uis.brage.unit.no/uis-xmlui/handle/11250/3152197"},
  {"id":"jones2013","abstract":"Deficits in eye contact have been a hallmark of autism, since the condition’s initial description. They are cited widely as a diagnostic feature and figure prominently in clinical instruments; however, the early onset of these deficits has not been known. Here we show in a prospective longitudinal study that infants later diagnosed with autism spectrum disorders (ASD) exhibit mean decline in eye fixation within the first 2 to 6 months of life, a pattern not observed in infants who do not develop ASD. These observations mark the earliest known indicators of social disability in infancy, but also falsify a prior hypothesis: in the first months of life, this basic mechanism of social adaptive action—eye looking—is not immediately diminished in infants later diagnosed with ASD; instead, eye looking appears to begin at normative levels prior to decline. The timing of decline highlights a narrow developmental window and reveals the early derailment of processes that would otherwise play a key role in canalizing typical social development. Finally, the observation of this decline in eye fixation—rather than outright absence—offers a promising opportunity for early intervention, one that could build on the apparent preservation of mechanisms subserving reflexive initial orientation towards the eyes.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Jones","given":"Warren"},{"family":"Klin","given":"Ami"}],"citation-key":"jones2013","container-title":"Nature","container-title-short":"Nature","DOI":"10.1038/nature12715","ISSN":"0028-0836","issue":"7480","issued":{"date-parts":[["2013",12,19]]},"page":"427-431","PMCID":"PMC4035120","PMID":"24196715","source":"PubMed Central","title":"Attention to Eyes is Present But in Decline in 2–6 Month-Olds Later Diagnosed with Autism","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4035120/","volume":"504"},
  {"id":"jones2023","abstract":"In the US, children with signs of autism often experience more than 1 year of delay before diagnosis and often experience longer delays if they are from racially, ethnically, or economically disadvantaged backgrounds. Most diagnoses are also received without use of standardized diagnostic instruments. To aid in early autism diagnosis, eye-tracking measurement of social visual engagement has shown potential as a performance-based biomarker.To evaluate the performance of eye-tracking measurement of social visual engagement (index test) relative to expert clinical diagnosis in young children referred to specialty autism clinics.In this study of 16- to 30-month-old children enrolled at 6 US specialty centers from April 2018 through May 2019, staff blind to clinical diagnoses used automated devices to measure eye-tracking–based social visual engagement. Expert clinical diagnoses were made using best practice standardized protocols by specialists blind to index test results. This study was completed in a 1-day protocol for each participant.Primary outcome measures were test sensitivity and specificity relative to expert clinical diagnosis. Secondary outcome measures were test correlations with expert clinical assessments of social disability, verbal ability, and nonverbal cognitive ability.Eye-tracking measurement of social visual engagement was successful in 475 (95.2%) of the 499 enrolled children (mean [SD] age, 24.1 [4.4] months; 38 [8.0%] were Asian; 37 [7.8%], Black; 352 [74.1%], White; 44 [9.3%], other; and 68 [14.3%], Hispanic). By expert clinical diagnosis, 221 children (46.5%) had autism and 254 (53.5%) did not. In all children, measurement of social visual engagement had sensitivity of 71.0% (95% CI, 64.7% to 76.6%) and specificity of 80.7% (95% CI, 75.4% to 85.1%). In the subgroup of 335 children whose autism diagnosis was certain, sensitivity was 78.0% (95% CI, 70.7% to 83.9%) and specificity was 85.4% (95% CI, 79.5% to 89.8%). Eye-tracking test results correlated with expert clinical assessments of individual levels of social disability (r = −0.75 [95% CI, −0.79 to −0.71]), verbal ability (r = 0.65 [95% CI, 0.59 to 0.70]), and nonverbal cognitive ability (r = 0.65 [95% CI, 0.59 to 0.70]).In 16- to 30-month-old children referred to specialty clinics, eye-tracking–based measurement of social visual engagement was predictive of autism diagnoses by clinical experts. Further evaluation of this test’s role in early diagnosis and assessment of autism in routine specialty clinic practice is warranted.ClinicalTrials.gov Identifier: NCT03469986","accessed":{"date-parts":[["2025",2,7]]},"author":[{"family":"Jones","given":"Warren"},{"family":"Klaiman","given":"Cheryl"},{"family":"Richardson","given":"Shana"},{"family":"Aoki","given":"Christa"},{"family":"Smith","given":"Christopher"},{"family":"Minjarez","given":"Mendy"},{"family":"Bernier","given":"Raphael"},{"family":"Pedapati","given":"Ernest"},{"family":"Bishop","given":"Somer"},{"family":"Ence","given":"Whitney"},{"family":"Wainer","given":"Allison"},{"family":"Moriuchi","given":"Jennifer"},{"family":"Tay","given":"Sew-Wah"},{"family":"Klin","given":"Ami"}],"citation-key":"jones2023","container-title":"JAMA","container-title-short":"JAMA","DOI":"10.1001/jama.2023.13295","ISSN":"0098-7484","issue":"9","issued":{"date-parts":[["2023",9,5]]},"page":"854-865","source":"Silverchair","title":"Eye-Tracking–Based Measurement of Social Visual Engagement Compared With Expert Clinical Diagnosis of Autism","type":"article-journal","URL":"https://doi.org/10.1001/jama.2023.13295","volume":"330"},
  {"id":"jones2023a","abstract":"In the US, children with signs of autism often experience more than 1 year of delay before diagnosis and often experience longer delays if they are from racially, ethnically, or economically disadvantaged backgrounds. Most diagnoses are also received without use of standardized diagnostic instruments. To aid in early autism diagnosis, eye-tracking measurement of social visual engagement has shown potential as a performance-based biomarker.To evaluate the performance of eye-tracking measurement of social visual engagement (index test) relative to expert clinical diagnosis in young children referred to specialty autism clinics.In this study of 16- to 30-month-old children enrolled at 6 US specialty centers from April 2018 through May 2019, staff blind to clinical diagnoses used automated devices to measure eye-tracking–based social visual engagement. Expert clinical diagnoses were made using best practice standardized protocols by specialists blind to index test results. This study was completed in a 1-day protocol for each participant.Primary outcome measures were test sensitivity and specificity relative to expert clinical diagnosis. Secondary outcome measures were test correlations with expert clinical assessments of social disability, verbal ability, and nonverbal cognitive ability.Eye-tracking measurement of social visual engagement was successful in 475 (95.2%) of the 499 enrolled children (mean [SD] age, 24.1 [4.4] months; 38 [8.0%] were Asian; 37 [7.8%], Black; 352 [74.1%], White; 44 [9.3%], other; and 68 [14.3%], Hispanic). By expert clinical diagnosis, 221 children (46.5%) had autism and 254 (53.5%) did not. In all children, measurement of social visual engagement had sensitivity of 71.0% (95% CI, 64.7% to 76.6%) and specificity of 80.7% (95% CI, 75.4% to 85.1%). In the subgroup of 335 children whose autism diagnosis was certain, sensitivity was 78.0% (95% CI, 70.7% to 83.9%) and specificity was 85.4% (95% CI, 79.5% to 89.8%). Eye-tracking test results correlated with expert clinical assessments of individual levels of social disability (r = −0.75 [95% CI, −0.79 to −0.71]), verbal ability (r = 0.65 [95% CI, 0.59 to 0.70]), and nonverbal cognitive ability (r = 0.65 [95% CI, 0.59 to 0.70]).In 16- to 30-month-old children referred to specialty clinics, eye-tracking–based measurement of social visual engagement was predictive of autism diagnoses by clinical experts. Further evaluation of this test’s role in early diagnosis and assessment of autism in routine specialty clinic practice is warranted.ClinicalTrials.gov Identifier: NCT03469986","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Jones","given":"Warren"},{"family":"Klaiman","given":"Cheryl"},{"family":"Richardson","given":"Shana"},{"family":"Aoki","given":"Christa"},{"family":"Smith","given":"Christopher"},{"family":"Minjarez","given":"Mendy"},{"family":"Bernier","given":"Raphael"},{"family":"Pedapati","given":"Ernest"},{"family":"Bishop","given":"Somer"},{"family":"Ence","given":"Whitney"},{"family":"Wainer","given":"Allison"},{"family":"Moriuchi","given":"Jennifer"},{"family":"Tay","given":"Sew-Wah"},{"family":"Klin","given":"Ami"}],"citation-key":"jones2023a","container-title":"JAMA","container-title-short":"JAMA","DOI":"10.1001/jama.2023.13295","ISSN":"0098-7484","issue":"9","issued":{"date-parts":[["2023",9,5]]},"page":"854-865","source":"Silverchair","title":"Eye-Tracking–Based Measurement of Social Visual Engagement Compared With Expert Clinical Diagnosis of Autism","type":"article-journal","URL":"https://doi.org/10.1001/jama.2023.13295","volume":"330"},
  {"id":"jones2023b","abstract":"Autism spectrum disorder is a common and early-emerging neurodevelopmental condition. While 80% of parents report having had concerns for their child’s development before age 2 years, many children are not diagnosed until ages 4 to 5 years or later.To develop an objective performance-based tool to aid in early diagnosis and assessment of autism in children younger than 3 years.In 2 prospective, consecutively enrolled, broad-spectrum, double-blind studies, we developed an objective eye-tracking–based index test for children aged 16 to 30 months, compared its performance with best-practice reference standard diagnosis of autism (discovery study), and then replicated findings in an independent sample (replication study). Discovery and replication studies were conducted in specialty centers for autism diagnosis and treatment. Reference standard diagnoses were made using best-practice standardized protocols by specialists blind to eye-tracking results. Eye-tracking tests were administered by staff blind to clinical results. Children were enrolled from April 27, 2013, until September 26, 2017. Data were analyzed from March 28, 2018, to January 3, 2019.Prespecified primary end points were the sensitivity and specificity of the eye-tracking–based index test compared with the reference standard. Prespecified secondary end points measured convergent validity between eye-tracking–based indices and reference standard assessments of social disability, verbal ability, and nonverbal ability.Data were collected from 1089 children: 719 children (mean [SD] age, 22.4 [3.6] months) in the discovery study, and 370 children (mean [SD] age, 25.4 [6.0] months) in the replication study. In discovery, 224 (31.2%) were female and 495 (68.8%) male; in replication, 120 (32.4%) were female and 250 (67.6%) male. Based on reference standard expert clinical diagnosis, there were 386 participants (53.7%) with nonautism diagnoses and 333 (46.3%) with autism diagnoses in discovery, and 184 participants (49.7%) with nonautism diagnoses and 186 (50.3%) with autism diagnoses in replication. In the discovery study, the area under the receiver operating characteristic curve was 0.90 (95% CI, 0.88-0.92), sensitivity was 81.9% (95% CI, 77.3%-85.7%), and specificity was 89.9% (95% CI, 86.4%-92.5%). In the replication study, the area under the receiver operating characteristic curve was 0.89 (95% CI, 0.86-0.93), sensitivity was 80.6% (95% CI, 74.1%-85.7%), and specificity was 82.3% (95% CI, 76.1%-87.2%). Eye-tracking test results correlated with expert clinical assessments of children’s individual levels of ability, explaining 68.6% (95% CI, 58.3%-78.6%), 63.4% (95% CI, 47.9%-79.2%), and 49.0% (95% CI, 33.8%-65.4%) of variance in reference standard assessments of social disability, verbal ability, and nonverbal cognitive ability, respectively.In two diagnostic studies of children younger than 3 years, objective eye-tracking–based measurements of social visual engagement quantified diagnostic status as well as individual levels of social disability, verbal ability, and nonverbal ability in autism. These findings suggest that objective measurements of social visual engagement can be used to aid in autism diagnosis and assessment.","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Jones","given":"Warren"},{"family":"Klaiman","given":"Cheryl"},{"family":"Richardson","given":"Shana"},{"family":"Lambha","given":"Meena"},{"family":"Reid","given":"Morganne"},{"family":"Hamner","given":"Taralee"},{"family":"Beacham","given":"Chloe"},{"family":"Lewis","given":"Peter"},{"family":"Paredes","given":"Jose"},{"family":"Edwards","given":"Laura"},{"family":"Marrus","given":"Natasha"},{"family":"Constantino","given":"John N."},{"family":"Shultz","given":"Sarah"},{"family":"Klin","given":"Ami"}],"citation-key":"jones2023b","container-title":"JAMA Network Open","container-title-short":"JAMA Network Open","DOI":"10.1001/jamanetworkopen.2023.30145","ISSN":"2574-3805","issue":"9","issued":{"date-parts":[["2023",9,5]]},"page":"e2330145","source":"Silverchair","title":"Development and Replication of Objective Measurements of Social Visual Engagement to Aid in Early Diagnosis and Assessment of Autism","type":"article-journal","URL":"https://doi.org/10.1001/jamanetworkopen.2023.30145","volume":"6"},
  {"id":"jordan2019","abstract":"The purpose of the study was to examine the effectiveness of the micro‐expressions training tool (METT) in identifying and using micro‐expressions to improve lie detection. Participants (n = 90) were randomly assigned to receive training in micro‐expressions recognition, a bogus control training, or no training. All participants made veracity judgements of five randomly selected videos of targets providing deceptive or truthful statements. With the use of the Bayesian analyses, we found that the METT group did not outperform those in the bogus training and no training groups. Further, overall accuracy was slightly below chance. Implications of these results are discussed. (PsycInfo Database Record (c) 2020 APA, all rights reserved)","author":[{"family":"Jordan","given":"Sarah"},{"family":"Brimbal","given":"Laure"},{"family":"Wallace","given":"D. Brian"},{"family":"Kassin","given":"Saul M."},{"family":"Hartwig","given":"Maria"},{"family":"Street","given":"Chris N. H."}],"citation-key":"jordan2019","container-title":"Journal of Investigative Psychology and Offender Profiling","DOI":"10.1002/jip.1532","event-place":"US","ISSN":"1544-4767","issue":"3","issued":{"date-parts":[["2019"]]},"page":"222-235","publisher":"John Wiley & Sons","publisher-place":"US","source":"APA PsycNet","title":"A test of the micro‐expressions training tool: Does it improve lie detection?","title-short":"A test of the micro‐expressions training tool","type":"article-journal","volume":"16"},
  {"id":"journal2024","abstract":"Children with autism spectrum disorder (ASD) often face challenges in early social communication skills, prompting the need for a detailed exploration of specific behaviors and their impact on cognitive and adaptive functioning. This study aims to address this gap by examining the developmental trajectories of early social communication skills in preschoolers with ASD aged 18–60 months, comparing them to age-matched typically developing (TD) children. Utilizing the early social communication scales (ESCS), the research employs a longitudinal design to capture changes over time. We apply a principal component analysis (PCA) to ESCS variables to identify underlying components, and cluster analysis to identify subgroups based on preverbal communication profiles. The results reveal consistent differences in early social communication skills between ASD and TD children, with ASD children exhibiting reduced skills. PCA identifies two components, distinguishing objects-directed behaviors and social interaction-directed behaviors. Cluster analysis identifies three subgroups of autistic children, each displaying specific communication profiles associated with distinct cognitive and adaptive functioning trajectories. In conclusion, this study provides a nuanced understanding of early social communication development in ASD, emphasizing the importance of low-level behaviors. The identification of subgroups and their unique trajectories contributes to a more comprehensive understanding of ASD heterogeneity. These findings underscore the significance of early diagnosis, focusing on specific behaviors predicting cognitive and adaptive functioning outcomes. The study encourages further research to explore the sequential development of these skills, offering valuable insights for interventions and support strategies.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Journal","given":"Fiona"},{"family":"Franchini","given":"Martina"},{"family":"Godel","given":"Michel"},{"family":"Kojovic","given":"Nada"},{"family":"Latrèche","given":"Kenza"},{"family":"Solazzo","given":"Stefania"},{"family":"Schneider","given":"Maude"},{"family":"Schaer","given":"Marie"}],"citation-key":"journal2024","container-title":"Autism Research","DOI":"10.1002/aur.3188","ISSN":"1939-3806","issue":"10","issued":{"date-parts":[["2024"]]},"language":"en","license":"© 2024 The Author(s). Autism Research published by International Society for Autism Research and Wiley Periodicals LLC.","page":"2030-2044","source":"Wiley Online Library","title":"Phenotyping variability in early socio-communicative skills in young children with autism and its influence on later development","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1002/aur.3188","volume":"17"},
  {"id":"kaasinen2018","abstract":"With the fourth industrial revolution, Industry 4.0, many work tasks are becoming knowledge intensive. At the forefront of the change are workers that are already mobile, working in the field with customers. We describe the human-centred design process that resulted in the Mobile Service Technician 4.0 concept. The concept illustrates how industrial field maintenance work could benefit from knowledge-sharing solutions based on Industry 4.0. The solutions utilize industrial internet, virtual and augmented reality as well as wearable technologies to improve mobile service technicians’ daily work performance and work satisfaction. The Mobile Service Technician 4.0 concept illustrates the user experience of future maintenance work: feeling competent, feeling connected to the work community, and feeling of success and achievement by being better prepared for maintenance visits, getting situationally relevant support in maintenance operations, sharing knowledge with peers, and making maintenance reports effortless.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Kaasinen","given":"Eija"},{"family":"Aromaa","given":"Susanna"},{"family":"Väätänen","given":"Antti"},{"family":"Mäkelä","given":"Ville"},{"family":"Hakulinen","given":"Jaakko"},{"family":"Keskinen","given":"Tuuli"},{"family":"Elo","given":"Joona"},{"family":"Siltanen","given":"Sanni"},{"family":"Rauhala","given":"Ville"},{"family":"Aaltonen","given":"Iina"},{"family":"Hella","given":"Juho"},{"family":"Honkamaa","given":"Petri"},{"family":"Leppä","given":"Mikael"},{"family":"Niemelä","given":"Antti"},{"family":"Parviainen","given":"Juha"},{"family":"Saarinen","given":"Santeri"},{"family":"Turunen","given":"Markku"},{"family":"Törnqvist","given":"Jouni"},{"family":"Valtonen","given":"Juha"},{"family":"Woodward","given":"Charles"}],"citation-key":"kaasinen2018","container-title":"Interaction Design and Architecture(s)","container-title-short":"IxD&A","DOI":"10.55612/s-5002-038-001","ISSN":"22832998","issue":"38","issued":{"date-parts":[["2018",9,10]]},"language":"en","page":"6-27","source":"DOI.org (Crossref)","title":"Mobile Service Technician 4.0 – Knowledge-Sharing Solutions for Industrial Field Maintenance","type":"article-journal","URL":"https://ixdea.org/38_1/"},
  {"id":"kalb2022","abstract":"There are long-standing disparities in the prevalence of autism spectrum disorder (ASD) across race and sex. Surprisingly, few studies have examined whether these disparities arise partially out of systematic biases in the Autism Diagnostic Observation Schedule, Second Edition (ADOS-2), the reference standard measure of ASD.To examine differential item functioning (DIF) of ADOS-2 items across sex and race.This is a cross-sectional study of children who were evaluated for ASD between 2014 and 2020 at a specialty outpatient clinic located in the Mid-Atlantic region of the US. Data were analyzed from July 2021 to February 2022.Child race (Black/African American vs White) and sex (female vs male).Item-level biases across ADOS-2 harmonized algorithm items, including social affect (SA; 10 items) and repetitive/restricted behaviors (RRBs; 4 items), were evaluated across 3 modules. Measurement bias was identified by examining DIF and differential test functioning (DTF), within a graded response, item response theory framework. Statistical significance was determined by a likelihood ratio χ2 test, and a series of metrics was used to examine the magnitude of DIF and DTF.A total of 6269 children (mean [SD] age, 6.77 [3.27] years; 1619 Black/African American [25.9%], 3151 White [50.3%], and 4970 male [79.4%]), were included in this study. Overall, 16 of 140 ADOS-2 diagnostic items (11%) had a significant DIF. For race, 8 items had a significant DIF, 6 of which involved SA. No single item showed DIF consistently across all modules. Most items with DIF had greater difficulty and poorer discrimination in Black/African American children compared with White children. For sex, 5 items showed significant DIF. DIF was split across SA and RRB. However, hand mannerisms evidenced DIF across all 5 algorithms, with generally greater difficulty. The magnitude of DIF was only moderate to large for 2 items: hand mannerisms (among female children) and repetitive interests (among Black/African American children). The overall estimated effect of DIF on total DTF was not large.These findings suggest that the ADOS-2 does not have widespread systematic measurement bias across race or sex. However, the findings raise some concerns around underdetection that warrant further research.","accessed":{"date-parts":[["2025",2,5]]},"author":[{"family":"Kalb","given":"Luther G."},{"family":"Singh","given":"Vini"},{"family":"Hong","given":"Ji Su"},{"family":"Holingue","given":"Calliope"},{"family":"Ludwig","given":"Natasha N."},{"family":"Pfeiffer","given":"Danika"},{"family":"Reetzke","given":"Rachel"},{"family":"Gross","given":"Alden L."},{"family":"Landa","given":"Rebecca"}],"citation-key":"kalb2022","container-title":"JAMA Network Open","container-title-short":"JAMA Network Open","DOI":"10.1001/jamanetworkopen.2022.9498","ISSN":"2574-3805","issue":"4","issued":{"date-parts":[["2022",4,26]]},"page":"e229498","source":"Silverchair","title":"Analysis of Race and Sex Bias in the Autism Diagnostic Observation Schedule (ADOS-2)","type":"article-journal","URL":"https://doi.org/10.1001/jamanetworkopen.2022.9498","volume":"5"},
  {"id":"kang2024","author":[{"family":"Kang","given":"Jueun"},{"family":"Sani","given":"Paolo"}],"citation-key":"kang2024","issued":{"date-parts":[["2024"]]},"language":"en","source":"Zotero","title":"Analysis by Synthesis Assessment of Speech Emotion Perception in  Different Languages","type":"article-journal"},
  {"id":"kangarani-farahani2024","abstract":"This article comprehensively reviews motor impairments in children with autism spectrum disorder (ASD) to: (1) determine the prevalence of motor problems in children with ASD; (2) understand the nature of motor difficulties in ASD and whether they are consistent with developmental coordination disorder (DCD); and (3) determine if the term DCD was used as a co-occurring diagnosis in children with ASD after publication of the DSM-5 in 2013. The following databases were systematically searched: MEDLINE, EMBASE, CINAHL, and PsycINFO from 2010 to December 2021. Articles were included if they: (1) were peer-reviewed and published in a scientific journal; (2) included children with ASD who were between 5 and 12 years; (3) used motor or function measures to assess motor abilities in children with ASD. Studies that included children with intellectual disabilities were excluded. Two independent reviewers reviewed titles, abstracts, and full-text articles for inclusion. Twenty-seven studies met the inclusion criteria and were assessed for quality by two independent reviewers using the Appraisal tool for Cross-Sectional Studies. The majority of articles (92.5%) indicated that 50–88% of children with ASD had significant motor impairments on standardized motor assessments and/or functional questionnaires. The nature of motor and function problems in ASD were consistent with DCD; however, only three out of 20 papers (15%) that were published from 2014 described the motor problems as DCD. One study reported that 15.1% of children with ASD with motor impairments had a co-occurring diagnosis of DCD, suggesting that DCD is under-recognized in this clinical population.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Kangarani-Farahani","given":"Melika"},{"family":"Malik","given":"Myrah Anum"},{"family":"Zwicker","given":"Jill G."}],"citation-key":"kangarani-farahani2024","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-05948-1","ISSN":"1573-3432","issue":"5","issued":{"date-parts":[["2024",5,1]]},"language":"en","page":"1977-1997","source":"Springer Link","title":"Motor Impairments in Children with Autism Spectrum Disorder: A Systematic Review and Meta-analysis","title-short":"Motor Impairments in Children with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-05948-1","volume":"54"},
  {"id":"kapp2021","abstract":"Currently an increasing number of head mounted displays (HMD) for virtual and augmented reality (VR/AR) are equipped with integrated eye trackers. Use cases of these integrated eye trackers include rendering optimization and gaze-based user interaction. In addition, visual attention in VR and AR is interesting for applied research based on eye tracking in cognitive or educational sciences for example. While some research toolkits for VR already exist, only a few target AR scenarios. In this work, we present an open-source eye tracking toolkit for reliable gaze data acquisition in AR based on Unity 3D and the Microsoft HoloLens 2, as well as an R package for seamless data analysis. Furthermore, we evaluate the spatial accuracy and precision of the integrated eye tracker for fixation targets with different distances and angles to the user (n=21). On average, we found that gaze estimates are reported with an angular accuracy of 0.83 degrees and a precision of 0.27 degrees while the user is resting, which is on par with state-of-the-art mobile eye trackers.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Kapp","given":"Sebastian"},{"family":"Barz","given":"Michael"},{"family":"Mukhametov","given":"Sergey"},{"family":"Sonntag","given":"Daniel"},{"family":"Kuhn","given":"Jochen"}],"citation-key":"kapp2021","container-title":"Sensors (Basel, Switzerland)","container-title-short":"Sensors (Basel)","DOI":"10.3390/s21062234","ISSN":"1424-8220","issue":"6","issued":{"date-parts":[["2021",3,23]]},"page":"2234","PMCID":"PMC8004990","PMID":"33806863","source":"PubMed Central","title":"ARETT: Augmented Reality Eye Tracking Toolkit for Head Mounted Displays","title-short":"ARETT","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8004990/","volume":"21"},
  {"id":"karami2021","abstract":"<p>In recent years, the application of virtual reality (VR) for therapeutic purposes has escalated dramatically. Favorable properties of VR for engaging patients with autism, in particular, have motivated an enormous body of investigations targeting autism-related disabilities with this technology. This study aims to provide a comprehensive meta-analysis for evaluating the effectiveness of VR on the rehabilitation and training of individuals diagnosed with an autism spectrum disorder. Accordingly, we conducted a systematic search of related databases and, after screening for inclusion criteria, reviewed 33 studies for more detailed analysis. Results revealed that individuals undergoing VR training have remarkable improvements with a relatively large effect size with Hedges <italic>g</italic> of 0.74. Furthermore, the results of the analysis of different skills indicated diverse effectiveness. The strongest effect was observed for daily living skills (<italic>g</italic> = 1.15). This effect was moderate for other skills: <italic>g</italic> = 0.45 for cognitive skills, <italic>g</italic> = 0.46 for emotion regulation and recognition skills, and <italic>g</italic> = 0.69 for social and communication skills. Moreover, five studies that had used augmented reality also showed promising efficacy (<italic>g</italic> = 0.92) that calls for more research on this tool. In conclusion, the application of VR-based settings in clinical practice is highly encouraged, although their standardization and customization need more research.</p>","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Karami","given":"Behnam"},{"family":"Koushki","given":"Roxana"},{"family":"Arabgol","given":"Fariba"},{"family":"Rahmani","given":"Maryam"},{"family":"Vahabie","given":"Abdol-Hossein"}],"citation-key":"karami2021","container-title":"Frontiers in Psychiatry","container-title-short":"Front. Psychiatry","DOI":"10.3389/fpsyt.2021.665326","ISSN":"1664-0640","issued":{"date-parts":[["2021",6,23]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Effectiveness of Virtual/Augmented Reality–Based Therapeutic Interventions on Individuals With Autism Spectrum Disorder: A Comprehensive Meta-Analysis","title-short":"Effectiveness of Virtual/Augmented Reality–Based Therapeutic Interventions on Individuals With Autism Spectrum Disorder","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2021.665326/full","volume":"12"},
  {"id":"kari2023","abstract":"Manipulating their environment is one of the fundamental actions that humans, and actors more generally, perform. Yet, today’s mixed reality systems enable us to situate virtual content in the physical scene but fall short of expanding the visual illusion to believable environment manipulations. In this paper, we present the concept and system of Scene Responsiveness, the visual illusion that virtual actions affect the physical scene. Using co-aligned digital twins for coherence-preserving just-in-time virtualization of physical objects in the environment, Scene Responsiveness allows actors to seemingly manipulate physical objects as if they were virtual. Based on Scene Responsiveness, we propose two general types of end to-end illusionary experiences that ensure visuotactile consistency through the presented techniques of object elusiveness and object rephysicalization. We demonstrate how our Daydreaming illusion enables virtual characters to enter the scene through a physically closed door and vandalize the physical scene, or users to enchant and summon far-away physical objects. In a user evaluation of our Copperfield illusion, we found that Scene Responsiveness can be rendered so convincingly that it lends itself to magic tricks. We present our system architecture and conclude by discussing the implications of scene-responsive mixed reality for gaming and telepresence.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Kari","given":"Mohamed"},{"family":"Schütte","given":"Reinhard"},{"family":"Sodhi","given":"Raj"}],"citation-key":"kari2023","collection-title":"UIST '23","container-title":"Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology","DOI":"10.1145/3586183.3606825","event-place":"New York, NY, USA","ISBN":"979-8-4007-0132-0","issued":{"date-parts":[["2023",10,29]]},"page":"1–15","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Scene Responsiveness for Visuotactile Illusions in Mixed Reality","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3586183.3606825"},
  {"id":"katsigiannis2018","abstract":"In this paper, we present DREAMER, a multimodal database consisting of electroencephalogram (EEG) and electrocardiogram (ECG) signals recorded during affect elicitation by means of audio-visual stimuli. Signals from 23 participants were recorded along with the participants self-assessment of their affective state after each stimuli, in terms of valence, arousal, and dominance. All the signals were captured using portable, wearable, wireless, low-cost, and off-the-shelf equipment that has the potential to allow the use of affective computing methods in everyday applications. A baseline for participant-wise affect recognition using EEG and ECG-based features, as well as their fusion, was established through supervised classification experiments using support vector machines (SVMs). The self-assessment of the participants was evaluated through comparison with the self-assessments from another study using the same audio-visual stimuli. Classification results for valence, arousal, and dominance of the proposed database are comparable to the ones achieved for other databases that use nonportable, expensive, medical grade devices. These results indicate the prospects of using low-cost devices for affect recognition applications. The proposed database will be made publicly available in order to allow researchers to achieve a more thorough evaluation of the suitability of these capturing devices for affect recognition applications.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Katsigiannis","given":"Stamos"},{"family":"Ramzan","given":"Naeem"}],"citation-key":"katsigiannis2018","container-title":"IEEE Journal of Biomedical and Health Informatics","DOI":"10.1109/JBHI.2017.2688239","ISSN":"2168-2208","issue":"1","issued":{"date-parts":[["2018",1]]},"page":"98-107","source":"IEEE Xplore","title":"DREAMER: A Database for Emotion Recognition Through EEG and ECG Signals From Wireless Low-cost Off-the-Shelf Devices","title-short":"DREAMER","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/7887697","volume":"22"},
  {"id":"kaur2018a","abstract":"Children with Autism Spectrum Disorder (ASD) have basic motor impairments in balance, gait, and coordination as well as autism-speciﬁc impairments in praxis/motor planning and interpersonal synchrony. Majority of the current literature focuses on isolated motor behaviors or domains. Additionally, the relationship between cognition, symptom severity, and motor performance in ASD is unclear. We used a comprehensive set of measures to compare gross and ﬁne motor, praxis/imitation, motor coordination, and interpersonal synchrony skills across three groups of children between 5 and 12 years of age: children with ASD with high IQ (HASD), children with ASD with low IQ (LASD), and typically developing (TD) children. We used the Bruininks-Oseretsky Test of Motor Proﬁciency and the Bilateral Motor Coordination subtest of the Sensory Integration and Praxis Tests to assess motor performance and praxis skills respectively. Children were also examined while performing simple and complex rhythmic upper and lower limb actions on their own (solo context) and with a social partner (social context). Both ASD groups had lower gross and ﬁne motor scores, greater praxis errors in total and within various error types, lower movement rates, greater movement variability, and weaker interpersonal synchrony compared to the TD group. In addition, the LASD group had lower gross motor scores and greater mirroring errors compared to the HASD group. Overall, a variety of motor impairments are present across the entire spectrum of children with ASD, regardless of their IQ scores. Both, ﬁne and gross motor performance signiﬁcantly correlated with IQ but not with autism severity; however, praxis errors (mainly, total, overﬂow, and rhythmicity) strongly correlated with autism severity and not IQ. Our study ﬁndings highlight the need for clinicians and therapists to include motor evaluations and interventions in the standard-of-care of children with ASD and for the broader autism community to recognize dyspraxia as an integral part of the deﬁnition of ASD.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Kaur","given":"Maninderjit"},{"family":"M. Srinivasan","given":"Sudha"},{"family":"N. Bhat","given":"Anjana"}],"citation-key":"kaur2018a","container-title":"Research in Developmental Disabilities","container-title-short":"Research in Developmental Disabilities","DOI":"10.1016/j.ridd.2017.10.025","ISSN":"08914222","issued":{"date-parts":[["2018",1]]},"language":"en","page":"79-95","source":"DOI.org (Crossref)","title":"Comparing motor performance, praxis, coordination, and interpersonal synchrony between children with and without Autism Spectrum Disorder (ASD)","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0891422217302949","volume":"72"},
  {"id":"kaur2025","abstract":"KeepCalm is a digital mental health application, co-designed with community partners, that incorporates wearable biosensing with support for teams to address challenging behaviors and emotion dysregulation in children on the autism spectrum.We followed a user-centered design framework. Before app development, we conducted design workshops, needs assessment interviews, a systematic review, and created an Expert Advisory Board. Once we had a working prototype, we recruited 73 participants to test and help improve the app across five testing cycles.Participants rated the app across testing cycles as highly acceptable, appropriate, feasible, and with good usability. Qualitative data indicated that KeepCalm helped teachers (a) be aware of students’ previously unrealized triggers, especially for nonspeaking students; (b) prevent behavioral episodes; (c) communicate with parents about behaviors/strategies; and (d) equipped parents with knowledge of strategies to use at home. We learned that in order to make the app acceptable and appropriate we needed to make the app enjoyable/easy to use and to focus development on novel features that augment teachers’ skills (e.g., behavioral pattern and stress detection). We also learned about the importance of maximizing feasibility, through in-person app training/support especially regarding the wearable devices, and the importance of having aides involved.Our findings have informed plans for wider-scale feasibility testing so that we may examine the determinants of implementation to inform adaptations and refinement, and gather preliminary efficacy data on KeepCalm’s impact on reducing challenging behaviors and supporting emotion regulation in students on the autism spectrum.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Kaur","given":"Isha"},{"family":"Kamel","given":"Rima"},{"family":"Sultanik","given":"Evan"},{"family":"Tan","given":"Jessica"},{"family":"Mazefsky","given":"Carla A"},{"family":"Brookman-Frazee","given":"Lauren"},{"family":"McPartland","given":"James C"},{"family":"Goodwin","given":"Matthew S"},{"family":"Pennington","given":"Jeffrey"},{"family":"Beidas","given":"Rinad S"},{"family":"Mandell","given":"David S"},{"family":"Nuske","given":"Heather J"}],"citation-key":"kaur2025","container-title":"Journal of Pediatric Psychology","container-title-short":"Journal of Pediatric Psychology","DOI":"10.1093/jpepsy/jsae078","ISSN":"0146-8693","issue":"1","issued":{"date-parts":[["2025",1,1]]},"page":"129-140","source":"Silverchair","title":"Supporting emotion regulation in children on the autism spectrum: co-developing a digital mental health application for school-based settings with community partners","title-short":"Supporting emotion regulation in children on the autism spectrum","type":"article-journal","URL":"https://doi.org/10.1093/jpepsy/jsae078","volume":"50"},
  {"id":"kawakami2022","abstract":"Data-driven AI systems are increasingly used to augment human decision-making in complex, social contexts, such as social work or legal practice. Yet, most existing design knowledge regarding how to best support AI-augmented decision-making comes from studies in comparatively well-defined settings. In this paper, we present findings from design interviews with 12 social workers who use an algorithmic decision support tool (ADS) to assist their day-to-day child maltreatment screening decisions. We generated a range of design concepts, each envisioning different ways of redesigning or augmenting the ADS interface. Overall, workers desired ways to understand the risk score and incorporate contextual knowledge, which move beyond existing notions of AI interpretability. Conversations around our design concepts also surfaced more fundamental concerns around the assumptions underlying statistical prediction, such as inference based on similar historical cases and statistical notions of uncertainty. Based on our findings, we discuss how ADS may be better designed to support the roles of human decision-makers in social decision-making contexts.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Kawakami","given":"Anna"},{"family":"Sivaraman","given":"Venkatesh"},{"family":"Stapleton","given":"Logan"},{"family":"Cheng","given":"Hao-Fei"},{"family":"Perer","given":"Adam"},{"family":"Wu","given":"Zhiwei Steven"},{"family":"Zhu","given":"Haiyi"},{"family":"Holstein","given":"Kenneth"}],"citation-key":"kawakami2022","collection-title":"DIS '22","container-title":"Proceedings of the 2022 ACM Designing Interactive Systems Conference","DOI":"10.1145/3532106.3533556","event-place":"New York, NY, USA","ISBN":"978-1-4503-9358-4","issued":{"date-parts":[["2022",6,13]]},"page":"454–470","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"“Why Do I Care What’s Similar?” Probing Challenges in AI-Assisted Child Welfare Decision-Making through Worker-AI Interface Design Concepts","title-short":"“Why Do I Care What’s Similar?","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3532106.3533556"},
  {"id":"ke2022","abstract":"This exploratory study was intended to investigate the design and feasibility of using a web virtual reality based social learning space for autistic children at home. The researchers of the current study developed and implemented an open-source, web virtual reality based learning program for children with autism. Endorsing mixed-method convergent parallel design, we collected both qualitative and quantitative data from four autistic children, including repeated measures of social skills performance, self- and parent-reported social and communication competence, observation notes, and individual interviews. The study found preliminary evidence for a positive impact of deploying a virtual reality-based social sandbox on the practice and development of complex social skills for autistic children. All participants showed significant reduced social communication impairments from the pre- to the post-intervention phases. Nevertheless, participants’ social skills performance in the virtual world was mediated by two social task design features—external goal structure and individualization. Play- and design-oriented social tasks in the three-dimensional virtual world framed meaningful social experiences or the naturalistic intervention for social skills development. Positive impacts of using a virtual reality-based social sandbox on complex social skills development for autistic children.Social task design features mediate social skills performance of autistic children.Purposeful environment arrangement creates a naturalistic intervention for autism. Positive impacts of using a virtual reality-based social sandbox on complex social skills development for autistic children. Social task design features mediate social skills performance of autistic children. Purposeful environment arrangement creates a naturalistic intervention for autism.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Ke","given":"Fengfeng"},{"family":"Moon","given":"Jewoong"},{"family":"Sokolikj","given":"Zlatko"}],"citation-key":"ke2022","container-title":"Disability and Rehabilitation: Assistive Technology","DOI":"10.1080/17483107.2022.2156630","ISSN":"1748-3107","issue":"4","issued":{"date-parts":[["2022",5,18]]},"page":"1178-1209","PMID":"36524469","publisher":"Taylor & Francis","source":"Taylor and Francis+NEJM","title":"Designing and deploying a virtual social sandbox for autistic children","type":"article-journal","URL":"https://doi.org/10.1080/17483107.2022.2156630","volume":"19"},
  {"id":"ke2022a","abstract":"In this study, the researchers explored the usage of a virtual reality (VR)–based social skills learning environment for children with autism spectrum disorder (ASD). Using OpenSimulator, the researchers constructed a desktop VR-based learning environment that supports social-oriented role-play, gaming, and design by children with ASD. Seven 10–14 years old children with ASD participated in this VR-based social skills program for 20+ hr on average. Data were collected via screen recording and observation of play- and design-oriented social skills enactment and pre- and postintervention Social Communication and Skills Questionnaires. Participants demonstrated an increased level of successful social skills performance from the baseline to the intervention phase. The findings provided preliminary evidence for the usage of a VR-based social skills learning environment for children with ASD.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Ke","given":"Fengfeng"},{"family":"Moon","given":"Jewoong"},{"family":"Sokolikj","given":"Zlatko"}],"citation-key":"ke2022a","container-title":"Journal of Special Education Technology","container-title-short":"J Spec Educ Technol","DOI":"10.1177/0162643420945603","ISSN":"0162-6434","issue":"1","issued":{"date-parts":[["2022",3,1]]},"language":"en","page":"49-62","publisher":"SAGE Publications Inc","source":"SAGE Journals","title":"Virtual Reality–Based Social Skills Training for Children With Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1177/0162643420945603","volume":"37"},
  {"id":"keehn2024","abstract":"Finding effective and scalable solutions to address diagnostic delays and disparities in autism is a public health imperative. Approaches that integrate eye-tracking biomarkers into tiered community-based models of autism evaluation hold promise for addressing this problem.To determine whether a battery of eye-tracking biomarkers can reliably differentiate young children with and without autism in a community-referred sample collected during clinical evaluation in the primary care setting and to evaluate whether combining eye-tracking biomarkers with primary care practitioner (PCP) diagnosis and diagnostic certainty is associated with diagnostic outcome.Early Autism Evaluation (EAE) Hub system PCPs referred a consecutive sample of children to this prospective diagnostic study for blinded eye-tracking index test and follow-up expert evaluation from June 7, 2019, to September 23, 2022. Participants included 146 children (aged 14-48 months) consecutively referred by 7 EAE Hubs. Of 154 children enrolled, 146 provided usable data for at least 1 eye-tracking measure.The primary outcomes were sensitivity and specificity of a composite eye-tracking (ie, index) test, which was a consolidated measure based on significant eye-tracking indices, compared with reference standard expert clinical autism diagnosis. Secondary outcome measures were sensitivity and specificity of an integrated approach using an index test and PCP diagnosis and certainty.Among 146 children (mean [SD] age, 2.6 [0.6] years; 104 [71%] male; 21 [14%] Hispanic or Latine and 96 [66%] non-Latine White; 102 [70%] with a reference standard autism diagnosis), 113 (77%) had concordant autism outcomes between the index (composite biomarker) and reference outcomes, with 77.5% sensitivity (95% CI, 68.4%-84.5%) and 77.3% specificity (95% CI, 63.0%-87.2%). When index diagnosis was based on the combination of a composite biomarker, PCP diagnosis, and diagnostic certainty, outcomes were concordant with reference standard for 114 of 127 cases (90%) with a sensitivity of 90.7% (95% CI, 83.3%-95.0%) and a specificity of 86.7% (95% CI, 70.3%-94.7%).In this prospective diagnostic study, a composite eye-tracking biomarker was associated with a best-estimate clinical diagnosis of autism, and an integrated diagnostic model including PCP diagnosis and diagnostic certainty demonstrated improved sensitivity and specificity. These findings suggest that equipping PCPs with a multimethod diagnostic approach has the potential to substantially improve access to timely, accurate diagnosis in local communities.","accessed":{"date-parts":[["2025",2,13]]},"author":[{"family":"Keehn","given":"Brandon"},{"family":"Monahan","given":"Patrick"},{"family":"Enneking","given":"Brett"},{"family":"Ryan","given":"Tybytha"},{"family":"Swigonski","given":"Nancy"},{"family":"McNally Keehn","given":"Rebecca"}],"citation-key":"keehn2024","container-title":"JAMA Network Open","container-title-short":"JAMA Network Open","DOI":"10.1001/jamanetworkopen.2024.11190","ISSN":"2574-3805","issue":"5","issued":{"date-parts":[["2024",5,14]]},"page":"e2411190","source":"Silverchair","title":"Eye-Tracking Biomarkers and Autism Diagnosis in Primary Care","type":"article-journal","URL":"https://doi.org/10.1001/jamanetworkopen.2024.11190","volume":"7"},
  {"id":"kerbl2023","abstract":"Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (≥ 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.","accessed":{"date-parts":[["2024",12,11]]},"author":[{"family":"Kerbl","given":"Bernhard"},{"family":"Kopanas","given":"Georgios"},{"family":"Leimkuehler","given":"Thomas"},{"family":"Drettakis","given":"George"}],"citation-key":"kerbl2023","container-title":"ACM Transactions on Graphics","container-title-short":"ACM Trans. Graph.","DOI":"10.1145/3592433","ISSN":"0730-0301, 1557-7368","issue":"4","issued":{"date-parts":[["2023",8]]},"language":"en","page":"1-14","source":"DOI.org (Crossref)","title":"3D Gaussian Splatting for Real-Time Radiance Field Rendering","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/3592433","volume":"42"},
  {"id":"kim2023","abstract":"Facial expression recognition (FER) in the wild from various viewpoints, lighting conditions, face poses, scales, and occlusions is an extremely challenging field of research. In this study, we construct a face graph by selecting action units that play an important role in changing facial expressions, and we propose an algorithm for recognizing facial expressions using a graph convolutional network (GCN). We first generated an attention map that can highlight action units to extract important facial expression features from faces in the wild. After feature extraction, a face graph is constructed by combining the attention map with face patches, and changes in expression in the wild are recognized using a GCN. Through comparative experiments conducted using both lab-controlled and wild datasets, we prove that the proposed method is the most suitable FER approach for use with image datasets captured in the wild and those under well-controlled indoor conditions.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Kim","given":"Hyeongjin"},{"family":"Lee","given":"Jong-Ha"},{"family":"Ko","given":"Byoung Chul"}],"citation-key":"kim2023","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2023.3286547","ISSN":"2169-3536","issued":{"date-parts":[["2023"]]},"page":"59774-59787","source":"IEEE Xplore","title":"Facial Expression Recognition in the Wild Using Face Graph and Attention","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/10153584","volume":"11"},
  {"id":"kim2024","abstract":"Background: Individuals with autism often experience heightened anxiety in workplace environments because of challenges in communication and sensory overload. As these experiences can result in negative self-image, promoting their self-efficacy in the workplace is crucial. Virtual reality (VR) systems have emerged as promising tools for enhancing the self-efficacy of individuals with autism in navigating social scenarios, aiding in the identification of anxiety-inducing situations, and preparing for real-world interactions. However, there is limited research exploring the potential of VR to enhance self-efficacy by facilitating an understanding of emotional and physiological states during social skills practice. Objective: This study aims to develop and evaluate a VR system that enabled users to experience simulated work-related social scenarios and reflect on their behavioral and physiological data through data visualizations. We intended to investigate how these data, combined with the simulations, can support individuals with autism in building their self-efficacy in social skills. Methods: We developed WorkplaceVR, a comprehensive VR system designed for engagement in simulated work-related social scenarios, supplemented with data-driven reflections of users’ behavioral and physiological responses. A within-subject deployment study was subsequently conducted with 14 young adults with autism to examine WorkplaceVR’s feasibility. A mixed methods approach was used, compassing pre- and postsystem use assessments of participants’ self-efficacy perceptions. Results: The study results revealed WorkplaceVR’s effectiveness in enhancing social skills and self-efficacy among individuals with autism. First, participants exhibited a statistically significant increase in perceived self-efficacy following their engagement with the VR system (P=.02). Second, thematic analysis of the interview data confirmed that the VR system and reflections on the data fostered increased self-awareness among participants about social situations that trigger their anxiety, as well as the behaviors they exhibit during anxious moments. This increased self-awareness prompted the participants to recollect their related experiences in the real world and articulate anxiety management strategies. Furthermore, the insights uncovered motivated participants to engage in self-advocacy, as they wanted to share the insights with others. Conclusions: This study highlights the potential of VR simulations enriched with physiological and behavioral sensing as a valuable tool for augmenting self-efficacy in workplace social interactions for individuals with autism. Data reflection facilitated by physiological sensors helped participants with autism become more self-aware of their emotions and behaviors, advocate for their characteristics, and develop positive self-beliefs.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Kim","given":"Sung-In"},{"family":"Jang","given":"So-youn"},{"family":"Kim","given":"Taewan"},{"family":"Kim","given":"Bogoan"},{"family":"Jeong","given":"Dayoung"},{"family":"Noh","given":"Taehyung"},{"family":"Jeong","given":"Mingon"},{"family":"Hall","given":"Kaely"},{"family":"Kim","given":"Meelim"},{"family":"Yoo","given":"Hee Jeong"},{"family":"Han","given":"Kyungsik"},{"family":"Hong","given":"Hwajung"},{"family":"Kim","given":"Jennifer G."}],"citation-key":"kim2024","container-title":"JMIR Formative Research","DOI":"10.2196/52157","issue":"1","issued":{"date-parts":[["2024",1,11]]},"language":"EN","license":"Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work (\"first published in the Journal of Medical Internet Research...\") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.","page":"e52157","publisher":"JMIR Publications Inc., Toronto, Canada","source":"formative.jmir.org","title":"Promoting Self-Efficacy of Individuals With Autism in Practicing Social Skills in the Workplace Using Virtual Reality and Physiological Sensors: Mixed Methods Study","title-short":"Promoting Self-Efficacy of Individuals With Autism in Practicing Social Skills in the Workplace Using Virtual Reality and Physiological Sensors","type":"article-journal","URL":"https://formative.jmir.org/2024/1/e52157","volume":"8"},
  {"id":"kirkham2024","abstract":"Background: Neuropsychological assessments traditionally include tests of executive functioning (EF) because of its critical role in daily activities and link to mental disorders. Established traditional EF assessments, although robust, lack ecological validity and are limited to single cognitive processes. These methods, which are suitable for clinical populations, are less informative regarding EF in healthy individuals. With these limitations in mind, immersive virtual reality (VR)–based assessments of EF have garnered interest because of their potential to increase test sensitivity, ecological validity, and neuropsychological assessment accessibility.\nObjective: This systematic review aims to explore the literature on immersive VR assessments of EF focusing on (1) EF components being assessed, (2) how these assessments are validated, and (3) strategies for monitoring potential adverse (cybersickness) and beneficial (immersion) effects.\nMethods: EBSCOhost, Scopus, and Web of Science were searched in July 2022 using keywords that reflected the main themes of VR, neuropsychological tests, and EF. Articles had to be peer-reviewed manuscripts written in English and published after 2013 that detailed empirical, clinical, or proof-of-concept studies in which a virtual environment using a head-mounted display was used to assess EF in an adult population. A tabular synthesis method was used in which validation details from each study, including comparative assessments and scores, were systematically organized in a table. The results were summed and qualitatively analyzed to provide a comprehensive overview of the findings.\nResults: The search retrieved 555 unique articles, of which 19 (3.4%) met the inclusion criteria. The reviewed studies encompassed EF and associated higher-order cognitive functions such as inhibitory control, cognitive flexibility, working memory, planning, and attention. VR assessments commonly underwent validation against gold-standard traditional tasks. However, discrepancies were observed, with some studies lacking reported a priori planned correlations, omitting detailed descriptions of the EF constructs evaluated using the VR paradigms, and frequently reporting incomplete results. Notably, only 4 of the 19 (21%) studies evaluated cybersickness, and 5 of the 19 (26%) studies included user experience assessments.\nConclusions: Although it acknowledges the potential of VR paradigms for assessing EF, the evidence has limitations. The methodological and psychometric properties of the included studies were inconsistently addressed, raising concerns about their validity and reliability. Infrequent monitoring of adverse effects such as cybersickness and considerable variability in sample sizes may limit interpretation and hinder psychometric evaluation. Several recommendations are proposed to improve the theory and practice of immersive VR assessments of EF. Future studies should explore the integration of biosensors with VR systems and the capabilities of VR in the context of spatial navigation assessments. Despite considerable promise, the systematic and validated implementation of VR assessments is essential for ensuring their practical utility in real-world applications.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Kirkham","given":"Rebecca"},{"family":"Kooijman","given":"Lars"},{"family":"Albertella","given":"Lucy"},{"family":"Myles","given":"Dan"},{"family":"Yücel","given":"Murat"},{"family":"Rotaru","given":"Kristian"}],"citation-key":"kirkham2024","container-title":"JMIR Serious Games","DOI":"10.2196/50282","issue":"1","issued":{"date-parts":[["2024",2,26]]},"language":"EN","license":"This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published JMIR Serious Games, is properly cited. The complete bibliographic information, a link to the original publication on https://games.jmir.org/, as well as this copyright and license information must be included.","page":"e50282","publisher":"JMIR Publications Inc., Toronto, Canada","source":"games.jmir.org","title":"Immersive Virtual Reality–Based Methods for Assessing Executive Functioning: Systematic Review","title-short":"Immersive Virtual Reality–Based Methods for Assessing Executive Functioning","type":"article-journal","URL":"https://games.jmir.org/2024/1/e50282","volume":"12"},
  {"id":"klin2002","abstract":"Manifestations of core social deficits in autism are more pronounced in everyday settings than in explicit experimental tasks. To bring experimental measures in line with clinical observation, we report a novel method of quantifying atypical strategies of social monitoring in a setting that simulates the demands of daily experience. Enhanced ecological validity was intended to maximize between-group effect sizes and assess the predictive utility of experimental variables relative to outcome measures of social competence.While viewing social scenes, eye-tracking technology measured visual fixations in 15 cognitively able males with autism and 15 age-, sex-, and verbal IQ–matched control subjects. We reliably coded fixations on 4 regions: mouth, eyes, body, and objects. Statistical analyses compared fixation time on regions of interest between groups and correlation of fixation time with outcome measures of social competence (ie, standardized measures of daily social adjustment and degree of autistic social symptoms).Significant between-group differences were obtained for all 4 regions. The best predictor of autism was reduced eye region fixation time. Fixation on mouths and objects was significantly correlated with social functioning: increased focus on mouths predicted improved social adjustment and less autistic social impairment, whereas more time on objects predicted the opposite relationship.When viewing naturalistic social situations, individuals with autism demonstrate abnormal patterns of social visual pursuit consistent with reduced salience of eyes and increased salience of mouths, bodies, and objects. Fixation times on mouths and objects but not on eyes are strong predictors of degree of social competence.Arch Gen Psychiatry. 2002;59:809-816-->","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Klin","given":"Ami"},{"family":"Jones","given":"Warren"},{"family":"Schultz","given":"Robert"},{"family":"Volkmar","given":"Fred"},{"family":"Cohen","given":"Donald"}],"citation-key":"klin2002","container-title":"Archives of General Psychiatry","container-title-short":"Archives of General Psychiatry","DOI":"10.1001/archpsyc.59.9.809","ISSN":"0003-990X","issue":"9","issued":{"date-parts":[["2002",9,1]]},"page":"809-816","source":"Silverchair","title":"Visual Fixation Patterns During Viewing of Naturalistic Social Situations as Predictors of Social Competence in Individuals With Autism","type":"article-journal","URL":"https://doi.org/10.1001/archpsyc.59.9.809","volume":"59"},
  {"id":"knott2024","abstract":"Background: Despite the known benefits of accurate and timely diagnosis for children with attention-deficit hyperactivity disorder and autism spectrum disorders (autism), for some children this goal is not always achieved. Existing research has explored diagnostic delay for autism and attention-deficit hyperactivity disorder only, and when attention-deficit hyperactivity disorder and autism co-occur, autism has been the focus. No study has directly compared age at diagnosis and diagnostic delay for males and females across attention-deficit hyperactivity disorder, autism and specifically, attention-deficit hyperactivity disorder + autism.\nMethods: Australian caregivers (N = 677) of children with attention-deficit hyperactivity disorder, autism or attention-deficit hyperactivity disorder + autism were recruited via social media (n = 594) and the Monash Autism and ADHD Genetics and Neurodevelopment Project (n = 83). Caregivers reported on their child’s diagnostic process. Diagnostic delay was the mean difference between general initial developmental concerns and the child’s attention-deficit hyperactivity disorder and autism diagnosis.\nResults: Children with autism were significantly younger at autism diagnosis than the attention-deficit hyperactivity disorder + autism group (ηp2 = 0.06), whereas children with attention-deficit hyperactivity disorder were significantly older at attention-deficit hyperactivity disorder diagnosis than the attention-deficit hyperactivity disorder + autism group (ηp2 = 0.01). Delay to attention-deficit hyperactivity disorder and autism diagnosis was significantly longer in the attention-deficit hyperactivity disorder + autism group compared to attention-deficit hyperactivity disorder (ηp2 = 0.02) and autism (η2 = 0.04) only. Delay to autism diagnosis for females with autism (η2 = 0.06) and attention-deficit hyperactivity disorder + autism (η2 = 0.04) was longer compared to males.\nConclusions: Having attention-deficit hyperactivity disorder + autism and being female were associated with longer delays to diagnosis. The reasons for these delays and possible adverse effects on outcomes require further study.","accessed":{"date-parts":[["2024",6,20]]},"author":[{"family":"Knott","given":"Rachael"},{"family":"Mellahn","given":"Olivia J"},{"family":"Tiego","given":"Jeggan"},{"family":"Kallady","given":"Kathryn"},{"family":"Brown","given":"Louise E"},{"family":"Coghill","given":"David"},{"family":"Williams","given":"Katrina"},{"family":"Bellgrove","given":"Mark A"},{"family":"Johnson","given":"Beth P"}],"citation-key":"knott2024","container-title":"Australian & New Zealand Journal of Psychiatry","container-title-short":"Aust N Z J Psychiatry","DOI":"10.1177/00048674231206997","ISSN":"0004-8674","issue":"2","issued":{"date-parts":[["2024",2,1]]},"language":"en","page":"142-151","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Age at diagnosis and diagnostic delay across attention-deficit hyperactivity and autism spectrums","type":"article-journal","URL":"https://doi.org/10.1177/00048674231206997","volume":"58"},
  {"id":"ko2023","abstract":"IMPORTANCE: Joint attention, composed of complex behaviors, is an early-emerging social function that is deficient in children with autism spectrum disorder (ASD). Currently, no methods are available for objectively quantifying joint attention.\nOBJECTIVE: To train deep learning (DL) models to distinguish ASD from typical development (TD) and to differentiate ASD symptom severities using video data of joint attention behaviors.\nDESIGN, SETTING, AND PARTICIPANTS: In this diagnostic study, joint attention tasks were administered to children with and without ASD, and video data were collected from multiple institutions from August 5, 2021, to July 18, 2022. Of 110 children, 95 (86.4%) completed study measures. Enrollment criteria were 24 to 72 months of age and ability to sit with no history of visual or auditory deficits.\nEXPOSURES: Children were screened using the Childhood Autism Rating Scale. Forty-five children were diagnosed with ASD. Three types of joint attention were assessed using a specific protocol.\nMAIN OUTCOMES AND MEASURES: Correctly distinguishing ASD from TD and different levels of ASD symptom severity using the DL model area under the receiver operating characteristic curve (AUROC), accuracy, precision, and recall.\nRESULTS: The analytical population consisted of 45 children with ASD (mean [SD] age, 48.0 [13.4] months; 24 [53.3%] boys) vs 50 with TD (mean [SD] age, 47.9 [12.5] months; 27 [54.0%] boys). The DL ASD vs TD models showed good predictive performance for initiation of joint attention (IJA) (AUROC, 99.6% [95% CI, 99.4%-99.7%]; accuracy, 97.6% [95% CI, 97.1%-98.1%]; precision, 95.5% [95% CI, 94.4%-96.5%]; and recall, 99.2% [95% CI, 98.7%-99.6%]), low-level response to joint attention (RJA) (AUROC, 99.8% [95% CI, 99.6%-99.9%]; accuracy, 98.8% [95% CI, 98.4%-99.2%]; precision, 98.9% [95% CI, 98.3%-99.4%]; and recall, 99.1% [95% CI, 98.6%-99.5%]), and high-level RJA (AUROC, 99.5% [95% CI, 99.2%-99.8%]; accuracy, 98.4% [95% CI, 97.9%-98.9%]; precision, 98.8% [95% CI, 98.2%-99.4%]; and recall, 98.6% [95% CI, 97.9%-99.2%]). The DL-based ASD symptom severity models showed reasonable predictive performance for IJA (AUROC, 90.3% [95% CI, 88.8%-91.8%]; accuracy, 84.8% [95% CI, 82.3%-87.2%]; precision, 76.2% [95% CI, 72.9%-79.6%]; and recall, 84.8% [95% CI, 82.3%-87.2%]), low-level RJA (AUROC, 84.4% [95% CI, 82.0%-86.7%]; accuracy, 78.4% [95% CI, 75.0%-81.7%]; precision, 74.7% [95% CI, 70.4%-78.8%]; and recall, 78.4% [95% CI, 75.0%-81.7%]), and high-level RJA (AUROC, 84.2% [95% CI, 81.8%-86.6%]; accuracy, 81.0% [95% CI, 77.3%-84.4%]; precision, 68.6% [95% CI, 63.8%-73.6%]; and recall, 81.0% [95% CI, 77.3%-84.4%]).\nCONCLUSIONS AND RELEVANCE: In this diagnostic study, DL models for identifying ASD and differentiating levels of ASD symptom severity were developed and the premises for DL-based predictions were visualized. The findings suggest that this method may allow digital measurement of joint attention; however, follow-up studies are necessary for further validation.","author":[{"family":"Ko","given":"Chanyoung"},{"family":"Lim","given":"Jae-Hyun"},{"family":"Hong","given":"JaeSeong"},{"family":"Hong","given":"Soon-Beom"},{"family":"Park","given":"Yu Rang"}],"citation-key":"ko2023","container-title":"JAMA network open","container-title-short":"JAMA Netw Open","DOI":"10.1001/jamanetworkopen.2023.15174","ISSN":"2574-3805","issue":"5","issued":{"date-parts":[["2023",5,1]]},"language":"eng","page":"e2315174","PMCID":"PMC10214037","PMID":"37227727","source":"PubMed","title":"Development and Validation of a Joint Attention-Based Deep Learning System for Detection and Symptom Severity Assessment of Autism Spectrum Disorder","type":"article-journal","volume":"6"},
  {"id":"koelstra2012","abstract":"We present a multimodal data set for the analysis of human affective states. The electroencephalogram (EEG) and peripheral physiological signals of 32 participants were recorded as each watched 40 one-minute long excerpts of music videos. Participants rated each video in terms of the levels of arousal, valence, like/dislike, dominance, and familiarity. For 22 of the 32 participants, frontal face video was also recorded. A novel method for stimuli selection is proposed using retrieval by affective tags from the last.fm website, video highlight detection, and an online assessment tool. An extensive analysis of the participants' ratings during the experiment is presented. Correlates between the EEG signal frequencies and the participants' ratings are investigated. Methods and results are presented for single-trial classification of arousal, valence, and like/dislike ratings using the modalities of EEG, peripheral physiological signals, and multimedia content analysis. Finally, decision fusion of the classification results from different modalities is performed. The data set is made publicly available and we encourage other researchers to use it for testing their own affective state estimation methods.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Koelstra","given":"Sander"},{"family":"Muhl","given":"Christian"},{"family":"Soleymani","given":"Mohammad"},{"family":"Lee","given":"Jong-Seok"},{"family":"Yazdani","given":"Ashkan"},{"family":"Ebrahimi","given":"Touradj"},{"family":"Pun","given":"Thierry"},{"family":"Nijholt","given":"Anton"},{"family":"Patras","given":"Ioannis"}],"citation-key":"koelstra2012","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/T-AFFC.2011.15","ISSN":"1949-3045","issue":"1","issued":{"date-parts":[["2012",1]]},"page":"18-31","source":"IEEE Xplore","title":"DEAP: A Database for Emotion Analysis ;Using Physiological Signals","title-short":"DEAP","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/5871728","volume":"3"},
  {"id":"koirala2021","abstract":"Sensory abnormalities are experienced by 90 - 95% of individuals with Autism Spectrum Disorder (ASD), a developmental disorder that impacts at least 1 in 132 children worldwide. Virtual reality (VR) technologies can precisely present sensory stimuli and be integrated with human sensing technologies to automatically detect sensory responses, and thus has a potential to improve sensory assessment objectiveness and sensitivity, compared to traditional questionnaire-based methods. However, there is a lack of evidence to demonstrate this potential. Therefore, we designed and developed a preliminary sensory assessment VR system (SAVR) to objectively and precisely evaluate the visual and touch sensory processing differences between adolescents with ASD and their typically developing (TD) peers through game playing. A controlled experiment was conducted with 12 adolescents with ASD and 12 TD adolescents. Participants' sensory pattern was assessed by SAVR and a widely used traditional questionnaire-the Adult/Adolescent Sensory Profile (AASP). We hypothesized that: 1) compared to AASP, SAVR can find more significant differences between the two participant groups, and 2) there are significant and strong correlations between the SAVR results and the AASP results. Statistical analyses of the experimental data supported the hypotheses. The implication and limitations of this preliminary exploration as well as future works are discussed.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Koirala","given":"Ankit"},{"family":"Yu","given":"Zhiwei"},{"family":"Schiltz","given":"Hillary"},{"family":"Van Hecke","given":"Amy"},{"family":"Armstrong","given":"Brian"},{"family":"Zheng","given":"Zhi"}],"citation-key":"koirala2021","container-title":"IEEE Transactions on Neural Systems and Rehabilitation Engineering","DOI":"10.1109/TNSRE.2021.3064148","ISSN":"1558-0210","issued":{"date-parts":[["2021"]]},"page":"619-628","source":"IEEE Xplore","title":"A Preliminary Exploration of Virtual Reality-Based Visual and Touch Sensory Processing Assessment for Adolescents With Autism Spectrum Disorder","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9371715","volume":"29"},
  {"id":"kojovic2021","abstract":"Clinical research in autism has recently witnessed promising digital phenotyping results, mainly focused on single feature extraction, such as gaze, head turn on name-calling or visual tracking of the moving object. The main drawback of these studies is the focus on relatively isolated behaviors elicited by largely controlled prompts. We recognize that while the diagnosis process understands the indexing of the specific behaviors, ASD also comes with broad impairments that often transcend single behavioral acts. For instance, the atypical nonverbal behaviors manifest through global patterns of atypical postures and movements, fewer gestures used and often decoupled from visual contact, facial affect, speech. Here, we tested the hypothesis that a deep neural network trained on the non-verbal aspects of social interaction can effectively differentiate between children with ASD and their typically developing peers. Our model achieves an accuracy of 80.9% (F1 score: 0.818; precision: 0.784; recall: 0.854) with the prediction probability positively correlated to the overall level of symptoms of autism in social affect and repetitive and restricted behaviors domain. Provided the non-invasive and affordable nature of computer vision, our approach carries reasonable promises that a reliable machine-learning-based ASD screening may become a reality not too far in the future.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Kojovic","given":"Nada"},{"family":"Natraj","given":"Shreyasvi"},{"family":"Mohanty","given":"Sharada Prasanna"},{"family":"Maillart","given":"Thomas"},{"family":"Schaer","given":"Marie"}],"citation-key":"kojovic2021","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-021-94378-z","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2021",7,23]]},"language":"en","license":"2021 The Author(s)","page":"15069","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Using 2D video-based pose estimation for automated prediction of autism spectrum disorders in young children","type":"article-journal","URL":"https://www.nature.com/articles/s41598-021-94378-z","volume":"11"},
  {"id":"kojovic2024","abstract":"Atypical deployment of social gaze is present early on in toddlers with autism spectrum disorders (ASDs). Yet, studies characterizing the developmental dynamic behind it are scarce. Here, we used a data-driven method to delineate the developmental change in visual exploration of social interaction over childhood years in autism. Longitudinal eye-tracking data were acquired as children with ASD and their typically developing (TD) peers freely explored a short cartoon movie. We found divergent moment-to-moment gaze patterns in children with ASD compared to their TD peers. This divergence was particularly evident in sequences that displayed social interactions between characters and even more so in children with lower developmental and functional levels. The basic visual properties of the animated scene did not account for the enhanced divergence. Over childhood years, these differences dramatically increased to become more idiosyncratic. These findings suggest that social attention should be targeted early in clinical treatments.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Kojovic","given":"Nada"},{"family":"Cekic","given":"Sezen"},{"family":"Castañón","given":"Santiago Herce"},{"family":"Franchini","given":"Martina"},{"family":"Sperdin","given":"Holger Franz"},{"family":"Sandini","given":"Corrado"},{"family":"Jan","given":"Reem Kais"},{"family":"Zöller","given":"Daniela"},{"family":"Ben Hadid","given":"Lylia"},{"family":"Bavelier","given":"Daphné"},{"family":"Schaer","given":"Marie"}],"citation-key":"kojovic2024","container-title":"eLife","DOI":"10.7554/eLife.85623","editor":[{"family":"Büchel","given":"Christian"},{"family":"Adolphs","given":"Ralph"}],"ISSN":"2050-084X","issued":{"date-parts":[["2024",1,9]]},"page":"e85623","publisher":"eLife Sciences Publications, Ltd","source":"eLife","title":"Unraveling the developmental dynamic of visual exploration of social interactions in autism","type":"article-journal","URL":"https://doi.org/10.7554/eLife.85623","volume":"13"},
  {"id":"kok2016","abstract":"Introduction There is limited research on Autism Spectrum Disorders (ASD) in females. Although the empathy construct has been examined thoroughly in autism, little attention has been paid to empathy in adult women with this condition or to gender differences within the disorder. Objective Self-reported empathy in adult women with ASD was examined and compared to that of typically developed men and women as well as to men with this condition. Methods Online databases were searched for articles investigating self-reported empathy among adult women with ASD. Only six studies comparing women to men were identified. Results All studies found women with an ASD to report lower levels of empathy than typically developed women, and typically developed men, but similar levels to men with this condition. Conclusion The self-reported empathic ability of women diagnosed with ASD resembles that of their male counterparts most closely; they show a hypermasculinisation in empathy. This is particularly surprising considering the large gender difference in empathy in the general population. Discussion One of the limitations of this review is that the current diagnostic criteria for ASD are oriented towards male-specific behaviour and fail to integrate gender specific characteristics. Hence, women diagnosed with ASD are likely to be at the male end of the continuum. The suggested hypermasculinisation of women on the spectrum, as evident from this review, may therefore be exaggerated due to a selection bias.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Kok","given":"Francien M."},{"family":"Groen","given":"Yvonne"},{"family":"Becke","given":"Miriam"},{"family":"Fuermaier","given":"Anselm B. M."},{"family":"Tucha","given":"Oliver"}],"citation-key":"kok2016","container-title":"PLOS ONE","container-title-short":"PLOS ONE","DOI":"10.1371/journal.pone.0151568","ISSN":"1932-6203","issue":"3","issued":{"date-parts":[["2016",3,21]]},"language":"en","page":"e0151568","publisher":"Public Library of Science","source":"PLoS Journals","title":"Self-Reported Empathy in Adult Women with Autism Spectrum Disorders – A Systematic Mini Review","type":"article-journal","URL":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0151568","volume":"11"},
  {"id":"kosunen2016","abstract":"Meditation in general and mindfulness in particular have been shown to be useful techniques in the treatment of a plethora of ailments, yet they can be challenging for novices. We present RelaWorld: a neuroadaptive virtual reality meditation system that combines virtual reality with neurofeedback to provide a tool that is easy for novices to use yet provides added value even for experienced meditators. Using a head-mounted display, users can levitate in a virtual world by doing meditation exercises. The system measures users' brain activity in real time via EEG and calculates estimates for the level of conCentration and relaxation. These values are then mapped into the virtual reality. In a user study of 43 subjects, we were able to show that the RelaWorld system elicits deeper relaxation, feeling of presence and a deeper level of meditation when compared to a similar setup without head-mounted display or neurofeedback.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Kosunen","given":"Ilkka"},{"family":"Salminen","given":"Mikko"},{"family":"Järvelä","given":"Simo"},{"family":"Ruonala","given":"Antti"},{"family":"Ravaja","given":"Niklas"},{"family":"Jacucci","given":"Giulio"}],"citation-key":"kosunen2016","collection-title":"IUI '16","container-title":"Proceedings of the 21st International Conference on Intelligent User Interfaces","DOI":"10.1145/2856767.2856796","event-place":"New York, NY, USA","ISBN":"978-1-4503-4137-0","issued":{"date-parts":[["2016",3,7]]},"page":"208–217","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"RelaWorld: Neuroadaptive and Immersive Virtual Reality Meditation System","title-short":"RelaWorld","type":"paper-conference","URL":"https://doi.org/10.1145/2856767.2856796"},
  {"id":"kourtesis2023","abstract":"Poor social skills in autism spectrum disorder (ASD) are associated with reduced independence in daily life. Current interventions for improving the social skills of individuals with ASD fail to represent the complexity of real-life social settings and situations. Virtual reality (VR) may facilitate social skills training in social environments and situations similar to those in real life; however, more research is needed to elucidate aspects such as the acceptability, usability, and user experience of VR systems in ASD. Twenty-five participants with ASD attended a neuropsychological evaluation and three sessions of VR social skills training, which incorporated five social scenarios with three difficulty levels. Participants reported high acceptability, system usability, and user experience. Significant correlations were observed between performance in social scenarios, self-reports, and executive functions. Working memory and planning ability were significant predictors of the functionality level in ASD and the VR system’s perceived usability, respectively. Yet, performance in social scenarios was the best predictor of usability, acceptability, and functionality level. Planning ability substantially predicted performance in social scenarios, suggesting an implication in social skills. Immersive VR social skills training in individuals with ASD appears to be an appropriate service, but an errorless approach that is adaptive to the individual’s needs should be preferred.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Kourtesis","given":"Panagiotis"},{"family":"Kouklari","given":"Evangelia-Chrysanthi"},{"family":"Roussos","given":"Petros"},{"family":"Mantas","given":"Vasileios"},{"family":"Papanikolaou","given":"Katerina"},{"family":"Skaloumbakas","given":"Christos"},{"family":"Pehlivanidis","given":"Artemios"}],"citation-key":"kourtesis2023","container-title":"Behavioral Sciences","DOI":"10.3390/bs13040336","ISSN":"2076-328X","issue":"4","issued":{"date-parts":[["2023",4]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"4","page":"336","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Virtual Reality Training of Social Skills in Adults with Autism Spectrum Disorder: An Examination of Acceptability, Usability, User Experience, Social Skills, and Executive Functions","title-short":"Virtual Reality Training of Social Skills in Adults with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.mdpi.com/2076-328X/13/4/336","volume":"13"},
  {"id":"kourtesis2023a","abstract":"Poor social skills in autism spectrum disorder (ASD) are associated with reduced independence in daily life. Current interventions for improving the social skills of individuals with ASD fail to represent the complexity of real-life social settings and situations. Virtual reality (VR) may facilitate social skills training in social environments and situations similar to those in real life; however, more research is needed to elucidate aspects such as the acceptability, usability, and user experience of VR systems in ASD. Twenty-five participants with ASD attended a neuropsychological evaluation and three sessions of VR social skills training, which incorporated five social scenarios with three difficulty levels. Participants reported high acceptability, system usability, and user experience. Significant correlations were observed between performance in social scenarios, self-reports, and executive functions. Working memory and planning ability were significant predictors of the functionality level in ASD and the VR system’s perceived usability, respectively. Yet, performance in social scenarios was the best predictor of usability, acceptability, and functionality level. Planning ability substantially predicted performance in social scenarios, suggesting an implication in social skills. Immersive VR social skills training in individuals with ASD appears to be an appropriate service, but an errorless approach that is adaptive to the individual’s needs should be preferred.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Kourtesis","given":"Panagiotis"},{"family":"Kouklari","given":"Evangelia-Chrysanthi"},{"family":"Roussos","given":"Petros"},{"family":"Mantas","given":"Vasileios"},{"family":"Papanikolaou","given":"Katerina"},{"family":"Skaloumbakas","given":"Christos"},{"family":"Pehlivanidis","given":"Artemios"}],"citation-key":"kourtesis2023a","container-title":"Behavioral Sciences","DOI":"10.3390/bs13040336","ISSN":"2076-328X","issue":"4","issued":{"date-parts":[["2023",4]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"4","page":"336","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Virtual Reality Training of Social Skills in Adults with Autism Spectrum Disorder: An Examination of Acceptability, Usability, User Experience, Social Skills, and Executive Functions","title-short":"Virtual Reality Training of Social Skills in Adults with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.mdpi.com/2076-328X/13/4/336","volume":"13"},
  {"id":"krishnappababu2024","abstract":"Autism, characterized by challenges in socialization and communication, benefits from early detection for prompt and timely intervention. Traditional autism screening questionnaires often exhibit reduced accuracy in primary care settings and significantly underperform underprivileged populations. We present findings on the effectiveness of an autism screening digital application (app) that can be administered at primary care clinics and also by caregivers at home. A large-scale validation was conducted with 1052 toddlers aged 16–40 months. Among them, 223 were subsequently diagnosed with autism. The age-appropriate interactive app utilized strategically designed stimuli, presented on the screen of the iPhone or iPad, to evoke behaviors related to social attention, facial expressions, head movements, blinking rate, and motor responses, which can be detected with the device's sensors and automatically quantified through computer vision (CV) and machine learning. The algorithm, combining various digital biomarkers, demonstrated strong accuracy: Area under the receiver operating characteristic curve (AUC) = 0.93, sensitivity = 86.0%, specificity = 91.0%, and precision = 71%, for distinguishing autistic versus non-autistic toddlers, marking a strong foundation as a digital phenotyping tool in the autism research, notably without any costly equipment like eye tracking devices and at home administered by caregivers.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Krishnappa Babu","given":"Pradeep Raj"},{"family":"Di Martino","given":"J. Matias"},{"family":"Carpenter","given":"Kimberly L.H."},{"family":"Compton","given":"Scott"},{"family":"Davis","given":"Naomi"},{"family":"Eichner","given":"Brian"},{"family":"Espinosa","given":"Steven"},{"family":"Franz","given":"Lauren"},{"family":"Perochon","given":"Sam"},{"family":"Dawson","given":"Geraldine"},{"family":"Sapiro","given":"Guillermo"}],"citation-key":"krishnappababu2024","collection-title":"CHI EA '24","container-title":"Extended Abstracts of the CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3613905.3650995","event-place":"New York, NY, USA","ISBN":"979-8-4007-0331-7","issued":{"date-parts":[["2024",5,11]]},"page":"1–7","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Large-scale Validation of a Scalable and Portable Behavioral Digital Screening Tool for Autism at Home","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3613905.3650995"},
  {"id":"kwan2024","abstract":"Individuals with autism spectrum disorder (ASD) tend to experience greater difficulties with social communication and sensory information processing. Of particular interest in ASD biomarker research is the study of visual attention, effectively quantified in eye tracking (ET) experiments. Eye tracking offers a powerful, safe, and feasible platform for gaining insights into attentional processes by measuring moment-by-moment gaze patterns in response to stimuli. Even though recording is done with millisecond granularity, analyses commonly collapse data across trials into variables such as proportion time spent looking at a region of interest (ROI). In addition, looking times in different ROIs are typically analyzed separately. We propose a novel multivariate functional outcome that carries proportion looking time information from multiple regions of interest jointly as a function of trial type, along with a novel constrained multivariate functional principal components analysis procedure to capture the variation in this outcome. The method incorporates the natural constraint that the proportion looking times from the multiple regions of interest must sum up to one. Our approach is motivated by the Activity Monitoring task, a social-attentional assay within the ET battery of the Autism Biomarkers Consortium for Clinical Trials (ABC-CT). Application of our methods to the ABC-CT data yields new insights into dominant modes of variation of proportion looking times from multiple regions of interest for school-age children with ASD and their typically developing (TD) peers, as well as richer analysis of diagnostic group differences in social attention.","accessed":{"date-parts":[["2025",2,10]]},"author":[{"family":"Kwan","given":"Brian"},{"family":"Sugar","given":"Catherine A."},{"family":"Qian","given":"Qi"},{"family":"Shic","given":"Frederick"},{"family":"Naples","given":"Adam"},{"family":"Johnson","given":"Scott P."},{"family":"Webb","given":"Sara J."},{"family":"Jeste","given":"Shafali"},{"family":"Faja","given":"Susan"},{"family":"Levin","given":"April R."},{"family":"Dawson","given":"Geraldine"},{"family":"McPartland","given":"James C."},{"family":"Şentürk","given":"Damla"}],"citation-key":"kwan2024","container-title":"Statistics in Biosciences","container-title-short":"Stat Biosci","DOI":"10.1007/s12561-023-09399-1","ISSN":"1867-1772","issue":"3","issued":{"date-parts":[["2024",12,1]]},"language":"en","page":"578-603","source":"Springer Link","title":"Constrained Multivariate Functional Principal Components Analysis for Novel Outcomes in Eye-Tracking Experiments","type":"article-journal","URL":"https://doi.org/10.1007/s12561-023-09399-1","volume":"16"},
  {"id":"lakshminarayanan2023","abstract":"Intellectual capital is a scarce resource in the healthcare industry. Making the most of this resource is the first step toward achieving a completely intelligent healthcare system. However, most existing centralized and deep learning-based systems are unable to adapt to the growing volume of global health records and face application issues. To balance the scarcity of healthcare resources, the emerging trend of IoMT (Internet of Medical Things) and edge computing will be very practical and cost-effective. A full examination of the transformational role of intelligent edge computing in the IoMT era to attain health care equity is offered in this research. Intelligent edge computing-aided distribution and collaborative information management is a possible approach for a long-term digital healthcare system. Furthermore, IEC (Intelligent Edge Computing) encourages digital health data to be processed only at the edge, minimizing the amount of information exchanged with central servers/the internet. This significantly increases the privacy of digital health data. Another critical component of a sustainable healthcare system is affordability in digital healthcare. Affordability in digital healthcare is another key component of a sustainable healthcare system. Despite its importance, it has received little attention due to its complexity. In isolated and rural areas where expensive equipment is unavailable, IEC with AR / VR, also known as edge device shadow, can play a significant role in the inexpensive data collection process. Healthcare equity becomes a reality by combining intelligent edge device shadows and edge computing.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Lakshminarayanan","given":"Vishal"},{"family":"Ravikumar","given":"Aswathy"},{"family":"Sriraman","given":"Harini"},{"family":"Alla","given":"Sujatha"},{"family":"Chattu","given":"Vijay Kumar"}],"citation-key":"lakshminarayanan2023","container-title":"Journal of Multidisciplinary Healthcare","DOI":"10.2147/JMDH.S419923","ISSN":"null","issued":{"date-parts":[["2023",12,31]]},"page":"2839-2859","PMID":"37753339","publisher":"Dove Medical Press","source":"Taylor and Francis+NEJM","title":"Health Care Equity Through Intelligent Edge Computing and Augmented Reality/Virtual Reality: A Systematic Review","title-short":"Health Care Equity Through Intelligent Edge Computing and Augmented Reality/Virtual Reality","type":"article-journal","URL":"https://www.tandfonline.com/doi/abs/10.2147/JMDH.S419923","volume":"16"},
  {"id":"leblanc2020","abstract":"Autism Spectrum Disorder is a neuropsychiatric condition affecting 53 million children worldwide and for which early diagnosis is critical to the outcome of behavior therapies. Machine learning applied to features manually extracted from readily accessible videos (e.g., from smartphones) has the potential to scale this diagnostic process. However, nearly unavoidable variability in video quality can lead to missing features that degrade algorithm performance. To manage this uncertainty, we evaluated the impact of missing values and feature imputation methods on two previously published autism detection classifiers, trained on standard-of-care instrument scoresheets and tested on ratings of 140 children videos from YouTube. We compare the baseline method of listwise deletion to classic univariate and multivariate techniques. We also introduce a feature replacement method that, based on a score, selects a feature from an expanded dataset to fill-in the missing value. The replacement feature selected can be identical for all records (general) or automatically adjusted to the record considered (dynamic). Our results show that general and dynamic feature replacement methods achieve a higher performance than classic univariate and multivariate methods, supporting the hypothesis that algorithmic management can maintain the fidelity of video-based diagnostics in the face of missing values and variable video quality.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Leblanc","given":"Emilie"},{"family":"Washington","given":"Peter"},{"family":"Varma","given":"Maya"},{"family":"Dunlap","given":"Kaitlyn"},{"family":"Penev","given":"Yordan"},{"family":"Kline","given":"Aaron"},{"family":"Wall","given":"Dennis P."}],"citation-key":"leblanc2020","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-020-76874-w","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2020",12,4]]},"language":"en","license":"2020 The Author(s)","page":"21245","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Feature replacement methods enable reliable home video analysis for machine learning detection of autism","type":"article-journal","URL":"https://www.nature.com/articles/s41598-020-76874-w","volume":"10"},
  {"id":"leharanger2023","abstract":"Mixed Reality (MR) technology is experiencing significant growth in the industrial and healthcare sectors. The headset HoloLens 2 displays virtual objects (in the form of holograms) in the user’s environment in real-time. Individuals with Autism Spectrum Disorder (ASD) exhibit, according to the DSM-5, persistent deficits in communication and social interaction, as well as a different sensitivity compared to neurotypical (NT) individuals. This study aims to propose a method for familiarizing eleven individuals with severe ASD with the HoloLens 2 headset and the use of MR technology through a tutorial. The secondary objective is to obtain quantitative learning indicators in MR, such as execution speed and eye tracking (ET), by comparing individuals with ASD to neurotypical individuals. We observed that 81.81% of individuals with ASD successfully familiarized themselves with MR after several sessions. Furthermore, the visual activity of individuals with ASD did not differ from that of neurotypical individuals when they successfully familiarized themselves. This study thus offers new perspectives on skill acquisition indicators useful for supporting neurodevelopmental disorders. It contributes to a better understanding of the neural mechanisms underlying learning in MR for individuals with ASD.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Leharanger","given":"Maxime"},{"family":"Rodriguez Martinez","given":"Eder Alejandro"},{"family":"Balédent","given":"Olivier"},{"family":"Vandromme","given":"Luc"}],"citation-key":"leharanger2023","container-title":"Sensors","DOI":"10.3390/s23146304","ISSN":"1424-8220","issue":"14","issued":{"date-parts":[["2023",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"14","page":"6304","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Familiarization with Mixed Reality for Individuals with Autism Spectrum Disorder: An Eye Tracking Study","title-short":"Familiarization with Mixed Reality for Individuals with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/23/14/6304","volume":"23"},
  {"id":"lehnhardt2016","abstract":"Females with high-functioning ASD are known to camouflage their autistic symptoms better than their male counterparts, making them prone to being under-ascertained and delayed in diagnostic assessment. Thus far the underlying cognitive processes that enable such successful socio-communicative adaptation are not well understood. The current results show sex-related differences in the cognitive profile of ASD individuals, which were diagnosed late in life exclusively. Higher verbal abilities were found in males (n = 69) as opposed to higher processing speed and better executive functions in females with ASD (n = 38). Since both sexes remained unidentified during childhood and adolescence, these results are suggestive for sex-distinctive cognitive strategies as an alternative to typically-developed reciprocal social behavior and social mimicry in high functioning ASD.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Lehnhardt","given":"Fritz-Georg"},{"family":"Falter","given":"Christine Michaela"},{"family":"Gawronski","given":"Astrid"},{"family":"Pfeiffer","given":"Kathleen"},{"family":"Tepest","given":"Ralf"},{"family":"Franklin","given":"Jeremy"},{"family":"Vogeley","given":"Kai"}],"citation-key":"lehnhardt2016","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-015-2558-7","ISSN":"1573-3432","issue":"1","issued":{"date-parts":[["2016",1,1]]},"language":"en","page":"139-154","source":"Springer Link","title":"Sex-Related Cognitive Profile in Autism Spectrum Disorders Diagnosed Late in Life: Implications for the Female Autistic Phenotype","title-short":"Sex-Related Cognitive Profile in Autism Spectrum Disorders Diagnosed Late in Life","type":"article-journal","URL":"https://doi.org/10.1007/s10803-015-2558-7","volume":"46"},
  {"id":"lehtiniemi2024","abstract":"In pilot trials, Finnish caseworkers in child welfare services used an AI tool predicting severe risks faced by their clients. Based on interviews with the caseworkers involved, this article draws on those trials to discuss AI valences, or the range of expectations of AI’s value and performance, in social work and beyond. While AI travels across sites of application and sectors of society, its value is often expected to come from the production of anticipatory knowledge. The predictive AI tool used by Finnish caseworkers offers an example: it turned past data about clients into predictions about their future, with an aim of authorizing present interventions to optimize the future. In the pilot trials, however, AI met the practice of social work. In contrast to generic expectations of predictive performance, caseworkers had contextual expectations for AI, reflecting their situated knowledge about their field. For caseworkers, anticipation does not mean producing pieces of speculative knowledge about the future. Instead, for them, anticipation is a professional knowledge-making practice, based on intimate encounters with clients. Caseworkers therefore expect AI to produce contextually relevant information that can facilitate those interactions. This suggests that for AI developments to matter in social work, it is necessary to consider AI not as a tool that produces knowledge outcomes, but one that supports human experts’ knowledge-making processes. More broadly, as AI tools enter new sensitive areas of application, instead of expecting generic value and performance from them, careful attention should be paid on contextual AI valences.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Lehtiniemi","given":"Tuukka"}],"citation-key":"lehtiniemi2024","container-title":"Information, Communication & Society","DOI":"10.1080/1369118X.2023.2234987","ISSN":"1369-118X","issue":"6","issued":{"date-parts":[["2024",4,25]]},"page":"1110-1125","publisher":"Routledge","source":"Taylor and Francis+NEJM","title":"Contextual social valences for artificial intelligence: anticipation that matters in social work","title-short":"Contextual social valences for artificial intelligence","type":"article-journal","URL":"https://doi.org/10.1080/1369118X.2023.2234987","volume":"27"},
  {"id":"leitner2014","abstract":"<p>Symptoms of attention deficit hyperactivity disorder (ADHD) and autistic spectrum disorder (ASD) often co-occur. The DSM-IV had specified that an ASD diagnosis is an exclusion criterion for ADHD, thereby limiting research of this common clinical co-occurrence. As neurodevelopmental disorders, both ASD and ADHD share some phenotypic similarities, but are characterized by distinct diagnostic criteria. The present review will examine the frequency and implications of this clinical co-occurrence in children, with an emphasis on the available data regarding pre-school age. The review will highlight possible etiologies explaining it, and suggest future research directions necessary to enhance our understanding of both etiology and therapeutic interventions, in light of the new DSM-V criteria, allowing for a dual diagnosis.</p>","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Leitner","given":"Yael"}],"citation-key":"leitner2014","container-title":"Frontiers in Human Neuroscience","container-title-short":"Front. Hum. Neurosci.","DOI":"10.3389/fnhum.2014.00268","ISSN":"1662-5161","issued":{"date-parts":[["2014",4,29]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"The Co-Occurrence of Autism and Attention Deficit Hyperactivity Disorder in Children – What Do We Know?","type":"article-journal","URL":"https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2014.00268/full","volume":"8"},
  {"id":"lekakis2016","abstract":"During the preoperative assessment in rhinoplasty, the surgeon takes a thorough history, performs a complete examination by assessing functional and aesthetic aspects of the nose, obtains a clear understanding of the patient's wishes, conducts facial analysis based on standardized photography, and communicates to the patient the goals and pitfalls of surgery. Computer imaging or morphing of the preoperative pictures of the nose has drawn a lot of interest in the last decade, and it is a sign of evolution of the preoperative consultation. Technological advances, also in the context of rhinoplasty, have led to the development of three-dimensional (3D) imaging techniques, and have completely revolutionized the way that surgeons manage their patients preoperatively and evaluate postoperative results today. The accurate 3D surface imaging aids the surgeon to communicate with the patient adequately before surgery, to set an appropriate surgical plan, and to measure the shape and volume changes of the patient's nose that result from the intervention. The present review provides an analysis on the current knowledge of 3D surface imaging in rhinoplasty derived from the literature, and highlights future directions of preoperative and postoperative assessment in the field.","accessed":{"date-parts":[["2024",9,15]]},"author":[{"family":"Lekakis","given":"Garyfalia"},{"family":"Claes","given":"Peter"},{"family":"Iii","given":"Grant S. Hamilton"},{"family":"Hellings","given":"P. W."}],"citation-key":"lekakis2016","container-title":"Facial Plastic Surgery","DOI":"10.1055/s-0035-1570122","ISSN":"0736-6825","issued":{"date-parts":[["2016",2,10]]},"language":"en","license":"Thieme Medical Publishers 333 Seventh Avenue, New York, NY 10001, USA.","page":"088-094","publisher":"Thieme Medical Publishers","source":"www.thieme-connect.de","title":"Three-Dimensional Surface Imaging and the Continuous Evolution of Preoperative and Postoperative Assessment in Rhinoplasty","type":"article-journal","URL":"https://www.thieme-connect.de/products/ejournals/abstract/10.1055/s-0035-1570122","volume":"32"},
  {"id":"lencastre2024","abstract":"One of the most challenging problems when diagnosing autism spectrum disorder (ASD) is the need for long sets of data. Collecting data during such long periods is challenging, particularly when dealing with children. This challenge motivates the investigation of possible classifiers of ASD that do not need such long data sets. In this paper, we use eye-tracking data sets covering only 5 s and introduce one metric able to distinguish between ASD and typically developed (TD) gaze patterns based on such short time-series and compare it with two benchmarks, one using the traditional eye-tracking metrics and one state-of-the-art AI classifier. Although the data can only track possible disorders in visual attention and our approach is not a substitute to medical diagnosis, we find that our newly introduced metric can achieve an accuracy of 93% in classifying eye gaze trajectories from children with ASD surpassing both benchmarks while needing fewer data. The classification accuracy of our method, using a 5 s data series, performs better than the standard metrics in eye-tracking and is at the level of the best AI benchmarks, even when these are trained with longer time series. We also discuss the advantages and limitations of our method in comparison with the state of the art: besides needing a low amount of data, this method is a simple, understandable, and straightforward criterion to apply, which often contrasts with “black box” AI methods.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Lencastre","given":"Pedro"},{"family":"Lotfigolian","given":"Maryam"},{"family":"Lind","given":"Pedro G."}],"citation-key":"lencastre2024","container-title":"Diagnostics","DOI":"10.3390/diagnostics14101047","ISSN":"2075-4418","issue":"10","issued":{"date-parts":[["2024",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"10","page":"1047","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Identifying Autism Gaze Patterns in Five-Second Data Records","type":"article-journal","URL":"https://www.mdpi.com/2075-4418/14/10/1047","volume":"14"},
  {"id":"lencastre2024a","abstract":"One of the most challenging problems when diagnosing autism spectrum disorder (ASD) is the need for long sets of data. Collecting data during such long periods is challenging, particularly when dealing with children. This challenge motivates the investigation of possible classifiers of ASD that do not need such long data sets. In this paper, we use eye-tracking data sets covering only 5 s and introduce one metric able to distinguish between ASD and typically developed (TD) gaze patterns based on such short time-series and compare it with two benchmarks, one using the traditional eye-tracking metrics and one state-of-the-art AI classifier. Although the data can only track possible disorders in visual attention and our approach is not a substitute to medical diagnosis, we find that our newly introduced metric can achieve an accuracy of 93% in classifying eye gaze trajectories from children with ASD surpassing both benchmarks while needing fewer data. The classification accuracy of our method, using a 5 s data series, performs better than the standard metrics in eye-tracking and is at the level of the best AI benchmarks, even when these are trained with longer time series. We also discuss the advantages and limitations of our method in comparison with the state of the art: besides needing a low amount of data, this method is a simple, understandable, and straightforward criterion to apply, which often contrasts with “black box” AI methods.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Lencastre","given":"Pedro"},{"family":"Lotfigolian","given":"Maryam"},{"family":"Lind","given":"Pedro G."}],"citation-key":"lencastre2024a","container-title":"Diagnostics","DOI":"10.3390/diagnostics14101047","ISSN":"2075-4418","issue":"10","issued":{"date-parts":[["2024",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"10","page":"1047","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Identifying Autism Gaze Patterns in Five-Second Data Records","type":"article-journal","URL":"https://www.mdpi.com/2075-4418/14/10/1047","volume":"14"},
  {"id":"leokumar2019","abstract":"In this paper, an effort has been made for intense review on Knowledge-Based Expert System (KB-ES) applications in manufacturing planning. Uniqueness of the present review work is addressed in terms of analysis on published review articles and their review gap. Research works exemplified between 1981 and 2016 were reviewed in terms of ES application in handling product variety, execution of process planning activities, machining, tool selection, tool design, welding, advanced manufacturing, product development. A statistical analysis was carried out in relation with number of publications, domain-specific area and their percentage contribution. It was inferred that, most of the work focused on ES applications related to tool design and machining apart from execution of various process planning activities. Future research can focus on the development frame-based, object oriented-based, ontology-based knowledge representation in order to develop robust system in decision-making for handling complex engineering problem. ES applications can be extended to field of micro fabrication, machine tool development and integrated system development from design to manufacturing.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Leo Kumar","given":"S.P."}],"citation-key":"leokumar2019","container-title":"International Journal of Production Research","DOI":"10.1080/00207543.2018.1424372","ISSN":"0020-7543","issue":"15-16","issued":{"date-parts":[["2019",8,29]]},"page":"4766-4790","publisher":"Taylor & Francis","source":"Taylor and Francis+NEJM","title":"Knowledge-based expert system in manufacturing planning: state-of-the-art review","title-short":"Knowledge-based expert system in manufacturing planning","type":"article-journal","URL":"https://doi.org/10.1080/00207543.2018.1424372","volume":"57"},
  {"id":"leong2023","abstract":"Emotion is an important driver of human decision-making and communication. With the recent rise of human–computer interaction, affective computing has become a trending research topic, aiming to develop computational systems that can understand human emotions and respond to them. A systematic review has been conducted to fill these gaps since previous reviews regarding machine-enabled automated visual emotion recognition neglect important methodological aspects, including emotion models and hardware usage. 467 relevant papers were initially found and examined. After the screening process with specific inclusion and exclusion criteria, 30 papers were selected. Methodological aspects including emotion models, devices, architectures, and classification techniques employed by the selected studies were analyzed, and the most popular techniques and current trends in visual emotion recognition were identified. This review not only offers a comprehensive and upto-date overview of the topic but also provides researchers with insights regarding methodological aspects like emotion models employed, devices used, and classification techniques for automated visual emotion recognition. By identifying current trends, like the increased use of deep learning algorithms and the need for further study on body gestures, this review advocates the advantages of implementing emotion recognition with the use of visual data and builds a solid foundation for applying relevant techniques in different fields.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Leong","given":"Sze Chit"},{"family":"Tang","given":"Yuk Ming"},{"family":"Lai","given":"Chung Hin"},{"family":"Lee","given":"C.K.M."}],"citation-key":"leong2023","container-title":"Computer Science Review","container-title-short":"Computer Science Review","DOI":"10.1016/j.cosrev.2023.100545","ISSN":"15740137","issued":{"date-parts":[["2023",5]]},"language":"en","page":"100545","source":"DOI.org (Crossref)","title":"Facial expression and body gesture emotion recognition: A systematic review on the use of visual data in affective computing","title-short":"Facial expression and body gesture emotion recognition","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S1574013723000126","volume":"48"},
  {"id":"li2018","abstract":"Micro-expressions (MEs) are rapid, involuntary facial expressions which reveal emotions that people do not intend to show. Studying MEs is valuable as recognizing them has many important applications, particularly in forensic science and psychotherapy. However, analyzing spontaneous MEs is very challenging due to their short duration and low intensity. Automatic ME analysis includes two tasks: ME spotting and ME recognition. For ME spotting, previous studies have focused on posed rather than spontaneous videos. For ME recognition, the performance of previous studies is low. To address these challenges, we make the following contributions: (i) We propose the first method for spotting spontaneous MEs in long videos (by exploiting feature difference contrast). This method is training free and works on arbitrary unseen videos. (ii) We present an advanced ME recognition framework, which outperforms previous work by a large margin on two challenging spontaneous ME databases (SMIC and CASMEII). (iii) We propose the first automatic ME analysis system (MESR), which can spot and recognize MEs from spontaneous video data. Finally, we show our method outperforms humans in the ME recognition task by a large margin, and achieves comparable performance to humans at the very challenging task of spotting and then recognizing spontaneous MEs.","accessed":{"date-parts":[["2024",7,23]]},"author":[{"family":"Li","given":"Xiaobai"},{"family":"Hong","given":"Xiaopeng"},{"family":"Moilanen","given":"Antti"},{"family":"Huang","given":"Xiaohua"},{"family":"Pfister","given":"Tomas"},{"family":"Zhao","given":"Guoying"},{"family":"Pietikäinen","given":"Matti"}],"citation-key":"li2018","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/TAFFC.2017.2667642","ISSN":"1949-3045","issue":"4","issued":{"date-parts":[["2018",10]]},"page":"563-577","source":"IEEE Xplore","title":"Towards Reading Hidden Emotions: A Comparative Study of Spontaneous Micro-Expression Spotting and Recognition Methods","title-short":"Towards Reading Hidden Emotions","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/7851001","volume":"9"},
  {"id":"li2024","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by difficulties in social communication and repetitive and stereotyped behaviors. According to the World Health Organization, about 1 in 100 children worldwide has autism. With the global prevalence of ASD, timely and accurate diagnosis has been essential in enhancing the intervention effectiveness for ASD children. Traditional ASD diagnostic methods rely on clinical observations and behavioral assessment, with the disadvantages of time-consuming and lack of objective biological indicators. Therefore, automated diagnostic methods based on machine learning and deep learning technologies have emerged and become significant since they can achieve more objective, efficient, and accurate ASD diagnosis. Electroencephalography (EEG) is an electrophysiological monitoring method that records changes in brain spontaneous potential activity, which is of great significance for identifying ASD children. By analyzing EEG data, it is possible to detect abnormal synchronous neuronal activity of ASD children. This paper gives a comprehensive review of the EEG-based ASD identification using traditional machine learning methods and deep learning approaches, including their merits and potential pitfalls. Additionally, it highlights the challenges and the opportunities ahead in search of more effective and efficient methods to automatically diagnose autism based on EEG signals, which aims to facilitate automated ASD identification.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Li","given":"Jing"},{"family":"Kong","given":"Xiaoli"},{"family":"Sun","given":"Linlin"},{"family":"Chen","given":"Xu"},{"family":"Ouyang","given":"Gaoxiang"},{"family":"Li","given":"Xiaoli"},{"family":"Chen","given":"Shengyong"}],"citation-key":"li2024","container-title":"Computers in Biology and Medicine","container-title-short":"Computers in Biology and Medicine","DOI":"10.1016/j.compbiomed.2024.108075","ISSN":"0010-4825","issued":{"date-parts":[["2024",3,1]]},"page":"108075","source":"ScienceDirect","title":"Identification of autism spectrum disorder based on electroencephalography: A systematic review","title-short":"Identification of autism spectrum disorder based on electroencephalography","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0010482524001598","volume":"170"},
  {"id":"li2024a","abstract":"BACKGROUND: Artificial intelligence-powered interventions have emerged as promising tools to support autistic individuals. However, more research must examine how teachers and educators perceive and experience these AI systems when implemented.\nOBJECTIVES: The first objective was to investigate informants' perceptions and experiences of AI-empowered interventions for children with autism. Mainly, it explores the informants' perceived benefits and challenges of using AI-empowered interventions and their recommendations for avoiding the perceived challenges.\nMETHODOLOGY: A qualitative phenomenological approach was used. Twenty educators and parents with experience implementing AI interventions for autism were recruited through purposive sampling. Semi-structured and focus group interviews conducted, transcribed verbatim, and analyzed using thematic analysis.\nFINDINGS: The analysis identified four major themes: perceived benefits of AI interventions, implementation challenges, needed support, and recommendations for improvement. Benefits included increased engagement and personalized learning. Challenges included technology issues, training needs, and data privacy concerns.\nCONCLUSIONS: AI-powered interventions show potential to improve autism support, but significant challenges must be addressed to ensure effective implementation from an educator's perspective. The benefits of personalized learning and student engagement demonstrate the potential value of these technologies. However, with adequate training, technical support, and measures to ensure data privacy, many educators will likely find integrating AI systems into their daily practices easier.\nIMPLICATIONS: To realize the full benefits of AI for autism, developers must work closely with educators to understand their needs, optimize implementation, and build trust through transparent privacy policies and procedures. With proper support, AI interventions can transform how autistic individuals are educated by tailoring instruction to each student's unique profile and needs.","author":[{"family":"Li","given":"Guang"},{"family":"Zarei","given":"Mohammad Amin"},{"family":"Alibakhshi","given":"Goudarz"},{"family":"Labbafi","given":"Akram"}],"citation-key":"li2024a","container-title":"BMC psychology","container-title-short":"BMC Psychol","DOI":"10.1186/s40359-024-01664-2","ISSN":"2050-7283","issue":"1","issued":{"date-parts":[["2024",4,11]]},"language":"eng","page":"199","PMCID":"PMC11010416","PMID":"38605422","source":"PubMed","title":"Teachers and educators' experiences and perceptions of artificial-powered interventions for autism groups","type":"article-journal","volume":"12"},
  {"id":"lim2016","abstract":"Whether emotion is universal or social is a recurrent issue in the history of emotion study among psychologists. Some researchers view emotion as a universal construct, and that a large part of emotional experience is biologically based. However, emotion is not only biologically determined, but is also influenced by the environment. Therefore, cultural differences exist in some aspects of emotions, one such important aspect of emotion being emotional arousal level. All affective states are systematically represented as two bipolar dimensions, valence and arousal. Arousal level of actual and ideal emotions has consistently been found to have cross-cultural differences. In Western or individualist culture, high arousal emotions are valued and promoted more than low arousal emotions. Moreover, Westerners experience high arousal emotions more than low arousal emotions. By contrast, in Eastern or collectivist culture, low arousal emotions are valued more than high arousal emotions. Moreover, people in the East actually experience and prefer to experience low arousal emotions more than high arousal emotions. Mechanism of these cross-cultural differences and implications are also discussed.","author":[{"family":"Lim","given":"Nangyeon"}],"citation-key":"lim2016","container-title":"Integrative Medicine Research","container-title-short":"Integr Med Res","DOI":"10.1016/j.imr.2016.03.004","ISSN":"2213-4220","issue":"2","issued":{"date-parts":[["2016",6]]},"language":"eng","page":"105-109","PMCID":"PMC5381435","PMID":"28462104","source":"PubMed","title":"Cultural differences in emotion: differences in emotional arousal level between the East and the West","title-short":"Cultural differences in emotion","type":"article-journal","volume":"5"},
  {"id":"little2024","abstract":"The International Classification of Functioning, Disability, and Health for Children and Youth outlines body structures and functions and activities and participation to fully describe elements that support or detract from participation. While flourishing has gained attention in recent literature, research also points to the role of functional difficulties among autistic youth in influencing participation. Clearly, function is a multi-dimensional and complex construct and likely consists of both indicators of flourishing and functional difficulties. We used data from the National Survey of Children’s Health (NSCH) from 2016 to 2020 to identify aspects of flourishing functional difficulties to achieve the following aims: (1) Investigate the factor structure of flourishing and functional difficulties among autistic youth ages 10–17 years; and (2) examine the extent to which child variables (i.e., sex, age, race, ethnicity, autism severity, poverty) are associated with flourishing and functional difficulties. Autistic children (n = 2960) between the ages of 10 and 17 years were included. We used confirmatory factor analysis followed by a multivariate general linear model (GLM) to examine the association between child variables and factors. Results indicated a six-factor structure (medical conditions, instrumental activities of daily living, activities of daily living, social competence, behavioral control, and school motivation) with good model fit (root mean square error of approximation = 0.08 [p = 0.926], comparative fit index = 0.94, Tucker–Lewis index = 0.91). Multivariate GLM showed that child factors were differentially and significantly associated with factors of functional difficulties and flourishing. Current findings suggest that 16 items measured by the NSCH result in a six-factor structure of flourishing and functional difficulties among autistic youth. A comprehensive approach to capture function among autistic youth must assess aspects of flourishing and difficulties.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Little","given":"Lauren M."},{"family":"Schwefel","given":"Laura-Lee"}],"citation-key":"little2024","container-title":"Children","DOI":"10.3390/children11030325","ISSN":"2227-9067","issue":"3","issued":{"date-parts":[["2024",3]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"3","page":"325","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Flourishing and Functional Difficulties among Autistic Youth: A Confirmatory Factor Analysis","title-short":"Flourishing and Functional Difficulties among Autistic Youth","type":"article-journal","URL":"https://www.mdpi.com/2227-9067/11/3/325","volume":"11"},
  {"id":"liu2017","abstract":"The rapid development of computer and robotic technologies in the last decade is giving hope to perform earlier and more accurate diagnoses of the Autism Spectrum Disorder (ASD), and more effective, consistent, and cost-conscious treatment. Besides the reduced cost, the main benefit of using technology to facilitate treatment is that stimuli produced during each session of the treatment can be controlled, which not only guarantees consistency across different sessions, but also makes it possible to focus on a single phenomenon, which is difficult even for a trained professional to perform, and deliver the stimuli according to the treatment plan. In this article, we provide a comprehensive review of research on recent technology-facilitated diagnosis and treat of children and adults with ASD. Different from existing reviews on this topic, which predominantly concern clinical issues, we focus on the engineering perspective of autism studies. All technology facilitated systems used for autism studies can be modeled as human machine interactive systems where one or more participants would constitute as the human component, and a computer-based or a robotic-based system would be the machine component. Based on this model, we organize our review with the following questions: (1) What are presented to the participants in the studies and how are the content and delivery methods enabled by technologies? (2) How are the reactions/inputs collected from the participants in response to the stimuli in the studies? (3) Are the experimental procedure and programs presented to participants dynamically adjustable based on the responses from the participants, and if so, how? and (4) How are the programs assessed?","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Liu","given":"Xiongyi"},{"family":"Wu","given":"Qing"},{"family":"Zhao","given":"Wenbing"},{"family":"Luo","given":"Xiong"}],"citation-key":"liu2017","container-title":"Applied Sciences","DOI":"10.3390/app7101051","ISSN":"2076-3417","issue":"10","issued":{"date-parts":[["2017",10]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"10","page":"1051","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Technology-Facilitated Diagnosis and Treatment of Individuals with Autism Spectrum Disorder: An Engineering Perspective","title-short":"Technology-Facilitated Diagnosis and Treatment of Individuals with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.mdpi.com/2076-3417/7/10/1051","volume":"7"},
  {"id":"liu2023","abstract":"With the rapid development of virtual reality technology, immersive experiences have become the new generation’s sought-after entertainment feast. Nowadays, various industries have also started utilizing virtual reality for vocational training in fields such as education, healthcare, entertainment, and military. In virtual environments, users can interact socially with others through virtual avatars as their representatives. In this study, we aim to integrate virtual reality devices, eye-tracking devices, and public cloud computing services to infer emotions based on changes in eye data. We evaluate the average accuracy of the proposed model and hope to enhance the facial emotions of avatars to better align with users’ intentions. This study will contribute to improving the authenticity of social interaction and providing users with a better social experience in virtual reality environments.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Liu","given":"Yi-Chun"},{"family":"Huang","given":"Huai-Sheng"}],"citation-key":"liu2023","container-title":"2023 VTS Asia Pacific Wireless Communications Symposium (APWCS)","DOI":"10.1109/APWCS60142.2023.10234036","event-title":"2023 VTS Asia Pacific Wireless Communications Symposium (APWCS)","issued":{"date-parts":[["2023",8]]},"page":"1-2","source":"IEEE Xplore","title":"Identifying Emotions for Virtual Reality Based on Eye Tracking and Cloud Computing","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10234036"},
  {"id":"liu2024","abstract":"Children diagnosed with Autism Spectrum Disorder (ASD) often exhibit motor disorders. Dance Movement Therapy (DMT) has shown great potential for improving the motor control ability of children with ASD. However, traditional DMT methods often lack vividness and are difficult to implement effectively. To address this issue, we propose a Mixed Reality DMT approach, utilizing interactive virtual agents. This approach offers immersive training content and multi-sensory feedback. To improve the training performance of children with ASD, we introduce a novel training paradigm featuring a self-guided mode. This paradigm enables the rapid creation of a virtual twin agent of the child with ASD using a single photo to embody oneself, which can then guide oneself during training. We conducted an experiment with the participation of 24 children diagnosed with ASD (or ASD propensity), recording their training performance under various experimental conditions. Through expert rating, behavior coding of training sessions, and statistical analysis, our findings revealed that the use of the twin agent for self-guidance resulted in noticeable improvements in the training performance of children with ASD. These improvements were particularly evident in terms of enhancing movement quality and refining overall target-related responses. Our study holds clinical potential in the field of medical treatment and rehabilitation for children with ASD.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Liu","given":"Weiying"},{"family":"Zhang","given":"Yanyan"},{"family":"Zhang","given":"Baiqiao"},{"family":"Xiong","given":"Qianqian"},{"family":"Zhao","given":"Hong"},{"family":"Li","given":"Sheng"},{"family":"Liu","given":"Juan"},{"family":"Bian","given":"Yulong"}],"citation-key":"liu2024","container-title":"IEEE Transactions on Visualization and Computer Graphics","DOI":"10.1109/TVCG.2024.3372063","ISSN":"1941-0506","issue":"5","issued":{"date-parts":[["2024",5]]},"page":"2119-2128","source":"IEEE Xplore","title":"Self-Guided DMT: Exploring a Novel Paradigm of Dance Movement Therapy in Mixed Reality for Children with ASD","title-short":"Self-Guided DMT","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/10463763?casa_token=i8gpa-BKw9kAAAAA:uZhWk5ZpLkLbE6ZufBkez7BqpCB83buMTfnlqOWIvuNG8CQH7_YDJPyqkVWoSwqaqGSjXrdAJw","volume":"30"},
  {"id":"lockwoodestrin2021","abstract":"There is increased recognition that women and girls with autism spectrum disorders (ASD) are underserved by the clinical criteria and processes required to receive a diagnosis. This mixed-methods systematic review aimed to identify key barriers to obtaining an ASD diagnosis in girls and young women under 21 years. Six themes were identified that focused on perceived gendered symptoms, namely behavioural problems, social and communication abilities, language, relationships, additional diagnoses/difficulties and restricted and repetitive behaviours and interests. Five themes were identified as (parental) perceived barriers to diagnosis, namely compensatory behaviours, parental concerns, others’ perceptions, lack of information/resources and clinician bias. This review highlights the importance of enhancing widespread understanding and recognition of ASD presentation in females across development. PROSPERO Centre for Reviews and Dissemination (ID 2018 CRD42018087235)","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Lockwood Estrin","given":"Georgia"},{"family":"Milner","given":"Victoria"},{"family":"Spain","given":"Debbie"},{"family":"Happé","given":"Francesca"},{"family":"Colvert","given":"Emma"}],"citation-key":"lockwoodestrin2021","container-title":"Review Journal of Autism and Developmental Disorders","container-title-short":"Rev J Autism Dev Disord","DOI":"10.1007/s40489-020-00225-8","ISSN":"2195-7185","issue":"4","issued":{"date-parts":[["2021",12,1]]},"language":"en","page":"454-470","source":"Springer Link","title":"Barriers to Autism Spectrum Disorder Diagnosis for Young Women and Girls: a Systematic Review","title-short":"Barriers to Autism Spectrum Disorder Diagnosis for Young Women and Girls","type":"article-journal","URL":"https://doi.org/10.1007/s40489-020-00225-8","volume":"8"},
  {"id":"lord2022","author":[{"family":"Lord","given":"Catherine"},{"family":"Charman","given":"Tony"},{"family":"Havdahl","given":"Alexandra"},{"family":"Carbone","given":"Paul"},{"family":"Anagnostou","given":"Evdokia"},{"family":"Boyd","given":"Brian"},{"family":"Carr","given":"Themba"},{"family":"Vries","given":"Petrus J.","non-dropping-particle":"de"},{"family":"Dissanayake","given":"Cheryl"},{"family":"Divan","given":"Gauri"},{"family":"Freitag","given":"Christine M."},{"family":"Gotelli","given":"Marina M."},{"family":"Kasari","given":"Connie"},{"family":"Knapp","given":"Martin"},{"family":"Mundy","given":"Peter"},{"family":"Plank","given":"Alex"},{"family":"Scahill","given":"Lawrence"},{"family":"Servili","given":"Chiara"},{"family":"Shattuck","given":"Paul"},{"family":"Simonoff","given":"Emily"},{"family":"Singer","given":"Alison Tepper"},{"family":"Slonims","given":"Vicky"},{"family":"Wang","given":"Paul P."},{"family":"Ysrraelit","given":"Maria Celica"},{"family":"Jellett","given":"Rachel"},{"family":"Pickles","given":"Andrew"},{"family":"Cusack","given":"James"},{"family":"Howlin","given":"Patricia"},{"family":"Szatmari","given":"Peter"},{"family":"Holbrook","given":"Alison"},{"family":"Toolan","given":"Christina"},{"family":"McCauley","given":"James B."}],"citation-key":"lord2022","container-title":"Lancet (London, England)","container-title-short":"Lancet","DOI":"10.1016/S0140-6736(21)01541-5","ISSN":"1474-547X","issue":"10321","issued":{"date-parts":[["2022",1,15]]},"language":"eng","page":"271-334","PMID":"34883054","source":"PubMed","title":"The Lancet Commission on the future of care and clinical research in autism","type":"article-journal","volume":"399"},
  {"id":"lord2023","abstract":"Researchers have developed a screening tool for autism that uses computer vision and machine learning to analyze autism-related behaviors — but greater reliability and robust validation will be needed if such tools are to be used in primary care settings.","accessed":{"date-parts":[["2025",2,22]]},"author":[{"family":"Lord","given":"Catherine"},{"family":"Wilson","given":"Rujuta B."}],"citation-key":"lord2023","container-title":"Nature Medicine","container-title-short":"Nat Med","DOI":"10.1038/s41591-023-02557-4","ISSN":"1546-170X","issue":"10","issued":{"date-parts":[["2023",10]]},"language":"en","license":"2023 Springer Nature America, Inc.","page":"2412-2413","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Digital phenotyping could help detect autism","type":"article-journal","URL":"https://www.nature.com/articles/s41591-023-02557-4","volume":"29"},
  {"id":"loth2017","abstract":"The tremendous clinical and aetiological diversity among individuals with autism spectrum disorder (ASD) has been a major obstacle to the development of new treatments, as many may only be effective in particular subgroups. Precision medicine approaches aim to overcome this challenge by combining pathophysiologically based treatments with stratification biomarkers that predict which treatment may be most beneficial for particular individuals. However, so far, we have no single validated stratification biomarker for ASD. This may be due to the fact that most research studies primarily have focused on the identification of mean case-control differences, rather than within-group variability, and included small samples that were underpowered for stratification approaches. The EU-AIMS Longitudinal European Autism Project (LEAP) is to date the largest multi-centre, multi-disciplinary observational study worldwide that aims to identify and validate stratification biomarkers for ASD.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Loth","given":"Eva"},{"family":"Charman","given":"Tony"},{"family":"Mason","given":"Luke"},{"family":"Tillmann","given":"Julian"},{"family":"Jones","given":"Emily J. H."},{"family":"Wooldridge","given":"Caroline"},{"family":"Ahmad","given":"Jumana"},{"family":"Auyeung","given":"Bonnie"},{"family":"Brogna","given":"Claudia"},{"family":"Ambrosino","given":"Sara"},{"family":"Banaschewski","given":"Tobias"},{"family":"Baron-Cohen","given":"Simon"},{"family":"Baumeister","given":"Sarah"},{"family":"Beckmann","given":"Christian"},{"family":"Brammer","given":"Michael"},{"family":"Brandeis","given":"Daniel"},{"family":"Bölte","given":"Sven"},{"family":"Bourgeron","given":"Thomas"},{"family":"Bours","given":"Carsten"},{"family":"Bruijn","given":"Yvette","non-dropping-particle":"de"},{"family":"Chakrabarti","given":"Bhismadev"},{"family":"Crawley","given":"Daisy"},{"family":"Cornelissen","given":"Ineke"},{"family":"Acqua","given":"Flavio Dell’"},{"family":"Dumas","given":"Guillaume"},{"family":"Durston","given":"Sarah"},{"family":"Ecker","given":"Christine"},{"family":"Faulkner","given":"Jessica"},{"family":"Frouin","given":"Vincent"},{"family":"Garces","given":"Pilar"},{"family":"Goyard","given":"David"},{"family":"Hayward","given":"Hannah"},{"family":"Ham","given":"Lindsay M."},{"family":"Hipp","given":"Joerg"},{"family":"Holt","given":"Rosemary J."},{"family":"Johnson","given":"Mark H."},{"family":"Isaksson","given":"Johan"},{"family":"Kundu","given":"Prantik"},{"family":"Lai","given":"Meng-Chuan"},{"family":"D’ardhuy","given":"Xavier Liogier"},{"family":"Lombardo","given":"Michael V."},{"family":"Lythgoe","given":"David J."},{"family":"Mandl","given":"René"},{"family":"Meyer-Lindenberg","given":"Andreas"},{"family":"Moessnang","given":"Carolin"},{"family":"Mueller","given":"Nico"},{"family":"O’Dwyer","given":"Laurence"},{"family":"Oldehinkel","given":"Marianne"},{"family":"Oranje","given":"Bob"},{"family":"Pandina","given":"Gahan"},{"family":"Persico","given":"Antonio M."},{"family":"Ruigrok","given":"Amber N. V."},{"family":"Ruggeri","given":"Barbara"},{"family":"Sabet","given":"Jessica"},{"family":"Sacco","given":"Roberto"},{"family":"Cáceres","given":"Antonia San José"},{"family":"Simonoff","given":"Emily"},{"family":"Toro","given":"Roberto"},{"family":"Tost","given":"Heike"},{"family":"Waldman","given":"Jack"},{"family":"Williams","given":"Steve C. R."},{"family":"Zwiers","given":"Marcel P."},{"family":"Spooren","given":"Will"},{"family":"Murphy","given":"Declan G. M."},{"family":"Buitelaar","given":"Jan K."}],"citation-key":"loth2017","container-title":"Molecular Autism","container-title-short":"Molecular Autism","DOI":"10.1186/s13229-017-0146-8","ISSN":"2040-2392","issue":"1","issued":{"date-parts":[["2017",6,23]]},"language":"en","page":"24","source":"Springer Link","title":"The EU-AIMS Longitudinal European Autism Project (LEAP): design and methodologies to identify and validate stratification biomarkers for autism spectrum disorders","title-short":"The EU-AIMS Longitudinal European Autism Project (LEAP)","type":"article-journal","URL":"https://doi.org/10.1186/s13229-017-0146-8","volume":"8"},
  {"id":"lu2022","abstract":"The recent shift to wellbeing, sustainability, and resilience under Industry 5.0 has prompted formal discussions that manufacturing should be human-centric – placing the wellbeing of industry workers at the center of manufacturing processes, instead of system-centric – only driven by efficiency and quality improvement and cost reduction. However, there is a lack of shared understanding of the essence of human-centric manufacturing, though significant research efforts exist in enhancing the physical and cognitive wellbeing of operators. Therefore, this position paper presents our arguments on the concept, needs, reference model, enabling technologies and system frameworks of human-centric manufacturing, providing a relatable vision and research agenda for future work in human-centric manufacturing systems. We believe human-centric manufacturing should ultimately address human needs defined in an Industrial Human Needs Pyramid – from basic needs of safety and health to the highest level of esteem and self-actualization. In parallel, human-machine relationships will change following a 5C evolution map – from current Coexistence, Cooperation and Collaboration to future Compassion and Coevolution. As such, human-centric manufacturing systems need to have bi-directional empathy, proactive communication and collaborative intelligence for establishing trustworthy human-machine coevolution relationships, thereby leading to high-performance human-machine teams. It is suggested that future research focus should be on developing transparent, trustworthy and quantifiable technologies that provide a rewarding working environment driven by real-world needs.","accessed":{"date-parts":[["2025",3,10]]},"author":[{"family":"Lu","given":"Yuqian"},{"family":"Zheng","given":"Hao"},{"family":"Chand","given":"Saahil"},{"family":"Xia","given":"Wanqing"},{"family":"Liu","given":"Zengkun"},{"family":"Xu","given":"Xun"},{"family":"Wang","given":"Lihui"},{"family":"Qin","given":"Zhaojun"},{"family":"Bao","given":"Jinsong"}],"citation-key":"lu2022","container-title":"Journal of Manufacturing Systems","container-title-short":"Journal of Manufacturing Systems","DOI":"10.1016/j.jmsy.2022.02.001","ISSN":"0278-6125","issued":{"date-parts":[["2022",1,1]]},"page":"612-627","source":"ScienceDirect","title":"Outlook on human-centric manufacturing towards Industry 5.0","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0278612522000164","volume":"62"},
  {"id":"macedonio2007","abstract":"In this paper, we discuss findings from a study that used panoramic video-based virtual environments (PVVEs) to induce self-reported anger. The study assessed “immersiveness” and physiological correlates of anger arousal (i.e., heart rate, blood pressure, galvanic skin response [GSR], respiration, and skin temperature). Results indicate that over time, panoramic video-based virtual scenarios can be, at the very least, physiologically arousing. Further, it can be affirmed from the results that hypnotizability, as defined by the applied measures, interacts with group on physiological arousal measures. Hence, physiological arousal appeared to be moderated by participant hypnotizability and absorption levels.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Macedonio","given":"Mary F."},{"family":"Parsons","given":"Thomas D."},{"family":"Digiuseppe","given":"Raymond A."},{"family":"Weiderhold","given":"Brenda A."},{"family":"Rizzo","given":"Albert A."}],"citation-key":"macedonio2007","container-title":"CyberPsychology & Behavior","DOI":"10.1089/cpb.2007.9997","ISSN":"1094-9313","issue":"4","issued":{"date-parts":[["2007",8]]},"page":"508-515","publisher":"Mary Ann Liebert, Inc., publishers","source":"liebertpub.com (Atypon)","title":"Immersiveness and Physiological Arousal within Panoramic Video-Based Virtual Reality","type":"article-journal","URL":"https://www.liebertpub.com/doi/10.1089/cpb.2007.9997","volume":"10"},
  {"id":"mai2023","abstract":"The wide application of smart devices enables the availability of multimodal data, which can be utilized in many tasks. In the field of multimodal sentiment analysis, most previous works focus on exploring intra- and inter-modal interactions. However, training a network with cross-modal information (language, audio and visual) is still challenging due to the modality gap. Besides, while learning dynamics within each sample draws great attention, the learning of inter-sample and inter-class relationships is neglected. Moreover, the size of datasets limits the generalization ability of the models. To address the afore-mentioned issues, we propose a novel framework HyCon for hybrid contrastive learning of tri-modal representation. Specifically, we simultaneously perform intra-/inter-modal contrastive learning and semi-contrastive learning, with which the model can fully explore cross-modal interactions, learn inter-sample and inter-class relationships, and reduce the modality gap. Besides, refinement term and modality margin are introduced to enable a better learning of unimodal pairs. Moreover, we devise pair selection mechanism to identify and assign weights to the informative negative and positive pairs. HyCon can naturally generate many training pairs for better generalization and reduce the negative effect of limited datasets. Extensive experiments demonstrate that our method outperforms baselines on multimodal sentiment analysis and emotion recognition.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Mai","given":"Sijie"},{"family":"Zeng","given":"Ying"},{"family":"Zheng","given":"Shuangjia"},{"family":"Hu","given":"Haifeng"}],"citation-key":"mai2023","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/TAFFC.2022.3172360","ISSN":"1949-3045","issue":"3","issued":{"date-parts":[["2023",7]]},"page":"2276-2289","source":"IEEE Xplore","title":"Hybrid Contrastive Learning of Tri-Modal Representation for Multimodal Sentiment Analysis","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9767560","volume":"14"},
  {"id":"mak2023","abstract":"Given the prevalence of Autism Spectrum Disorder (ASD) and the demand for treatment, there is a continuous seeking and uncertainty of effective interventions for people with ASD. As technology continues to advance, the application of Virtual Reality is emerging in clinical settings. This systematic review summarised findings to evaluate the application of virtual reality (VR) on the skill-specific performance in people with ASD. The purpose is to determine (1) if VR is an effective treatment for people with ASD in skill-specific performance and (2) can Occupational Therapists employ VR in their practice. Eight databases were systematically searched for peer-reviewed articles that were published from January 2012 to February 2018. Eight articles met the inclusion criteria. The measurements of specific skills were categorised into three main domains: job interviewing, driving, and other ADLs. A diverse range of outcome measures were utilised and provided various results. Despite the consistent positive results reported in the studies, the current evidence base lacks justification of sample sizes, reliability and validity of the findings. Although VR shows potential as an effective intervention, limitations and bias of studies should be considered. Results of studies must be interpreted with caution if Occupational Therapists are interested in employing VR in their practice.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Mak","given":"Grace"},{"family":"Zhao","given":"Lea"}],"citation-key":"mak2023","container-title":"Interactive Learning Environments","DOI":"10.1080/10494820.2020.1811733","ISSN":"1049-4820","issue":"2","issued":{"date-parts":[["2023",2,17]]},"page":"804-817","publisher":"Routledge","source":"Taylor and Francis+NEJM","title":"A systematic review: the application of virtual reality on the skill-specific performance in people with ASD","title-short":"A systematic review","type":"article-journal","URL":"https://doi.org/10.1080/10494820.2020.1811733","volume":"31"},
  {"id":"mangala2024","abstract":"Injection moulding is the most popular technique used by Sri Lankan small and medium-scale enterprises for producing plastic parts in large quantities. Once a strong industry that catered to over 50% of local demand for dies and moulds are now barely meeting one-tenth of the demand due to import competition. Moreover, the local industry lacks access to state-of-the-art design tools owing to funding limitations and mainly relies on experience of long-standing mould design experts. The brain drain following country's economic downturn has now severely affected growth or even existence of this important industry. In this context, the paper introduces a unique strategy to digitally transform the tacit knowledge of mould design experts, and thereby establish a data-driven decision-making process for mould design. In order to manage both explicit and tacit knowledge in injection mould design, a framework was developed, and corresponding databases were established. The proposed expert model uses a predefined case bank and a case-based filtering algorithm to identify matching data sets for a given new design from explicit and tacit databases. Suitability of parameters of the new design is determined using a decision-making algorithm, where higher weightage is assigned to tacit knowledge-based on data availability. The expert model was validated using a case study, and results of the expert model were found to be significantly agreeable to the output of industry-standard mould design software. The findings indicate potential of the proposed tacit knowledge-based expert model to positively impact mould industry affected by low resources and help reach Industry 4.0.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Mangala","given":"K.H.J."},{"family":"Ranaweera","given":"R.K.P.S."},{"family":"Punchihewa","given":"H.K.G."}],"citation-key":"mangala2024","container-title":"2024 9th International Conference on Information Technology Research (ICITR)","DOI":"10.1109/ICITR64794.2024.10857747","event-title":"2024 9th International Conference on Information Technology Research (ICITR)","ISSN":"2831-3399","issued":{"date-parts":[["2024",12]]},"page":"1-6","source":"IEEE Xplore","title":"Tacit Knowledge-Based Expert Model for Decision Support in Injection Mould Design","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10857747"},
  {"id":"manju2023","abstract":"Nowadays there is an increase in number of autisms, a neuro-developmental disorder across the world. The level of autism varies with the symptoms such as inattention, interaction, social communication, repetitive behaviors, irritability and the like. Early recovery of a child from autism is necessary to live in a normal socio-communicable life. To measure the inattention of the autism child by enhancing the visual perception through virtual environment. The proposed Virtual Reality Intervention (VRI) enhances visual perception, learning, and social interaction. The proposed method observes the attention level of the autism child through eye tracking or eye movements who interacts with virtual world using eye tracking methodology. As eye tracking is the major component to measure the reduced looking time of objects and subjects which considered being the earliest signs of autism spectrum disorder (ASD). For observing the attention of kids during testing, Eye movements and gestures plays a major role. Using head position and eye pupil direction, attention has been analyzed. Quantitative and Qualitative findings conclude that the inattention of autism child can gradually be reduced by iterating the virtual therapy through eye ball tracking technique. Qualitative finding is done using Aberrant Behavior Checklist (ABC) and quantitative using eye-pupil and head position. Autism affected children can easily recovered from this inattention symptom by continuous iterations on virtual therapy. Similar virtual therapies can also be provided to address other symptoms of autism.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Manju","given":"T."},{"family":"Magesh","given":""},{"family":"Padmavathi","given":"S."},{"family":"Durairaj","given":""}],"citation-key":"manju2023","container-title":"ACM Trans. Asian Low-Resour. Lang. Inf. Process.","DOI":"10.1145/3592855","ISSN":"2375-4699","issued":{"date-parts":[["2023",4,19]]},"note":"Just Accepted","source":"ACM Digital Library","title":"Increasing the Social Interaction of Autism Child using Virtual Reality Intervention (VRI)","type":"article-journal","URL":"https://dl.acm.org/doi/10.1145/3592855"},
  {"id":"marschik2023","abstract":"The Prechtl General Movements Assessment (GMA) has become a clinician and researcher toolbox for evaluating neurodevelopment in early infancy. Given that it involves the observation of infant movements from video recordings, utilising smartphone applications to obtain these recordings seems like the natural progression for the field. In this review, we look back on the development of apps for acquiring general movement videos, describe the application and research studies of available apps, and discuss future directions of mobile solutions and their usability in research and clinical practice. We emphasise the importance of understanding the background that has led to these developments while introducing new technologies, including the barriers and facilitators along the pathway. The GMApp and Baby Moves apps were the first ones developed to increase accessibility of the GMA, with two further apps, NeuroMotion and InMotion, designed since. The Baby Moves app has been applied most frequently. For the mobile future of GMA, we advocate collaboration to boost the field’s progression and to reduce research waste. We propose future collaborative solutions, including standardisation of cross-site data collection, adaptation to local context and privacy laws, employment of user feedback, and sustainable IT structures enabling continuous software updating.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Marschik","given":"Peter B."},{"family":"Kwong","given":"Amanda K. L."},{"family":"Silva","given":"Nelson"},{"family":"Olsen","given":"Joy E."},{"family":"Schulte-Rüther","given":"Martin"},{"family":"Bölte","given":"Sven"},{"family":"Örtqvist","given":"Maria"},{"family":"Eeles","given":"Abbey"},{"family":"Poustka","given":"Luise"},{"family":"Einspieler","given":"Christa"},{"family":"Nielsen-Saines","given":"Karin"},{"family":"Zhang","given":"Dajie"},{"family":"Spittle","given":"Alicia J."}],"citation-key":"marschik2023","container-title":"Journal of Clinical Medicine","DOI":"10.3390/jcm12103576","ISSN":"2077-0383","issue":"10","issued":{"date-parts":[["2023",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"10","page":"3576","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Mobile Solutions for Clinical Surveillance and Evaluation in Infancy—General Movement Apps","type":"article-journal","URL":"https://www.mdpi.com/2077-0383/12/10/3576","volume":"12"},
  {"id":"mason2021","abstract":"The neurocognitive mechanisms underlying autism spectrum disorder (ASD) remain unclear. Progress has been largely hampered by small sample sizes, variable age ranges and resulting inconsistent findings. There is a pressing need for large definitive studies to delineate the nature and extent of key case/control differences to direct research towards fruitful areas for future investigation. Here we focus on perception of biological motion, a promising index of social brain function which may be altered in ASD. In a large sample ranging from childhood to adulthood, we assess whether biological motion preference differs in ASD compared to neurotypical participants (NT), how differences are modulated by age and sex and whether they are associated with dimensional variation in concurrent or later symptomatology.","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Mason","given":"L."},{"family":"Shic","given":"F."},{"family":"Falck-Ytter","given":"T."},{"family":"Chakrabarti","given":"B."},{"family":"Charman","given":"T."},{"family":"Loth","given":"E."},{"family":"Tillmann","given":"J."},{"family":"Banaschewski","given":"T."},{"family":"Baron-Cohen","given":"S."},{"family":"Bölte","given":"S."},{"family":"Buitelaar","given":"J."},{"family":"Durston","given":"S."},{"family":"Oranje","given":"B."},{"family":"Persico","given":"A. M."},{"family":"Beckmann","given":"C."},{"family":"Bougeron","given":"T."},{"family":"Dell’Acqua","given":"F."},{"family":"Ecker","given":"C."},{"family":"Moessnang","given":"C."},{"family":"Murphy","given":"D."},{"family":"Johnson","given":"M. H."},{"family":"Jones","given":"E. J. H."},{"family":"Ahmad","given":"Jumana"},{"family":"Ambrosino","given":"Sara"},{"family":"Baumeister","given":"Sarah"},{"family":"Bours","given":"Carsten"},{"family":"Brammer","given":"Michael"},{"family":"Brandeis","given":"Daniel"},{"family":"Brogna","given":"Claudia"},{"family":"Bruijn","given":"Yvette","non-dropping-particle":"de"},{"family":"Chatham","given":"Chris"},{"family":"Cornelissen","given":"Ineke"},{"family":"Crawley","given":"Daisy"},{"family":"Dumas","given":"Guillaume"},{"family":"Faulkner","given":"Jessica"},{"family":"Frouin","given":"Vincent"},{"family":"Garcés","given":"Pilar"},{"family":"Goyard","given":"David"},{"family":"Ham","given":"Lindsay"},{"family":"Hipp","given":"Joerg"},{"family":"Holt","given":"Rosemary"},{"family":"Lai","given":"Meng-Chuan"},{"family":"D’ardhuy","given":"Xavier Liogier"},{"family":"Lombardo","given":"Michael V."},{"family":"Lythgoe","given":"David J."},{"family":"Mandl","given":"René"},{"family":"Marquand","given":"Andre"},{"family":"Mennes","given":"Maarten"},{"family":"Meyer-Lindenberg","given":"Andreas"},{"family":"Bast","given":"Nico"},{"family":"Oakley","given":"Bethany"},{"family":"O’Dwyer","given":"Laurence"},{"family":"Oldehinkel","given":"Marianne"},{"family":"Pandina","given":"Gahan"},{"family":"Ruggeri","given":"Barbara"},{"family":"Ruigrok","given":"Amber"},{"family":"Sabet","given":"Jessica"},{"family":"Sacco","given":"Roberto"},{"family":"Cáceres","given":"Antonia San José"},{"family":"Simonoff","given":"Emily"},{"family":"Spooren","given":"Will"},{"family":"Toro","given":"Roberto"},{"family":"Tost","given":"Heike"},{"family":"Waldman","given":"Jack"},{"family":"Williams","given":"Steve C. R."},{"family":"Wooldridge","given":"Caroline"},{"family":"Zwiers","given":"Marcel P."},{"literal":"the LEAP Team*"}],"citation-key":"mason2021","container-title":"Molecular Autism","container-title-short":"Molecular Autism","DOI":"10.1186/s13229-021-00476-0","ISSN":"2040-2392","issue":"1","issued":{"date-parts":[["2021",12,15]]},"language":"en","page":"74","source":"Springer Link","title":"Preference for biological motion is reduced in ASD: implications for clinical trials and the search for biomarkers","title-short":"Preference for biological motion is reduced in ASD","type":"article-journal","URL":"https://doi.org/10.1186/s13229-021-00476-0","volume":"12"},
  {"id":"medda2019","abstract":"The aim of the present study was to establish diagnostic validity of the new algorithm of the Autism Diagnostic Observation Scale, the ADOS-2, to differentiate between ASD and other clinically relevant psychiatric and developmental disorders in a large German sample. Validity of ADOS and ADOS-2 diagnostic algorithms was established in 826 individuals (n = 455 autism, n = 216 autism spectrum, n = 155 non-ASD patients) by receiver operating curves. Confidence intervals overlapped largely for ADOS and ADOS-2 algorithms, confirming diagnostic validity of both algorithms. Adding information of the Social Communication Questionnaire and the Social Responsiveness Scale resulted in slightly improved classification rates for autism in Module 4. We thus replicated previous findings of the diagnostic validity of the ADOS-2 algorithms.","accessed":{"date-parts":[["2025",2,5]]},"author":[{"family":"Medda","given":"Juliane E."},{"family":"Cholemkery","given":"Hannah"},{"family":"Freitag","given":"Christine M."}],"citation-key":"medda2019","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-018-3750-3","ISSN":"0162-3257","issue":"2","issued":{"date-parts":[["2019"]]},"page":"750-761","PMCID":"PMC6373322","PMID":"30238180","source":"PubMed Central","title":"Sensitivity and Specificity of the ADOS-2 Algorithm in a Large German Sample","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6373322/","volume":"49"},
  {"id":"megerian2022","abstract":"Objective:\nThe lack of diagnostic tools for Autism Spectrum Disorder in primary care settings and long wait lists for specialist assessment contribute to an average delay of 3 years between first parental concern and diagnosis. This study examined the performance of an artificial intelligence-based device intended to aid PCPs in the diagnosis of ASD.\nBackground:\nNA\nDesign/Methods:\nMethods:\nThis was a prospective multi-site pivotal study conducted in 6 states using a double-blind active comparator design with 425 completed subjects (36% female) ages 18–72 months with concern for developmental delay. Previous research developed, tuned, and tested a device that uses a gradient boosted decision tree machine learning algorithm which analyzes 64 behavioral features from 3 distinct inputs: 1) Caregiver questionnaire 2) two, 90 second minimum home videos analyzed by trained video analysts 3) PCP questionnaire.\nResults:\nDevice results were compared to diagnosis by independent agreement of specialist clinicians based on clinical assessment, including a modified CARS-2 and DSM-5 criteria. Specialists were child psychiatrists, child psychologists, pediatric neurologists, and developmental behavioral pediatricians experienced in diagnosing ASD.\nResults Comparison of device results to specialist diagnosis found the PPV: 80.8% [95%CI, 70.3%–88.8%], NPV: 98.3% [90.6%–100%], sensitivity: 98.4% [91.6%–100%], specificity: 78.9% [67.6%–87.7%] for subjects with determinate device results. There was no evidence that device performance significantly varied when PCP used the device remotely compared to in-person.\nConclusions:\nUsing this device, PCPs could efficiently, accurately, and equitably diagnose a subset of children 18–72 months old, thereby streamlining specialist referrals and facilitating earlier ASD diagnosis and interventions. The results further provide preliminary evidence that PCP evaluation of the child can be done via telemedicine or in-person with no degradation in device performance.\nDisclosure: Dr. Megerian has received personal compensation for serving as an employee of Yamo Pharmaceuticals. Dr. Megerian has received personal compensation in the range of $10,000-$49,999 for serving as a Consultant for Cognito Therapeutics. Dr. Megerian has received personal compensation in the range of $10,000-$49,999 for serving as a Consultant for Kuzani Pharmaceuticals. Dr. Megerian has received research support from Childrens Hospital of Orange County. Dr. Dey has nothing to disclose. Dr. Melmed has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Ovid. Dr. Melmed has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Cognoa. Dr. Melmed has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Akili. Dr. Melmed has received personal compensation in the range of $500-$4,999 for serving on a Speakers Bureau for Akili. Dr. Melmed has received research support from Akili. Dr. Melmed has received research support from Quadrant. The institution of Dr. Melmed has received research support from Cognoa. Dr. Coury has received personal compensation in the range of $0-$499 for serving as a Consultant for BioRosa. Dr. Coury has received personal compensation in the range of $10,000-$49,999 for serving as a Consultant for Quadrant. Dr. Coury has received personal compensation in the range of $0-$499 for serving as a Consultant for Stalicla. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Cognoa. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving as a Consultant for MaraBio. Dr. Coury has received personal compensation in the range of $0-$499 for serving on a Scientific Advisory or Data Safety Monitoring board for BioRosa. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Cognoa. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for GW Biosciences. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for MaraBio. Dr. Coury has received personal compensation in the range of $10,000-$49,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Quadrant Biosciences. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Stalicla SA. Dr. Coury has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for AMO Pharma. The institution of Dr. Coury has received research support from GW Biosciences. The institution of Dr. Coury has received research support from Stalicla SA. Prof. Lerner has received personal compensation for serving as an employee of Cognoa. Prof. Lerner has received personal compensation in the range of $5,000-$9,999 for serving as a Consultant for Cognoa. Dr. Nicholls has received personal compensation in the range of $50,000-$99,999 for serving as an Expert Witness for various attorneys. Dr. Nicholls has received publishing royalties from a publication relating to health care. Kristin Sohl has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Autism Navigator. Kristin Sohl has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Cognoa . Kristin Sohl has received personal compensation in the range of $5,000-$9,999 for serving as an Editor, Associate Editor, or Editorial Advisory Board Member for Quadrant Biosciences . The institution of Kristin Sohl has received research support from Autism Speaks. The institution of Kristin Sohl has received research support from NIH. The institution of Kristin Sohl has received research support from DOD. The institution of Kristin Sohl has received research support from HRSA. The institution of Kristin Sohl has received research support from Missouri Department of Mental Health. Dr. Rouhbakhsh has a non-compensated relationship as a Editorial Board Member with The Journal of Occupational and Environmental Medicine that is relevant to AAN interests or activities. Dr. Narasimhan has nothing to disclose. Dr. Romain has received personal compensation for serving as an employee of CHOC children's Hospital . Dr. Romain has received personal compensation in the range of $10,000-$49,999 for serving as a Consultant for COGNOA. Dr. Golla has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Cognoa . Dr. Shareef has nothing to disclose. Dr. Ostrovsky has received personal compensation in the range of $500-$4,999 for serving on a Scientific Advisory or Data Safety Monitoring board for Cognoa. Dr. Ostrovsky has received stock or an ownership interest from Social Innovation Ventures. Dr. Shannon has received personal compensation for serving as an employee of Cognoa. Dr. Shannon has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Pear. Dr. Shannon has received personal compensation in the range of $500-$4,999 for serving as an Expert Witness for Advanced Medical Group. Dr. Kraft has received personal compensation for serving as an employee of Cognoa. Dr. Kraft has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Happiest Baby, Inc. Dr. Kraft has received personal compensation in the range of $0-$499 for serving as an officer or member of the Board of Directors for DotCom Therapy. Dr. Kraft has received personal compensation in the range of $0-$499 for serving as an officer or member of the Board of Directors for Cognoa, Inc. Mr. Liu-Mayo has received personal compensation for serving as an employee of Cognoa. Mr. Liu-Mayo has received stock or an ownership interest from Cognoa. Mr. Abbas has received personal compensation for serving as an employee of Cognoa. Mr. Abbas has received intellectual property interests from a discovery or technology relating to health care. Dr. Gal-Szabo has received personal compensation in the range of $10,000-$49,999 for serving as a Consultant for Cognoa Inc. Prof. Wall has received personal compensation in the range of $500-$4,999 for serving as a Consultant for Cognoa. Dr. Taraman has received personal compensation for serving as an employee of Cognoa. Dr. Taraman has received personal compensation for serving as an employee of Pediatric Subspecialty Faculty. Dr. Taraman has received personal compensation in the range of $10,000-$49,999 for serving as a Consultant for Cognito Therapeutics . Dr. Taraman has received stock or an ownership interest from Handzin. Dr. Taraman has received stock or an ownership interest from Cognoa. Dr. Taraman has received research support from Innovative Health Solutions. Dr. Taraman has received intellectual property interests from a discovery or technology relating to health care. Dr. Taraman has received intellectual property interests from a discovery or technology relating to health care. Dr. Taraman has received intellectual property interests from a discovery or technology relating to health care.","accessed":{"date-parts":[["2025",2,5]]},"author":[{"family":"Megerian","given":"Jonathan T."},{"family":"Dey","given":"Sangeeta"},{"family":"Melmed","given":"Raun D."},{"family":"Coury","given":"Daniel L."},{"family":"Lerner","given":"Marc"},{"family":"Nicholls","given":"Christopher"},{"family":"Sohl","given":"Kristin"},{"family":"Rouhbakhsh","given":"Rambod"},{"family":"Narasimhan","given":"Anandhi"},{"family":"Romain","given":"Jonathan"},{"family":"Golla","given":"Sailaja"},{"family":"Shareef","given":"Safiullah"},{"family":"Ostrovsky","given":"Andrey"},{"family":"Shannon","given":"Jennifer"},{"family":"Kraft","given":"Colleen"},{"family":"Liu-Mayo","given":"Stuart"},{"family":"Abbas","given":"Halim"},{"family":"Gal-Szabo","given":"Diana E."},{"family":"Wall","given":"Dennis P."},{"family":"Taraman","given":"Sharief"}],"citation-key":"megerian2022","container-title":"Neurology","DOI":"10.1212/WNL.98.18_supplement.1025","issue":"18_supplement","issued":{"date-parts":[["2022",5,3]]},"page":"1025","publisher":"Wolters Kluwer","source":"neurology.org (Atypon)","title":"Performance of Canvas Dx, a Novel Software-based Autism Spectrum Disorder Diagnosis Aid for Use in a Primary Care Setting (P13-5.001)","type":"article-journal","URL":"https://www.neurology.org/doi/abs/10.1212/WNL.98.18_supplement.1025","volume":"98"},
  {"id":"megerian2022a","abstract":"Autism spectrum disorder (ASD) can be reliably diagnosed at 18 months, yet significant diagnostic delays persist in the United States. This double-blinded, multi-site, prospective, active comparator cohort study tested the accuracy of an artificial intelligence-based Software as a Medical Device designed to aid primary care healthcare providers (HCPs) in diagnosing ASD. The Device combines behavioral features from three distinct inputs (a caregiver questionnaire, analysis of two short home videos, and an HCP questionnaire) in a gradient boosted decision tree machine learning algorithm to produce either an ASD positive, ASD negative, or indeterminate output. This study compared Device outputs to diagnostic agreement by two or more independent specialists in a cohort of 18–72-month-olds with developmental delay concerns (425 study completers, 36% female, 29% ASD prevalence). Device output PPV for all study completers was 80.8% (95% confidence intervals (CI), 70.3%–88.8%) and NPV was 98.3% (90.6%–100%). For the 31.8% of participants who received a determinate output (ASD positive or negative) Device sensitivity was 98.4% (91.6%–100%) and specificity was 78.9% (67.6%–87.7%). The Device’s indeterminate output acts as a risk control measure when inputs are insufficiently granular to make a determinate recommendation with confidence. If this risk control measure were removed, the sensitivity for all study completers would fall to 51.6% (63/122) (95% CI 42.4%, 60.8%), and specificity would fall to 18.5% (56/303) (95% CI 14.3%, 23.3%). Among participants for whom the Device abstained from providing a result, specialists identified that 91% had one or more complex neurodevelopmental disorders. No significant differences in Device performance were found across participants’ sex, race/ethnicity, income, or education level. For nearly a third of this primary care sample, the Device enabled timely diagnostic evaluation with a high degree of accuracy. The Device shows promise to significantly increase the number of children able to be diagnosed with ASD in a primary care setting, potentially facilitating earlier intervention and more efficient use of specialist resources.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Megerian","given":"Jonathan T."},{"family":"Dey","given":"Sangeeta"},{"family":"Melmed","given":"Raun D."},{"family":"Coury","given":"Daniel L."},{"family":"Lerner","given":"Marc"},{"family":"Nicholls","given":"Christopher J."},{"family":"Sohl","given":"Kristin"},{"family":"Rouhbakhsh","given":"Rambod"},{"family":"Narasimhan","given":"Anandhi"},{"family":"Romain","given":"Jonathan"},{"family":"Golla","given":"Sailaja"},{"family":"Shareef","given":"Safiullah"},{"family":"Ostrovsky","given":"Andrey"},{"family":"Shannon","given":"Jennifer"},{"family":"Kraft","given":"Colleen"},{"family":"Liu-Mayo","given":"Stuart"},{"family":"Abbas","given":"Halim"},{"family":"Gal-Szabo","given":"Diana E."},{"family":"Wall","given":"Dennis P."},{"family":"Taraman","given":"Sharief"}],"citation-key":"megerian2022a","container-title":"npj Digital Medicine","container-title-short":"npj Digit. Med.","DOI":"10.1038/s41746-022-00598-6","ISSN":"2398-6352","issue":"1","issued":{"date-parts":[["2022",5,5]]},"language":"en","license":"2022 The Author(s)","page":"1-11","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Evaluation of an artificial intelligence-based medical device for diagnosis of autism spectrum disorder","type":"article-journal","URL":"https://www.nature.com/articles/s41746-022-00598-6","volume":"5"},
  {"id":"megerian2022b","abstract":"Autism spectrum disorder (ASD) can be reliably diagnosed at 18 months, yet significant diagnostic delays persist in the United States. This double-blinded, multi-site, prospective, active comparator cohort study tested the accuracy of an artificial intelligence-based Software as a Medical Device designed to aid primary care healthcare providers (HCPs) in diagnosing ASD. The Device combines behavioral features from three distinct inputs (a caregiver questionnaire, analysis of two short home videos, and an HCP questionnaire) in a gradient boosted decision tree machine learning algorithm to produce either an ASD positive, ASD negative, or indeterminate output. This study compared Device outputs to diagnostic agreement by two or more independent specialists in a cohort of 18–72-month-olds with developmental delay concerns (425 study completers, 36% female, 29% ASD prevalence). Device output PPV for all study completers was 80.8% (95% confidence intervals (CI), 70.3%–88.8%) and NPV was 98.3% (90.6%–100%). For the 31.8% of participants who received a determinate output (ASD positive or negative) Device sensitivity was 98.4% (91.6%–100%) and specificity was 78.9% (67.6%–87.7%). The Device’s indeterminate output acts as a risk control measure when inputs are insufficiently granular to make a determinate recommendation with confidence. If this risk control measure were removed, the sensitivity for all study completers would fall to 51.6% (63/122) (95% CI 42.4%, 60.8%), and specificity would fall to 18.5% (56/303) (95% CI 14.3%, 23.3%). Among participants for whom the Device abstained from providing a result, specialists identified that 91% had one or more complex neurodevelopmental disorders. No significant differences in Device performance were found across participants’ sex, race/ethnicity, income, or education level. For nearly a third of this primary care sample, the Device enabled timely diagnostic evaluation with a high degree of accuracy. The Device shows promise to significantly increase the number of children able to be diagnosed with ASD in a primary care setting, potentially facilitating earlier intervention and more efficient use of specialist resources.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Megerian","given":"Jonathan T."},{"family":"Dey","given":"Sangeeta"},{"family":"Melmed","given":"Raun D."},{"family":"Coury","given":"Daniel L."},{"family":"Lerner","given":"Marc"},{"family":"Nicholls","given":"Christopher J."},{"family":"Sohl","given":"Kristin"},{"family":"Rouhbakhsh","given":"Rambod"},{"family":"Narasimhan","given":"Anandhi"},{"family":"Romain","given":"Jonathan"},{"family":"Golla","given":"Sailaja"},{"family":"Shareef","given":"Safiullah"},{"family":"Ostrovsky","given":"Andrey"},{"family":"Shannon","given":"Jennifer"},{"family":"Kraft","given":"Colleen"},{"family":"Liu-Mayo","given":"Stuart"},{"family":"Abbas","given":"Halim"},{"family":"Gal-Szabo","given":"Diana E."},{"family":"Wall","given":"Dennis P."},{"family":"Taraman","given":"Sharief"}],"citation-key":"megerian2022b","container-title":"npj Digital Medicine","container-title-short":"npj Digit. Med.","DOI":"10.1038/s41746-022-00598-6","ISSN":"2398-6352","issue":"1","issued":{"date-parts":[["2022",5,5]]},"language":"en","license":"2022 The Author(s)","page":"1-11","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Evaluation of an artificial intelligence-based medical device for diagnosis of autism spectrum disorder","type":"article-journal","URL":"https://www.nature.com/articles/s41746-022-00598-6","volume":"5"},
  {"id":"meng2021","abstract":"With the development of global technology and teaching trends, digital technology teaching has become a common phenomenon today. This study uses the virtual reality social skills course to teach ten autistic students for Elementary and Junior High School, with the theme of “One Art Tour with Students” and four key points in the 12-year National Basic Education Curriculum. In virtual reality situational teaching, through t test analysis, it is found that inappropriate social behavior is obviously improved, and environmental adaptability is also greatly improved. Through interviews, parents and teachers believe that children’s social skills have improved. In addition, the research found that some problems must be noticed in the actual teaching process, including (1) black picture in virtual reality; (2) students control the handle controller in the virtual reality; and (3) definition of virtual space. The situations mentioned above should be handled with caution, they may affect the effectiveness of students' learning and involve the safety of the teaching process. These findings are suitable for virtual reality teaching and operation of students with autism, so opinions are provided to the field scholars as a reference.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Meng","given":"Ying-Ru"},{"family":"Yeh","given":"Chia-Chi"}],"citation-key":"meng2021","container-title":"SN Computer Science","container-title-short":"SN COMPUT. SCI.","DOI":"10.1007/s42979-021-00914-z","ISSN":"2661-8907","issue":"1","issued":{"date-parts":[["2021",11,10]]},"language":"en","page":"55","source":"Springer Link","title":"Exploring the Social Interaction of Autistic Students of Elementary and Junior High School Students Through the Teaching of Social Skills and Learning Process in Virtual Reality","type":"article-journal","URL":"https://doi.org/10.1007/s42979-021-00914-z","volume":"3"},
  {"id":"meng2023","abstract":"BACKGROUND: Studies on eye movements found that children with autism spectrum disorder (ASD) had abnormal gaze behavior to social stimuli. The current study aimed to investigate whether their eye movement patterns in relation to cartoon characters or real people could be useful in identifying ASD children.\nMETHODS: Eye-tracking tests based on videos of cartoon characters and real people were performed for ASD and typically developing (TD) children aged between 12 and 60 months. A three-level hierarchical structure including participants, events, and areas of interest was used to arrange the data obtained from eye-tracking tests. Random forest was adopted as the feature selection tool and classifier, and the flattened vectors and diagnostic information were used as features and labels. A logistic regression was used to evaluate the impact of the most important features.\nRESULTS: A total of 161 children (117 ASD and 44 TD) with a mean age of 39.70 ± 12.27 months were recruited. The overall accuracy, precision, and recall of the model were 0.73, 0.73, and 0.75, respectively. Attention to human-related elements was positively related to the diagnosis of ASD, while fixation time for cartoons was negatively related to the diagnosis.\nCONCLUSION: Using eye-tracking techniques with machine learning algorithms might be promising for identifying ASD. The value of artificial faces, such as cartoon characters, in the field of ASD diagnosis and intervention is worth further exploring.","author":[{"family":"Meng","given":"Fanchao"},{"family":"Li","given":"Fenghua"},{"family":"Wu","given":"Shuxian"},{"family":"Yang","given":"Tingyu"},{"family":"Xiao","given":"Zhou"},{"family":"Zhang","given":"Yujian"},{"family":"Liu","given":"Zhengkui"},{"family":"Lu","given":"Jianping"},{"family":"Luo","given":"Xuerong"}],"citation-key":"meng2023","container-title":"Frontiers in Neuroscience","container-title-short":"Front Neurosci","DOI":"10.3389/fnins.2023.1170951","ISSN":"1662-4548","issued":{"date-parts":[["2023"]]},"language":"eng","page":"1170951","PMCID":"PMC10545898","PMID":"37795184","source":"PubMed","title":"Machine learning-based early diagnosis of autism according to eye movements of real and artificial faces scanning","type":"article-journal","volume":"17"},
  {"id":"meridianmcdonald2023","abstract":"Autism may be a single diagnosis, but the characteristics of autistic people are highly heterogeneous. These heterogeneous characteristics include phenotypic traits, predictive factors, and biomarkers that contribute to the neurodiversity of autism. This neurodiversity transcends biological diversity to include a variety of medical, social, ecological, and Indigenous models (and their combinations) of disability and difference. However, a unifying theoretical model of autism, the Broader Autism Phenotype Constellations-Disability Matrix Paradigm, may resolve tensions between these models of disability and controversies of autism. These challenges could also be supported by biological studies of autism that include broader perspectives and topics, as well as enhanced communication and resources.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Meridian McDonald","given":"T. A."}],"citation-key":"meridianmcdonald2023","container-title":"Neurobiology of Autism Spectrum Disorders","DOI":"10.1007/978-3-031-42383-3_15","editor":[{"family":"El Idrissi","given":"Abdeslem"},{"family":"McCloskey","given":"Dan"}],"event-place":"Cham","ISBN":"978-3-031-42383-3","issued":{"date-parts":[["2023"]]},"language":"en","page":"313-332","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"Autism and Neurodiversity","type":"chapter","URL":"https://doi.org/10.1007/978-3-031-42383-3_15"},
  {"id":"mihailov2020","abstract":"Extensive heterogeneity in autism spectrum disorder (ASD) has hindered the characterization of consistent biomarkers, which has led to widespread negative results. Isolating homogenized subtypes could provide insight into underlying biological mechanisms and an overall better understanding of ASD. A total of 1093 participants from the population-based “Healthy Brain Network” cohort (Child Mind Institute in the New York City area, USA) were selected based on score availability in behaviors relevant to ASD, aged 6–18 and IQ >= 70. All participants underwent an unsupervised clustering analysis on behavioral dimensions to reveal subgroups with ASD traits, identified by the presence of social deficits. Analysis revealed three socially impaired ASD traits subgroups: (1) high in emotionally dysfunctional traits, (2) high in ADHD-like traits, and (3) high in anxiety and depressive symptoms. 527 subjects had good quality structural MRI T1 data. Site effects on cortical features were adjusted using the ComBat method. Neuroimaging analyses compared cortical thickness, gyrification, and surface area, and were controlled for age, gender, and IQ, and corrected for multiple comparisons. Structural neuroimaging analyses contrasting one combined heterogeneous ASD traits group against controls did not yield any significant differences. Unique cortical signatures, however, were observed within each of the three individual ASD traits subgroups versus controls. These observations provide evidence of ASD traits subtypes, and confirm the necessity of applying dimensional approaches to extract meaningful differences, thus reducing heterogeneity and paving the way to better understanding ASD traits.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Mihailov","given":"Angeline"},{"family":"Philippe","given":"Cathy"},{"family":"Gloaguen","given":"Arnaud"},{"family":"Grigis","given":"Antoine"},{"family":"Laidi","given":"Charles"},{"family":"Piguet","given":"Camille"},{"family":"Houenou","given":"Josselin"},{"family":"Frouin","given":"Vincent"}],"citation-key":"mihailov2020","container-title":"Translational Psychiatry","container-title-short":"Transl Psychiatry","DOI":"10.1038/s41398-020-00894-3","ISSN":"2158-3188","issued":{"date-parts":[["2020",6,27]]},"page":"207","PMCID":"PMC7320967","PMID":"32594096","source":"PubMed Central","title":"Cortical signatures in behaviorally clustered autistic traits subgroups: a population-based study","title-short":"Cortical signatures in behaviorally clustered autistic traits subgroups","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7320967/","volume":"10"},
  {"id":"miller2023","abstract":"Background\nAutistic children and adults have known differences in motor performance, including postural instability and atypical gross motor control. Few studies have specifically tested dynamic postural control. This is the first study to quantify movement smoothness and its relationship to task performance during lateral dynamic postural control tasks in autism.\nResearch question\nWe sought to test the hypothesis that autistic children would have less smooth movements to lateral static targets compared to neurotypical children, and that this difference would relate to specific movement strategies.\nMethods\nWe used camera-based motion-capture to measure spatiotemporal characteristics of lateral movement of a marker placed on the C7 vertebrae, and of markers comprising trunk and pelvis segments during a dynamic postural movements to near and far targets administered in an immersive virtual environment. We tested a sample of 15 autistic children and 11 age-matched neurotypical children. We quantified movement smoothness using log dimensionless jerk.\nResults\nAutistic children exhibited more medial-lateral pelvic position range of motion compared to neurotypical children, and used a stepping strategy more often compared to neurotypical children. Autistic children also had higher log dimensionless jerk than neurotypical children for motion of the C7 marker. All participants had higher log dimensionless jerk for far targets than for near targets. Autistic children had longer trial durations than neurotypical children, and younger children had longer trial durations than older children across diagnostic groups.\nSignificance\nThe stepping strategy observed more often in the autistic group likely contributed to log dimensionless jerk and reduced movement smoothness. This strategy is indicative of either an attempt to prevent an impending loss of balance, or an attempt to compensate for and recover from a loss of balance once it is detected.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Miller","given":"Haylie L."},{"family":"Templin","given":"Tylan N."},{"family":"Fears","given":"Nicholas E."},{"family":"Sherrod","given":"Gabriela M."},{"family":"Patterson","given":"Rita M."},{"family":"Bugnariu","given":"Nicoleta L."}],"citation-key":"miller2023","container-title":"Gait & Posture","container-title-short":"Gait & Posture","DOI":"10.1016/j.gaitpost.2022.10.015","ISSN":"0966-6362","issued":{"date-parts":[["2023",1,1]]},"page":"76-82","source":"ScienceDirect","title":"Movement smoothness during dynamic postural control to a static target differs between autistic and neurotypical children","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S096663622200618X","volume":"99"},
  {"id":"milton2014","abstract":"The field of autism studies is a highly disputed territory within which competing contradictory discourses abound. In this field, it is the voices and claims of autistic people regarding their own expertise in knowledge production concerning autism that is most recent in the debate, and traditionally the least attended to. In this article, I utilise the theories of Harry Collins and colleagues in order to reflect upon and conceptualise the various claims to knowledge production and expertise within the field of autism studies, from the perspective of an author who has been diagnosed as being on the autism spectrum. The notion that autistic people lack sociality is problematised, with the suggestion that autistic people are not well described by notions such as the ‘social brain’, or as possessing ‘zero degrees of cognitive empathy’. I then argue, however, that there is a qualitative difference in autistic sociality, and question to what extent such differences are of a biological or cultural nature, and to what extent interactional expertise can be gained by both parties in interactions between autistic and non-autistic people. In conclusion, I argue that autistic people have often become distrustful of researchers and their aims, and are frequently frozen out of the processes of knowledge production. Such a context results in a negative feedback spiral with further damage to the growth of interactional expertise between researchers and autistic people, and a breakdown in trust and communication leading to an increase in tension between stakeholder groups. The involvement of autistic scholars in research and improvements in participatory methods can thus be seen as a requirement, if social research in the field of autism is to claim ethical and epistemological integrity.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Milton","given":"Damian EM"}],"citation-key":"milton2014","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/1362361314525281","ISSN":"1362-3613","issue":"7","issued":{"date-parts":[["2014",10,1]]},"language":"en","page":"794-802","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Autistic expertise: A critical reflection on the production of knowledge in autism studies","title-short":"Autistic expertise","type":"article-journal","URL":"https://doi.org/10.1177/1362361314525281","volume":"18"},
  {"id":"minissi2024","abstract":"Clinical assessment procedures encounter challenges in terms of objectivity because they rely on subjective data. Computational psychiatry proposes overcoming this limitation by introducing biosignal-based assessments able to detect clinical biomarkers, while virtual reality (VR) can offer ecological settings for measurement. Autism spectrum disorder (ASD) is a neurodevelopmental disorder where many biosignals have been tested to improve assessment procedures. However, in ASD research there is a lack of studies systematically comparing biosignals for the automatic classification of ASD when recorded simultaneously in ecological settings, and comparisons among previous studies are challenging due to methodological inconsistencies. In this study, we examined a VR screening tool consisting of four virtual scenes, and we compared machine learning models based on implicit (motor skills and eye movements) and explicit (behavioral responses) biosignals. Machine learning models were developed for each biosignal within the virtual scenes and then combined into a final model per biosignal. A linear support vector classifier with recursive feature elimination was used and tested using nested cross-validation. The final model based on motor skills exhibited the highest robustness in identifying ASD, achieving an AUC of 0.89 (SD = 0.08). The best behavioral model showed an AUC of 0.80, while further research is needed for the eye-movement models due to limitations with the eye-tracking glasses. These findings highlight the potential of motor skills in enhancing objectivity and reliability in the early assessment of ASD compared to other biosignals.","accessed":{"date-parts":[["2025",2,17]]},"author":[{"family":"Minissi","given":"Maria Eleonora"},{"family":"Altozano","given":"Alberto"},{"family":"Marín-Morales","given":"Javier"},{"family":"Chicchi Giglioli","given":"Irene Alice"},{"family":"Mantovani","given":"Fabrizia"},{"family":"Alcañiz","given":"Mariano"}],"citation-key":"minissi2024","container-title":"Computers in Biology and Medicine","container-title-short":"Computers in Biology and Medicine","DOI":"10.1016/j.compbiomed.2024.108194","ISSN":"0010-4825","issued":{"date-parts":[["2024",3,1]]},"page":"108194","source":"ScienceDirect","title":"Biosignal comparison for autism assessment using machine learning models and virtual reality","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0010482524002786","volume":"171"},
  {"id":"moldoveanu2024","abstract":"Although communicative and relational skills are currently in the greatest demand in organizations large and small, we are as educators, executives, and talent developers very far away from the kind of precision in identifying, measuring, selecting and developing these skills that we have achieved with cognitive and technical skills. At the same time, the relentless automation of swaths of human tasks has placed a sharp light on the ‘quintessentially human skills’ – those that cannot and in some cases should not be subject to algorithmic automation. This book aims to ‘change the soft skills game’ by introducing language for identifying and describing them, ways of measuring the degree to which a person possesses them and selecting those who possess them in the utmost from those less skilled, and ways of helping students and executives alike develop them, through a methodology that has been designed and practiced for the past ten years.     We need a ‘re-set’ in the way we think about human skill and in particular the ways we think about those human skills which cannot be sub-contracted to an algorithm running on silicon. This book aims to provide that re-set.","author":[{"family":"Moldoveanu","given":"Mihnea"}],"citation-key":"moldoveanu2024","ISBN":"978-3-11-105552-7","issued":{"date-parts":[["2024",4,22]]},"language":"en","number-of-pages":"236","publisher":"Walter de Gruyter GmbH & Co KG","source":"Google Books","title":"Soft Skills: How to See, Measure and Build the Skills that Make Us Uniquely Human","title-short":"Soft Skills","type":"book"},
  {"id":"moleda2023","abstract":"Appropriate maintenance of industrial equipment keeps production systems in good health and ensures the stability of production processes. In specific production sectors, such as the electrical power industry, equipment failures are rare but may lead to high costs and substantial economic losses not only for the power plant but for consumers and the larger society. Therefore, the power production industry relies on a variety of approaches to maintenance tasks, ranging from traditional solutions and engineering know-how to smart, AI-based analytics to avoid potential downtimes. This review shows the evolution of maintenance approaches to support maintenance planning, equipment monitoring and supervision. We present older techniques traditionally used in maintenance tasks and those that rely on IT analytics to automate tasks and perform the inference process for failure detection. We analyze prognostics and health-management techniques in detail, including their requirements, advantages and limitations. The review focuses on the power-generation sector. However, some of the issues addressed are common to other industries. The article also presents concepts and solutions that utilize emerging technologies related to Industry 4.0, touching on prescriptive analysis, Big Data and the Internet of Things. The primary motivation and purpose of the article are to present the existing practices and classic methods used by engineers, as well as modern approaches drawing from Artificial Intelligence and the concept of Industry 4.0. The summary of existing practices and the state of the art in the area of predictive maintenance provides two benefits. On the one hand, it leads to improving processes by matching existing tools and methods. On the other hand, it shows researchers potential directions for further analysis and new developments.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Molęda","given":"Marek"},{"family":"Małysiak-Mrozek","given":"Bożena"},{"family":"Ding","given":"Weiping"},{"family":"Sunderam","given":"Vaidy"},{"family":"Mrozek","given":"Dariusz"}],"citation-key":"moleda2023","container-title":"Sensors","DOI":"10.3390/s23135970","ISSN":"1424-8220","issue":"13","issued":{"date-parts":[["2023",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"13","page":"5970","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"From Corrective to Predictive Maintenance—A Review of Maintenance Approaches for the Power Industry","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/23/13/5970","volume":"23"},
  {"id":"molloy2022","abstract":"The search for biomarkers for autism spectrum disorder (henceforth autism) has received a lot of attention due to their potential clinical relevance. The clinical and aetiological heterogeneity of autism suggests the presence of subgroups. The lack of identification of a valid diagnostic biomarker for autism, and the inconsistencies seen in studies assessing differences between autism and typically developing control groups, may be partially explained by the vast heterogeneity observed in autism. The focus now is to better understand the clinical and biological heterogeneity and identify stratification biomarkers, which are measures that describe subgroups of individuals with shared biology. Using stratification approaches to assess treatment within pre-defined subgroups could clarify who may benefit from different treatments and therapies, and ultimately lead to more effective individualised treatment plans.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Molloy","given":"C. J."},{"family":"Gallagher","given":"L."}],"citation-key":"molloy2022","container-title":"Irish Journal of Psychological Medicine","DOI":"10.1017/ipm.2021.73","ISSN":"0790-9667, 2051-6967","issue":"3","issued":{"date-parts":[["2022",9]]},"language":"en","page":"305-311","source":"Cambridge University Press","title":"Can stratification biomarkers address the heterogeneity of autism spectrum disorder?","type":"article-journal","URL":"https://www.cambridge.org/core/journals/irish-journal-of-psychological-medicine/article/can-stratification-biomarkers-address-the-heterogeneity-of-autism-spectrum-disorder/673518A0ACC4FB64B8B5248E2051673A","volume":"39"},
  {"id":"moon2024","abstract":"Caseworkers in the child welfare (CW) sector use predictive decision-making algorithms built on risk assessment (RA) data to guide and support CW decisions. Researchers have highlighted that RAs can contain biased signals which flatten CW case complexities and that the algorithms may benefit from incorporating contextually rich case narratives, i.e. - the casenotes written by caseworkers. To investigate this hypothesized improvement, we quantitatively deconstructed two commonly used RAs from a United States CW agency. We trained classifier models to compare the predictive validity of RAs with and without casenote narratives and applied computational text analysis on casenotes to highlight topics uncovered in the casenotes. Our study finds that common risk metrics used to assess families and build CWS predictive risk models (PRMs) are unable to predict discharge outcomes for children who are not reunified with their birth parent(s). We also find that although casenotes cannot predict discharge outcomes, they contain contextual case signals. Given the lack of predictive validity of RA scores and casenotes, we propose moving beyond quantitative risk assessments for public sector algorithms and towards using contextual sources of information such as narratives to study public sociotechnical systems.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Moon","given":"Erina Seh-Young"},{"family":"Saxena","given":"Devansh"},{"family":"Maharaj","given":"Tegan"},{"family":"Guha","given":"Shion"}],"citation-key":"moon2024","collection-title":"GI '24","container-title":"Proceedings of the 50th Graphics Interface Conference","DOI":"10.1145/3670947.3670976","event-place":"New York, NY, USA","ISBN":"979-8-4007-1828-1","issued":{"date-parts":[["2024",9,21]]},"page":"1–13","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Beyond Predictive Algorithms in Child Welfare","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3670947.3670976"},
  {"id":"moon2024a","abstract":"This study aimed to explore the design and development of verbal prompts in virtual reality (VR)-based social skills training for autistic children. Autism indicates a category with neurodiversity that influences individuals’ capability to engage in social and cognitive tasks. This complex neurodevelopmental condition manifests in a wide array of patterns, featuring unique experiences of each individual. This study explored both advantages and challenges encountered when autistic children interact with verbal prompts in multi-user, desktop VR-based social skills training. Our explanatory case study involved VR-based learning experiences of four autistic children. We used a qualitative thematic analysis to analyse the study participants’ interaction patterns with verbal prompts in the VR-based training. Our research can contribute to both theoretical knowledge and practical design guidelines for the creation of verbal prompts in desktop VR-based training programmes tailored for autistic children.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Moon","given":"Jewoong"}],"citation-key":"moon2024a","container-title":"Research in Learning Technology","DOI":"10.25304/rlt.v32.3129","ISSN":"2156-7077","issued":{"date-parts":[["2024",3,7]]},"language":"en","license":"Copyright (c) 2024 Jewoong Moon","source":"journal.alt.ac.uk","title":"Learning experience design of verbal prompts in virtual reality-based training for autistic children","type":"article-journal","URL":"https://journal.alt.ac.uk/index.php/rlt/article/view/3129","volume":"32"},
  {"id":"moon2024b","abstract":"The purpose of this single-case experimental design (SCED) study is to investigate how adaptive prompts in virtual reality (VR)-based social skills training affect the social skills performance of autistic children. Adaptive prompts are driven by autistic children’s emotional states. To integrate adaptive prompts in VR-based training, we conducted speech data mining and endorsed micro-adaptivity design. We recruited four autistic children (12–13 years) for the SCED study. We carried out alternating treatments design to evaluate the impacts of adaptive and non-adaptive prompting conditions throughout a series of VR-based social skills training sessions. Using mixed-method data collection and analyses, we found that adaptive prompts can foster autistic children’s desirable social skills performance in VR-based training. Based on the study findings, we also describe design implications and limitations for future research.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Moon","given":"Jewoong"},{"family":"Ke","given":"Fengfeng"}],"citation-key":"moon2024b","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-06021-7","ISSN":"1573-3432","issue":"8","issued":{"date-parts":[["2024",8,1]]},"language":"en","page":"2826-2846","source":"Springer Link","title":"Effects of Adaptive Prompts in Virtual Reality-Based Social Skills Training for Children with Autism","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-06021-7","volume":"54"},
  {"id":"moore2018","abstract":"The wide range of ability and disability in ASD creates a need for tools that parse the phenotypic heterogeneity into meaningful subtypes. Using eye tracking, our past studies revealed that when presented with social and geometric images, a subset of ASD toddlers preferred viewing geometric images, and these toddlers also had greater symptom severity than ASD toddlers with greater social attention. This study tests whether this “GeoPref test” effect would generalize across different social stimuli.","accessed":{"date-parts":[["2025",2,23]]},"author":[{"family":"Moore","given":"Adrienne"},{"family":"Wozniak","given":"Madeline"},{"family":"Yousef","given":"Andrew"},{"family":"Barnes","given":"Cindy Carter"},{"family":"Cha","given":"Debra"},{"family":"Courchesne","given":"Eric"},{"family":"Pierce","given":"Karen"}],"citation-key":"moore2018","container-title":"Molecular Autism","container-title-short":"Molecular Autism","DOI":"10.1186/s13229-018-0202-z","ISSN":"2040-2392","issue":"1","issued":{"date-parts":[["2018",3,21]]},"page":"19","source":"BioMed Central","title":"The geometric preference subtype in ASD: identifying a consistent, early-emerging phenomenon through eye tracking","title-short":"The geometric preference subtype in ASD","type":"article-journal","URL":"https://doi.org/10.1186/s13229-018-0202-z","volume":"9"},
  {"id":"moreno-arjonilla2024","abstract":"Virtual reality (VR) has evolved substantially beyond its initial remit of gaming and entertainment, catalyzed by advancements such as improved screen resolutions and more accessible devices. Among various interaction techniques introduced to VR, eye-tracking stands out as a pivotal development. It not only augments immersion but offers a nuanced insight into user behavior and attention. This precision in capturing gaze direction has made eye-tracking instrumental for applications far beyond mere interaction, influencing areas like medical diagnostics, neuroscientific research, educational interventions, and architectural design, to name a few. Though eye-tracking’s integration into VR has been acknowledged in prior reviews, its true depth, spanning the intricacies of its deployment to its broader ramifications across diverse sectors, has been sparsely explored. This survey undertakes that endeavor, offering a comprehensive overview of eye-tracking’s state of the art within the VR landscape. We delve into its technological nuances, its pivotal role in modern VR applications, and its transformative impact on domains ranging from medicine and neuroscience to marketing and education. Through this exploration, we aim to present a cohesive understanding of the current capabilities, challenges, and future potential of eye-tracking in VR, underscoring its significance and the novelty of our contribution.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Moreno-Arjonilla","given":"Jesús"},{"family":"López-Ruiz","given":"Alfonso"},{"family":"Jiménez-Pérez","given":"J. Roberto"},{"family":"Callejas-Aguilera","given":"José E."},{"family":"Jurado","given":"Juan M."}],"citation-key":"moreno-arjonilla2024","container-title":"Virtual Reality","container-title-short":"Virtual Reality","DOI":"10.1007/s10055-023-00903-y","ISSN":"1434-9957","issue":"1","issued":{"date-parts":[["2024",2,5]]},"language":"en","page":"38","source":"Springer Link","title":"Eye-tracking on virtual reality: a survey","title-short":"Eye-tracking on virtual reality","type":"article-journal","URL":"https://doi.org/10.1007/s10055-023-00903-y","volume":"28"},
  {"id":"mukherjee2024","abstract":"Current challenges in early identification of autism spectrum disorder lead to significant delays in starting interventions, thereby compromising outcomes. Digital tools can potentially address this barrier as they are accessible, can measure autism-relevant phenotypes and can be administered in children’s natural environments by non-specialists. The purpose of this systematic review is to identify and characterise potentially scalable digital tools for direct assessment of autism spectrum disorder risk in early childhood. In total, 51,953 titles, 6884 abstracts and 567 full-text articles from four databases were screened using predefined criteria. Of these, 38 met inclusion criteria. Tasks are presented on both portable and non-portable technologies, typically by researchers in laboratory or clinic settings. Gamified tasks, virtual-reality platforms and automated analysis of video or audio recordings of children’s behaviours and speech are used to assess autism spectrum disorder risk. Tasks tapping social communication/interaction and motor domains most reliably discriminate between autism spectrum disorder and typically developing groups. Digital tools employing objective data collection and analysis methods hold immense potential for early identification of autism spectrum disorder risk. Next steps should be to further validate these tools, evaluate their generalisability outside laboratory or clinic settings, and standardise derived measures across tasks. Furthermore, stakeholders from underserved communities should be involved in the research and development process.\nLay abstract\nThe challenge of finding autistic children, and finding them early enough to make a difference for them and their families, becomes all the greater in parts of the world where human and material resources are in short supply. Poverty of resources delays interventions, translating into a poverty of outcomes. Digital tools carry potential to lessen this delay because they can be administered by non-specialists in children’s homes, schools or other everyday environments, they can measure a wide range of autistic behaviours objectively and they can automate analysis without requiring an expert in computers or statistics. This literature review aimed to identify and describe digital tools for screening children who may be at risk for autism. These tools are predominantly at the ‘proof-of-concept’ stage. Both portable (laptops, mobile phones, smart toys) and fixed (desktop computers, virtual-reality platforms) technologies are used to present computerised games, or to record children’s behaviours or speech. Computerised analysis of children’s interactions with these technologies differentiates children with and without autism, with promising results. Tasks assessing social responses and hand and body movements are the most reliable in distinguishing autistic from typically developing children. Such digital tools hold immense potential for early identification of autism spectrum disorder risk at a large scale. Next steps should be to further validate these tools and to evaluate their applicability in a variety of settings. Crucially, stakeholders from underserved communities globally must be involved in this research, lest it fail to capture the issues that these stakeholders are facing.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Mukherjee","given":"Debarati"},{"family":"Bhavnani","given":"Supriya"},{"family":"Lockwood Estrin","given":"Georgia"},{"family":"Rao","given":"Vaisnavi"},{"family":"Dasgupta","given":"Jayashree"},{"family":"Irfan","given":"Hiba"},{"family":"Chakrabarti","given":"Bhismadev"},{"family":"Patel","given":"Vikram"},{"family":"Belmonte","given":"Matthew K"}],"citation-key":"mukherjee2024","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/13623613221133176","ISSN":"1362-3613","issue":"1","issued":{"date-parts":[["2024",1,1]]},"language":"en","page":"6-31","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Digital tools for direct assessment of autism risk during early childhood: A systematic review","title-short":"Digital tools for direct assessment of autism risk during early childhood","type":"article-journal","URL":"https://doi.org/10.1177/13623613221133176","volume":"28"},
  {"id":"murias2018","abstract":"Social communication impairments are a core feature of autism spectrum disorder (ASD), and this class of symptoms is a target for treatments for the disorder. Measures of social attention, assessed via eye-gaze tracking (EGT), have been proposed as an early efficacy biomarker for clinical trials targeting social communication skills. EGT measures have been shown to differentiate children with ASD from typical children; however, there is less known about their relationships with social communication outcome measures that are typically used in ASD clinical trials. In the present study, an EGT task involving viewing a videotape of an actor making bids for a child's attention was evaluated in 25 children with ASD aged 24-72 months. Children's attention to the actor during the dyadic bid condition measured via EGT was found to be strongly associated with five well-validated caregiver-reported outcome measures that are commonly used to assess social communication in clinical trials. These results highlight the convergent validity of EGT measures of social attention in relation to caregiver-reported clinical measures. EGT holds promise as a non-invasive, quantitative, and objective biomarker that is associated with social communication abilities in children with ASD. Autism Res 2018, 11: 166-174. © 2017 International Society for Autism Research, Wiley Periodicals, Inc.\nLAY SUMMARY: Eye-gaze tracking (EGT), an automated tool that tracks eye-gaze patterns, might help measure outcomes in clinical trials investigating interventions to treat autism spectrum disorders. In this study, an EGT task was evaluated in children with ASD, who watched a video with an actor talking directly to them. Patterns of eye-gaze were associated with caregiver-reported measures of social communication that are used in clinical trials. We show EGT may be a promising objective tool measuring outcomes.","author":[{"family":"Murias","given":"Michael"},{"family":"Major","given":"Samantha"},{"family":"Davlantis","given":"Katherine"},{"family":"Franz","given":"Lauren"},{"family":"Harris","given":"Adrianne"},{"family":"Rardin","given":"Benjamin"},{"family":"Sabatos-DeVito","given":"Maura"},{"family":"Dawson","given":"Geraldine"}],"citation-key":"murias2018","container-title":"Autism Research: Official Journal of the International Society for Autism Research","container-title-short":"Autism Res","DOI":"10.1002/aur.1894","ISSN":"1939-3806","issue":"1","issued":{"date-parts":[["2018",1]]},"language":"eng","page":"166-174","PMID":"29193826","source":"PubMed","title":"Validation of eye-tracking measures of social attention as a potential biomarker for autism clinical trials","type":"article-journal","volume":"11"},
  {"id":"nabil2021","abstract":"Autism Spectrum Disorder (Autism) is a developmental disorder that impedes the social and communication capabilities of a person through out his life. Early detection of autism is critical in contributing to better prognosis. In this study, the use of home videos to provide accessible diagnosis is investigated. A machine learning approach is adopted to detect autism from home videos. Feature selection and state-of-the-art classification methods are applied to provide a sound diagnosis based on home video ratings obtained from non-clinicians feedback. Our models results indicate that home videos can effectively detect autistic group with True Positive Rate reaching 94.05% using Support Vector Machines and backwards feature selection. In this study, human-interpretable models are presented to elucidate the reasoning behind the classification process and its subsequent decision. In addition, the prime features that need to be monitored for early autism detection are revealed.","author":[{"family":"Nabil","given":"Mohamed A."},{"family":"Akram","given":"Ansam"},{"family":"Fathalla","given":"Karma M."}],"citation-key":"nabil2021","container-title":"Health Informatics Journal","container-title-short":"Health Informatics J","DOI":"10.1177/1460458221991882","ISSN":"1741-2811","issue":"1","issued":{"date-parts":[["2021"]]},"language":"eng","page":"1460458221991882","PMID":"33583277","source":"PubMed","title":"Applying machine learning on home videos for remote autism diagnosis: Further study and analysis","title-short":"Applying machine learning on home videos for remote autism diagnosis","type":"article-journal","volume":"27"},
  {"id":"napolitano2022","abstract":"<p>Autism Spectrum Disorder (ASD) is a complex neurodevelopmental disorder with a worldwide prevalence of about 1%, characterized by impairments in social interaction, communication, repetitive patterns of behaviors, and can be associated with hyper- or hypo-reactivity of sensory stimulation and cognitive disability. ASD comorbid features include internalizing and externalizing symptoms such as anxiety, depression, hyperactivity, and attention problems. The precise etiology of ASD is still unknown and it is undoubted that the disorder is linked to some extent to both genetic and environmental factors. It is also well-documented and known that one of the most striking and consistent finding in ASD is the higher prevalence in males compared to females, with around 70% of ASD cases described being males. The present review looked into the most significant studies that attempted to investigate differences in ASD males and females thus trying to shade some light on the peculiar characteristics of this prevalence in terms of diagnosis, imaging, major autistic-like behavior and sex-dependent uniqueness. The study also discussed sex differences found in animal models of ASD, to provide a possible explanation of the neurological mechanisms underpinning the different presentation of autistic symptoms in males and females.</p>","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Napolitano","given":"Antonio"},{"family":"Schiavi","given":"Sara"},{"family":"La Rosa","given":"Piergiorgio"},{"family":"Rossi-Espagnet","given":"Maria Camilla"},{"family":"Petrillo","given":"Sara"},{"family":"Bottino","given":"Francesca"},{"family":"Tagliente","given":"Emanuela"},{"family":"Longo","given":"Daniela"},{"family":"Lupi","given":"Elisabetta"},{"family":"Casula","given":"Laura"},{"family":"Valeri","given":"Giovanni"},{"family":"Piemonte","given":"Fiorella"},{"family":"Trezza","given":"Viviana"},{"family":"Vicari","given":"Stefano"}],"citation-key":"napolitano2022","container-title":"Frontiers in Psychiatry","container-title-short":"Front. Psychiatry","DOI":"10.3389/fpsyt.2022.889636","ISSN":"1664-0640","issued":{"date-parts":[["2022",5,13]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Sex Differences in Autism Spectrum Disorder: Diagnostic, Neurobiological, and Behavioral Features","title-short":"Sex Differences in Autism Spectrum Disorder","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2022.889636/full","volume":"13"},
  {"id":"naqvi2022","abstract":"Across various industries, maintenance entries recorded over time contain decades of experience and health records of different assets. Maintenance logs are usually free-form text entries recorded by maintenance operators. These records are also highly unstructured and imbalanced. Because of these reasons, this huge source of knowledge is usually underutilized and does not contribute to the development of tools to help improve maintenance processes. In the last few years, due to recent advancements in the field of Natural Language Processing (NLP) and increased focus on industry 4.0, there is a need to revisit this problem. This study explores the use of state-of-the-art NLP methods on free-form maintenance text to leverage this data. More specifically, the purpose of the study is to estimate the problem category of maintenance log to see how well recent NLP models adapt to free-form maintenance text. Findings of this study indicate that CamemBERT with the fine-tuning approach outperforms the classical NLP approaches. Class imbalance problem is also addressed through data augmentation using deep contextualized embedding showing further performance improvement. Model accuracy and Matthews correlation coefficient (MCC) are used as performance metrics to give a better understanding of results with imbalanced classes.","author":[{"family":"Naqvi","given":"Syed Meesam Raza"},{"family":"Varnier","given":"Christophe"},{"family":"Nicod","given":"Jean-Marc"},{"family":"Zerhouni","given":"Noureddine"},{"family":"Ghufran","given":"Mohammad"}],"citation-key":"naqvi2022","container-title":"Progresses in Artificial Intelligence & Robotics: Algorithms & Applications","DOI":"10.1007/978-3-030-98531-8_7","editor":[{"family":"Troiano","given":"Luigi"},{"family":"Vaccaro","given":"Alfredo"},{"family":"Kesswani","given":"Nishtha"},{"family":"Díaz Rodriguez","given":"Irene"},{"family":"Brigui","given":"Imene"}],"event-place":"Cham","ISBN":"978-3-030-98531-8","issued":{"date-parts":[["2022"]]},"language":"en","page":"63-75","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"Leveraging Free-Form Text in Maintenance Logs Through BERT Transfer Learning","type":"paper-conference"},
  {"id":"naqvi2024","abstract":"Maintenance records in Computerized Maintenance Management Systems (CMMS) contain valuable human knowledge on maintenance activities. These records primarily consist of noisy and unstructured texts written by maintenance experts. The technical nature of the text, combined with a concise writing style and frequent use of abbreviations, makes it difficult to be processed through classical Natural Language Processing (NLP) pipelines. Due to these complexities, this text must be normalized before feeding to classical machine learning models. Developing these custom normalization pipelines requires manual labor and domain expertise and is a time-consuming process that demands constant updates. This leads to the under-utilization of this valuable source of information to generate insights to help with maintenance decision support. This study proposes a Technical Language Processing (TLP) pipeline for semantic search in industrial text using BERT (Bidirectional Encoder Representations), a transformer-based Large Language Model (LLM). The proposed pipeline can automatically process complex unstructured industrial text and does not require custom preprocessing. To adapt the BERT model for the target domain, three unsupervised domain fine-tuning techniques are compared to identify the best strategy for leveraging available tacit knowledge in industrial text. The proposed approach is validated on two industrial maintenance records from the mining and aviation domains. Semantic search results are analyzed from a quantitative and qualitative perspective. Analysis shows that TSDAE, a state-of-the-art unsupervised domain fine-tuning technique, can efficiently identify intricate patterns in the industrial text regardless of associated complexities. BERT model fine-tuned with TSDAE on industrial text achieved a precision of 0.94 and 0.97 for mining excavators and aviation maintenance records, respectively.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Naqvi","given":"Syed Meesam Raza"},{"family":"Ghufran","given":"Mohammad"},{"family":"Varnier","given":"Christophe"},{"family":"Nicod","given":"Jean-Marc"},{"family":"Javed","given":"Kamran"},{"family":"Zerhouni","given":"Noureddine"}],"citation-key":"naqvi2024","container-title":"Computers in Industry","container-title-short":"Computers in Industry","DOI":"10.1016/j.compind.2024.104083","ISSN":"0166-3615","issued":{"date-parts":[["2024",5,1]]},"page":"104083","source":"ScienceDirect","title":"Unlocking maintenance insights in industrial text through semantic search","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0166361524000113","volume":"157-158"},
  {"id":"nardelli2015","abstract":"This paper reports on how emotional states elicited by affective sounds can be effectively recognized by means of estimates of Autonomic Nervous System (ANS) dynamics. Specifically, emotional states are modeled as a combination of arousal and valence dimensions according to the well-known circumplex model of affect, whereas the ANS dynamics is estimated through standard and nonlinear analysis of Heart rate variability (HRV) exclusively, which is derived from the electrocardiogram (ECG). In addition, Lagged Poincaré Plots of the HRV series were also taken into account. The affective sounds were gathered from the International Affective Digitized Sound System and grouped into four different levels of arousal (intensity) and two levels of valence (unpleasant and pleasant). A group of 27 healthy volunteers were administered with these standardized stimuli while ECG signals were continuously recorded. Then, those HRV features showing significant changes (p <; 0.05 from statistical tests) between the arousal and valence dimensions were used as input of an automatic classification system for the recognition of the four classes of arousal and two classes of valence. Experimental results demonstrated that a quadratic discriminant classifier, tested through Leave-One-Subject-Out procedure, was able to achieve a recognition accuracy of 84.72 percent on the valence dimension, and 84.26 percent on the arousal dimension.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Nardelli","given":"Mimma"},{"family":"Valenza","given":"Gaetano"},{"family":"Greco","given":"Alberto"},{"family":"Lanata","given":"Antonio"},{"family":"Scilingo","given":"Enzo Pasquale"}],"citation-key":"nardelli2015","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/TAFFC.2015.2432810","ISSN":"1949-3045","issue":"4","issued":{"date-parts":[["2015",10]]},"page":"385-394","source":"IEEE Xplore","title":"Recognizing Emotions Induced by Affective Sounds through Heart Rate Variability","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/7106477","volume":"6"},
  {"id":"natoli2023","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental condition with more males than females diagnosed, and researchers have considered whether the existence of a female-specific ASD phenotype may contribute to differences in rates of diagnosis. We sought to inform this issue through a systematic review and meta-analysis of potential sex differences specifically in young autistic children across a range of domains including core ASD features, social functioning, cognition, and co-occurring internalising and/or externalising conditions. The systematic review identified 35 studies examining sex differences in young autistic children. Conflicting results were evident across studies, with some reporting small sex differences and others reporting no sex differences. Meta-analysis revealed no overarching significant sex differences in the domains investigated. However, the meta-analytic effect for the RRB domain approached significance, with females demonstrating fewer RRBs than males. Many of the primary studies included here utilised data from standardised diagnostic instruments to measure autism features, so while this study suggests non-significant sex differences in early childhood ASD, it remains possible that current tools are insufficiently sensitive to detect differences in ASD presentation by sex at this age. It is also possible that the diagnostic criteria may reflect a predominately ‘male phenotype’ and this may obscure the detection of genuine sex differences in young autistic children.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Natoli","given":"Katherine"},{"family":"Brown","given":"Amy"},{"family":"Bent","given":"Catherine A."},{"family":"Luu","given":"Jenny"},{"family":"Hudry","given":"Kristelle"}],"citation-key":"natoli2023","container-title":"Research in Autism Spectrum Disorders","container-title-short":"Research in Autism Spectrum Disorders","DOI":"10.1016/j.rasd.2023.102207","ISSN":"1750-9467","issued":{"date-parts":[["2023",9,1]]},"page":"102207","source":"ScienceDirect","title":"No sex differences in core autism features, social functioning, cognition or co-occurring conditions in young autistic children: A systematic review and meta-analysis","title-short":"No sex differences in core autism features, social functioning, cognition or co-occurring conditions in young autistic children","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1750946723001071","volume":"107"},
  {"id":"newbutt2020","abstract":"This article seeks to place children on the autism spectrum at the center of a study examining the potential of virtual reality (VR) head-mounted displays (HMDs) used in classrooms. In doing so, we provide data that address 3 important and often overlooked research questions in the field of autism and technology, working in school-based settings with 31 autistic children from 6 to 16 years of age. First, what type of VR HMD device (and experiences therein) are preferred by children on the autism spectrum using HMDs (given possible sensory concerns). Second, how do children on the autism spectrum report the physical experience, enjoyment, and potential of VR HMDs in their classrooms? Finally, we were interested in exploring what children on the autism spectrum would like to use VR in schools for? Through a mixed methods approach, we found that costly and technologically advanced HMDs were preferred (namely: HTC Vive). In addition, HMDs were reported as being enjoyable, physically and visually comfortable, easy to use, and exciting, and children wanted to use them again. They identified several potential usages for HMDs, including relaxing/feeling calm, being able to explore somewhere virtually before visiting in the real world, and to develop learning opportunities in school. We discuss these findings in the context of VR in classrooms, in addition to considering limitations and implication of our findings.","author":[{"family":"Newbutt","given":"Nigel"},{"family":"Bradley","given":"Ryan"},{"family":"Conley","given":"Iian"}],"citation-key":"newbutt2020","container-title":"Cyberpsychology, Behavior and Social Networking","container-title-short":"Cyberpsychol Behav Soc Netw","DOI":"10.1089/cyber.2019.0206","ISSN":"2152-2723","issue":"1","issued":{"date-parts":[["2020",1]]},"language":"eng","page":"23-33","PMID":"31502866","source":"PubMed","title":"Using Virtual Reality Head-Mounted Displays in Schools with Autistic Children: Views, Experiences, and Future Directions","title-short":"Using Virtual Reality Head-Mounted Displays in Schools with Autistic Children","type":"article-journal","volume":"23"},
  {"id":"nguyenngoc2022","abstract":"The transition to industry 4.0 has impacted factories, but it also affects the entire value chain. In this sense, human-centred factors play a core role in transitioning to sustainable manufacturing processes and consumption. The awareness of human roles in Industry 4.0 is increasing, as evidenced by active work in developing methods, exploring influencing factors, and proving the effectiveness of design oriented to humans. However, numerous studies have been brought into existence but then disconnected from other studies. As a consequence, these studies in industry and research alike are not regularly adopted, and the network of studies is seemingly broad and expands without forming a coherent structure. This study is a unique attempt to bridge the gap through the literature characteristics and lessons learnt derived from a collection of case studies regarding human-centred design (HCD) in the context of Industry 4.0. This objective is achieved by a well-rounded systematic literature review whose special unit of analysis is given to the case studies, delivering contributions in three ways: (1) providing an insight into how the literature has evolved through the cross-disciplinary lens; (2) identifying what research themes associated with design methods are emerging in the field; (3) and setting the research agenda in the context of HCD in Industry 4.0, taking into account the lessons learnt, as uncovered by the in-depth review of case studies.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Nguyen Ngoc","given":"Hien"},{"family":"Lasa","given":"Ganix"},{"family":"Iriarte","given":"Ion"}],"citation-key":"nguyenngoc2022","container-title":"Journal of Intelligent Manufacturing","container-title-short":"J Intell Manuf","DOI":"10.1007/s10845-021-01796-x","ISSN":"1572-8145","issue":"1","issued":{"date-parts":[["2022",1,1]]},"language":"en","page":"35-76","source":"Springer Link","title":"Human-centred design in industry 4.0: case study review and opportunities for future research","title-short":"Human-centred design in industry 4.0","type":"article-journal","URL":"https://doi.org/10.1007/s10845-021-01796-x","volume":"33"},
  {"id":"nidhi2023","abstract":"Human ideas and sentiments are mirrored in facial expressions. Facial expression recognition (FER) is a crucial type of visual data that can be utilized to deduce a person’s emotional state. It gives the spectator a plethora of social cues, such as the viewer’s focus of attention, emotion, motivation, and intention. It’s said to be a powerful instrument for silent communication. AI-based facial recognition systems can be deployed at different areas like bus stations, railway stations, airports, or stadiums to help security forces identify potential threats. There has been a lot of research done in this area. But, it lacks a detailed review of the literature that highlights and analyses the previous work in FER (including work on compound emotion and micro-expressions), and a comparative analysis of different models applied to available datasets, further identifying aligned future directions. So, this paper includes a comprehensive overview of different models that can be used in the field of FER and a comparative study of the traditional methods based on hand-crafted feature extraction and deep learning methods in terms of their advantages and disadvantages which distinguishes our work from existing review studies.This paper also brings you to an eye on the analysis of different FER systems, the performance of different models on available datasets, evaluation of the classification performance of traditional and deep learning algorithms in the context of facial emotion recognition which reveals a good understanding of the classifier’s characteristics. Along with the proposed models, this study describes the commonly used datasets showing the year-wise performance achieved by state-of-the-art methods which lacks in the existing manuscripts. At last, the authors itemize recognized research gaps and challenges encountered by researchers which can be considered in future research work.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"literal":"Nidhi"},{"family":"Verma","given":"Bindu"}],"citation-key":"nidhi2023","container-title":"Applied Intelligence","container-title-short":"Appl Intell","DOI":"10.1007/s10489-023-05052-y","ISSN":"1573-7497","issue":"24","issued":{"date-parts":[["2023",12,1]]},"language":"en","page":"30219-30249","source":"Springer Link","title":"From methods to datasets: a detailed study on facial emotion recognition","title-short":"From methods to datasets","type":"article-journal","URL":"https://doi.org/10.1007/s10489-023-05052-y","volume":"53"},
  {"id":"nishijima2024","abstract":"Methods for converting the tacit knowledge of experts into explicit knowledge have drawn increasing attention. Gaze data has emerged as a valuable approach in this effort. However, the effective transfer of tacit knowledge remains a challenge. No studies have directly compared the effects of gaze-based and annotation-based guidance or adequately examined their impacts on skill improvement after instruction. This study examined the effects of gaze and annotation guidance on the spatiotemporal characteristics of eye movements and the skill transfer of expert evaluation techniques in karate kata performances. 28 non-expert participants were assigned to three groups: a gaze guidance group, an annotation guidance group, and a control group. Participants were presented with instructional slideshows based on the expert's gaze data and annotations. Before and after instruction, participants were asked to evaluate karate kata performance videos performed by practitioners with different skill levels. The results showed that the annotation guidance group exhibited an effect of directing gaze toward the presented areas of focus, with a trend of increased total number of fixation areas. On the other hand, while the gaze guidance group was not encouraged to make fixations on multiple areas, the possibility of promoting peripheral vision was inferred based on measurements from the eye-tracking system. Regarding ranking results, 71.4% of participants in the gaze guidance group showed an improvement in ranking skills, with a trend toward better scoring ability compared to the other groups. This demonstrates the necessity of selecting appropriate methods based on instructional goals to transfer tacit knowledge effectively. Gaze-based instructional methods are expected to be versatile and applicable to karate kata and fields such as industry, medicine, and other sports.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Nishijima","given":"Shota"},{"family":"Takai","given":"Asuka"}],"citation-key":"nishijima2024","DOI":"10.48550/arXiv.2412.17296","issued":{"date-parts":[["2024",12,23]]},"number":"arXiv:2412.17296","publisher":"arXiv","source":"arXiv.org","title":"Comparison of Spatiotemporal Characteristics of Eye Movements in Non-experts and the Skill Transfer Effects of Gaze Guidance and Annotation Guidance","type":"article","URL":"http://arxiv.org/abs/2412.17296"},
  {"id":"nordahl-hansen2020","abstract":"In this overview of the two neurodevelopmental disorders, intellectual disabilities and autism spectrum disorders we systematically searched the literature for scientific publications of group-based designs that tested various interventions through the use of Virtual Reality technology. After screening of a total of n = 366 publications, n = 13 studies (intellectual disabilities n = 7, autism spectrum disorders n = 6) were included in the final analyses. We present descriptive data in terms of type of intervention content for the various studies as well as information regarding research design, number of participants enrolled in the studies, age cohorts, and outcome measures. We discuss the findings as a whole but also by comparing the studies that are published within each of the two neurodevelopmental disorder groups. Finally we discuss some challenges and opportunities for future research.","author":[{"family":"Nordahl-Hansen","given":"Anders"},{"family":"Dechsling","given":"Anders"},{"family":"Sütterlin","given":"Stefan"},{"family":"Børtveit","given":"Line"},{"family":"Zhang","given":"Dajie"},{"family":"Øien","given":"Roald A."},{"family":"Marschik","given":"Peter B."}],"citation-key":"nordahl-hansen2020","container-title":"Augmented Cognition. Human Cognition and Behavior","DOI":"10.1007/978-3-030-50439-7_17","editor":[{"family":"Schmorrow","given":"Dylan D."},{"family":"Fidopiastis","given":"Cali M."}],"event-place":"Cham","ISBN":"978-3-030-50439-7","issued":{"date-parts":[["2020"]]},"language":"en","page":"257-267","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"An Overview of Virtual Reality Interventions for Two Neurodevelopmental Disorders: Intellectual Disabilities and Autism","title-short":"An Overview of Virtual Reality Interventions for Two Neurodevelopmental Disorders","type":"paper-conference"},
  {"id":"nordinforsberg2023","abstract":"The Human Resource (HR) area has made little use of innovative technologies to develop its processes, routines and education. However, we believe that digital tools such as Virtual Reality (VR) can play an important role in developing social aspects of work. We have investigated Human Resource Development Professionals’ (HRD-Ps’) perception of using a VR-prototype for training of social skills in the workplace. A digital three-dimensional world was designed for the study participants, in which they interacted with agents to train social skills in the workplace. Study participants explored a VR-prototype through the usage of head-mounted devices (HMD). We collected the designer’s description of the intended design element of the VR prototype and pre- and post-intervention questionnaire from the study participants and conducted a top-down thematic analysis. The three intended design elements 1) focus on the training experience, 2) learning-depth through emotional response for engagement and motivation, and 3) perspective-taking enabled by game design, were confirmed and reflected upon by the HRD-Ps’. Additionally, using VR for social skills training in the workplace was recognized as innovative, and could have the capacity to position an organization as being in the forefront of digitalization. The conclusion is that VR has a potential to create engagement and provide insights in HR matters, but further studies are needed to show the full power and potential in using VR for HR matters.","author":[{"family":"Nordin Forsberg","given":"Britta"},{"family":"Lundström","given":"Anders"},{"family":"Gulliksen","given":"Jan"}],"citation-key":"nordinforsberg2023","container-title":"Human-Computer Interaction – INTERACT 2023","DOI":"10.1007/978-3-031-42293-5_17","editor":[{"family":"Abdelnour Nocera","given":"José"},{"family":"Kristín Lárusdóttir","given":"Marta"},{"family":"Petrie","given":"Helen"},{"family":"Piccinno","given":"Antonio"},{"family":"Winckler","given":"Marco"}],"event-place":"Cham","ISBN":"978-3-031-42293-5","issued":{"date-parts":[["2023"]]},"language":"en","page":"231-251","publisher":"Springer Nature Switzerland","publisher-place":"Cham","source":"Springer Link","title":"VR for HR – A Case Study of Human Resource Development Professionals Using Virtual Reality for Social Skills Training in the Workplace","type":"paper-conference"},
  {"id":"nyrenius2023","abstract":"Background\nPatients with ‘underlying’ autism spectrum disorder (ASD) constitute a significant minority in adult out-patient psychiatry. Diagnoses of previously unrecognised ASD are increasing in adults. Characteristics of patients with autism within adult out-patient psychiatry have not been sufficiently explored, and there have not been any systematic comparisons of characteristics between patients with and those without autism within adult out-patient psychiatric populations.\n\nAims\nTo examine psychiatrically relevant characteristics in autistic adult psychiatric out-patients, and to compare the characteristics with non-autistic adult psychiatric out-patients.\n\nMethod\nWe assessed 90 patients who were referred to a Swedish psychiatric out-patient clinic and screened for ASD during 2019–2020. Sixty-three patients met the DSM-5 criteria for ASD or ‘subthreshold’ ASD. The 27 who did not meet the criteria for ASD were used as a comparison group. Assessments were made with structured and well-validated instruments, including parent ratings of developmental history.\n\nResults\nNo differences were found between the groups regarding self-reported sociodemographic variables. The ASD group showed a higher number of co-occurring psychiatric disorders than the non-ASD group (t(88) = 5.17, 95% CI 1.29–2.91, d = 1.19). Functional level was lower in the ASD group (t(88) = −2.66, 95% CI −9.46 to −1.27, d = −0.73), and was predicted by the number of co-occurring psychiatric disorders.\n\nConclusions\nThe results underscore the need for thorough assessment of psychiatric disorders in autistic patients in adult psychiatric services. ASD should be considered as a possible ‘underlying’ condition in adult psychiatry, and there is no easy way of ruling out ASD in this population.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Nyrenius","given":"Johan"},{"family":"Eberhard","given":"Jonas"},{"family":"Ghaziuddin","given":"Mohammad"},{"family":"Gillberg","given":"Christopher"},{"family":"Billstedt","given":"Eva"}],"citation-key":"nyrenius2023","container-title":"BJPsych Open","DOI":"10.1192/bjo.2023.13","ISSN":"2056-4724","issue":"3","issued":{"date-parts":[["2023",5]]},"language":"en","page":"e89","source":"Cambridge University Press","title":"The ‘lost generation’ in adult psychiatry: psychiatric, neurodevelopmental and sociodemographic characteristics of psychiatric patients with autism unrecognised in childhood","title-short":"The ‘lost generation’ in adult psychiatry","type":"article-journal","URL":"https://www.cambridge.org/core/journals/bjpsych-open/article/lost-generation-in-adult-psychiatry-psychiatric-neurodevelopmental-and-sociodemographic-characteristics-of-psychiatric-patients-with-autism-unrecognised-in-childhood/90D91FDE2321CC7DBE080DA78363CCF8","volume":"9"},
  {"id":"ochoa-lubinoff2023","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Ochoa-Lubinoff","given":"Cesar"},{"family":"Makol","given":"Bridget A."},{"family":"Dillon","given":"Emily F."}],"citation-key":"ochoa-lubinoff2023","collection-title":"Neurological Disorders in Women: From Epidemiology to Outcome","container-title":"Neurologic Clinics","container-title-short":"Neurologic Clinics","DOI":"10.1016/j.ncl.2022.10.006","ISSN":"0733-8619","issue":"2","issued":{"date-parts":[["2023",5,1]]},"page":"381-397","source":"ScienceDirect","title":"Autism in Women","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0733861922000925","volume":"41"},
  {"id":"ordieres-mere2023","abstract":"This study proposes a flexible architecture under the LAsim Smart FActor Plus reference framework, fostering the integration of different related data sources—processes, products and the human dimension (operators or other agents)—to increase business value creation. The proposed architecture promotes distributed component perspectives at different levels using different types of digital assets. Integrated reusable services to build composed business applications are found to help increase business understanding and transparency. The robustness attribute is related to the concept of persistence and seeks to reduce the degree of intervention required and thus enable integration. Use cases are presented to demonstrate the advantages provided by the proposed architecture.","accessed":{"date-parts":[["2025",3,7]]},"author":[{"family":"Ordieres-Meré","given":"Joaquín"},{"family":"Gutierrez","given":"Miguel"},{"family":"Villalba-Díez","given":"Javier"}],"citation-key":"ordieres-mere2023","container-title":"Computers in Industry","container-title-short":"Computers in Industry","DOI":"10.1016/j.compind.2023.103947","ISSN":"0166-3615","issued":{"date-parts":[["2023",9,1]]},"page":"103947","source":"ScienceDirect","title":"Toward the industry 5.0 paradigm: Increasing value creation through the robust integration of humans and machines","title-short":"Toward the industry 5.0 paradigm","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0166361523000970","volume":"150"},
  {"id":"ozturk2018","abstract":"Emotion recognition behavior and performance may vary between people with major \nneurodevelopmental disorders such as Autism Spectrum Disorder (ASD), Attention Deficit \nHyperactivity Disorder (ADHD) and control groups. It i... | Find, read and cite all the research you need on Tech Science Press","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Ozturk","given":"Mahiye"},{"family":"Arman","given":"Ayse"},{"family":"Bulut","given":"Gresa"},{"family":"Tugce","given":"Onur"},{"family":"Yilmaz","given":"Sultan"},{"family":"Genc","given":"Herdem"},{"family":"Yazgan","given":"M."},{"family":"Teker","given":"Umut"},{"family":"Cataltepe","given":"Zehra"}],"citation-key":"ozturk2018","container-title":"Intelligent Automation & Soft Computing","container-title-short":"IASC","DOI":"10.31209/2018.100000058","ISSN":"1079-8587, 2326-005X","issue":"4","issued":{"date-parts":[["2018"]]},"language":"en","page":"891-905","publisher":"Tech Science Press","source":"www.techscience.com","title":"Statistical Analysis and Multimodal Classification on Noisy Eye Tracker and Application Log Data of Children with Autism and ADHD","type":"article-journal","URL":"https://www.techscience.com/iasc/v24n4/39813","volume":"24"},
  {"id":"paolucci2023","abstract":"There is considerable discussion about the advantages and disadvantages of early ASD diagnosis. However, the development of easily understandable and administrable tools for teachers or caregivers in order to identify potentially alarming behaviours (red flags) is usually considered valuable even by scholars who are concerned with very early diagnosis. This study proposes an AI pre-screening tool with the aim of creating an easily administrable tool for non-competent observers useful to identify potentially alarming signs in pre-verbal interactions. The use of these features is evaluated using an explainable artificial intelligence algorithm to assess which of the proposed new interaction characteristics were more effective in classifying individuals with ASD vs. controls. We used a rating scale with three core sections – sensorimotor, behavioural, and emotional – each further divided into four items. By seeing home videos of children doing everyday activities, two experienced observers rated each of these items from 1 (highly typical interaction) to 8 (extremely atypical interaction). Then, a machine learning model based on XGBoost was developed for identifying ASD children. The classification obtained was interpreted through the use of SHAP explanations, obtaining an area under the receiver operating curve of 0.938 and 0.914 for the two observers, respectively. These results demonstrated the significance of early detection of body-related sensorimotor features.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Paolucci","given":"Claudio"},{"family":"Giorgini","given":"Federica"},{"family":"Scheda","given":"Riccardo"},{"family":"Alessi","given":"Flavio Valerio"},{"family":"Diciotti","given":"Stefano"}],"citation-key":"paolucci2023","container-title":"Computers in Human Behavior","container-title-short":"Computers in Human Behavior","DOI":"10.1016/j.chb.2023.107877","ISSN":"0747-5632","issued":{"date-parts":[["2023",11,1]]},"page":"107877","source":"ScienceDirect","title":"Early prediction of Autism Spectrum Disorders through interaction analysis in home videos and explainable artificial intelligence","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0747563223002285","volume":"148"},
  {"id":"paolucci2023a","abstract":"There is considerable discussion about the advantages and disadvantages of early ASD diagnosis. However, the development of easily understandable and administrable tools for teachers or caregivers in order to identify potentially alarming behaviours (red flags) is usually considered valuable even by scholars who are concerned with very early diagnosis. This study proposes an AI pre-screening tool with the aim of creating an easily administrable tool for non-competent observers useful to identify potentially alarming signs in pre-verbal interactions. The use of these features is evaluated using an explainable artificial intelligence algorithm to assess which of the proposed new interaction characteristics were more effective in classifying individuals with ASD vs. controls. We used a rating scale with three core sections – sensorimotor, behavioural, and emotional – each further divided into four items. By seeing home videos of children doing everyday activities, two experienced observers rated each of these items from 1 (highly typical interaction) to 8 (extremely atypical interaction). Then, a machine learning model based on XGBoost was developed for identifying ASD children. The classification obtained was interpreted through the use of SHAP explanations, obtaining an area under the receiver operating curve of 0.938 and 0.914 for the two observers, respectively. These results demonstrated the significance of early detection of body-related sensorimotor features.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Paolucci","given":"Claudio"},{"family":"Giorgini","given":"Federica"},{"family":"Scheda","given":"Riccardo"},{"family":"Alessi","given":"Flavio Valerio"},{"family":"Diciotti","given":"Stefano"}],"citation-key":"paolucci2023a","container-title":"Computers in Human Behavior","container-title-short":"Computers in Human Behavior","DOI":"10.1016/j.chb.2023.107877","ISSN":"07475632","issued":{"date-parts":[["2023",11]]},"language":"en","page":"107877","source":"DOI.org (Crossref)","title":"Early prediction of Autism Spectrum Disorders through interaction analysis in home videos and explainable artificial intelligence","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0747563223002285","volume":"148"},
  {"id":"paquet2017","abstract":"Objective\nMotor disorders are known in autism spectrum disorder (ASD), but muscle tone assessments are rarely performed. Muscle tone underpins movement. We investigated muscle tone in 34 ASD children using a standardized neuro-developmental battery, which uses the French norms for muscular tone in children.\nMethods\nDangling and extensibility were used to examine passive muscle tone in the upper and lower limbs and the body axis. A comparison between muscles of the right and left sides enabled the determination of tonic laterality.\nResults\nWe found a disharmonious tonic typology, with a tonic component for the muscles of the trunk and the proximal muscles of the lower limbs and a laxity component for the ankles and the proximal and distal muscles of the upper limbs (wrists and shoulders). No establishment of tonic laterality was found in the upper limbs in 61% of ASD children (P<0.001).\nConclusion\nThe disturbed tonic organization influenced by subcortical structures, such as the cerebellum, may partially explain the motor disorders, and indefinite tonic laterality may also be linked to low hemispheric brain dominance described in autism. This preliminary examination is necessary before any gross motor assessments to understand the nature of movement disorders, explore typologies and highlight possible soft neuro-motor signs.\nRésumé\nObjectifs\nLes troubles moteurs sont connus dans le trouble du spectre de l’autisme (TSA), mais l’évaluation du tonus musculaire est rarement réalisée. Pourtant le tonus musculaire sous-tend le mouvement. Nous avons étudié le tonus musculaire chez 34 enfants avec TSA à partir d’une batterie neurodéveloppementale standardisée, qui utilise les normes françaises chez l’enfant pour le tonus musculaire.\nMéthodes\nLe ballant et l’extensibilité ont été utilisés pour examiner le tonus musculaire passif au niveau des membres supérieurs et inférieurs puis de l’axe du corps. Une comparaison entre les muscles des côtés droit et gauche a permis la détermination d’une latéralité tonique.\nRésultats\nNous avons trouvé une typologie tonique dysharmonique, avec une composante d’hypertonie au niveau des muscles du tronc et des muscles proximaux des membres inférieurs et une composante d’hyperlaxité pour les chevilles et les muscles proximaux et distal des membres supérieurs (poignets et épaules). Une absence de prédominance tonique au niveau des membres supérieurs a été trouvé chez 61 % des enfants atteints de TSA (p<0,001).\nConclusion\nL’organisation tonique perturbée influencée par les structures sous-corticales, comme le cervelet, pourrait expliquer en partie les troubles moteurs décrits dans les TSA, de plus, la latéralité tonique indéterminée pourrait également être liée à une dominance cérébrale hémisphérique absente ou peu dominante décrite dans l’autisme. Cet examen préliminaire est nécessaire avant toute évaluation de la motricité globale pour comprendre la nature des troubles du mouvement, explorer les typologies et mettre en évidence des signes neurologiques doux.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Paquet","given":"Aude"},{"family":"Olliac","given":"Bertrand"},{"family":"Golse","given":"Bernard"},{"family":"Vaivre-Douret","given":"Laurence"}],"citation-key":"paquet2017","container-title":"Neurophysiologie Clinique/Clinical Neurophysiology","container-title-short":"Neurophysiologie Clinique/Clinical Neurophysiology","DOI":"10.1016/j.neucli.2017.07.001","ISSN":"0987-7053","issue":"4","issued":{"date-parts":[["2017",9,1]]},"page":"261-268","source":"ScienceDirect","title":"Evaluation of neuromuscular tone phenotypes in children with autism spectrum disorder: An exploratory study","title-short":"Evaluation of neuromuscular tone phenotypes in children with autism spectrum disorder","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0987705317300540","volume":"47"},
  {"id":"paquet2019","abstract":"Introduction: Several authors have suggested the existence of motor disorders associated with developmental coordination disorder (DCD) in individuals with autism spectrum disorder (ASD). However, there are few comparative studies of psychomotor profiles that include assessments of neurological soft signs in children with ASD or DCD. We used a neuropsychomotor assessment for children with ASD from a standardized neurodevelopmental examination to understand the nature of the difficulties these children encounter. To uncover the differences and similarities in psychomotor profiles, we compared the profiles of children with ASD with those of children with DCD and focused on two recently described DCD subgroups: visuospatial–constructional (VSC) and mixed (MX). Methods: We compared 18 children with ASD and 58 children with DCD (33 with VSC-DCD and 25 with MX-DCD) who were assessed with a battery of French-language tests (the NP-MOT) to evaluate the neuropsychomotor functions associated with visual perception and visual–spatial–motor structuring. Results: Although there were similarities between the profiles of children with ASD and those with DCD (VSC-DCD or MX-DCD), these similarities were not associated with the predictive diagnostic markers that characterized subtypes of DCD. Instead, many variables (visuospatial–motor structuration, synkinetic movements, dynamic balance, manual dexterity, coordination, praxis, bodily spatial integration, and digital perception) differed among the three groups; the best performance was observed in the children with ASD. Conclusion: The neuropsychomotor profiles of children with ASD and those with VSC-DCD or MX-DCD differed, and these differences are discussed. Our results highlight that impairments of ASD are specific about lateralization disturbances and support the hypothesis of proprioceptive impairment due to visual fixation problems influenced by muscular tone in relation to the subcortical and cortical structures and possible interhemispheric disorder. Thus, some neuropsychomotor functions that underpin both gestures and a set of motor skills are affected.","accessed":{"date-parts":[["2024",6,17]]},"author":[{"family":"Paquet","given":"Aude"},{"family":"Olliac","given":"Bertrand"},{"family":"Golse","given":"Bernard"},{"family":"Vaivre-Douret","given":"Laurence"}],"citation-key":"paquet2019","container-title":"Journal of Clinical and Experimental Neuropsychology","DOI":"10.1080/13803395.2018.1483486","ISSN":"1380-3395","issue":"1","issued":{"date-parts":[["2019",1,2]]},"page":"1–14","PMID":"29923455","publisher":"Routledge","source":"Taylor and Francis+NEJM","title":"Nature of motor impairments in autism spectrum disorder: A comparison with developmental coordination disorder","title-short":"Nature of motor impairments in autism spectrum disorder","type":"article-journal","URL":"https://doi.org/10.1080/13803395.2018.1483486","volume":"41"},
  {"id":"parra2021","abstract":"In this article, we introduce three-dimensional Serious Games (3DSGs) under an evidence-centered design (ECD) framework and use an organizational neuroscience-based eye-tracking measure to capture implicit behavioral signals associated with leadership skills. While ECD is a well-established framework used in the design and development of assessments, it has rarely been utilized in organizational research. The study proposes a novel 3DSG combined with organizational neuroscience methods as a promising tool to assess and recognize leadership-related behavioral patterns that manifest during complex and realistic social situations. We offer a research protocol for assessing task- and relationship-oriented leadership skills that uses ECD, eye-tracking measures, and machine learning. Seamlessly embedding biological measures into 3DSGs enables objective assessment methods that are based on machine learning techniques to achieve high ecological validity. We conclude by describing a future research agenda for the combined use of 3DSGs and organizational neuroscience methods for leadership and human resources.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Parra","given":"Elena"},{"family":"Chicchi Giglioli","given":"Irene Alice"},{"family":"Philip","given":"Jestine"},{"family":"Carrasco-Ribelles","given":"Lucia Amalia"},{"family":"Marín-Morales","given":"Javier"},{"family":"Alcañiz Raya","given":"Mariano"}],"citation-key":"parra2021","container-title":"Applied Sciences","DOI":"10.3390/app11135956","ISSN":"2076-3417","issue":"13","issued":{"date-parts":[["2021",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"13","page":"5956","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Combining Virtual Reality and Organizational Neuroscience for Leadership Assessment","type":"article-journal","URL":"https://www.mdpi.com/2076-3417/11/13/5956","volume":"11"},
  {"id":"parra2022","abstract":"<p>The aim of this study was to evaluate the viability of a new selection procedure based on machine learning (ML) and virtual reality (VR). Specifically, decision-making behaviours and eye-gaze patterns were used to classify individuals based on their leadership styles while immersed in virtual environments that represented social workplace situations. The virtual environments were designed using an evidence-centred design approach. Interaction and gaze patterns were recorded in 83 subjects, who were classified as having either high or low leadership style, which was assessed using the Multifactor leadership questionnaire. A ML model that combined behaviour outputs and eye-gaze patterns was developed to predict subjects’ leadership styles (high vs low). The results indicated that the different styles could be differentiated by eye-gaze patterns and behaviours carried out during immersive VR. Eye-tracking measures contributed more significantly to this differentiation than behavioural metrics. Although the results should be taken with caution as the small sample does not allow generalization of the data, this study illustrates the potential for a future research roadmap that combines VR, implicit measures, and ML for personnel selection.</p>","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Parra","given":"Elena"},{"family":"García Delgado","given":"Aitana"},{"family":"Carrasco-Ribelles","given":"Lucía Amalia"},{"family":"Chicchi Giglioli","given":"Irene Alice"},{"family":"Marín-Morales","given":"Javier"},{"family":"Giglio","given":"Cristina"},{"family":"Alcañiz Raya","given":"Mariano"}],"citation-key":"parra2022","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2022.864266","ISSN":"1664-1078","issued":{"date-parts":[["2022",5,31]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Combining Virtual Reality and Machine Learning for Leadership Styles Recognition","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.864266/full","volume":"13"},
  {"id":"pastel2023","abstract":"In recent years, Virtual Reality (VR) has become a valuable tool in rehabilitation and sports training applications. New technologies offer opportunities to combine various systems and use them for sports-related scientific purposes. For instance, examining the visual perception of athletes within a standardized environment could be helpful to understand the differences between novices and experts in their visual behavior and could further reveal possible training applications for enhancing athletes’ visual attention. The current systematic literature review thematizes the importance of eye-tracking (ET) systems’ usage integrated into head-mounted displays (HMDs) in virtual environments for further inclusion in sports-related usage. An overview of possible implementations is given, and additional recommendations for using the combined technic regarding sports are made. Although only one study examined gaze behavior during sports activity within a standardized virtual environment, 38 relevant papers were identified using the ET systems integrated into the HMDs, which ideas can be transferred to the sports sector. The increased usability and fidelity in the virtual environment enabled through the combined technology were illustrated, and different approaches were listed in using and calculating gaze parameters. This literature review examines the possibility of integrating ET in VR, which can be further used to improve usability, interaction methods, image presentation, and visual perception analyses within future physical training scenarios. The compiled studies have shown that the existing methods are feasible due to the performance of the integrated ET systems but still need to be improved for practical use.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Pastel","given":"Stefan"},{"family":"Marlok","given":"Josua"},{"family":"Bandow","given":"Nicole"},{"family":"Witte","given":"Kerstin"}],"citation-key":"pastel2023","container-title":"Multimedia Tools and Applications","container-title-short":"Multimed Tools Appl","DOI":"10.1007/s11042-022-13474-y","ISSN":"1573-7721","issue":"3","issued":{"date-parts":[["2023",1,1]]},"language":"en","page":"4181-4208","source":"Springer Link","title":"Application of eye-tracking systems integrated into immersive virtual reality and possible transfer to the sports sector - A systematic review","type":"article-journal","URL":"https://doi.org/10.1007/s11042-022-13474-y","volume":"82"},
  {"id":"perkovich2024","abstract":"Over the past years, researchers have been using head-mounted eye-tracking systems to study young children’s gaze behaviors in everyday activities through which children learn about the world. This method has great potential to further our understanding of how millisecond-level gaze behaviors create multisensory experiences and fluctuate around social environments. While this line of work can yield insight into early perceptual experiences and potential learning mechanisms, the majority of the work is exclusively conducted with typically-developing children. Sensory sensitivities, social-communication difficulties, and challenging behaviors (e.g., disruption, elopement) are common among children with developmental disorders, and they may represent potential methodological challenges for collecting high-quality data.","accessed":{"date-parts":[["2025",2,5]]},"author":[{"family":"Perkovich","given":"E."},{"family":"Laakman","given":"A."},{"family":"Mire","given":"S."},{"family":"Yoshida","given":"H."}],"citation-key":"perkovich2024","container-title":"Journal of Neurodevelopmental Disorders","container-title-short":"Journal of Neurodevelopmental Disorders","DOI":"10.1186/s11689-024-09524-1","ISSN":"1866-1955","issue":"1","issued":{"date-parts":[["2024",3,4]]},"page":"7","source":"BioMed Central","title":"Conducting head-mounted eye-tracking research with young children with autism and children with increased likelihood of later autism diagnosis","type":"article-journal","URL":"https://doi.org/10.1186/s11689-024-09524-1","volume":"16"},
  {"id":"perochon2023a","abstract":"Early detection of autism, a neurodevelopmental condition associated with challenges in social communication, ensures timely access to intervention. Autism screening questionnaires have been shown to have lower accuracy when used in real-world settings, such as primary care, as compared to research studies, particularly for children of color and girls. Here we report findings from a multiclinic, prospective study assessing the accuracy of an autism screening digital application (app) administered during a pediatric well-child visit to 475 (17–36 months old) children (269 boys and 206 girls), of which 49 were diagnosed with autism and 98 were diagnosed with developmental delay without autism. The app displayed stimuli that elicited behavioral signs of autism, quantified using computer vision and machine learning. An algorithm combining multiple digital phenotypes showed high diagnostic accuracy with the area under the receiver operating characteristic curve = 0.90, sensitivity = 87.8%, specificity = 80.8%, negative predictive value = 97.8% and positive predictive value = 40.6%. The algorithm had similar sensitivity performance across subgroups as defined by sex, race and ethnicity. These results demonstrate the potential for digital phenotyping to provide an objective, scalable approach to autism screening in real-world settings. Moreover, combining results from digital phenotyping and caregiver questionnaires may increase autism screening accuracy and help reduce disparities in access to diagnosis and intervention.","accessed":{"date-parts":[["2025",2,3]]},"author":[{"family":"Perochon","given":"Sam"},{"family":"Di Martino","given":"J. Matias"},{"family":"Carpenter","given":"Kimberly L. H."},{"family":"Compton","given":"Scott"},{"family":"Davis","given":"Naomi"},{"family":"Eichner","given":"Brian"},{"family":"Espinosa","given":"Steven"},{"family":"Franz","given":"Lauren"},{"family":"Krishnappa Babu","given":"Pradeep Raj"},{"family":"Sapiro","given":"Guillermo"},{"family":"Dawson","given":"Geraldine"}],"citation-key":"perochon2023a","container-title":"Nature Medicine","container-title-short":"Nat Med","DOI":"10.1038/s41591-023-02574-3","ISSN":"1546-170X","issue":"10","issued":{"date-parts":[["2023",10]]},"language":"en","license":"2023 The Author(s)","page":"2489-2497","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Early detection of autism using digital behavioral phenotyping","type":"article-journal","URL":"https://www.nature.com/articles/s41591-023-02574-3","volume":"29"},
  {"id":"pham2023","abstract":"Delays in autism spectrum disorder identification/services could impact developmental outcomes. Although trends are encouraging, children from historically underrepresented minority backgrounds are often identified later and have reduced engagement in care. It is unclear if disparities exist throughout the screen-evaluate-treat chain, or if early detection programs such as Get SET Early that standardize these steps are effective countermeasures. Pediatricians/primary care providers administered Communication and Symbolic Behavior Scales IT Checklist screens at 12-, 18-, and 24-month well-baby examinations, and parents designated race, ethnicity, and developmental concerns. Toddlers who scored in the range of concern, or whose pediatricians/primary care providers had concerns, were referred for evaluations. Rates of screening and evaluation engagement within ethnic/racial groups were compared to U.S. Census proportions. Age at screen, evaluation, and treatment and quantity was compared across groups. Regressions examined whether key factors were associated with ethnicity or race. No differences were found for mean age of screen, evaluation, initiation of behavioral therapy, or quantity received between racial and ethnic groups. Historically underrepresented minority children were more likely to fall into the range of concern, referred for evaluations, and have their parents express developmental concerns. Although there remain gaps within the pipeline, implementation of systemized programs can be effective in ensuring equitable access to resources across communities.\nLay abstract\nDelays in autism spectrum disorder identification and access to care could impact developmental outcomes. Although trends are encouraging, children from historically underrepresented minority backgrounds are often identified at later ages and have reduced engagement in services. It is unclear if disparities exist all along the screen-evaluation-treatment chain, or if early detection programs such as Get SET Early that standardize, these steps are effective at ameliorating disparities. As part of the Get SET Early model, primary care providers administered a parent-report screen at well-baby examinations, and parents designated race, ethnicity, and developmental concerns. Toddlers who scored in the range of concern, or whose primary care provider had concerns, were referred for an evaluation. Rates of screening and evaluation engagement within ethnic/racial groups were compared to US Census data. Age at screen, evaluation, and treatment engagement and quantity was compared across groups. Statistical models examined whether key factors such as parent concern were associated with ethnicity or race. No differences were found in the mean age at the first screen, evaluation, or initiation or quantity of behavioral therapy between participants. However, children from historically underrepresented minority backgrounds were more likely to fall into the range of concern on the parent-report screen, their parents expressed developmental concerns more often, and pediatricians were more likely to refer for an evaluation than their White/Not Hispanic counterparts. Overall results suggest that models that support transparent tracking of steps in the screen-evaluation-treatment chain and service referral pipelines may be an effective strategy for ensuring equitable access to care for all children.","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Pham","given":"Christie"},{"family":"Bacon","given":"Elizabeth C"},{"family":"Grzybowski","given":"Andrea"},{"family":"Carter-Barnes","given":"Cynthia"},{"family":"Arias","given":"Steven"},{"family":"Xu","given":"Ronghui"},{"family":"Lopez","given":"Linda"},{"family":"Courchesne","given":"Eric"},{"family":"Pierce","given":"Karen"}],"citation-key":"pham2023","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/13623613221147416","ISSN":"1362-3613","issue":"6","issued":{"date-parts":[["2023",8,1]]},"language":"en","page":"1790-1802","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Examination of the impact of the Get SET Early program on equitable access to care within the screen-evaluate-treat chain in toddlers with autism spectrum disorder","type":"article-journal","URL":"https://doi.org/10.1177/13623613221147416","volume":"27"},
  {"id":"picard1997","abstract":"According to Rosalind Picard, if we want computers to be genuinely intelligent and to interact naturally with us, we must give computers the ability to recognize, understand, even to have and express emotions.\n            The latest scientific findings indicate that emotions play an essential role in decision making, perception, learning, and more—that is, they influence the very mechanisms of rational thinking. Not only too much, but too little emotion can impair decision making. According to Rosalind Picard, if we want computers to be genuinely intelligent and to interact naturally with us, we must give computers the ability to recognize, understand, even to have and express emotions.\n            Part 1 of this book provides the intellectual framework for affective computing. It includes background on human emotions, requirements for emotionally intelligent computers, applications of affective computing, and moral and social questions raised by the technology. Part 2 discusses the design and construction of affective computers. Although this material is more technical than that in Part 1, the author has kept it less technical than typical scientific publications in order to make it accessible to newcomers. Topics in Part 2 include signal-based representations of emotions, human affect recognition as a pattern recognition and learning problem, recent and ongoing efforts to build models of emotion for synthesizing emotions in computers, and the new application area of affective wearable computers.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Picard","given":"Rosalind W."}],"citation-key":"picard1997","DOI":"10.7551/mitpress/1140.001.0001","ISBN":"978-0-262-28158-4","issued":{"date-parts":[["1997",9,24]]},"language":"en","publisher":"The MIT Press","source":"DOI.org (Crossref)","title":"Affective Computing","type":"book","URL":"https://direct.mit.edu/books/book/4296/Affective-Computing"},
  {"id":"pierce2016","abstract":"BACKGROUND: Clinically and biologically, autism spectrum disorder (ASD) is heterogeneous. Unusual patterns of visual preference as indexed by eye tracking are hallmarks; however, whether they can be used to define an early biomarker of ASD as a whole or leveraged to define a subtype is unclear. To begin to examine this issue, large cohorts are required.\nMETHODS: A sample of 334 toddlers from six distinct groups (115 toddlers with ASD, 20 toddlers with ASD features, 57 toddlers with developmental delay, 53 toddlers with other conditions [e.g., premature birth, prenatal drug exposure], 64 toddlers with typical development, and 25 unaffected toddlers with siblings with ASD) was studied. Toddlers watched a movie containing geometric and social images. Fixation duration and number of saccades within each area of interest and validation statistics for this independent sample were computed. Next, to maximize power, data from our previous study (n = 110) were added for a total of 444 subjects. A subset of toddlers repeated the eye-tracking procedure.\nRESULTS: As in the original study, a subset of toddlers with ASD fixated on geometric images >69% of the time. Using this cutoff, sensitivity for ASD was 21%, specificity was 98%, and positive predictive value was 86%. Toddlers with ASD who strongly preferred geometric images had 1) worse cognitive, language, and social skills relative to toddlers with ASD who strongly preferred social images and 2) fewer saccades when viewing geometric images. Unaffected siblings of ASD probands did not show evidence of heightened preference for geometric images. Test-retest reliability was good. Examination of age effects suggested that this test may not be appropriate with children >4 years old.\nCONCLUSIONS: Enhanced visual preference for geometric repetition may be an early developmental biomarker of an ASD subtype with more severe symptoms.","author":[{"family":"Pierce","given":"Karen"},{"family":"Marinero","given":"Steven"},{"family":"Hazin","given":"Roxana"},{"family":"McKenna","given":"Benjamin"},{"family":"Barnes","given":"Cynthia Carter"},{"family":"Malige","given":"Ajith"}],"citation-key":"pierce2016","container-title":"Biological Psychiatry","container-title-short":"Biol Psychiatry","DOI":"10.1016/j.biopsych.2015.03.032","ISSN":"1873-2402","issue":"8","issued":{"date-parts":[["2016",4,15]]},"language":"eng","page":"657-666","PMCID":"PMC4600640","PMID":"25981170","source":"PubMed","title":"Eye Tracking Reveals Abnormal Visual Preference for Geometric Images as an Early Biomarker of an Autism Spectrum Disorder Subtype Associated With Increased Symptom Severity","type":"article-journal","volume":"79"},
  {"id":"pierce2021","abstract":"Objectives\nTo examine the impact of a new approach, Get SET Early, on the rates of early autism spectrum disorder (ASD) detection and factors that influence the screen-evaluate-treat chain.\nStudy design\nAfter attending Get SET Early training, 203 pediatricians administered 57 603 total screens using the Communication and Symbolic Behavior Scales Infant-Toddler Checklist at 12-, 18-, and 24-month well-baby examinations, and parents designated presence or absence of concern. For screen-positive toddlers, pediatricians specified if the child was being referred for evaluation, and if not, why not.\nResults\nCollapsed across ages, toddlers were evaluated and referred for treatment at a median age of 19 months, and those screened at 12 months (59.4% of sample) by 15 months. Pediatricians referred one-third of screen-positive toddlers for evaluation, citing lack of confidence in the accuracy of screen-positive results as the primary reason for nonreferral. If a parent expressed concerns, referral probability doubled, and the rate of an ASD diagnosis increased by 37%. Of 897 toddlers evaluated, almost one-half were diagnosed as ASD, translating into an ASD prevalence of 1%.\nConclusions\nThe Get SET Early model was effective at detecting ASD and initiating very early treatment. Results also underscored the need for change in early identification approaches to formally operationalize and incorporate pediatrician judgment and level of parent concern into the process.","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Pierce","given":"Karen"},{"family":"Gazestani","given":"Vahid"},{"family":"Bacon","given":"Elizabeth"},{"family":"Courchesne","given":"Eric"},{"family":"Cheng","given":"Amanda"},{"family":"Barnes","given":"Cynthia Carter"},{"family":"Nalabolu","given":"Srinivasa"},{"family":"Cha","given":"Debra"},{"family":"Arias","given":"Steven"},{"family":"Lopez","given":"Linda"},{"family":"Pham","given":"Christie"},{"family":"Gaines","given":"Kim"},{"family":"Gyurjyan","given":"Gohar"},{"family":"Cook-Clark","given":"Terri"},{"family":"Karins","given":"Kathy"}],"citation-key":"pierce2021","container-title":"The Journal of Pediatrics","container-title-short":"The Journal of Pediatrics","DOI":"10.1016/j.jpeds.2021.04.041","ISSN":"0022-3476","issued":{"date-parts":[["2021",9,1]]},"page":"179-188","source":"ScienceDirect","title":"<i>Get SET Early</i> to Identify and Treatment Refer Autism Spectrum Disorder at 1 Year and Discover Factors That Influence Early Diagnosis","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0022347621003929","volume":"236"},
  {"id":"poglitsch2024","abstract":"In this paper, we present a systematic review of the applications of (1) Extended Reality (XR), (2) Augmented Reality (AR), and (3) Virtual Reality (VR) technologies to enhance emotion recognition and emotion expression in people with Autism Spectrum Disorder (ASD). ASD can affect various abilities, and poses challenges to the recognition of emotions in others, which is often referred to as “social blindness”. Treating this condition typically requires intensive one-on-one or small-group therapy sessions, which can be costly and limited in terms of availability. With the growing number of diagnoses of ASD, concerns have risen regarding a potential “lost generation” that may face difficulties in fulfilling its potential. Through this comprehensive review, we aim to provide an overview of innovative approaches that use XR technologies to improve the learning experience of individuals with ASD.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Poglitsch","given":"Christian"},{"family":"Safikhani","given":"Saeed"},{"family":"List","given":"Erin"},{"family":"Pirker","given":"Johanna"}],"citation-key":"poglitsch2024","container-title":"Computers & Graphics","container-title-short":"Computers & Graphics","DOI":"10.1016/j.cag.2024.103942","ISSN":"0097-8493","issued":{"date-parts":[["2024",6,1]]},"page":"103942","source":"ScienceDirect","title":"XR technologies to enhance the emotional skills of people with autism spectrum disorder: A systematic review","title-short":"XR technologies to enhance the emotional skills of people with autism spectrum disorder","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0097849324000773","volume":"121"},
  {"id":"polakova2023","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Poláková","given":"Michaela"},{"family":"Suleimanová","given":"Juliet Horváthová"},{"family":"Madzík","given":"Peter"},{"family":"Copuš","given":"Lukáš"},{"family":"Molnárová","given":"Ivana"},{"family":"Polednová","given":"Jana"}],"citation-key":"polakova2023","container-title":"Heliyon","container-title-short":"Heliyon","DOI":"10.1016/j.heliyon.2023.e18670","ISSN":"2405-8440","issue":"8","issued":{"date-parts":[["2023",8,1]]},"language":"English","PMID":"37520995","publisher":"Elsevier","source":"www.cell.com","title":"Soft skills and their importance in the labour market under the conditions of Industry 5.0","type":"article-journal","URL":"https://www.cell.com/heliyon/abstract/S2405-8440(23)05878-4","volume":"9"},
  {"id":"prince2023understanding","author":[{"family":"Prince","given":"Simon J.D."}],"citation-key":"prince2023understanding","issued":{"date-parts":[["2023"]]},"publisher":"The MIT Press","title":"Understanding deep learning","type":"book","URL":"http://udlbook.com"},
  {"id":"rausch2024","abstract":"The Ritvo Autism Asperger Diagnostic Scale-Revised (RAADS-R) demonstrated excellent results in its original study, with a sensitivity of 97% and a specificity of 100% (Ritvo et al. in J Autism Dev Disord 41:1076–1089, 2011). As a result, it was included in the National Institute for Health and Care Excellence (NICE) guidelines (Recommendations | Autism spectrum disorder in adults: diagnosis and management | Guidance | NICE, 2022). The questionnaire includes 80 questions across four subcategories (language, social relatedness, circumscribed interests, sensory motor). So far, the subcategory sensory motor has not been addressed in most available instruments, despite being part of the diagnostic criteria specified in DSM-5 (Falkai et al., in Diagnostisches Und Statistisches Manual Psychischer Störungen DSM-5. Hogrefe, 2015) and ICD-11 (ICD-11 for Mortality and Morbidity Statistics, 2022). In our validation study, we tested a translated German version of the questionnaire in 299 individuals (110 persons with ASD according to ICD-10 F84.0, F84.5, 64 persons with an primary mental disorders (PMD), 125 persons with no disorders). To enhance the practical use of the instrument in clinical everyday practice, the questionnaire was completed by the participants without the presence of a clinician—unlike the original study. Psychiatric diagnoses were established following the highest standards, and psychometric properties were calculated using established protocols. The German version of the RADS-R yielded very good results, with a high sensitivity of 92.5% and a high specificity of 93.6%. The area under the curve (AUC = 0.976), indicates a high quality and discriminatory power of RADS-R. Furthermore, the ROC curve analysis showed that the optimal threshold to distinguish between the ASD and non-ASD groups in the German version of the RAADS-R is a score of 81. In comparison to the RADS-R, the co-administered instruments Social Responsiveness Scale (SRS), Autism Spectrum Quotient (AQ), and Empathy Quotient (EQ) each showed slightly better specificity but worse sensitivity in this sample.The study included individuals already diagnosed with ASD according to ICD-10 (F84.0, F84.5), with or without an primary mental disorders, preventing us from identifying the influence of comorbidities on the RADS-R results. In addition, a self-report questionnaire has generally only limited objectivity and may allow for false representation of the symptoms. The RADS-R compares well with other questionnaires and can provide valuable additional information. It could turn out to be a helpful diagnostic tool for patients in Germany. We propose naming the German version RADS-R (Ritvo Autism Diagnostic Scale – rRevised) to reflect the change in terminology.","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Rausch","given":"Jördis"},{"family":"Fangmeier","given":"Thomas"},{"family":"Falter-Wagner","given":"Christine M."},{"family":"Ackermann","given":"Helene"},{"family":"Espelöer","given":"Julia"},{"family":"Hölzel","given":"Lars P."},{"family":"Riedel","given":"Andreas"},{"family":"Ritvo","given":"Ariella"},{"family":"Vogeley","given":"Kai"},{"family":"Elst","given":"Ludger Tebartz","non-dropping-particle":"van"}],"citation-key":"rausch2024","container-title":"European Archives of Psychiatry and Clinical Neuroscience","container-title-short":"Eur Arch Psychiatry Clin Neurosci","DOI":"10.1007/s00406-024-01894-w","ISSN":"1433-8491","issued":{"date-parts":[["2024",10,27]]},"language":"en","source":"Springer Link","title":"A novel screening instrument for the assessment of autism in German language: validation of the German version of the RAADS-R, the RADS-R","title-short":"A novel screening instrument for the assessment of autism in German language","type":"article-journal","URL":"https://doi.org/10.1007/s00406-024-01894-w"},
  {"id":"reinmund2024","abstract":"Politicians and care associations advocate for the use of machine learning (ML) systems to improve the delivery of adult social services. Yet, guidance on how to implement ML systems remains limited and research indicates that future implementation efforts are likely to encounter difficulties. We aim to enhance the understanding of ML system implementations by conducting a longitudinal field study with a team responsible for deploying a ML system within an adult social services department. The ML system implementation represented a cross-organisational effort to facilitate the department’s transition to a proactive practice. Throughout this process, stakeholders adapted to numerous challenges in real-time. This study makes three contributions. First, we provide a description of how ML systems are implemented and highlight practical challenges. Second, we illustrate the utility of HCI knowledge in designing workflows for ML-assisted preventative care programmes. Finally, we provide recommendations for future deployments of ML systems in social care.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Reinmund","given":"Tyler"},{"family":"Kunze","given":"Lars"},{"family":"Jirotka","given":"Marina Denise"}],"citation-key":"reinmund2024","collection-title":"CHI '24","container-title":"Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3613904.3642247","event-place":"New York, NY, USA","ISBN":"979-8-4007-0330-0","issued":{"date-parts":[["2024",5,11]]},"page":"1–19","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Transitioning Towards a Proactive Practice: A Longitudinal Field Study on the Implementation of a ML System in Adult Social Care","title-short":"Transitioning Towards a Proactive Practice","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3613904.3642247"},
  {"id":"rezayi2025","abstract":"Compared to typically developing people, children with autism spectrum disorder (ASD) have distinct cognitive and intelligence profiles. Some of these children require cognitive rehabilitation. Through the use of cutting-edge therapy and cognitive empowerment methods, some cognitive skills in children with ASD can be strengthened by digital game-based tools. This study’s main purpose is to provide a systematic review and qualitative study about designing digital games for cognitive enhancement in autistic children and to determine the main design components of such digital games. The primary focus of this study is to explore the citations in which the technical and functional elements are provided thoroughly. Furthermore, a conceptual framework is elaborated for designing a digital game for autism. A thorough review of the literature was conducted in the databases of Medline (via PubMed), Web of Science (WOS), Scopus, and IEEE Xplore for English publications published before January 23, 2023. Of 976 papers, 34 studies were found to be eligible in this systematic review. The bulk of the studies were carried out in Asia and Europe. Three (8.8%) studies used games that were built to be multilingual, while 22 (64.7%) studies used games that were only created in English. Creating motivation through narratives, providing incentive systems, raising the complexity level, targeting main skills, and adjusting the choices are the principal components of digital game design. (1) Main cognitive rehabilitation domains in ASD; (2) game designing details: platforms and game genres, motivations, evaluations, game graphics designs, aesthetic mechanisms, incentive systems, and famous game development engines; and (3) mutual interaction between child, therapist, and parents are the crucial categories that are described to devise a conceptual framework in this qualitative study. Of the total number of included studies, 25 studies reported positive effects on autism cases, and in nine, there has not been any evaluation of real cases; however, only usability tests have been conducted. Children with autism may benefit from using appropriate digital game-based interventions to improve mental indices. According to a review, it can be stated that the suitable computerized and digital game-based solutions could enhance cognitive outcomes in children with autism spectrum disorder. However, more research is required to ascertain the true efficacy of these new technologies.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Rezayi","given":"Sorayya"},{"family":"Shahmoradi","given":"Leila"},{"family":"Tehrani-Doost","given":"Mehdi"}],"citation-key":"rezayi2025","container-title":"Cognitive Computation","container-title-short":"Cogn Comput","DOI":"10.1007/s12559-024-10395-w","ISSN":"1866-9964","issue":"1","issued":{"date-parts":[["2025",1,31]]},"language":"en","page":"60","source":"Springer Link","title":"Systematic Review and Thematic Analysis of Digital Games for Cognitive Enhancement in Children with Autism Spectrum Disorder: Toward a Conceptual Framework","title-short":"Systematic Review and Thematic Analysis of Digital Games for Cognitive Enhancement in Children with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s12559-024-10395-w","volume":"17"},
  {"id":"ricou2024","abstract":"Human faces contain a large amount of information, attracting our attention and inducing physiological engagement. Attraction to human faces can be observed from birth and develops with age and social experience. The oculometric (visual exploration) and pupillometric (physiological reactivity) parameters quantified by eye-tracking can be relevant measures to study attractiveness and engagement with human faces. Autistic people have particularities in terms of visual exploration and physiological reactivity to faces, with a reduction in the time spent on the eyes associated with a reduced pupil dilation. To date, no study has assessed the developmental dynamics of oculo-pupillometric parameters in response to faces. This study aimed to characterize these parameters throughout typical and autistic development. 109 autistic participants (3-34 years old) were compared to 150 neurotypical participants (3-32 years old). Visual stimuli were organized along a gradient of social saliency, going from static objects to static neutral faces, dynamic neutral faces and dynamic emotional faces. Ocular exploration and physiological reactivity in response to faces appear invariant throughout life in the autistic population. Their developmental dynamics differ from those of the neurotypical population, which shows first, an increasing attentional focus on the eye region with age, and second, a pupillary hypersensitivity to social salient stimuli at an early age which then decreases linearly. Our results highlight an apparent lack of maturation of face processing in the case of autism spectrum disorder (ASD) at the population level, possibly hiding atypical and complex individual developmental trajectories. On the other hand, the neurotypical population exhibits a maturation of both oculometric and pupillometric parameters, pointing towards limited age windows in which specific parameters could be used as discriminating biomarkers of ASD.","accessed":{"date-parts":[["2025",2,3]]},"author":[{"family":"Ricou","given":"Camille"},{"family":"Mofid","given":"Yassine"},{"family":"Roché","given":"Laetitia"},{"family":"Bufo","given":"Maria Rosa"},{"family":"Houy-Durand","given":"Emmanuelle"},{"family":"Malvy","given":"Joëlle"},{"family":"Lemaire","given":"Mathieu"},{"family":"Elian","given":"Jean-Claude"},{"family":"Martineau","given":"Joëlle"},{"family":"Bonnet-Brilhault","given":"Frederique"},{"family":"Wardak","given":"Claire"},{"family":"Aguillon-Hernandez","given":"Nadia"}],"citation-key":"ricou2024","DOI":"10.31234/osf.io/vfte9","issued":{"date-parts":[["2024"]]},"source":"Europe PMC","title":"Invariant response to faces in ASD: unexpected trajectory of oculo-pupillometric biomarkers from childhood to adulthoo","title-short":"Invariant response to faces in ASD","type":"article","URL":"https://doi.org/10.31234/osf.io/vfte9"},
  {"id":"robles2022","abstract":"Autism - also known as Autism Spectrum Disorders or Autism Spectrum Conditions - is a neurodevelopmental condition characterized by repetitive behaviours and differences in communication and social interaction. As a consequence, many autistic individuals may struggle in everyday life, which sometimes manifests in depression, unemployment, or addiction. One crucial problem in patient support and treatment is the long waiting time to diagnosis, which was approximated to seven months on average. Yet, the earlier an intervention can take place the better the patient can be supported, which was identified as a crucial factor. We propose a system to support the screening of Autism Spectrum Disorders based on a virtual reality social interaction, namely a shopping experience, with an embodied agent. During this everyday interaction, behavioral responses are tracked and recorded. We analyze this behavior with machine learning approaches to classify participants from an autistic participant sample in comparison to a typically developed individuals control sample with high accuracy, demonstrating the feasibility of the approach. We believe that such tools can strongly impact the way mental disorders are assessed and may help to further find objective criteria and categorization.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Robles","given":"Marta"},{"family":"Namdarian","given":"Negar"},{"family":"Otto","given":"Julia"},{"family":"Wassiljew","given":"Evelyn"},{"family":"Navab","given":"Nassir"},{"family":"Falter-Wagner","given":"Christine M."},{"family":"Roth","given":"Daniel"}],"citation-key":"robles2022","container-title":"IEEE Transactions on Visualization and Computer Graphics","DOI":"10.1109/TVCG.2022.3150489","ISSN":"1941-0506","issue":"5","issued":{"date-parts":[["2022",5]]},"page":"2168-2178","source":"IEEE Xplore","title":"A Virtual Reality Based System for the Screening and Classification of Autism","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9714809","volume":"28"},
  {"id":"robles2024","abstract":"Background/Objective\nAutism has been investigated through traditional emotion recognition paradigms, merely investigating accuracy, thereby constraining how potential differences across autistic and control individuals may be observed, identified, and described. Moreover, the use of emotional facial expression information for social functioning in autism is of relevance to provide a deeper understanding of the condition.\nMethod\nAdult autistic individuals (n = 34) and adult control individuals (n = 34) were assessed with a social perception behavioral paradigm exploring facial expression predictions and their impact on social evaluation.\nResults\nAutistic individuals held less stereotypical predictions than controls. Importantly, despite such differences in predictions, the use of such predictions for social evaluation did not differ significantly between groups, as autistic individuals relied on their predictions to evaluate others to the same extent as controls.\nConclusions\nThese results help to understand how autistic individuals perceive social stimuli and evaluate others, revealing a deviation from stereotypicality beyond which social evaluation strategies may be intact.","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Robles","given":"Marta"},{"family":"Ramos-Grille","given":"Irene"},{"family":"Hervás","given":"Amaia"},{"family":"Duran-Tauleria","given":"Enric"},{"family":"Galiano-Landeira","given":"Jordi"},{"family":"Wormwood","given":"Jolie B."},{"family":"Falter-Wagner","given":"Christine M."},{"family":"Chanes","given":"Lorena"}],"citation-key":"robles2024","container-title":"International Journal of Clinical and Health Psychology","container-title-short":"International Journal of Clinical and Health Psychology","DOI":"10.1016/j.ijchp.2024.100440","ISSN":"1697-2600","issue":"2","issued":{"date-parts":[["2024",4,1]]},"page":"100440","source":"ScienceDirect","title":"Reduced stereotypicality and spared use of facial expression predictions for social evaluation in autism","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S169726002400005X","volume":"24"},
  {"id":"romero-ayuso2021","abstract":"This review aims to evaluate the effectiveness of virtual reality-based interventions (VR-based interventions) on cognitive deficits in children with attention deficit hyperactivity disorder (ADHD). A systematic review and meta-analysis were performed according to the PRISMA statement and the Cochrane Handbook guidelines for conducting meta-analyses. The Grading of Recommendations, Assessment, Development and Evaluation (GRADE) was used to assess the quality of the evidence. Clinical trials published up to 29 October 2020, were included. The meta-analysis included four studies, with a population of 125 participants with ADHD. The magnitude of the effect was large for omissions (SMD = −1.38; p = 0.009), correct hits (SMD = −1.50; p = 0.004), and perceptual sensitivity (SMD = −1.07; p = 0.01); and moderate for commissions (SMD = −0.62; p = 0.002) and reaction time (SMD = −0.67; p = 0.03). The use of VR-based interventions for cognitive rehabilitation in children with ADHD is limited. The results showed that VR-based interventions are more effective in improving sustained attention. Improvements were observed in attentional vigilance measures, increasing the number of correct responses and decreasing the number of errors of omission. No improvements were observed in impulsivity responses.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Romero-Ayuso","given":"Dulce"},{"family":"Toledano-González","given":"Abel"},{"family":"Rodríguez-Martínez","given":"María del Carmen"},{"family":"Arroyo-Castillo","given":"Palma"},{"family":"Triviño-Juárez","given":"José Matías"},{"family":"González","given":"Pascual"},{"family":"Ariza-Vega","given":"Patrocinio"},{"family":"Del Pino González","given":"Antonio"},{"family":"Segura-Fragoso","given":"Antonio"}],"citation-key":"romero-ayuso2021","container-title":"Children","container-title-short":"Children (Basel)","DOI":"10.3390/children8020070","ISSN":"2227-9067","issue":"2","issued":{"date-parts":[["2021",1,21]]},"page":"70","PMCID":"PMC7909839","PMID":"33494272","source":"PubMed Central","title":"Effectiveness of Virtual Reality-Based Interventions for Children and Adolescents with ADHD: A Systematic Review and Meta-Analysis","title-short":"Effectiveness of Virtual Reality-Based Interventions for Children and Adolescents with ADHD","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7909839/","volume":"8"},
  {"id":"ruan2024","abstract":"<sec><title>Introduction</title><p>Early and accurate diagnosis of autism spectrum disorder (ASD) is crucial for effective intervention, yet it remains a significant challenge due to its complexity and variability. Micro-expressions are rapid, involuntary facial movements indicative of underlying emotional states. It is unknown whether micro-expression can serve as a valid bio-marker for ASD diagnosis.</p></sec><sec><title>Methods</title><p>This study introduces a novel machine-learning (ML) framework that advances ASD diagnostics by focusing on facial micro-expressions. We applied cutting-edge algorithms to detect and analyze these micro-expressions from video data, aiming to identify distinctive patterns that could differentiate individuals with ASD from typically developing peers. Our computational approach included three key components: (1) micro-expression spotting using Shallow Optical Flow Three-stream CNN (SOFTNet), (2) feature extraction via Micron-BERT, and (3) classification with majority voting of three competing models (MLP, SVM, and ResNet).</p></sec><sec><title>Results</title><p>Despite the sophisticated methodology, the ML framework's ability to reliably identify ASD-specific patterns was limited by the quality of video data. This limitation raised concerns about the efficacy of using micro-expressions for ASD diagnostics and pointed to the necessity for enhanced video data quality.</p></sec><sec><title>Discussion</title><p>Our research has provided a cautious evaluation of micro-expression diagnostic value, underscoring the need for advancements in behavioral imaging and multimodal AI technology to leverage the full capabilities of ML in an ASD-specific clinical context.</p></sec>","accessed":{"date-parts":[["2025",1,9]]},"author":[{"family":"Ruan","given":"Mindi"},{"family":"Zhang","given":"Na"},{"family":"Yu","given":"Xiangxu"},{"family":"Li","given":"Wenqi"},{"family":"Hu","given":"Chuanbo"},{"family":"Webster","given":"Paula J."},{"family":"K. Paul","given":"Lynn"},{"family":"Wang","given":"Shuo"},{"family":"Li","given":"Xin"}],"citation-key":"ruan2024","container-title":"Frontiers in Neuroinformatics","container-title-short":"Front. Neuroinform.","DOI":"10.3389/fninf.2024.1435091","ISSN":"1662-5196","issued":{"date-parts":[["2024",10,3]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Can micro-expressions be used as a biomarker for autism spectrum disorder?","type":"article-journal","URL":"https://www.frontiersin.org/journals/neuroinformatics/articles/10.3389/fninf.2024.1435091/full","volume":"18"},
  {"id":"rudovic2018","abstract":"Robots have the potential to facilitate future therapies for children on the autism spectrum. However, existing robots are limited in their ability to automatically perceive and respond to human affect, which is necessary for establishing and maintaining engaging interactions. Their inference challenge is made even harder by the fact that many individuals with autism have atypical and unusually diverse styles of expressing their affective-cognitive states. To tackle the heterogeneity in children with autism, we used the latest advances in deep learning to formulate a personalized machine learning (ML) framework for automatic perception of the children's affective states and engagement during robot-assisted autism therapy. Instead of using the traditional one-size-fits-all ML approach, we personalized our framework to each child using their contextual information (demographics and behavioral assessment scores) and individual characteristics. We evaluated this framework on a multimodal (audio, video, and autonomic physiology) data set of 35 children (ages 3 to 13) with autism, from two cultures (Asia and Europe), and achieved an average agreement (intraclass correlation) of ~60% with human experts in the estimation of affect and engagement, also outperforming nonpersonalized ML solutions. These results demonstrate the feasibility of robot perception of affect and engagement in children with autism and have implications for the design of future autism therapies.","author":[{"family":"Rudovic","given":"Ognjen"},{"family":"Lee","given":"Jaeryoung"},{"family":"Dai","given":"Miles"},{"family":"Schuller","given":"Björn"},{"family":"Picard","given":"Rosalind W."}],"citation-key":"rudovic2018","container-title":"Science Robotics","container-title-short":"Sci Robot","DOI":"10.1126/scirobotics.aao6760","ISSN":"2470-9476","issue":"19","issued":{"date-parts":[["2018",6,27]]},"language":"eng","page":"eaao6760","PMID":"33141688","source":"PubMed","title":"Personalized machine learning for robot perception of affect and engagement in autism therapy","type":"article-journal","volume":"3"},
  {"id":"ruizmorales2017","abstract":"The paper presents a narrative on the state of the question about the teaching and assessment of generic soft skills through Virtual Environments (VEs) in universities, based on consultation of scientific journals in electronic and printed format published between 2000 and 2014, as well as research projects focused on the development of generic skills through VEs. The paper summarises the theoretical and empirical contributions as a way of providing a greater insight into a line of research that began barely a decade ago. Soft skills related to student training, when combined with specific skills, enable better performance in personal, academic, social and organisational settings. This premise implies the need to consider the development of new methodologies for teaching, learning and assessment of soft skills. Results include the value of soft skills in training university students, as well as the development of innovative projects focused on the provision of teaching and assessment procedures that are feasible and effective for the achievement of soft skills assessment in VEs.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Ruiz Morales","given":"Yovanni Alexander"},{"family":"Biencinto López","given":"Chantal"},{"family":"Garcìa Garcìa","given":"Mercedes"},{"family":"Carpintero","given":"Elvira"}],"citation-key":"ruizmorales2017","container-title":"RELIEVE - Revista Electrónica de Investigación y Evaluación Educativa","container-title-short":"RELIEVE","DOI":"10.7203/relieve.23.1.7183","ISSN":"1134-4032","issue":"1","issued":{"date-parts":[["2017",1,15]]},"language":"en","source":"DOI.org (Crossref)","title":"Evaluación de competencias genéricas en el ámbito universitario a través de entornos virtuales: Una revisión narrativa","title-short":"Evaluación de competencias genéricas en el ámbito universitario a través de entornos virtuales","type":"article-journal","URL":"https://revistaseug.ugr.es/index.php/RELIEVE/article/view/17302","volume":"23"},
  {"id":"ryan2021","abstract":"Event cameras contain emerging, neuromorphic vision sensors that capture local-light​ intensity changes at each pixel, generating a stream of asynchronous events. This way of acquiring visual information constitutes a departure from traditional frame-based cameras and offers several significant advantages — low energy consumption, high temporal resolution, high dynamic range and low latency. Driver monitoring systems (DMS) are in-cabin safety systems designed to sense and understand a drivers physical and cognitive state. Event cameras are particularly suited to DMS due to their inherent advantages. This paper proposes a novel method to simultaneously detect and track faces and eyes for driver monitoring. A unique, fully convolutional recurrent neural network architecture is presented. To train this network, a synthetic event-based dataset is simulated with accurate bounding box annotations, called Neuromorphic-HELEN. Additionally, a method to detect and analyse drivers’ eye blinks is proposed, exploiting the high temporal resolution of event cameras. Behaviour of blinking provides greater insights into a driver level of fatigue or drowsiness. We show that blinks have a unique temporal signature that can be better captured by event cameras.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Ryan","given":"Cian"},{"family":"O’Sullivan","given":"Brian"},{"family":"Elrasad","given":"Amr"},{"family":"Cahill","given":"Aisling"},{"family":"Lemley","given":"Joe"},{"family":"Kielty","given":"Paul"},{"family":"Posch","given":"Christoph"},{"family":"Perot","given":"Etienne"}],"citation-key":"ryan2021","container-title":"Neural Networks","container-title-short":"Neural Networks","DOI":"10.1016/j.neunet.2021.03.019","ISSN":"0893-6080","issued":{"date-parts":[["2021",9,1]]},"page":"87-97","source":"ScienceDirect","title":"Real-time face & eye tracking and blink detection using event cameras","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0893608021001076","volume":"141"},
  {"id":"sainsbury2023","abstract":"Early identification and intervention are recognised as important elements of the clinical pathway for autism spectrum disorder (ASD). Children with ASD and attention deficit hyperactivity disorder (ADHD) may be diagnosed at a different age than children who only have one of these diagnoses. This systematic review aimed to identify the age at which children were diagnosed with both ASD and ADHD. Of the 9552 articles screened, 12 were included in the review. The findings suggest that ASD is typically diagnosed later when ADHD is present, and ADHD is typically diagnosed earlier when ASD is present. Further research is needed to understand the factors impacting a delayed ASD diagnosis and an earlier ADHD diagnosis when the two conditions co-occur.","accessed":{"date-parts":[["2024",6,20]]},"author":[{"family":"Sainsbury","given":"Willow J."},{"family":"Carrasco","given":"Kelly"},{"family":"Whitehouse","given":"Andrew J. O."},{"family":"McNeil","given":"Lauren"},{"family":"Waddington","given":"Hannah"}],"citation-key":"sainsbury2023","container-title":"Review Journal of Autism and Developmental Disorders","container-title-short":"Rev J Autism Dev Disord","DOI":"10.1007/s40489-022-00309-7","ISSN":"2195-7185","issue":"3","issued":{"date-parts":[["2023",9,1]]},"language":"en","page":"563-575","source":"Springer Link","title":"Age of Diagnosis for Co-occurring Autism and Attention Deficit Hyperactivity Disorder During Childhood and Adolescence: a Systematic Review","title-short":"Age of Diagnosis for Co-occurring Autism and Attention Deficit Hyperactivity Disorder During Childhood and Adolescence","type":"article-journal","URL":"https://doi.org/10.1007/s40489-022-00309-7","volume":"10"},
  {"id":"salazar2015","abstract":"We employed a clinical sample of young children with ASD, with and without intellectual disability, to determine the rate and type of psychiatric disorders and possible association with risk factors. We assessed 101 children (57 males, 44 females) aged 4.5–9.8 years. 90.5 % of the sample met the criteria. Most common diagnoses were: generalized anxiety disorder (66.5 %), specific phobias (52.7 %) and attention deficit hyperactivity disorder (59.1 %). Boys were more likely to have oppositional defiant disorder (OR 3.9). Higher IQ was associated with anxiety disorders (OR 2.9) and older age with agoraphobia (OR 5.8). Night terrors was associated with parental psychological distress (OR 14.2). Most young ASD children met the criteria for additional psychopathology.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Salazar","given":"Fernando"},{"family":"Baird","given":"Gillian"},{"family":"Chandler","given":"Susie"},{"family":"Tseng","given":"Evelin"},{"family":"O’sullivan","given":"Tony"},{"family":"Howlin","given":"Patricia"},{"family":"Pickles","given":"Andrew"},{"family":"Simonoff","given":"Emily"}],"citation-key":"salazar2015","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-015-2361-5","ISSN":"1573-3432","issue":"8","issued":{"date-parts":[["2015",8,1]]},"language":"en","page":"2283-2294","source":"Springer Link","title":"Co-occurring Psychiatric Disorders in Preschool and Elementary School-Aged Children with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s10803-015-2361-5","volume":"45"},
  {"id":"salvucci2000","abstract":"The process of fixation identification—separating and labeling fixations and saccades in eye-tracking protocols—is an essential part of eye-movement data analysis and can have a dramatic impact on higher-level analyses. However, algorithms for performing fixation identification are often described informally and rarely compared in a meaningful way. In this paper we propose a taxonomy of fixation identification algorithms that classifies algorithms in terms of how they utilize spatial and temporal information in eye-tracking protocols. Using this taxonomy, we describe five algorithms that are representative of different classes in the taxonomy and are based on commonly employed techniques. We then evaluate and compare these algorithms with respect to a number of qualitative characteristics. The results of these comparisons offer interesting implications for the use of the various algorithms in future work.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Salvucci","given":"Dario D."},{"family":"Goldberg","given":"Joseph H."}],"citation-key":"salvucci2000","collection-title":"ETRA '00","container-title":"Proceedings of the 2000 symposium on Eye tracking research & applications","DOI":"10.1145/355017.355028","event-place":"New York, NY, USA","ISBN":"978-1-58113-280-9","issued":{"date-parts":[["2000",11,8]]},"page":"71–78","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Identifying fixations and saccades in eye-tracking protocols","type":"paper-conference","URL":"https://doi.org/10.1145/355017.355028"},
  {"id":"saputra","abstract":"Metaverse, a combination of social media, gaming, and virtual reality technology innovation, is a new concept that has attracted the attention of various groups. This concept has also aided numerous groups of people, including the academician. As","accessed":{"date-parts":[["2025",1,16]]},"author":[{"family":"Saputra","given":"Nur Mega Aris"}],"citation-key":"saputra","container-title":"Jurnal Kajian Bimbingan dan Konseling","language":"en","source":"www.academia.edu","title":"How to Prevent Student Mental Health Problems in Metaverse Era?","type":"article-journal","URL":"https://www.academia.edu/103827113/How_to_Prevent_Student_Mental_Health_Problems_in_Metaverse_Era"},
  {"id":"sarwat2024","abstract":"In-home rehabilitation systems are a promising, potential alternative to conventional therapy for stroke survivors. Unfortunately, physiological differences between participants and sensor displacement in wearable sensors pose a significant challenge to classifier performance, particularly for people with stroke who may encounter difficulties repeatedly performing trials. This makes it challenging to create reliable in-home rehabilitation systems that can accurately classify gestures.","accessed":{"date-parts":[["2024",6,25]]},"author":[{"family":"Sarwat","given":"Hussein"},{"family":"Alkhashab","given":"Amr"},{"family":"Song","given":"Xinyu"},{"family":"Jiang","given":"Shuo"},{"family":"Jia","given":"Jie"},{"family":"Shull","given":"Peter B."}],"citation-key":"sarwat2024","container-title":"Journal of NeuroEngineering and Rehabilitation","container-title-short":"J NeuroEngineering Rehabil","DOI":"10.1186/s12984-024-01398-7","ISSN":"1743-0003","issue":"1","issued":{"date-parts":[["2024",6,12]]},"language":"en","page":"100","source":"Springer Link","title":"Post-stroke hand gesture recognition via one-shot transfer learning using prototypical networks","type":"article-journal","URL":"https://doi.org/10.1186/s12984-024-01398-7","volume":"21"},
  {"id":"sasikumar2024","abstract":"In collaborative settings where multiple individuals are tasked with completing a shared goal, understanding one’s partner’s emotional state could be crucial for achieving a successful outcome. This is particularly relevant in remote collaboration contexts, where physical distance can impede understanding, empathy, and mutual comprehension between partners. In this paper, we demonstrate representing emotional patterns from physiological data in a shared Virtual Reality (VR) environment, and explore how it impacted communication styles. A user study investigated the potential effects of this emotional representation in fostering empathetic communication during remote collaboration. The study’s findings revealed that although there was minimal variance in the workload associated with observing physiological cues, participants generally preferred monitoring their partner’s attentional state. However, with the assembly task chosen, most participants only directed a minimal proportion of their attention toward the physiological cues displayed by their partner, and were frequently uncertain of how to interpret and use the information obtained. We also discuss limitations of the research and opportunities for future work.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Sasikumar","given":"Prasanth"},{"family":"Hajika","given":"Ryo"},{"family":"Gupta","given":"Kunal"},{"family":"Gunasekaran","given":"Tamil Selvan"},{"family":"Pai","given":"Yun Suen"},{"family":"Bai","given":"Huidong"},{"family":"Nanayakkara","given":"Suranga"},{"family":"Billinghurst","given":"Mark"}],"citation-key":"sasikumar2024","container-title":"2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)","DOI":"10.1109/VR58804.2024.00096","event-title":"2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)","ISSN":"2642-5254","issued":{"date-parts":[["2024",3]]},"page":"765-773","source":"IEEE Xplore","title":"A User Study on Sharing Physiological Cues in VR Assembly Tasks","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/10494102"},
  {"id":"schmidt2018","abstract":"Affect recognition aims to detect a person's affective state based on observables, with the goal to e.g. improve human-computer interaction. Long-term stress is known to have severe implications on wellbeing, which call for continuous and automated stress monitoring systems. However, the affective computing community lacks commonly used standard datasets for wearable stress detection which a) provide multimodal high-quality data, and b) include multiple affective states. Therefore, we introduce WESAD, a new publicly available dataset for wearable stress and affect detection. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset. Furthermore, a benchmark is created on the dataset, using well-known features and standard machine learning methods. Considering the three-class classification problem ( baseline vs. stress vs. amusement ), we achieved classification accuracies of up to 80%,. In the binary case ( stress vs. non-stress ), accuracies of up to 93%, were reached. Finally, we provide a detailed analysis and comparison of the two device locations ( chest vs. wrist ) as well as the different sensor modalities.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Schmidt","given":"Philip"},{"family":"Reiss","given":"Attila"},{"family":"Duerichen","given":"Robert"},{"family":"Marberger","given":"Claus"},{"family":"Van Laerhoven","given":"Kristof"}],"citation-key":"schmidt2018","collection-title":"ICMI '18","container-title":"Proceedings of the 20th ACM International Conference on Multimodal Interaction","DOI":"10.1145/3242969.3242985","event-place":"New York, NY, USA","ISBN":"978-1-4503-5692-3","issued":{"date-parts":[["2018",10,2]]},"page":"400–408","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection","type":"paper-conference","URL":"https://doi.org/10.1145/3242969.3242985"},
  {"id":"serradilla2020","abstract":"Given the growing amount of industrial data spaces worldwide, deep learning solutions have become popular for predictive maintenance, which monitor assets to optimise maintenance tasks. Choosing the most suitable architecture for each use-case is complex given the number of examples found in literature. This work aims at facilitating this task by reviewing state-of-the-art deep learning architectures, and how they integrate with predictive maintenance stages to meet industrial companies' requirements (i.e. anomaly detection, root cause analysis, remaining useful life estimation). They are categorised and compared in industrial applications, explaining how to fill their gaps. Finally, open challenges and future research paths are presented.","accessed":{"date-parts":[["2024",8,29]]},"author":[{"family":"Serradilla","given":"Oscar"},{"family":"Zugasti","given":"Ekhi"},{"family":"Zurutuza","given":"Urko"}],"citation-key":"serradilla2020","DOI":"10.48550/arXiv.2010.03207","issued":{"date-parts":[["2020",10,7]]},"number":"arXiv:2010.03207","publisher":"arXiv","source":"arXiv.org","title":"Deep learning models for predictive maintenance: a survey, comparison, challenges and prospect","title-short":"Deep learning models for predictive maintenance","type":"article","URL":"http://arxiv.org/abs/2010.03207"},
  {"id":"serradilla2022","abstract":"Given the growing amount of industrial data in the 4th industrial revolution, deep learning solutions have become popular for predictive maintenance (PdM) tasks, which involve monitoring assets to anticipate their requirements and optimise maintenance tasks. However, given the large variety of such tasks in the literature, choosing the most suitable architecture for each use case is difficult. This work aims to facilitate this task by reviewing various state-of-the-art deep learning (DL) architectures and analysing how well they integrate with predictive maintenance stages to meet industrial companies’ requirements from a PdM perspective. This review includes a self-organising map (SOM), one-class neural network (OC-NN) and generative techniques. This article explains how to adapt DL architectures to facilitate data variability handling, model adaptability and ensemble learning, all of which are characteristics relevant to industrial requirements. In addition, this review compares the results of state-of-the-art DL architectures on a publicly available dataset to facilitate reproducibility and replicability, enabling comparisons. Furthermore, this work covers the mitigation step with deep learning models, the final PdM stage that is essential for implementing PdM systems. Moreover, state-of-the-art deep learning architectures are categorised, analysed and compared; their industrial applications are presented; and an explanation of how to combine different architectures in a solution is presented that addresses their gaps. Finally, open challenges and possible future research paths are presented and supported in this review, and current research trends are identified.","accessed":{"date-parts":[["2024",8,27]]},"author":[{"family":"Serradilla","given":"Oscar"},{"family":"Zugasti","given":"Ekhi"},{"family":"Rodriguez","given":"Jon"},{"family":"Zurutuza","given":"Urko"}],"citation-key":"serradilla2022","container-title":"Applied Intelligence","container-title-short":"Appl Intell","DOI":"10.1007/s10489-021-03004-y","ISSN":"1573-7497","issue":"10","issued":{"date-parts":[["2022",8,1]]},"language":"en","page":"10934-10964","source":"Springer Link","title":"Deep learning models for predictive maintenance: a survey, comparison, challenges and prospects","title-short":"Deep learning models for predictive maintenance","type":"article-journal","URL":"https://doi.org/10.1007/s10489-021-03004-y","volume":"52"},
  {"id":"shao2024","abstract":"Event camera is an emerging bio-inspired vision sensors that report per-pixel brightness changes asynchronously. It holds noticeable advantage of high dynamic range, high speed response, and low power budget that enable it to best capture local motions in uncontrolled environments. This motivates us to unlock the potential of event cameras for human pose estimation, as the human pose estimation with event cameras is rarely explored. Due to the novel paradigm shift from conventional frame-based cameras, however, event signals in a time interval contain very limited information, as event cameras can only capture the moving body parts and ignores those static body parts, resulting in some parts to be incomplete or even disappeared in the time interval. This paper proposes a novel densely connected recurrent architecture to address the problem of incomplete information. By this recurrent architecture, we can explicitly model not only the sequential but also non-sequential geometric consistency across time steps to accumulate information from previous frames to recover the entire human bodies, achieving a stable and accurate human pose estimation from event data. Moreover, to better evaluate our model, we collect a large-scale multimodal event-based dataset that comes with human pose annotations, which is by far the most challenging one to the best of our knowledge. The experimental results on two public datasets and our own dataset demonstrate the effectiveness and strength of our approach. Code is available online for facilitating the future research.","accessed":{"date-parts":[["2024",6,11]]},"author":[{"family":"Shao","given":"Zhanpeng"},{"family":"Wang","given":"Xueping"},{"family":"Zhou","given":"Wen"},{"family":"Wang","given":"Wuzhen"},{"family":"Yang","given":"Jianyu"},{"family":"Li","given":"Youfu"}],"citation-key":"shao2024","container-title":"Pattern Recognition","container-title-short":"Pattern Recognition","DOI":"10.1016/j.patcog.2023.110048","ISSN":"0031-3203","issued":{"date-parts":[["2024",3,1]]},"page":"110048","source":"ScienceDirect","title":"A temporal densely connected recurrent network for event-based human pose estimation","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0031320323007458","volume":"147"},
  {"id":"sharma2023","abstract":"In data fusion, various data sources are unified to get more data than a single source. Due to the increasing amount of real-time data and increasing data complexity, the traditional methods are not enough in today’s world, therefore the dependency on machine learning algorithms is increasing for data fusion. Many machine learning methods have been studied before but a structural review of machine learning algorithms in data fusion is yet to come. Therefore, it is vital to analyze and sum up the various machine learning techniques used in data fusion. This paper provides a structural analysis of machine learning techniques used in data fusion. Firstly, the paper explains the framework of machine learning and data fusion followed by various standards as well as essential machine learning techniques which are used in most of the paper, and at last, a quick introduction to all typical machine learning techniques are given for better understanding.","author":[{"family":"Sharma","given":"Muskan"},{"family":"Kushwaha","given":"Priyanka"},{"family":"Kumari","given":"Pragati"},{"family":"Kumari","given":"Pushpanjali"},{"family":"Yadav","given":"Richa"}],"citation-key":"sharma2023","container-title":"Communication and Intelligent Systems","DOI":"10.1007/978-981-99-2100-3_31","editor":[{"family":"Sharma","given":"Harish"},{"family":"Shrivastava","given":"Vivek"},{"family":"Bharti","given":"Kusum Kumari"},{"family":"Wang","given":"Lipo"}],"event-place":"Singapore","ISBN":"978-981-99-2100-3","issued":{"date-parts":[["2023"]]},"language":"en","page":"391-405","publisher":"Springer Nature","publisher-place":"Singapore","source":"Springer Link","title":"Machine Learning Techniques in Data Fusion: A Review","title-short":"Machine Learning Techniques in Data Fusion","type":"paper-conference"},
  {"id":"sharmin2018","abstract":"Smart technologies (wearable and mobile devices) show tremendous potential in the detection, diagnosis, and management of Autism Spectrum Disorder (ASD) by enabling continuous real-time data collection, identifying effective treatment strategies, and supporting intervention design and delivery. Though promising, effective utilization of smart technology in aiding ASD is still limited. We propose a set of implications to guide the design of ASD-support technology by analyzing 149 peer-reviewed articles focused on children with autism from ACM Digital Library, IEEE Xplore, and PubMed. Our analysis reveals that technology should facilitate real-time detection and identification of points-of-interest, adapt its behavior driven by the real-time affective state of the user, utilize familiar and unfamiliar features depending on user-context, and aid in revealing even minuscule progress made by children with autism. Our findings indicate that such technology should strive to blend-in with everyday objects. Moreover, gradual exposure and desensitization may facilitate successful adaptation of novel technology.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Sharmin","given":"Moushumi"},{"family":"Hossain","given":"Md Monsur"},{"family":"Saha","given":"Abir"},{"family":"Das","given":"Maitraye"},{"family":"Maxwell","given":"Margot"},{"family":"Ahmed","given":"Shameem"}],"citation-key":"sharmin2018","collection-title":"CHI '18","container-title":"Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems","DOI":"10.1145/3173574.3173676","event-place":"New York, NY, USA","ISBN":"978-1-4503-5620-6","issued":{"date-parts":[["2018",4,19]]},"page":"1–16","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"From Research to Practice: Informing the Design of Autism Support Smart Technology","title-short":"From Research to Practice","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3173574.3173676"},
  {"id":"shic2022","abstract":"Eye tracking (ET) is a powerful methodology for studying attentional processes through quantification of eye movements. The precision, usability, and cost-effectiveness of ET render it a promising platform for developing biomarkers for use in clinical trials for autism spectrum disorder (ASD).","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Shic","given":"Frederick"},{"family":"Naples","given":"Adam J."},{"family":"Barney","given":"Erin C."},{"family":"Chang","given":"Shou An"},{"family":"Li","given":"Beibin"},{"family":"McAllister","given":"Takumi"},{"family":"Kim","given":"Minah"},{"family":"Dommer","given":"Kelsey J."},{"family":"Hasselmo","given":"Simone"},{"family":"Atyabi","given":"Adham"},{"family":"Wang","given":"Quan"},{"family":"Helleman","given":"Gerhard"},{"family":"Levin","given":"April R."},{"family":"Seow","given":"Helen"},{"family":"Bernier","given":"Raphael"},{"family":"Charwaska","given":"Katarzyna"},{"family":"Dawson","given":"Geraldine"},{"family":"Dziura","given":"James"},{"family":"Faja","given":"Susan"},{"family":"Jeste","given":"Shafali Spurling"},{"family":"Johnson","given":"Scott P."},{"family":"Murias","given":"Michael"},{"family":"Nelson","given":"Charles A."},{"family":"Sabatos-DeVito","given":"Maura"},{"family":"Senturk","given":"Damla"},{"family":"Sugar","given":"Catherine A."},{"family":"Webb","given":"Sara J."},{"family":"McPartland","given":"James C."}],"citation-key":"shic2022","container-title":"Molecular Autism","container-title-short":"Molecular Autism","DOI":"10.1186/s13229-021-00482-2","ISSN":"2040-2392","issue":"1","issued":{"date-parts":[["2022",3,21]]},"page":"15","source":"BioMed Central","title":"The Autism Biomarkers Consortium for Clinical Trials: evaluation of a battery of candidate eye-tracking biomarkers for use in autism clinical trials","title-short":"The Autism Biomarkers Consortium for Clinical Trials","type":"article-journal","URL":"https://doi.org/10.1186/s13229-021-00482-2","volume":"13"},
  {"id":"shic2023","abstract":"The Selective Social Attention (SSA) task is a brief eye-tracking task involving experimental conditions varying along socio-communicative axes. Traditionally the SSA has been used to probe socially-specific attentional patterns in infants and toddlers who develop autism spectrum disorder (ASD). This current work extends these findings to preschool and school-age children., Children four-to-twelve-years-old with ASD (N=23) and a typically-developing comparison group (TD; N=25) completed the SSA task as well as standardized clinical assessments. Linear mixed models examined group and condition effects on two outcome variables: percent of time spent looking at the scene relative to scene presentation time (%Valid), and percent of time looking at the face relative to time spent looking at the scene (%Face). Age and IQ were included as covariates. Outcome variables’ relationships to clinical data were assessed via correlation analysis., The ASD group, compared to the TD group, looked less at the scene and focused less on the actress’ face during the most socially-engaging experimental conditions. Additionally, within the ASD group, %Face negatively correlated with SRS Total T-scores with a particularly strong negative correlation with the Autistic Mannerism subscale T-score., These results highlight the extensibility of the SSA to older children with ASD, including replication of between-group differences previously seen in infants and toddlers, as well as its ability to capture meaningful clinical variation within the autism spectrum across a wide developmental span inclusive of preschool and school-aged children. The properties suggest that the SSA may have broad potential as a biomarker for ASD., Previous work found that an infant’s or toddler’s performance on a simple eye-tracking task was different depending on if they had a diagnosis of ASD or not. This paper shows that the same differences exist in 4-12-year-olds and shows that performance on this task is different for those with higher ratings of autistic traits. This is an important step in being able to use a quick, easy technology like eye tracking to help clinicians identify risk or track possible changes in behavior.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Shic","given":"Frederick"},{"family":"Barney","given":"Erin C."},{"family":"Naples","given":"Adam J."},{"family":"Dommer","given":"Kelsey J."},{"family":"Chang","given":"Shou An"},{"family":"Li","given":"Beibin"},{"family":"McAllister","given":"Takumi"},{"family":"Atyabi","given":"Adham"},{"family":"Wang","given":"Quan"},{"family":"Bernier","given":"Raphael"},{"family":"Dawson","given":"Geraldine"},{"family":"Dziura","given":"James"},{"family":"Faja","given":"Susan"},{"family":"Jeste","given":"Shafali Spurling"},{"family":"Murias","given":"Michael"},{"family":"Johnson","given":"Scott P."},{"family":"Sabatos-DeVito","given":"Maura"},{"family":"Helleman","given":"Gerhard"},{"family":"Senturk","given":"Damla"},{"family":"Sugar","given":"Catherine A."},{"family":"Webb","given":"Sara Jane"},{"family":"McPartland","given":"James C."},{"family":"Chawarska","given":"Katarzyna"}],"citation-key":"shic2023","container-title":"Autism research : official journal of the International Society for Autism Research","container-title-short":"Autism Res","DOI":"10.1002/aur.3026","ISSN":"1939-3792","issue":"11","issued":{"date-parts":[["2023",11]]},"page":"2150-2159","PMCID":"PMC11003770","PMID":"37749934","source":"PubMed Central","title":"The Selective Social Attention Task in Children with ASD: Results from the Autism Biomarkers Consortium for Clinical Trials (ABC-CT) Feasibility Study","title-short":"The Selective Social Attention Task in Children with ASD","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11003770/","volume":"16"},
  {"id":"shin2022","abstract":"This study aimed to develop quantitative assessments of spontaneous movements in high-risk preterm infants based on a deep learning algorithm. Video images of spontaneous movements were recorded in very preterm infants at the term-equivalent age. The Hammersmith Infant Neurological Examination (HINE) was performed in infants at 4 months of corrected age. Joint positional data were extracted using a pretrained pose-estimation model. Complexity and similarity indices of joint angle and angular velocity in terms of sample entropy and Pearson correlation coefficient were compared between the infants with HINE < 60 and ≥ 60. Video images of spontaneous movements were recorded in 65 preterm infants at term-equivalent age. Complexity indices of joint angles and angular velocities differed between the infants with HINE < 60 and ≥ 60 and correlated positively with HINE scores in most of the joints at the upper and lower extremities (p < 0.05). Similarity indices between each joint angle or joint angular velocity did not differ between the two groups in most of the joints at the upper and lower extremities. Quantitative assessments of spontaneous movements in preterm infants are feasible using a deep learning algorithm and sample entropy. The results indicated that complexity indices of joint movements at both the upper and lower extremities can be potential candidates for detecting developmental outcomes in preterm infants.","accessed":{"date-parts":[["2025",1,22]]},"author":[{"family":"Shin","given":"Hyun Iee"},{"family":"Shin","given":"Hyung-Ik"},{"family":"Bang","given":"Moon Suk"},{"family":"Kim","given":"Don-Kyu"},{"family":"Shin","given":"Seung Han"},{"family":"Kim","given":"Ee-Kyung"},{"family":"Kim","given":"Yoo-Jin"},{"family":"Lee","given":"Eun Sun"},{"family":"Park","given":"Seul Gi"},{"family":"Ji","given":"Hye Min"},{"family":"Lee","given":"Woo Hyung"}],"citation-key":"shin2022","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-022-07139-x","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2022",2,24]]},"language":"en","page":"3138","source":"Springer Link","title":"Deep learning-based quantitative analyses of spontaneous movements and their association with early neurological development in preterm infants","type":"article-journal","URL":"https://doi.org/10.1038/s41598-022-07139-x","volume":"12"},
  {"id":"shirama2016","abstract":"We examined the factors that influence ocular fixation control in adults with autism spectrum disorder (ASD) including sensory information, individuals’ motor characteristics, and inhibitory control. The ASD group showed difficulty in maintaining fixation especially when there was no fixation target. The fixational eye movement characteristics of individuals were consistent regardless of the presence or absence of a fixation target in the controls, but not in the ASD group. Additionally, fixation stability did not correlate with an ability to suppress reflexive saccades measured by an antisaccade task. These findings suggest that ASD adults have deficits in converting alternative sensory information, such as retinal signals in the peripheral visual field or extraretinal signals, to motor commands when the foveal information is unavailable.","accessed":{"date-parts":[["2025",2,3]]},"author":[{"family":"Shirama","given":"Aya"},{"family":"Kanai","given":"Chieko"},{"family":"Kato","given":"Nobumasa"},{"family":"Kashino","given":"Makio"}],"citation-key":"shirama2016","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-015-2688-y","ISSN":"1573-3432","issue":"5","issued":{"date-parts":[["2016",5,1]]},"language":"en","page":"1613-1622","source":"Springer Link","title":"Ocular Fixation Abnormality in Patients with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s10803-015-2688-y","volume":"46"},
  {"id":"sipatchin2021","abstract":"Background: A case study is proposed to empirically test and discuss the eye-tracking status-quo hardware capabilities and limitations of an off-the-shelf virtual reality (VR) headset with embedded eye-tracking for at-home ready-to-go online usability in ophthalmology applications. Methods: The eye-tracking status-quo data quality of the HTC Vive Pro Eye is investigated with novel testing specific to objective online VR perimetry. Testing was done across a wide visual field of the head-mounted-display’s (HMD) screen and in two different moving conditions. A new automatic and low-cost Raspberry Pi system is introduced for VR temporal precision testing for assessing the usability of the HTC Vive Pro Eye as an online assistance tool for visual loss. Results: The target position on the screen and head movement evidenced limitations of the eye-tracker capabilities as a perimetry assessment tool. Temporal precision testing showed the system’s latency of 58.1 milliseconds (ms), evidencing its good potential usage as a ready-to-go online assistance tool for visual loss. Conclusions: The test of the eye-tracking data quality provides novel analysis useful for testing upcoming VR headsets with embedded eye-tracking and opens discussion regarding expanding future introduction of these HMDs into patients’ homes for low-vision clinical usability.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Sipatchin","given":"Alexandra"},{"family":"Wahl","given":"Siegfried"},{"family":"Rifai","given":"Katharina"}],"citation-key":"sipatchin2021","container-title":"Healthcare","container-title-short":"Healthcare (Basel)","DOI":"10.3390/healthcare9020180","ISSN":"2227-9032","issue":"2","issued":{"date-parts":[["2021",2,9]]},"page":"180","PMCID":"PMC7914806","PMID":"33572072","source":"PubMed Central","title":"Eye-Tracking for Clinical Ophthalmology with Virtual Reality (VR): A Case Study of the HTC Vive Pro Eye’s Usability","title-short":"Eye-Tracking for Clinical Ophthalmology with Virtual Reality (VR)","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7914806/","volume":"9"},
  {"id":"smith2022","abstract":"ObjectiveThe objective of this study was to implement a validated, university-based early detection program, the Get SET Early model, in a community-based setting. Get SET was developed to improve Screening, Evaluation, and Treatment referral practices. Specifically, its purpose was to lower the age of diagnosis and enable toddlers with autism spectrum disorder (ASD) to begin treatment by 36 months.MethodsOne hundred nine pediatric health care providers were recruited to administer the Communication and Symbolic Behavior Scales Developmental Profile Infant-Toddler Checklist at 12-month, 18-month, and 24-month well-baby visits and referred toddlers whose scores indicated the need for a developmental evaluation. Licensed psychologists were trained to provide diagnostic evaluations to toddlers as young as 12 months. Mean age of diagnosis was compared with current population rates.ResultsIn 4 years, 45,504 screens were administered at well-baby visits, and 648 children were evaluated at least 1 time. The overall median age for ASD diagnosis was 22 months, which is significantly lower than the median age reported by the CDC (57 months). For children screened at 12 months, the age of first diagnosis was significantly lower at 15 months. Of the 350 children who completed at least 1 follow-up evaluation, 323 were diagnosed with ASD or another delay, and 239 (74%) were enrolled in a treatment program.ConclusionToddlers with ASD were diagnosed nearly 3 years earlier than the most recent CDC report, which allowed children to start a treatment program by 36 months. Overall, Get SET Early was an effective strategy for improving the current approach to screening, evaluation, and treatment. Efforts to demonstrate sustainability are underway.","accessed":{"date-parts":[["2025",2,23]]},"author":[{"family":"Smith","given":"Christopher J"},{"family":"James","given":"Stephen"},{"family":"Skepnek","given":"Erica"},{"family":"Leuthe","given":"Eileen"},{"family":"Outhier","given":"Lisa Elder"},{"family":"Avelar","given":"Delia"},{"family":"Barnes","given":"Cynthia Carter"},{"family":"Bacon","given":"Elizabeth"},{"family":"Pierce","given":"Karen"}],"citation-key":"smith2022","container-title":"Journal of developmental and behavioral pediatrics","container-title-short":"J Dev Behav Pediatr","DOI":"10.1097/dbp.0000000000001130","ISSN":"1536-7312","issue":"9","issued":{"date-parts":[["2022",12,1]]},"language":"eng","page":"494-502","PMCID":"PMC9725891","PMID":"36443921","source":"Europe PMC","title":"Implementing the Get SET Early Model in a Community Setting to Lower the Age of ASD Diagnosis","type":"article-journal","URL":"https://europepmc.org/articles/PMC9725891","volume":"43"},
  {"id":"soenksen2022","abstract":"Artificial intelligence (AI) systems hold great promise to improve healthcare over the next decades. Specifically, AI systems leveraging multiple data sources and input modalities are poised to become a viable method to deliver more accurate results and deployable pipelines across a wide range of applications. In this work, we propose and evaluate a unified Holistic AI in Medicine (HAIM) framework to facilitate the generation and testing of AI systems that leverage multimodal inputs. Our approach uses generalizable data pre-processing and machine learning modeling stages that can be readily adapted for research and deployment in healthcare environments. We evaluate our HAIM framework by training and characterizing 14,324 independent models based on HAIM-MIMIC-MM, a multimodal clinical database (N=34,537 samples) containing 7,279 unique hospitalizations and 6,485 patients, spanning all possible input combinations of 4 data modalities (i.e., tabular, time-series, text, and images), 11 unique data sources and 12 predictive tasks. We show that this framework can consistently and robustly produce models that outperform similar single-source approaches across various healthcare demonstrations (by 6-33%), including 10 distinct chest pathology diagnoses, along with length-of-stay and 48-hour mortality predictions. We also quantify the contribution of each modality and data source using Shapley values, which demonstrates the heterogeneity in data modality importance and the necessity of multimodal inputs across different healthcare-relevant tasks. The generalizable properties and flexibility of our Holistic AI in Medicine (HAIM) framework could offer a promising pathway for future multimodal predictive systems in clinical and operational healthcare settings.","accessed":{"date-parts":[["2024",8,29]]},"author":[{"family":"Soenksen","given":"Luis R."},{"family":"Ma","given":"Yu"},{"family":"Zeng","given":"Cynthia"},{"family":"Boussioux","given":"Leonard D. J."},{"family":"Carballo","given":"Kimberly Villalobos"},{"family":"Na","given":"Liangyuan"},{"family":"Wiberg","given":"Holly M."},{"family":"Li","given":"Michael L."},{"family":"Fuentes","given":"Ignacio"},{"family":"Bertsimas","given":"Dimitris"}],"citation-key":"soenksen2022","container-title":"npj Digital Medicine","container-title-short":"npj Digit. Med.","DOI":"10.1038/s41746-022-00689-4","ISSN":"2398-6352","issue":"1","issued":{"date-parts":[["2022",9,20]]},"page":"149","source":"arXiv.org","title":"Integrated multimodal artificial intelligence framework for healthcare applications","type":"article-journal","URL":"http://arxiv.org/abs/2202.12998","volume":"5"},
  {"id":"soleymani2012","abstract":"MAHNOB-HCI is a multimodal database recorded in response to affective stimuli with the goal of emotion recognition and implicit tagging research. A multimodal setup was arranged for synchronized recording of face videos, audio signals, eye gaze data, and peripheral/central nervous system physiological signals. Twenty-seven participants from both genders and different cultural backgrounds participated in two experiments. In the first experiment, they watched 20 emotional videos and self-reported their felt emotions using arousal, valence, dominance, and predictability as well as emotional keywords. In the second experiment, short videos and images were shown once without any tag and then with correct or incorrect tags. Agreement or disagreement with the displayed tags was assessed by the participants. The recorded videos and bodily responses were segmented and stored in a database. The database is made available to the academic community via a web-based system. The collected data were analyzed and single modality and modality fusion results for both emotion recognition and implicit tagging experiments are reported. These results show the potential uses of the recorded modalities and the significance of the emotion elicitation protocol.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Soleymani","given":"Mohammad"},{"family":"Lichtenauer","given":"Jeroen"},{"family":"Pun","given":"Thierry"},{"family":"Pantic","given":"Maja"}],"citation-key":"soleymani2012","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/T-AFFC.2011.25","ISSN":"1949-3045","issue":"1","issued":{"date-parts":[["2012",1]]},"page":"42-55","source":"IEEE Xplore","title":"A Multimodal Database for Affect Recognition and Implicit Tagging","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/5975141","volume":"3"},
  {"id":"soltiyeva2023","abstract":"One of the biggest difficulties faced by children with Autism Spectrum Disorder during their learning process and general life, is communication and social interaction. In recent years, researchers and practitioners have invested in different approaches to improving aspects of their communication and learning. However, there is still no consolidated approach and the community is still looking for new approaches that can meet this need. Addressing this challenge, in this article we propose a novelty approach (i.e., an Adaptive Immersive Virtual Reality Training System), aiming to enrich social interaction and communication skills for children with Autism Spectrum Disorder. In this adaptive system (called My Lovely Granny’s Farm), the behavior of the virtual trainer changes depending on the mood and actions of the users (i.e., patients/learners). Additionally, we conducted an initial observational study by monitoring the behavior of children with autism in a virtual environment. In the initial study, the system was offered to users with a high degree of interactivity so that they might practice various social situations in a safe and controlled environment. The results demonstrate that the use of the system can allow patients who needed treatment to receive therapy without leaving home. Our approach is the first experience of treating children with autism in Kazakhstan and can contribute to improving the communication and social interaction of children with Autism Spectrum Disorder. We contribute to the community of educational technologies and mental health by providing a system that can improve communication among children with autism and providing insights on how to design this kind of system.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Soltiyeva","given":"Aiganym"},{"family":"Oliveira","given":"Wilk"},{"family":"Madina","given":"Alimanova"},{"family":"Adilkhan","given":"Shyngys"},{"family":"Urmanov","given":"Marat"},{"family":"Hamari","given":"Juho"}],"citation-key":"soltiyeva2023","container-title":"Education and Information Technologies","container-title-short":"Educ Inf Technol","DOI":"10.1007/s10639-023-11862-x","ISSN":"1573-7608","issue":"12","issued":{"date-parts":[["2023",12,1]]},"language":"en","page":"16887-16907","source":"Springer Link","title":"My Lovely Granny’s Farm: An immersive virtual reality training system for children with autism spectrum disorder","title-short":"My Lovely Granny’s Farm","type":"article-journal","URL":"https://doi.org/10.1007/s10639-023-11862-x","volume":"28"},
  {"id":"souchet2022","abstract":"Virtual Reality Head-Mounted Displays (HMDs) reached the consumer market and are used for learning purposes. Risks regarding visual fatigue and high cognitive load arise while using HMDs. These risks could impact learning efficiency. Visual fatigue and cognitive load can be measured with eye tracking, a technique that is progressively implemented in HMDs. Thus, we investigate how to assess visual fatigue and cognitive load via eye tracking. We conducted this review based on five research questions. We first described visual fatigue and possible cognitive overload while learning with HMDs. The review indicates that visual fatigue can be measured with blinks and cognitive load with pupil diameter based on thirty-seven included papers. Yet, distinguishing visual fatigue from cognitive load with such measures is challenging due to possible links between them. Despite measure interpretation issues, eye tracking is promising for live assessment. More researches are needed to make data interpretation more robust and document human factor risks when learning with HMDs.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Souchet","given":"Alexis D."},{"family":"Philippe","given":"Stéphanie"},{"family":"Lourdeaux","given":"Domitile"},{"family":"Leroy","given":"Laure"}],"citation-key":"souchet2022","container-title":"International Journal of Human–Computer Interaction","DOI":"10.1080/10447318.2021.1976509","ISSN":"1044-7318","issue":"9","issued":{"date-parts":[["2022",5,28]]},"page":"801–824","publisher":"Taylor & Francis","source":"Taylor and Francis+NEJM","title":"Measuring Visual Fatigue and Cognitive Load via Eye Tracking while Learning with Virtual Reality Head-Mounted Displays: A Review","title-short":"Measuring Visual Fatigue and Cognitive Load via Eye Tracking while Learning with Virtual Reality Head-Mounted Displays","type":"article-journal","URL":"https://doi.org/10.1080/10447318.2021.1976509","volume":"38"},
  {"id":"startsev2019","abstract":"Deep learning approaches have achieved breakthrough performance in various domains. However, the segmentation of raw eye-movement data into discrete events is still done predominantly either by hand or by algorithms that use hand-picked parameters and thresholds. We propose and make publicly available a small 1D-CNN in conjunction with a bidirectional long short-term memory network that classifies gaze samples as fixations, saccades, smooth pursuit, or noise, simultaneously assigning labels in windows of up to 1 s. In addition to unprocessed gaze coordinates, our approach uses different combinations of the speed of gaze, its direction, and acceleration, all computed at different temporal scales, as input features. Its performance was evaluated on a large-scale hand-labeled ground truth data set (GazeCom) and against 12 reference algorithms. Furthermore, we introduced a novel pipeline and metric for event detection in eye-tracking recordings, which enforce stricter criteria on the algorithmically produced events in order to consider them as potentially correct detections. Results show that our deep approach outperforms all others, including the state-of-the-art multi-observer smooth pursuit detector. We additionally test our best model on an independent set of recordings, where our approach stays highly competitive compared to literature methods.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Startsev","given":"Mikhail"},{"family":"Agtzidis","given":"Ioannis"},{"family":"Dorr","given":"Michael"}],"citation-key":"startsev2019","container-title":"Behavior Research Methods","container-title-short":"Behav Res","DOI":"10.3758/s13428-018-1144-2","ISSN":"1554-3528","issue":"2","issued":{"date-parts":[["2019",4,1]]},"language":"en","page":"556-572","source":"Springer Link","title":"1D CNN with BLSTM for automated classification of fixations, saccades, and smooth pursuits","type":"article-journal","URL":"https://doi.org/10.3758/s13428-018-1144-2","volume":"51"},
  {"id":"stasolla2021","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Stasolla","given":"Fabrizio"}],"citation-key":"stasolla2021","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2021.720626","ISSN":"1664-1078","issued":{"date-parts":[["2021",7,12]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Virtual Reality and Wearable Technologies to Support Adaptive Responding of Children and Adolescents With Neurodevelopmental Disorders: A Critical Comment and New Perspectives","title-short":"Virtual Reality and Wearable Technologies to Support Adaptive Responding of Children and Adolescents With Neurodevelopmental Disorders","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2021.720626/full","volume":"12"},
  {"id":"stewart2024","abstract":"English Abstract: The conceptualisation of Autism has greatly evolved over the past several decades. In this review article, we focus on several areas where our understanding of Autism has changed: (1) from a ‘narrow’ definition to a ‘wide’ diagnostic criteria; (2) from a rare to a relatively common condition, although probably still under-recognised in women and older people; (3) a condition diagnosed predominately in males to now being identified in people of all genders; (4) from something affecting children, to a lifelong condition; (5) from something discrete and distinct, to a dimensional view; (6) from one thing to many ‘Autisms’, and a compound or fractionable condition; (7) from a focus on ‘pure’ Autism, to recognition that complexity and comorbidity is the norm; and finally, (8) from conceptualising Autism purely as a developmental disorder, to recognising a neurodiversity perspective, operationalised in participatory research models. We also explore opportunities for how research can become more generalisable, including in a global context, and make suggestions for areas currently neglected in Autism research.French Abstract: La conceptualisation de l'autisme a considérablement évolué au cours des dernières décennies. Dans cet article de synthèse, nous nous concentrons sur plusieurs domaines où notre compréhension de l'autisme a changé : (1) d'une définition « étroite » à des critères diagnostiques « larges » ; (2) d'une condition rare à une condition relativement courante, bien que probablement encore sous-reconnue chez les femmes et les personnes âgées ; (3) d'une condition diagnostiquée principalement chez les hommes à une identification désormais chez les personnes de tous genres ; (4) de quelque chose qui touche les enfants à une condition tout au long de la vie ; (5) de quelque chose de discret et distinct à une vision dimensionnelle ; (6) d'une seule entité à de nombreux « autismes », et une condition composite ou fractionnable ; (7) d'une focalisation sur l'autisme « pur » à la reconnaissance que la complexité et la comorbidité sont la norme ; et enfin, (8) de la conceptualisation de l'autisme uniquement comme un trouble du développement à la reconnaissance d'une perspective de neurodiversité, opérationnalisée dans des modèles de recherche participative. Nous explorons également les opportunités pour que la recherche devienne plus généralisable, y compris dans un contexte mondial, et formulons des suggestions pour des domaines actuellement négligés dans la recherche sur l'autisme.Spanish Abstract: La conceptualización del autismo ha evolucionado considerablemente en las últimas décadas. En este artículo de síntesis, nos centramos en varios ámbitos donde nuestra comprensión del autismo ha cambiado: (1) desde una definición \"estrecha\" hacia criterios diagnósticos \"amplios\"; (2) desde una condición rara hacia una condición relativamente común, aunque probablemente aún subestimada en mujeres y personas mayores; (3) desde una condición diagnosticada principalmente en hombres hacia una identificación ahora en personas de todos los géneros; (4) desde algo que afecta solo a niños hacia una condición a lo largo de toda la vida; (5) desde algo discreto y distintivo hacia una visión dimensional; (6) desde una sola entidad hacia muchos \"autismos\", y una condición compuesta o divisible; (7) desde un enfoque en el autismo \"puro\" hacia el reconocimiento de que la complejidad y la comorbilidad son la norma; y finalmente, (8) desde la conceptualización del autismo únicamente como un trastorno del desarrollo hacia el reconocimiento de una perspectiva de neurodiversidad, operacionalizada en modelos de investigación participativa. También exploramos las oportunidades para que la investigación sea más generalizable, incluso en un contexto global, y formulamos sugerencias para áreas actualmente descuidadas en la investigación sobre el autismo.","author":[{"family":"Stewart","given":"Gavin"},{"family":"Happe","given":"Francesca"}],"citation-key":"stewart2024","container-title":"Approche Neuropsychologique des Apprentissages Chez L'Enfant","ISSN":"0999-792x","issued":{"date-parts":[["2024",3,5]]},"page":"53-61","source":"King's College London","title":"Autism – an evolving conceptualisation","type":"article-journal","volume":"188"},
  {"id":"stoffregen2022","abstract":"Pixels in an event camera operate asynchronously and independently, reporting changes in intensity as events - tuples of (x,y) position, polarity s and timestamp t at microsecond resolution. Event cameras operate at low power (≈ 5mW) and respond to changes in the scene with a latency on the order of microseconds. These properties make event cameras an exciting candidate for eye tracking sensors on mobile platforms such as Augmented/Virtual Reality (AR/VR) headsets, since these systems have hard real-time and power constraints. One proven method for eye tracking and gaze estimation is corneal glint detection. We exploit the fact that corneal glint tracking only requires a sparse set of pixels in the image, by making use of the natural sparsity of event cameras, which only detect changes in the scene. To enhance this effect, we design an illumination scheme, Coded Differential Lighting, which enhances specular reflections, suppresses all other events, and solves the light-to-glint correspondence. This is the first purely event-based corneal glint detection and tracking algorithm, which operates on standard hardware at kHz sampling rate.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Stoffregen","given":"Timo"},{"family":"Daraei","given":"Hossein"},{"family":"Robinson","given":"Clare"},{"family":"Fix","given":"Alexander"}],"citation-key":"stoffregen2022","container-title":"2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","DOI":"10.1109/WACV51458.2022.00399","event-title":"2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)","ISSN":"2642-9381","issued":{"date-parts":[["2022",1]]},"page":"3937-3945","source":"IEEE Xplore","title":"Event-Based Kilohertz Eye Tracking using Coded Differential Lighting","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9706617"},
  {"id":"stokes2022","abstract":"Objective:\nDistractions inordinately impair attention in children with Attention-Deficit Hyperactivity Disorder (ADHD) but examining this behavior under real-life conditions poses a challenge for researchers and clinicians. Virtual reality (VR) technologies may mitigate the limitations of traditional laboratory methods by providing a more ecologically relevant experience. The use of eye-tracking measures to assess attentional functioning in a VR context in ADHD is novel. In this proof of principle project, we evaluate the temporal dynamics of distraction via eye-tracking measures in a VR classroom setting with 20 children diagnosed with ADHD between 8 and 12 years of age.\n\nMethod:\nWe recorded continuous eye movements while participants performed math, Stroop, and continuous performance test (CPT) tasks with a series of “real-world” classroom distractors presented. We analyzed the impact of the distractors on rates of on-task performance and on-task, eye-gaze (i.e., looking at a classroom whiteboard) versus off-task eye-gaze (i.e., looking away from the whiteboard).\n\nResults:\nWe found that while children did not always look at distractors themselves for long periods of time, the presence of a distractor disrupted on-task gaze at task-relevant whiteboard stimuli and lowered rates of task performance. This suggests that children with attention deficits may have a hard time returning to tasks once those tasks are interrupted, even if the distractor itself does not hold attention. Eye-tracking measures within the VR context can reveal rich information about attentional disruption.\n\nConclusions:\nLeveraging virtual reality technology in combination with eye-tracking measures is well-suited to advance the understanding of mechanisms underlying attentional impairment in naturalistic settings. Assessment within these immersive and well-controlled simulated environments provides new options for increasing our understanding of distractibility and its potential impact on the development of interventions for children with ADHD.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Stokes","given":"Jared D."},{"family":"Rizzo","given":"Albert"},{"family":"Geng","given":"Joy J."},{"family":"Schweitzer","given":"Julie B."}],"citation-key":"stokes2022","container-title":"Frontiers in virtual reality","container-title-short":"Front Virtual Real","DOI":"10.3389/frvir.2022.855895","ISSN":"2673-4192","issued":{"date-parts":[["2022",3]]},"page":"855895","PMCID":"PMC9119405","PMID":"35601272","source":"PubMed Central","title":"Measuring Attentional Distraction in Children With ADHD Using Virtual Reality Technology With Eye-Tracking","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9119405/","volume":"3"},
  {"id":"stretton2024","abstract":"Background\nThe shortage of nursing and healthcare clinical placements has prompted the investigation of ways to supplement authentic learning. Mobile mixed reality has become increasingly available, however, the affordances and design principles for the facilitation of critical thinking are yet to be explored.\nObjective\nTo examine how mobile mixed reality facilitates critical thinking in nursing and healthcare higher education.\nDesign\nSystematic review.\nReview methods\nA search in seven databases (MEDLINE, PsychINFO, AMED, ERIC, Scopus, Cochrane, and Web of Science) was conducted with 3488 titles and abstracts screened. The quality of the included studies was evaluated using the Mixed Methods Assessment Tool (MMAT).\nResults\nA total of 12 studies with 1108 participants were included. The breadth of healthcare disciplines was limited to five disciplines that utilised bespoke scenarios on head-mounted displays. Most scenarios were emergency or critical response, with limited time for pre-brief, debrief, or overall user time. Only two studies directly measured critical thinking, with others including indirect reference to diagnoses, interpretation, analysis, or evaluation of healthcare scenarios. Affordances and design principles for the future development of mobile mixed reality for critical thinking in nursing and healthcare higher education are identified.\nConclusions\nWhile some pedagogical affordances of mobile mixed reality can be identified in a narrow number of healthcare disciplines, there remain to be limited valid measures of critical thinking used to quantify effectiveness. Future studies would benefit from considering scenarios beyond emergency and critical responses, including longitudinal studies that reflect the development of critical thinking over time, and exploration of co-designed scenarios with and by nursing and healthcare students.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Stretton","given":"Todd"},{"family":"Cochrane","given":"Thomas"},{"family":"Sevigny","given":"Charles"},{"family":"Rathner","given":"Joseph"}],"citation-key":"stretton2024","container-title":"Nurse Education Today","container-title-short":"Nurse Education Today","DOI":"10.1016/j.nedt.2023.106072","ISSN":"0260-6917","issued":{"date-parts":[["2024",2,1]]},"page":"106072","source":"ScienceDirect","title":"Exploring mobile mixed reality for critical thinking in nursing and healthcare education: A systematic review","title-short":"Exploring mobile mixed reality for critical thinking in nursing and healthcare education","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0260691723003660","volume":"133"},
  {"id":"sun","abstract":"Mass personalisation production is one of the strategic priorities for the next transformation of the production paradigm and market economy. With the purpose of offering personalised products to satisfy customers on an individual basis, tacit knowledge rooted in individuals has become increasingly accepted as an integral part of product design. This paper aims to explore the state-of-the-art in tacit knowledge management with a product design focus. Particularly, methods for tacit knowledge acquisition, transfer, and reuse are reviewed and analysed. Research on tacit knowledge acquisition is mainly dedicated to making tacit knowledge explicit. In knowledge transfer, both formal and informal approaches have been adopted to enable knowledge circulation. Research on tacit knowledge reuse is much less and scattered, and the main work focuses on user modelling and the reuse of empirical knowledge. Five challenges of tacit knowledge management are identified in this paper: lack of unified tacit knowledge definition, massive heterogeneous data, authenticity and completeness verification, uncertainty and gaps in bridging tacit knowledge management and personalised design, lack of practical knowledge sharing and inheritance tools. To fill these research gaps, five thematic future directions are suggested with possible visions to facilitate knowledge circulation, customer co-creation and innovation in mass personalised design.","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Sun","given":"Xiaoguang"},{"family":"Huang","given":"Rong"},{"family":"Jiang","given":"Ziqi"},{"family":"Lu","given":"Jin"},{"family":"Yang","given":"Sheng"}],"citation-key":"sun","container-title":"Journal of Engineering Design","DOI":"10.1080/09544828.2023.2301232","ISSN":"0954-4828","issue":"0","page":"1-38","publisher":"Taylor & Francis","source":"Taylor and Francis+NEJM","title":"On tacit knowledge management in product design: status, challenges, and trends","title-short":"On tacit knowledge management in product design","type":"article-journal","URL":"https://doi.org/10.1080/09544828.2023.2301232","volume":"0"},
  {"id":"sun2024","abstract":"Introduction\nEarly identification of Autism Spectrum Disorder (ASD) is critical for effective intervention. Restricted interests (RIs), a subset of repetitive behaviors, are a prominent but underutilized domain for early ASD diagnosis. This study aimed to identify objective biomarkers for ASD by integrating electroencephalography (EEG) and eye-tracking (ET) to analyze toddlers’ visual attention and cortical responses to RI versus neutral interest (NI) objects.\n\nMethods\nThe study involved 59 toddlers aged 2-4 years, including 32 with ASD and 27 non-ASD controls. Participants underwent a 24-object passive viewing paradigm, featuring RI (e.g., transportation items) and NI objects (e.g., balloons). ET metrics (fixation time and pupil size) and EEG time-frequency (TF) power in theta (4-8 Hz) and alpha (8-13 Hz) bands were analyzed. Statistical methods included logistic regression models to assess the predictive potential of combined EEG and ET biomarkers.\n\nResults\nToddlers with ASD exhibited significantly increased fixation times and pupil sizes for RI objects compared to NI objects, alongside distinct EEG patterns with elevated theta and reduced alpha power in occipital regions during RI stimuli. The multimodal logistic regression model, incorporating EEG and ET metrics, achieved an area under the curve (AUC) of 0.75, demonstrating robust predictive capability for ASD.\n\nDiscussion\nThis novel integration of ET and EEG metrics highlights the potential of RIs as diagnostic markers for ASD. The observed neural and attentional distinctions underscore the utility of multimodal biomarkers for early diagnosis and personalized intervention strategies. Future work should validate findings across broader age ranges and diverse populations.","accessed":{"date-parts":[["2025",1,14]]},"author":[{"family":"Sun","given":"Binbin"},{"family":"Calvert","given":"Elombe Issa"},{"family":"Ye","given":"Alyssa"},{"family":"Mao","given":"Heng"},{"family":"Liu","given":"Kevin"},{"family":"Wang","given":"Raymond Kong"},{"family":"Wang","given":"Xin-Yuan"},{"family":"Wu","given":"Zhi-Liu"},{"family":"Wei","given":"Zhen"},{"family":"Kong","given":"Xue-jun"}],"citation-key":"sun2024","container-title":"Frontiers in Neuroscience","container-title-short":"Front Neurosci","DOI":"10.3389/fnins.2024.1502045","ISSN":"1662-4548","issued":{"date-parts":[["2024",11,27]]},"page":"1502045","PMCID":"PMC11631861","PMID":"39664447","source":"PubMed Central","title":"Interest paradigm for early identification of autism spectrum disorder: an analysis from electroencephalography combined with eye tracking","title-short":"Interest paradigm for early identification of autism spectrum disorder","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11631861/","volume":"18"},
  {"id":"tabbaa2022","abstract":"The paper introduces a multimodal affective dataset named VREED (VR Eyes: Emotions Dataset) in which emotions were triggered using immersive 360° Video-Based Virtual Environments (360-VEs) delivered via Virtual Reality (VR) headset. Behavioural (eye tracking) and physiological signals (Electrocardiogram (ECG) and Galvanic Skin Response (GSR)) were captured, together with self-reported responses, from healthy participants (n=34) experiencing 360-VEs (n=12, 1--3 min each) selected through focus groups and a pilot trial. Statistical analysis confirmed the validity of the selected 360-VEs in eliciting the desired emotions. Preliminary machine learning analysis was carried out, demonstrating state-of-the-art performance reported in affective computing literature using non-immersive modalities. VREED is among the first multimodal VR datasets in emotion recognition using behavioural and physiological signals. VREED is made publicly available on Kaggle1. We hope that this contribution encourages other researchers to utilise VREED further to understand emotional responses in VR and ultimately enhance VR experiences design in applications where emotional elicitation plays a key role, i.e. healthcare, gaming, education, etc.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Tabbaa","given":"Luma"},{"family":"Searle","given":"Ryan"},{"family":"Bafti","given":"Saber Mirzaee"},{"family":"Hossain","given":"Md Moinul"},{"family":"Intarasisrisawat","given":"Jittrapol"},{"family":"Glancy","given":"Maxine"},{"family":"Ang","given":"Chee Siang"}],"citation-key":"tabbaa2022","container-title":"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.","DOI":"10.1145/3495002","issue":"4","issued":{"date-parts":[["2022",12,30]]},"page":"178:1–178:20","source":"ACM Digital Library","title":"VREED: Virtual Reality Emotion Recognition Dataset Using Eye Tracking & Physiological Measures","title-short":"VREED","type":"article-journal","URL":"https://doi.org/10.1145/3495002","volume":"5"},
  {"id":"tafasca2023","abstract":"Gaze behaviors such as eye-contact or shared attention are important markers for diagnosing developmental disorders in children. While previous studies have looked at some of these elements, the analysis is usually performed on private datasets and is restricted to lab settings. Furthermore, all publicly available gaze target prediction benchmarks mostly contain instances of adults, which makes models trained on them less applicable to scenarios with young children. In this paper, we propose the first study for predicting the gaze target of children and interacting adults. To this end, we introduce the ChildPlay dataset: a curated collection of short video clips featuring children playing and interacting with adults in uncontrolled environments (e.g. kindergarten, therapy centers, preschools etc.), which we annotate with rich gaze information. We further propose a new model for gaze target prediction that is geometrically grounded by explicitly identifying the scene parts in the 3D field of view (3DFoV) of the person, leveraging recent geometry preserving depth inference methods. Our model achieves state of the art results on benchmark datasets and ChildPlay. Furthermore, results show that looking at faces prediction performance on children is much worse than on adults, and can be significantly improved by fine-tuning models using child gaze annotations. Our dataset and models will be made publicly available.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Tafasca","given":"Samy"},{"family":"Gupta","given":"Anshul"},{"family":"Odobez","given":"Jean-Marc"}],"citation-key":"tafasca2023","DOI":"10.48550/arXiv.2307.01630","issued":{"date-parts":[["2023",7,4]]},"number":"arXiv:2307.01630","publisher":"arXiv","source":"arXiv.org","title":"ChildPlay: A New Benchmark for Understanding Children's Gaze Behaviour","title-short":"ChildPlay","type":"article","URL":"http://arxiv.org/abs/2307.01630"},
  {"id":"tafasca2023a","abstract":"Nowadays, 1 in 36 children is diagnosed with autism spectrum disorder (ASD) according to the Centers for Disease Control and Prevention (CDC) [52], which makes this condition one of the most prevalent neurodevelopmental disorders. For children on the autism spectrum who face substantial developmental delays, the trajectory of their cognitive growth can be markedly improved by interventions if the condition is identified early. Therefore, there is a critical need for more scalable screening and diagnostic tools, as well as the need to improve phenotyping to refine estimates of ASD symptoms in children. Here, we introduce AI4Autism: a 4-year project funded by the Swiss National Science Foundation, which aims to address the needs outlined above. In this project, we examine the potential of digital sensing to provide automated measures of the extended autism phenotype. This is accomplished using multimodal techniques based on computer vision and Internet of Things sensing, for the purpose of stratifying autism subtypes in ways that would allow for precision medicine. We present an overview of our main results so far, introducing datasets and annotations that we intend to make publicly available, as well as methods and algorithms for analyzing children’s behaviors and producing an ASD diagnosis.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Tafasca","given":"Samy"},{"family":"Gupta","given":"Anshul"},{"family":"Kojovic","given":"Nada"},{"family":"Gelsomini","given":"Mirko"},{"family":"Maillart","given":"Thomas"},{"family":"Papandrea","given":"Michela"},{"family":"Schaer","given":"Marie"},{"family":"Odobez","given":"Jean-Marc"}],"citation-key":"tafasca2023a","collection-title":"ICMI '23 Companion","container-title":"Companion Publication of the 25th International Conference on Multimodal Interaction","DOI":"10.1145/3610661.3616239","event-place":"New York, NY, USA","ISBN":"979-8-4007-0321-8","issued":{"date-parts":[["2023",10,9]]},"page":"414–425","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"The AI4Autism Project: A Multimodal and Interdisciplinary Approach to Autism Diagnosis and Stratification","title-short":"The AI4Autism Project","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3610661.3616239"},
  {"id":"tahrisqalli2023","abstract":"Eye tracking technology has emerged as a valuable tool in the field of medicine, offering a wide range of applications across various disciplines. This perspective article aims to provide a comprehensive overview of the diverse applications of eye tracking technology in medical practice.By summarizing the latest research findings, this article explores the potential of eye tracking technology in enhancing diagnostic accuracy, assessing and improving medical performance, as well as improving rehabilitation outcomes. Additionally, it highlights the role of eye tracking in neurology, cardiology, pathology, surgery, as well as rehabilitation, offering objective measures for various medical conditions. Furthermore, the article discusses the utility of eye tracking in autism spectrum disorders, attention-deficit/hyperactivity disorder (ADHD), and human-computer interaction in medical simulations and training. Ultimately, this perspective article underscores the transformative impact of eye tracking technology on medical practice and suggests future directions for its continued development and integration.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Tahri Sqalli","given":"Mohammed"},{"family":"Aslonov","given":"Begali"},{"family":"Gafurov","given":"Mukhammadjon"},{"family":"Mukhammadiev","given":"Nurmukhammad"},{"family":"Sqalli Houssaini","given":"Yahya"}],"citation-key":"tahrisqalli2023","container-title":"Frontiers in Medical Technology","container-title-short":"Front. Med. Technol.","DOI":"10.3389/fmedt.2023.1253001","ISSN":"2673-3129","issued":{"date-parts":[["2023",11,17]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Eye tracking technology in medical practice: a perspective on its diverse applications","title-short":"Eye tracking technology in medical practice","type":"article-journal","URL":"https://www.frontiersin.org/articles/10.3389/fmedt.2023.1253001","volume":"5"},
  {"id":"tevanov2017","abstract":"Doctor-patient relationship is mostly build on effective communication which plays an important role in delivering proper health care. Doctors have the duty to provide appropriate and sufficient information to the patient, concerning his medical condition and the available treatment options. The breakdown between doctor-patient relationship is the cause of majority of patients' complaints and aversions. Using customized 3D printed models for each patient and having the conversation and the explanations needed, based on the palpable particularities of the patient's medical condition, helps towards a more efficient communication and a better understanding of the ailment and the treatment's outcomes, thus reducing patients' insecurities to the medical act, preventing complaints, dissatisfaction and malpractice accusations.","author":[{"family":"Tevanov","given":"Iulia"},{"family":"Liciu","given":"Eduard"},{"family":"Chirila","given":"Marius"},{"family":"Dusca","given":"Andrei"},{"family":"Ulici","given":"Alexandru"}],"citation-key":"tevanov2017","container-title":"Romanian Journal of Legal Medicine","container-title-short":"Romanian Journal of Legal Medicine","DOI":"10.4323/rjlm.2017.279","issued":{"date-parts":[["2017",10,31]]},"page":"279-282","source":"ResearchGate","title":"The use of 3D printing in improving patient-doctor relationship and malpractice prevention","type":"article-journal","volume":"25"},
  {"id":"tian2021","abstract":"Previous studies have suggested that virtual reality (VR) can elicit emotions in different visual modes using 2D or 3D headsets. However, the effects on emotional arousal by using these two visual modes have not been comprehensively investigated, and the underlying neural mechanisms are not yet clear. This paper presents a cognitive psychological experiment that was conducted to analyze how these two visual modes impact emotional arousal. Forty volunteers were recruited and were randomly assigned to two groups. They were asked to watch a series of positive, neutral and negative short VR videos in 2D and 3D. Multichannel electroencephalograms (EEG) and skin conductance responses (SCR) were recorded simultaneously during their participation. The results indicated that emotional stimulation was more intense in the 3D environment due to the improved perception of the environment; greater emotional arousal was generated; and higher beta (21–30 Hz) EEG power was identified in 3D than in 2D. We also found that both hemispheres were involved in stereo vision processing and that brain lateralization existed in the processing.","accessed":{"date-parts":[["2024",11,25]]},"author":[{"family":"Tian","given":"Feng"},{"family":"Hua","given":"Minlei"},{"family":"Zhang","given":"Wenrui"},{"family":"Li","given":"Yingjie"},{"family":"Yang","given":"Xiaoli"}],"citation-key":"tian2021","container-title":"PLOS ONE","container-title-short":"PLOS ONE","DOI":"10.1371/journal.pone.0256211","ISSN":"1932-6203","issue":"9","issued":{"date-parts":[["2021",9,9]]},"language":"en","page":"e0256211","publisher":"Public Library of Science","source":"PLoS Journals","title":"Emotional arousal in 2D versus 3D virtual reality environments","type":"article-journal","URL":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0256211","volume":"16"},
  {"id":"tokgoz2023","abstract":"Advancements in facial plastic surgery optimal outcome attainment by using simulation and optimization efforts are progressing as technology advances. Computed tomography (CT) and magnetic resonance imaging (MRI) are the technologies applied in this area of interest while technologies such as virtual and augmented reality applications as well as advanced manufacturing techniques further advanced simulation and surgical planning aspects of plastic surgery. In this work, we will outline examples and review technologies used for facial plastic surgery that helped to improve simulation and optimization aspects of the plastic surgery processes.","accessed":{"date-parts":[["2024",9,15]]},"author":[{"family":"Tokgöz","given":"Emre"},{"family":"Carro","given":"Marina A."}],"citation-key":"tokgoz2023","container-title":"Cosmetic and Reconstructive Facial Plastic Surgery: A Review of Medical and Biomedical Engineering and Science Concepts","DOI":"10.1007/978-3-031-31168-0_7","editor":[{"family":"Tokgöz","given":"Emre"},{"family":"Carro","given":"Marina A."}],"event-place":"Cham","ISBN":"978-3-031-31168-0","issued":{"date-parts":[["2023"]]},"language":"en","page":"231-256","publisher":"Springer Nature Switzerland","publisher-place":"Cham","source":"Springer Link","title":"Cosmetic and Reconstructive Facial Plastic Surgery Related Simulation and Optimization Efforts","type":"chapter","URL":"https://doi.org/10.1007/978-3-031-31168-0_7"},
  {"id":"tomasev2020","abstract":"Advances in machine learning (ML) and artificial intelligence (AI) present an opportunity to build better tools and solutions to help address some of the world’s most pressing challenges, and deliver positive social impact in accordance with the priorities outlined in the United Nations’ 17 Sustainable Development Goals (SDGs). The AI for Social Good (AI4SG) movement aims to establish interdisciplinary partnerships centred around AI applications towards SDGs. We provide a set of guidelines for establishing successful long-term collaborations between AI researchers and application-domain experts, relate them to existing AI4SG projects and identify key opportunities for future AI applications targeted towards social good.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Tomašev","given":"Nenad"},{"family":"Cornebise","given":"Julien"},{"family":"Hutter","given":"Frank"},{"family":"Mohamed","given":"Shakir"},{"family":"Picciariello","given":"Angela"},{"family":"Connelly","given":"Bec"},{"family":"Belgrave","given":"Danielle C. M."},{"family":"Ezer","given":"Daphne"},{"family":"Haert","given":"Fanny Cachat","dropping-particle":"van der"},{"family":"Mugisha","given":"Frank"},{"family":"Abila","given":"Gerald"},{"family":"Arai","given":"Hiromi"},{"family":"Almiraat","given":"Hisham"},{"family":"Proskurnia","given":"Julia"},{"family":"Snyder","given":"Kyle"},{"family":"Otake-Matsuura","given":"Mihoko"},{"family":"Othman","given":"Mustafa"},{"family":"Glasmachers","given":"Tobias"},{"family":"Wever","given":"Wilfried","dropping-particle":"de"},{"family":"Teh","given":"Yee Whye"},{"family":"Khan","given":"Mohammad Emtiyaz"},{"family":"Winne","given":"Ruben De"},{"family":"Schaul","given":"Tom"},{"family":"Clopath","given":"Claudia"}],"citation-key":"tomasev2020","container-title":"Nature Communications","container-title-short":"Nat Commun","DOI":"10.1038/s41467-020-15871-z","ISSN":"2041-1723","issue":"1","issued":{"date-parts":[["2020",5,18]]},"language":"en","license":"2020 Crown","page":"2468","publisher":"Nature Publishing Group","source":"www.nature.com","title":"AI for social good: unlocking the opportunity for positive impact","title-short":"AI for social good","type":"article-journal","URL":"https://www.nature.com/articles/s41467-020-15871-z","volume":"11"},
  {"id":"tsai2007","abstract":"Most research focuses on actual affect, or the affective states that people actually feel. In this article, I demonstrate the importance and utility of studying ideal affect, or the affective states that people ideally want to feel. First, I define ideal affect and describe the cultural causes and behavioral consequences of ideal affect. To illustrate these points, I compare American and East Asian cultures, which differ in their valuation of high-arousal positive affective states (e.g., excitement, enthusiasm) and low-arousal positive affective states (e.g., calm, peacefulness). I then introduce affect valuation theory, which integrates ideal affect with current models of affect and emotion and, in doing so, provides a new framework for understanding how cultural and temperamental factors may shape affect and behavior. (PsycINFO Database Record (c) 2016 APA, all rights reserved)","author":[{"family":"Tsai","given":"Jeanne L."}],"citation-key":"tsai2007","container-title":"Perspectives on Psychological Science","DOI":"10.1111/j.1745-6916.2007.00043.x","event-place":"United Kingdom","ISSN":"1745-6924","issue":"3","issued":{"date-parts":[["2007"]]},"page":"242-259","publisher":"Blackwell Publishing","publisher-place":"United Kingdom","source":"APA PsycNet","title":"Ideal affect: Cultural causes and behavioral consequences","title-short":"Ideal affect","type":"article-journal","volume":"2"},
  {"id":"tubio-fungueirino2021","abstract":"Autism spectrum disorder (ASD) is a neurodevelopmental disorder with increasing prevalence, and a male-to-female ratio of 4:1. Research has been suggesting that discrepancy in prevalence may be due to the fact that females camouflage their symptoms. In this study, we aimed to systematically review evidence on the camouflage effect in females with ASD. Following the PRISMA guidelines, we reviewed empirical research published from January 2009 to September 2019 on PubMed, Web of Science, PsychInfo and Scopus databases. Thirteen empirical articles were included in this review. Overall, evidence supports that camouflaging seems to be an adaptive mechanism for females with ASD, despite the negative implications of these behaviours in their daily life.","accessed":{"date-parts":[["2025",2,13]]},"author":[{"family":"Tubío-Fungueiriño","given":"María"},{"family":"Cruz","given":"Sara"},{"family":"Sampaio","given":"Adriana"},{"family":"Carracedo","given":"Angel"},{"family":"Fernández-Prieto","given":"Montse"}],"citation-key":"tubio-fungueirino2021","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-020-04695-x","ISSN":"1573-3432","issue":"7","issued":{"date-parts":[["2021",7,1]]},"language":"en","page":"2190-2199","source":"Springer Link","title":"Social Camouflaging in Females with Autism Spectrum Disorder: A Systematic Review","title-short":"Social Camouflaging in Females with Autism Spectrum Disorder","type":"article-journal","URL":"https://doi.org/10.1007/s10803-020-04695-x","volume":"51"},
  {"id":"tuker2024","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Tuker","given":"Cetin"}],"citation-key":"tuker2024","container-title":"Encyclopedia of Computer Graphics and Games","DOI":"10.1007/978-3-031-23161-2_173","editor":[{"family":"Lee","given":"Newton"}],"event-place":"Cham","ISBN":"978-3-031-23161-2","issued":{"date-parts":[["2024"]]},"language":"en","page":"1904-1912","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"Training Spatial Skills with Virtual Reality and Augmented Reality","type":"chapter","URL":"https://doi.org/10.1007/978-3-031-23161-2_173"},
  {"id":"uddin2023","abstract":"Recent advancements in the domain of virtual reality have culminated in the development of the Metaverse, a comprehensive virtual environment fostering interactions among individuals and digital entities. This study undertakes an analytical exploration of the Metaverse’s implications on mental health, overall well-being, and disability with a focused application to the tourism sector. The constructed model incorporates variables such as activity type within the Metaverse, usage frequency, and an individual’s existing mental health state and consideration for disability. Using Habitat Simulator and the Oculus Rift simulator, the research simulates diverse scenarios to discern the Metaverse’s influence on mental health, including its impact on individuals with disabilities in a tourism context. Our findings reveal a dichotomous impact: the nature of the engaged activity governs whether the effects on mental health and well-being, including those specific to disability, are beneficial or detrimental. The present research enhances the understanding of the Metaverse’s impact on mental health, well-being, and disability, and its potential to transform conventional tourism practices and marketing strategies. By emphasizing the activity type within its impact studies, the research provides insights for enhancing the beneficial effects and mitigating the harmful repercussions of the Metaverse, especially in tourism. The study also underscores the importance of establishing monitoring systems and personalized interventions to safeguard individuals’ well-being in the Metaverse, capitalizing on its potential to augment tourism experiences. This bears significance for policymakers, mental health practitioners, and tourism industry professionals in their collective efforts to encourage responsible usage and maximize the positive effects of the Metaverse. In contributing to the wider comprehension of the psychological effects of nascent technologies, this research accentuates their implications for individuals and industries, with a specific emphasis on the impact of the Metaverse on mental health, overall well-being, and disability in the tourism sector.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Ud Din","given":"Ikram"},{"family":"Almogren","given":"Ahmad"}],"citation-key":"uddin2023","container-title":"Information Technology & Tourism","container-title-short":"Inf Technol Tourism","DOI":"10.1007/s40558-023-00259-8","ISSN":"1943-4294","issue":"3","issued":{"date-parts":[["2023",9,1]]},"language":"en","page":"367-389","source":"Springer Link","title":"Exploring the psychological effects of Metaverse on mental health and well-being","type":"article-journal","URL":"https://doi.org/10.1007/s40558-023-00259-8","volume":"25"},
  {"id":"usmani2022","abstract":"The metaverse and non-fungible tokens (NFTs) were some of the hottest tech terms in 2021, according to a Google Trends search. Our review aims to describe the metaverse and NFTs in the context of their potential application in the treatment of mental health disorders. Advancements in technology have been changing human lives at an ever-increasing pace. Metaverse, also known as the three-dimensional (3D) internet, is the convergence of virtual reality (VR) and physical reality in a digital space. It could potentially change the internet as we know it, with NFTs as the key building blocks in the new expansive virtual ecosystem. This immersive 3D virtual world boasts the features of the real world with the added ability to change the surrounding environment according to individual needs and requirements. VR, augmented reality (AR) and mixed reality (MR) have been employed as tools in the treatment of various mental health disorders for the past decade. Studies have reported positive results on their effectiveness in the diagnosis and treatment of mental health disorders. VR/AR/MR have been hailed as a solution to the acute shortage of mental health professionals and the lack of access to mental healthcare. But, on the flip side, young adults tend to spend a significant amount of time playing 3D immersive games and using social media, which can lead to insecurity, anxiety, depression, and behavioural addiction. Additionally, endless scrolling through social media platforms negatively affects individuals' attention span as well as aggravating the symptoms of adolescents with attention deficit hyperactivity disorder., We aimed to explore the ramifications of expanding applications of the metaverse on mental health. So far, no other review has explored the future of mental health in the context of the metaverse.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Usmani","given":"Sadia Suhail"},{"family":"Sharath","given":"Medha"},{"family":"Mehendale","given":"Meghana"}],"citation-key":"usmani2022","container-title":"General Psychiatry","container-title-short":"Gen Psychiatr","DOI":"10.1136/gpsych-2022-100825","ISSN":"2517-729X","issue":"4","issued":{"date-parts":[["2022",7,22]]},"page":"e100825","PMCID":"PMC9472101","PMID":"36189180","source":"PubMed Central","title":"Future of mental health in the metaverse","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9472101/","volume":"35"},
  {"id":"vabalas2020","abstract":"Autism is a developmental condition currently identified by experts using observation, interview, and questionnaire techniques and primarily assessing social and communication deficits. Motor function and movement imitation are also altered in autism and can be measured more objectively. In this study, motion and eye tracking data from a movement imitation task were combined with supervised machine learning methods to classify 22 autistic and 22 non-autistic adults. The focus was on a reliable machine learning application. We have used nested validation to develop models and further tested the models with an independent data sample. Feature selection was aimed at selection stability to assure result interpretability. Our models predicted diagnosis with 73% accuracy from kinematic features, 70% accuracy from eye movement features and 78% accuracy from combined features. We further explored features which were most important for predictions to better understand movement imitation differences in autism. Consistent with the behavioural results, most discriminative features were from the experimental condition in which non-autistic individuals tended to successfully imitate unusual movement kinematics while autistic individuals tended to fail. Machine learning results show promise that future work could aid in the diagnosis process by providing quantitative tests to supplement current qualitative ones.","accessed":{"date-parts":[["2024",6,19]]},"author":[{"family":"Vabalas","given":"Andrius"},{"family":"Gowen","given":"Emma"},{"family":"Poliakoff","given":"Ellen"},{"family":"Casson","given":"Alexander J."}],"citation-key":"vabalas2020","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-020-65384-4","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2020",5,20]]},"language":"en","license":"2020 The Author(s)","page":"8346","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Applying Machine Learning to Kinematic and Eye Movement Features of a Movement Imitation Task to Predict Autism Diagnosis","type":"article-journal","URL":"https://www.nature.com/articles/s41598-020-65384-4","volume":"10"},
  {"id":"valenza2012","abstract":"This paper reports on a new methodology for the automatic assessment of emotional responses. More specifically, emotions are elicited in agreement with a bidimensional spatial localization of affective states, that is, arousal and valence dimensions. A dedicated experimental protocol was designed and realized where specific affective states are suitably induced while three peripheral physiological signals, i.e., ElectroCardioGram (ECG), ElectroDermal Response (EDR), and ReSPiration activity (RSP), are simultaneously acquired. A group of 35 volunteers was presented with sets of images gathered from the International Affective Picture System (IAPS) having five levels of arousal and five levels of valence, including a neutral reference level in both. Standard methods as well as nonlinear dynamic techniques were used to extract sets of features from the collected signals. The goal of this paper is to implement an automatic multiclass arousal/valence classifier comparing performance when extracted features from nonlinear methods are used as an alternative to standard features. Results show that, when nonlinearly extracted features are used, the percentages of successful recognition dramatically increase. A good recognition accuracy (>;90 percent) after 40-fold cross-validation steps for both arousal and valence classes was achieved by using the Quadratic Discriminant Classifier (QDC).","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Valenza","given":"Gaetano"},{"family":"Lanata","given":"Antonio"},{"family":"Scilingo","given":"Enzo Pasquale"}],"citation-key":"valenza2012","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/T-AFFC.2011.30","ISSN":"1949-3045","issue":"2","issued":{"date-parts":[["2012",4]]},"page":"237-249","source":"IEEE Xplore","title":"The Role of Nonlinear Dynamics in Affective Valence and Arousal Recognition","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/6007125","volume":"3"},
  {"id":"vandermeer2012","abstract":"Objective\nAutism spectrum disorders (ASD) and attention-deficit/hyperactivity disorder (ADHD) frequently co-occur. Given the heterogeneity of both disorders, several more homogeneous ASD–ADHD comorbidity subgroups may exist. The current study examined whether such subgroups exist, and whether their overlap or distinctiveness in associated comorbid symptoms and cognitive profiles gives support for a gradient overarching disorder hypothesis or a separate disorders hypothesis.\nMethod\nLatent class analysis was performed on Social Communication Questionnaire (SCQ) and Conners' Parent Rating Scale (CPRS-R:L) data for 644 children and adolescents (5 through 17 years of age). Classes were compared for comorbid symptoms and cognitive profiles of motor speed and variability, executive functioning, attention, emotion recognition, and detail-focused processing style.\nResults\nLatent class analysis revealed five classes: two without behavioral problems, one with only ADHD behavior, and two with both clinical symptom levels of ASD and ADHD but with one domain more prominent than the other (ADHD[+ASD] and ASD[+ADHD]). In accordance with the gradient overarching disorder hypothesis were the presence of an ADHD class without ASD symptoms and the absence of an ASD class without ADHD symptoms, as well as cognitive functioning of the simple ADHD class being less impaired than that of both comorbid classes. In conflict with this hypothesis was that there was some specificity of cognitive deficits across classes.\nConclusions\nThe overlapping cognitive deficits may be used to further unravel the shared etiological underpinnings of ASD and ADHD, and the nonoverlapping deficits may indicate why some children develop ADHD despite their enhanced risk for ASD. The two subtypes of children with both ASD and ADHD behavior will most likely benefit from different clinical approaches.","accessed":{"date-parts":[["2025",3,11]]},"author":[{"family":"Meer","given":"Jolanda M. J.","non-dropping-particle":"van der"},{"family":"Oerlemans","given":"Anoek M."},{"family":"Steijn","given":"Daphne J.","non-dropping-particle":"van"},{"family":"Lappenschaar","given":"Martijn G. A."},{"family":"Sonneville","given":"Leo M. J.","non-dropping-particle":"de"},{"family":"Buitelaar","given":"Jan K."},{"family":"Rommelse","given":"Nanda N. J."}],"citation-key":"vandermeer2012","container-title":"Journal of the American Academy of Child & Adolescent Psychiatry","container-title-short":"Journal of the American Academy of Child & Adolescent Psychiatry","DOI":"10.1016/j.jaac.2012.08.024","ISSN":"0890-8567","issue":"11","issued":{"date-parts":[["2012",11,1]]},"page":"1160-1172.e3","source":"ScienceDirect","title":"Are Autism Spectrum Disorder and Attention-Deficit/Hyperactivity Disorder Different Manifestations of One Overarching Disorder? Cognitive and Symptom Evidence From a Clinical and Population-Based Sample","title-short":"Are Autism Spectrum Disorder and Attention-Deficit/Hyperactivity Disorder Different Manifestations of One Overarching Disorder?","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0890856712006491","volume":"51"},
  {"id":"vanpelt2022","abstract":"Background\nSocial cognitive difficulties in Autism Spectrum Disorder (ASD) can affect the daily lives of people with ASD profoundly, impacting the development and maintenance of meaningful social relations. Social cognition training (SCT) is commonly used for improving social functioning, but lacks ecological validity and the ability to effectively mimic social situations. Development of virtual reality (VR) interventions, focusing on enhancing social cognition, could add to the effectiveness of SCT within ASD care, by offering a safe, interactive and practical training setting, where generalization of knowledge and skills to the real-world are promoted. In this paper, our primary aim is to evaluate the feasibility and acceptance by participants and therapists of the Dynamic Interactive Social Cognition\nMethod\nTraining in Virtual Reality (DiSCoVR) protocol as developed for adults with schizophrenic spectrum disorder (SSD), adapted for ASD (DiSCoVR-A). 26 participants, aged 18–63, took part in a pilot study. 22 participants completed baseline and post-assessment, including primary outcome evaluation assessment through a semi-structured interview. Secondary measures focused on social cognition, emotion recognition, mental flexibility, social anxiety, empathy and social responsiveness and were assessed at baseline (T0), post-treatment (T1), and at follow-up (T2) sixteen weeks after completion of the intervention.\nResults\nOur results show that the majority of participant and therapists found the VR intervention acceptable and feasible, as reported in evaluation questionnaires and interviews.\nConclusion\nThese preliminary findings are promising; however, controlled research is needed to further investigate the effectiveness of VR within social cognition training for adults with ASD.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Pelt","given":"B. J.","non-dropping-particle":"van"},{"family":"Nijman","given":"S. A."},{"family":"Haren","given":"N. E. M.","non-dropping-particle":"van"},{"family":"Veling","given":"W."},{"family":"Pijnenborg","given":"G. H. M."},{"family":"Balkom","given":"I. D. C.","non-dropping-particle":"van"},{"family":"Landlust","given":"A. M."},{"family":"Greaves-Lord","given":"K."}],"citation-key":"vanpelt2022","container-title":"Research in Autism Spectrum Disorders","container-title-short":"Research in Autism Spectrum Disorders","DOI":"10.1016/j.rasd.2022.102003","ISSN":"1750-9467","issued":{"date-parts":[["2022",8,1]]},"page":"102003","source":"ScienceDirect","title":"Dynamic Interactive Social Cognition Training in Virtual Reality (DiSCoVR) for adults with Autism Spectrum Disorder: A feasibility study","title-short":"Dynamic Interactive Social Cognition Training in Virtual Reality (DiSCoVR) for adults with Autism Spectrum Disorder","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1750946722000903","volume":"96"},
  {"id":"vanthof2021","abstract":"Between 1990 and 2012, the global mean age at diagnosis of autism spectrum disorder ranged from 38 to 120 months. Measures have since been introduced to reduce the age at autism spectrum disorder diagnosis, but the current global mean age is unknown. This review and meta-analysis report the average age at diagnosis from studies published between 2012 and 2019. We initially identified 1150 articles, including 56 studies that reported the mean or median age at diagnosis across 40 countries (n = 120,540 individuals with autism spectrum disorder). Meta-analysis results (on 35 studies, including 55 cohorts from 35 countries, n = 66,966 individuals with autism spectrum disorder) found a current mean age at diagnosis of 60.48 months (range: 30.90–234.57 months). The subgroup analysis for studies that only included children aged ⩽10 years (nine studies, including 26 cohorts from 23 countries, n = 18,134 children with autism spectrum disorder) showed a mean age at diagnosis of 43.18 months (range: 30.90–74.70 months). Numerous factors may influence age at diagnosis and were reported by 46 studies, often with conflicting or inconclusive findings. Our study is the first to ascertain the global average age at autism spectrum disorder diagnosis from a meta-analysis. Continued efforts to lower the average age at autism spectrum disorder diagnosis are needed.\nLay abstract\nWe currently assume that the global mean age at diagnosis of autism spectrum disorder ranges from 38 to 120 months. However, this range is based on studies from 1991 to 2012 and measures have since been introduced to reduce the age at autism spectrum disorder diagnosis. We performed a systematic review and meta-analysis (statistical analysis that combines the results of multiple scientific studies) for studies published between 2012 and 2019 to evaluate the current age at autism spectrum disorder diagnosis. We included 56 studies that reported the age at diagnosis for 40 countries (containing 120,540 individuals with autism spectrum disorder). Results showed the current mean age at diagnosis to be 60.48 months (range: 30.90–234.57 months) and 43.18 months (range: 30.90–74.70 months) for studies that only included children aged ⩽10 years. Numerous factors that may influence age at diagnosis (e.g. type of autism spectrum disorder diagnosis, additional diagnoses and gender) were reported by 46 studies, often with conflicting or inconclusive results. Our study is the first to determine the global average age at autism spectrum disorder diagnosis from a meta-analysis. Although progress is being made in the earlier detection of autism spectrum disorder, it requires our constant attention.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Hof","given":"Maarten","non-dropping-particle":"van ’t"},{"family":"Tisseur","given":"Chanel"},{"family":"Berckelear-Onnes","given":"Ina","non-dropping-particle":"van"},{"family":"Nieuwenhuyzen","given":"Annemyn","non-dropping-particle":"van"},{"family":"Daniels","given":"Amy M"},{"family":"Deen","given":"Mathijs"},{"family":"Hoek","given":"Hans W"},{"family":"Ester","given":"Wietske A"}],"citation-key":"vanthof2021","container-title":"Autism","container-title-short":"Autism","DOI":"10.1177/1362361320971107","ISSN":"1362-3613","issue":"4","issued":{"date-parts":[["2021",5,1]]},"language":"en","page":"862-873","publisher":"SAGE Publications Ltd","source":"SAGE Journals","title":"Age at autism spectrum disorder diagnosis: A systematic review and meta-analysis from 2012 to 2019","title-short":"Age at autism spectrum disorder diagnosis","type":"article-journal","URL":"https://doi.org/10.1177/1362361320971107","volume":"25"},
  {"id":"varma2022","abstract":"BACKGROUND: Autism spectrum disorder (ASD) is a widespread neurodevelopmental condition with a range of potential causes and symptoms. Standard diagnostic mechanisms for ASD, which involve lengthy parent questionnaires and clinical observation, often result in long waiting times for results. Recent advances in computer vision and mobile technology hold potential for speeding up the diagnostic process by enabling computational analysis of behavioral and social impairments from home videos. Such techniques can improve objectivity and contribute quantitatively to the diagnostic process.\nOBJECTIVE: In this work, we evaluate whether home videos collected from a game-based mobile app can be used to provide diagnostic insights into ASD. To the best of our knowledge, this is the first study attempting to identify potential social indicators of ASD from mobile phone videos without the use of eye-tracking hardware, manual annotations, and structured scenarios or clinical environments.\nMETHODS: Here, we used a mobile health app to collect over 11 hours of video footage depicting 95 children engaged in gameplay in a natural home environment. We used automated data set annotations to analyze two social indicators that have previously been shown to differ between children with ASD and their neurotypical (NT) peers: (1) gaze fixation patterns, which represent regions of an individual's visual focus and (2) visual scanning methods, which refer to the ways in which individuals scan their surrounding environment. We compared the gaze fixation and visual scanning methods used by children during a 90-second gameplay video to identify statistically significant differences between the 2 cohorts; we then trained a long short-term memory (LSTM) neural network to determine if gaze indicators could be predictive of ASD.\nRESULTS: Our results show that gaze fixation patterns differ between the 2 cohorts; specifically, we could identify 1 statistically significant region of fixation (P<.001). In addition, we also demonstrate that there are unique visual scanning patterns that exist for individuals with ASD when compared to NT children (P<.001). A deep learning model trained on coarse gaze fixation annotations demonstrates mild predictive power in identifying ASD.\nCONCLUSIONS: Ultimately, our study demonstrates that heterogeneous video data sets collected from mobile devices hold potential for quantifying visual patterns and providing insights into ASD. We show the importance of automated labeling techniques in generating large-scale data sets while simultaneously preserving the privacy of participants, and we demonstrate that specific social engagement indicators associated with ASD can be identified and characterized using such data.","author":[{"family":"Varma","given":"Maya"},{"family":"Washington","given":"Peter"},{"family":"Chrisman","given":"Brianna"},{"family":"Kline","given":"Aaron"},{"family":"Leblanc","given":"Emilie"},{"family":"Paskov","given":"Kelley"},{"family":"Stockham","given":"Nate"},{"family":"Jung","given":"Jae-Yoon"},{"family":"Sun","given":"Min Woo"},{"family":"Wall","given":"Dennis P."}],"citation-key":"varma2022","container-title":"Journal of Medical Internet Research","container-title-short":"J Med Internet Res","DOI":"10.2196/31830","ISSN":"1438-8871","issue":"2","issued":{"date-parts":[["2022",2,15]]},"language":"eng","page":"e31830","PMCID":"PMC8889483","PMID":"35166683","source":"PubMed","title":"Identification of Social Engagement Indicators Associated With Autism Spectrum Disorder Using a Game-Based Mobile App: Comparative Study of Gaze Fixation and Visual Scanning Methods","title-short":"Identification of Social Engagement Indicators Associated With Autism Spectrum Disorder Using a Game-Based Mobile App","type":"article-journal","volume":"24"},
  {"id":"vriend2024","abstract":"<p>Specific Phobia (SP), Generalized Anxiety Disorders (GAD), and Social Anxiety Disorder (SAD) are the most prevalent anxiety disorders in children and adolescents. Although anxiety has a major influence on the body, evidence-based treatments mainly focus on cognitive and behavioral aspects of anxiety. Body- and movement-oriented interventions, such as psychomotor therapy (PMT), address the physical aspects. Bodily experience and interoceptive awareness are used to change behavior, cognition, and emotions. This review aimed to provide an overview of the efficacy of PMT for children and adolescents aged 0–18 years with SP, GAD, or SAD.</p><sec><title>Method</title><p>Data were collected in PsycINFO, Medline, Embase, ERIC, and Web of Science, from January 2020 until April 2022. Two independent researchers (EV and JM) selected the articles and performed a critical appraisal.</p></sec><sec><title>Results</title><p>From 1,438 articles found, only one article met the inclusion criteria.</p></sec><sec><title>Conclusion</title><p>No consensus-based statement about the efficacy of PMT in children and adolescents with SP, GAD, or SAD can be made due to the gap in the literature. Future research is needed to evaluate the efficacy. The first step may be to design treatment protocols. Subsequently, these protocols may be evaluated concerning efficacy.</p></sec>","accessed":{"date-parts":[["2025",3,3]]},"author":[{"family":"Vriend","given":"Evelien"},{"family":"Moeijes","given":"Janet"},{"family":"Scheffers","given":"Mia"}],"citation-key":"vriend2024","container-title":"Frontiers in Child and Adolescent Psychiatry","container-title-short":"Front. Child Adolesc. Psychiatry","DOI":"10.3389/frcha.2023.1182188","ISSN":"2813-4540","issued":{"date-parts":[["2024",1,8]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Efficacy of psychomotor therapy for children and adolescents with anxiety disorders—a systematic literature review","type":"article-journal","URL":"https://www.frontiersin.org/journals/child-and-adolescent-psychiatry/articles/10.3389/frcha.2023.1182188/full","volume":"2"},
  {"id":"vuyk1998","abstract":"The influence of using computerized visual communication on preoperative communication between the surgeon and the patient was analysed. This was a retrospective study based on a questionnaire completed by 50 patients who had undergone various facial plastic surgical procedures. Prediction tracings and postoperative slides were compared by the surgeon. The role of computer imaging in communication between doctor and patient, as well as the patient–doctor relationship and trust in the judgement of the doctor was considered to be positive by most of the patients. The vast majority of patients thought computer imaging should be a routine part of preoperative evaluation. Both the surgeon and the patients agreed that the representative value of prediction tracing was about 80%. In view of the possible positive influences on communication and relationship in the preoperative phase, computer imaging may help to provide a clear and realistic preoperative informed consent.","accessed":{"date-parts":[["2024",9,15]]},"author":[{"literal":"Vuyk"},{"literal":"Stroomer"},{"literal":"Vinayak"}],"citation-key":"vuyk1998","container-title":"Clinical Otolaryngology & Allied Sciences","DOI":"10.1046/j.1365-2273.1998.00139.x","ISSN":"1365-2273","issue":"3","issued":{"date-parts":[["1998"]]},"language":"en","license":"Blackwell Science Ltd","page":"235-243","source":"Wiley Online Library","title":"The role of computer imaging in facial plastic surgery consultation: a clinical study","title-short":"The role of computer imaging in facial plastic surgery consultation","type":"article-journal","URL":"https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2273.1998.00139.x","volume":"23"},
  {"id":"wagner2025","abstract":"The wait for ASD evaluation dramatically increases with age, with wait times of a year or more common as children reach preschool. Even when appointments become available, families from traditionally underserved groups struggle to access care. Addressing care disparities requires designing identification tools and processes specifically for and with individuals most at-risk for health inequities. This work describes the development of a novel telemedicine-based ASD assessment tool, the TELE-ASD-PEDS-Preschool (TAP-Preschool). We applied machine learning models to a clinical data set of preschoolers with ASD and other developmental concerns (n = 914) to generate behavioral targets that best distinguish ASD and non-ASD features. We conducted focus groups with clinicians, early interventionists, and parents of children with ASD from traditionally underrepresented racial/ethnic and linguistic groups. Focus group themes and machine learning analyses were used to generate a play-based instrument with assessment tasks and scoring procedures based on the child’s language (i.e., TAP-P Verbal, TAP-P Non-verbal). TAP-P procedures were piloted with 30 families. Use of the instrument in isolation (i.e., without history or collateral information) yielded accurate diagnostic classification in 63% of cases. Children with existing ASD diagnoses received higher TAP-P scores, relative to children with other developmental concerns. Clinician diagnostic accuracy and certainty were higher when confirming existing ASD diagnoses (80% agreement) than when ruling out ASD in children with other developmental concerns (30% agreement). Utilizing an equity approach to understand the functionality and impact of tele-assessment for preschool children has potential to transform the ASD evaluation process and improve care access.","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Wagner","given":"Liliana"},{"family":"Vehorn","given":"Alison"},{"family":"Weitlauf","given":"Amy S."},{"family":"Lavanderos","given":"Ambar Munoz"},{"family":"Wade","given":"Joshua"},{"family":"Corona","given":"Laura"},{"family":"Warren","given":"Zachary"}],"citation-key":"wagner2025","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-023-06176-3","ISSN":"1573-3432","issue":"1","issued":{"date-parts":[["2025",1,1]]},"language":"en","page":"30-42","source":"Springer Link","title":"Development of a Novel Telemedicine Tool to Reduce Disparities Related to the Identification of Preschool Children with Autism","type":"article-journal","URL":"https://doi.org/10.1007/s10803-023-06176-3","volume":"55"},
  {"id":"wahid2023","abstract":"The reliance on Online Social Networks (OSN) for both formal and informal social interactions has dramatically changed the way people communicate. In this paper, a novel Social Behavioral Biometric (SBB), human micro-expression, is introduced for person identification. An emotion detection model is developed to extract emotion probability scores from person’s writing samples posted on Twitter. The corresponding emotion-progression features are extracted using an original technique that turns users’ microblogs into emotion-progression signals. Finally, a novel social behavioral biometric system that leverages rank-level weighted majority voting to achieve an accurate person identification is implemented. The proposed system is validated on a proprietary benchmark dataset consisting of 250 Twitter users. The experimental results convincingly demonstrate that the proposed social behavioral biometric, human micro-expression, possesses a strong distinguishable ability and can be used for person identification. The study further reveals that the proposed social behavioral biometric outperforms all the original SBB traits.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Wahid","given":"Zaman"},{"family":"Bari","given":"Asm Hossain"},{"family":"Anzum","given":"Fahim"},{"family":"Gavrilova","given":"Marina L."}],"citation-key":"wahid2023","container-title":"IEEE Access","DOI":"10.1109/ACCESS.2023.3283932","ISSN":"2169-3536","issued":{"date-parts":[["2023"]]},"page":"57481-57493","source":"IEEE Xplore","title":"Human Micro-Expression: A Novel Social Behavioral Biometric for Person Identification","title-short":"Human Micro-Expression","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/10145790","volume":"11"},
  {"id":"wahid2023a","abstract":"The advent of Social Behavioral Biometrics (SBB) in the realm of person identification has underscored the importance of understanding unique patterns of social interactions and communication. This paper introduces a novel multimodal SBB system that integrates human micro-expressions from text, an emerging biometric trait, with other established SBB traits in order to enhance online user identification performance. Including human micro-expression, the proposed method extracts five other original SBB traits for a comprehensive representation of the social behavioral characteristics of an individual. Upon finding the independent person identification score by every SBB trait, a rank-level fusion that leverages the weighted Borda count is employed to fuse the scores from all the traits, obtaining the final identification score. The proposed method is evaluated on a benchmark dataset of 250 Twitter users, and the results indicate that the incorporation of human micro-expression with existing SBB traits can substantially boost the overall online user identification performance, with an accuracy of 73.87% and a recall score of 74%. Furthermore, the proposed method outperforms the state-of-the-art SBB systems.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Wahid","given":"Zaman"},{"family":"Bari","given":"A. S. M. Hossain"},{"family":"Gavrilova","given":"Marina"}],"citation-key":"wahid2023a","container-title":"Sensors","DOI":"10.3390/s23198197","ISSN":"1424-8220","issue":"19","issued":{"date-parts":[["2023",1]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"19","page":"8197","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Human Micro-Expressions in Multimodal Social Behavioral Biometrics","type":"article-journal","URL":"https://www.mdpi.com/1424-8220/23/19/8197","volume":"23"},
  {"id":"wang2023","abstract":"With the development of surgical medicine and people’s more requirements for disease treatment, as well as the realistic demand of reducing errors and reducing surgical risks based on accurate surgical operations. Three-dimensional (3D) panoramic virtual reality technology is applied to surgical operations to meet the needs of different patients. This article discusses the interactive immersion experience of surgery, 3D simulation of surgical process, operational accuracy and other aspects. The purpose of this study is to explore the role and value of the simulation exercise of panoramic photography in the virtual surgical environment for the application of real surgery, start to discuss the details of the operation process, improve the probability of success of surgery, and reduce doctor-patient disputes. Based on the above research, the application prospect of 3D panoramic virtual reality technology in the field of surgery and medicine is prospected.","accessed":{"date-parts":[["2024",9,15]]},"author":[{"family":"Wang","given":"Yujie"},{"family":"Song","given":"Jiajia"}],"citation-key":"wang2023","container-title":"SHS Web of Conferences","container-title-short":"SHS Web Conf.","DOI":"10.1051/shsconf/202316501004","ISSN":"2261-2424","issued":{"date-parts":[["2023"]]},"language":"en","license":"© The Authors, published by EDP Sciences, 2023","page":"01004","publisher":"EDP Sciences","source":"www.shs-conferences.org","title":"Analysis of the role and value of Three-dimensional panoramic virtual reality technology — Take surgery as an example","type":"article-journal","URL":"https://www.shs-conferences.org/articles/shsconf/abs/2023/14/shsconf_cike2023_01004/shsconf_cike2023_01004.html","volume":"165"},
  {"id":"wang2024","abstract":"Facility management is globally recognized as a critical and knowledge-intensive field. It confronts challenges due to the increasing complexity of facilities and the vast amount of operation and maintenance information. Augmented reality (AR), emerges as a promising technology to address these challenges by enhancing knowledge transfer in facility management through immersive and interactive environments. The objective of this research is to conduct a systematic review of augmented reality applications in facility management, and explore its knowledge transfer capabilities in facility management. The review narrowed the literature by filtering from 618 publications to 107 papers published between 2011 and 2023. A contents analysis based on these articles could gain an insight into current facility management systems as well as augmented reality application domains in a series of facility management activities including facility design/layout, assembly, monitoring, maintenance and renovation. Based on the above analysis, this research discussed the augmented reality capabilities of knowledge transfer in facility management. The findings reveal that augmented reality facilitates knowledge transfer by enabling visualization, interaction, and collaboration among stakeholders. It is influenced by factors including user interfaces and interaction types, as well as vocational training and acceptance level of stakeholders. Challenges remain in terms of tracking, registration, ergonomics, security, and management practices. Finally, this research highlighted future trends focusing on the development of knowledge-driven digital twins, trustworthy knowledge management, and collaborative platforms to further promote augmented reality knowledge transfer in facility management. This research also contributes to deeper understanding of the role of augmented reality within this field and provides insights for stakeholders aiming to utilize this technology.","accessed":{"date-parts":[["2025",3,4]]},"author":[{"family":"Wang","given":"Xiang"},{"family":"Wang","given":"Shiqi"},{"family":"Xiao","given":"Fu"},{"family":"Luo","given":"Xiaowei"}],"citation-key":"wang2024","container-title":"Journal of Building Engineering","container-title-short":"Journal of Building Engineering","DOI":"10.1016/j.jobe.2024.111186","ISSN":"2352-7102","issued":{"date-parts":[["2024",12,1]]},"page":"111186","source":"ScienceDirect","title":"Augmented reality-based knowledge transfer for facility management: A systematic review","title-short":"Augmented reality-based knowledge transfer for facility management","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S2352710224027542","volume":"98"},
  {"id":"washington2022","abstract":"Artificial Intelligence (A.I.) solutions are increasingly considered for telemedicine. For these methods to serve children and their families in home settings, it is crucial to ensure the privacy of the child and parent or caregiver. To address this challenge, we explore the potential for global image transformations to provide privacy while preserving the quality of behavioral annotations. Crowd workers have previously been shown to reliably annotate behavioral features in unstructured home videos, allowing machine learning classifiers to detect autism using the annotations as input. We evaluate this method with videos altered via pixelation, dense optical flow, and Gaussian blurring. On a balanced test set of 30 videos of children with autism and 30 neurotypical controls, we find that the visual privacy alterations do not drastically alter any individual behavioral annotation at the item level. The AUROC on the evaluation set was 90.0% ±7.5% for unaltered videos, 85.0% ±9.0% for pixelation, 85.0% ±9.0% for optical flow, and 83.3% ±9.3% for blurring, demonstrating that an aggregation of small changes across behavioral questions can collectively result in increased misdiagnosis rates. We also compare crowd answers against clinicians who provided the same annotations for the same videos as crowd workers, and we find that clinicians have higher sensitivity in their recognition of autism-related symptoms. We also find that there is a linear correlation (r = 0.75, p < 0.0001) between the mean Clinical Global Impression (CGI) score provided by professional clinicians and the corresponding score emitted by a previously validated autism classifier with crowd inputs, indicating that the classifier's output probability is a reliable estimate of the clinical impression of autism. A significant correlation is maintained with privacy alterations, indicating that crowd annotations can approximate clinician-provided autism impression from home videos in a privacy-preserved manner.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Washington","given":"Peter"},{"family":"Chrisman","given":"Brianna"},{"family":"Leblanc","given":"Emilie"},{"family":"Dunlap","given":"Kaitlyn"},{"family":"Kline","given":"Aaron"},{"family":"Mutlu","given":"Cezmi"},{"family":"Stockham","given":"Nate"},{"family":"Paskov","given":"Kelley"},{"family":"Wall","given":"Dennis Paul"}],"citation-key":"washington2022","container-title":"Intelligence-Based Medicine","container-title-short":"Intelligence-Based Medicine","DOI":"10.1016/j.ibmed.2022.100056","ISSN":"2666-5212","issued":{"date-parts":[["2022",1,1]]},"page":"100056","source":"ScienceDirect","title":"Crowd annotations can approximate clinical autism impressions from short home videos with privacy protections","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S2666521222000096","volume":"6"},
  {"id":"washington2023","abstract":"Autism spectrum disorder (autism) is a neurodevelopmental delay that affects at least 1 in 44 children. Like many neurological disorder phenotypes, the diagnostic features are observable, can be tracked over time, and can be managed or even eliminated through proper therapy and treatments. However, there are major bottlenecks in the diagnostic, therapeutic, and longitudinal tracking pipelines for autism and related neurodevelopmental delays, creating an opportunity for novel data science solutions to augment and transform existing workflows and provide increased access to services for affected families. Several efforts previously conducted by a multitude of research labs have spawned great progress toward improved digital diagnostics and digital therapies for children with autism. We review the literature on digital health methods for autism behavior quantification and beneficial therapies using data science. We describe both case–control studies and classification systems for digital phenotyping. We then discuss digital diagnostics and therapeutics that integrate machine learning models of autism-related behaviors, including the factors that must be addressed for translational use. Finally, we describe ongoing challenges and potential opportunities for the field of autism data science. Given the heterogeneous nature of autism and the complexities of the relevant behaviors, this review contains insights that are relevant to neurological behavior analysis and digital psychiatry more broadly.","accessed":{"date-parts":[["2024",6,19]]},"author":[{"family":"Washington","given":"Peter"},{"family":"Wall","given":"Dennis P."}],"citation-key":"washington2023","container-title":"Annual Review of Biomedical Data Science","DOI":"10.1146/annurev-biodatasci-020722-125454","ISSN":"2574-3414","issue":"Volume 6, 2023","issued":{"date-parts":[["2023",8,10]]},"language":"en","page":"211-228","publisher":"Annual Reviews","source":"www.annualreviews.org","title":"A Review of and Roadmap for Data Science and Machine Learning for the Neuropsychiatric Phenotype of Autism","type":"article-journal","URL":"https://www.annualreviews.org/content/journals/10.1146/annurev-biodatasci-020722-125454","volume":"6"},
  {"id":"washington2023a","abstract":"Autism spectrum disorder (autism) is a neurodevelopmental delay that affects at least 1 in 44 children. Like many neurological disorder phenotypes, the diagnostic features are observable, can be tracked over time, and can be managed or even eliminated through proper therapy and treatments. However, there are major bottlenecks in the diagnostic, therapeutic, and longitudinal tracking pipelines for autism and related neurodevelopmental delays, creating an opportunity for novel data science solutions to augment and transform existing workflows and provide increased access to services for affected families. Several efforts previously conducted by a multitude of research labs have spawned great progress toward improved digital diagnostics and digital therapies for children with autism. We review the literature on digital health methods for autism behavior quantification and beneficial therapies using data science. We describe both case–control studies and classification systems for digital phenotyping. We then discuss digital diagnostics and therapeutics that integrate machine learning models of autism-related behaviors, including the factors that must be addressed for translational use. Finally, we describe ongoing challenges and potential opportunities for the field of autism data science. Given the heterogeneous nature of autism and the complexities of the relevant behaviors, this review contains insights that are relevant to neurological behavior analysis and digital psychiatry more broadly.","accessed":{"date-parts":[["2025",2,24]]},"author":[{"family":"Washington","given":"Peter"},{"family":"Wall","given":"Dennis P."}],"citation-key":"washington2023a","container-title":"Annual Review of Biomedical Data Science","DOI":"10.1146/annurev-biodatasci-020722-125454","ISSN":"2574-3414","issue":"Volume 6, 2023","issued":{"date-parts":[["2023",8,10]]},"language":"en","page":"211-228","publisher":"Annual Reviews","source":"www.annualreviews.org","title":"A Review of and Roadmap for Data Science and Machine Learning for the Neuropsychiatric Phenotype of Autism","type":"article-journal","URL":"https://www.annualreviews.org/content/journals/10.1146/annurev-biodatasci-020722-125454","volume":"6"},
  {"id":"wei2023","abstract":"This paper presents the preliminary results of an accuracy testing of the Meta Quest Pro’s eye tracker. We conducted user testing to evaluate the spatial accuracy, spatial precision and subjective performance under head-free and head-restrained conditions. Our measurements indicated an average accuracy of 1.652° with a precision of 0.699° (standard deviation) and 0.849° (root mean square) for a visual field spanning 15° during head-free. The signal quality of Quest Pro’s eye-tracker is comparable to existing AR/VR eye-tracking headsets. Notably, careful considerations are required when designing the size of scene objects, mapping areas of interest, and determining the interaction flow. Researchers should also be cautious about interpreting the fixation results when multiple targets are within close proximity. Further investigation and better specification information transparency are needed to establish its capabilities and limitations.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Wei","given":"Shu"},{"family":"Bloemers","given":"Desmond"},{"family":"Rovira","given":"Aitor"}],"citation-key":"wei2023","collection-title":"IMX '23","container-title":"Proceedings of the 2023 ACM International Conference on Interactive Media Experiences","DOI":"10.1145/3573381.3596467","event-place":"New York, NY, USA","ISBN":"979-8-4007-0028-6","issued":{"date-parts":[["2023",8,29]]},"page":"216–221","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"A Preliminary Study of the Eye Tracker in the Meta Quest Pro","type":"paper-conference","URL":"https://dl.acm.org/doi/10.1145/3573381.3596467"},
  {"id":"wei2023a","abstract":"BACKGROUND: Machine learning has been widely used to identify Autism Spectrum Disorder (ASD) based on eye-tracking, but its accuracy is uncertain. We aimed to summarize the available evidence on the performances of machine learning algorithms in classifying ASD and typically developing (TD) individuals based on eye-tracking data.\nMETHODS: We searched Medline, Embase, Web of Science, Scopus, Cochrane Library, IEEE Xplore Digital Library, Wan Fang Database, China National Knowledge Infrastructure, Chinese BioMedical Literature Database, VIP Database for Chinese Technical Periodicals, from database inception to December 24, 2021. Studies using machine learning methods to classify ASD and TD individuals based on eye-tracking technologies were included. We extracted the data on study population, model performances, algorithms of machine learning, and paradigms of eye-tracking. This study is registered with PROSPERO, CRD42022296037.\nRESULTS: 261 articles were identified, of which 24 studies with sample sizes ranging from 28 to 141 were included (n = 1396 individuals). Machine learning based on eye-tracking yielded the pooled classified accuracy of 81 % (I2 = 73 %), specificity of 79 % (I2 = 61 %), and sensitivity of 84 % (I2 = 61 %) in classifying ASD and TD individuals. In subgroup analysis, the accuracy was 88 % (95 % CI: 85-91 %), 79 % (95 % CI: 72-84 %), 71 % (95 % CI: 59-91 %) for preschool-aged, school-aged, and adolescent-adult group. Eye-tracking stimuli and machine learning algorithms varied widely across studies, with social, static, and active stimuli and Support Vector Machine and Random Forest most commonly reported. Regarding the model performance evaluation, 15 studies reported their final results on validation datasets, four based on testing datasets, and five did not report whether they used validation datasets. Most studies failed to report the information on eye-tracking hardware and the implementation process.\nCONCLUSION: Using eye-tracking data, machine learning has shown potential in identifying ASD individuals with high accuracy, especially in preschool-aged children. However, the heterogeneity between studies, the absence of test set-based performance evaluations, the small sample size, and the non-standardized implementation of eye-tracking might deteriorate the reliability of results. Further well-designed and well-executed studies with comprehensive and transparent reporting are needed to determine the optimal eye-tracking paradigms and machine learning algorithms.","author":[{"family":"Wei","given":"Qiuhong"},{"family":"Cao","given":"Huiling"},{"family":"Shi","given":"Yuan"},{"family":"Xu","given":"Ximing"},{"family":"Li","given":"Tingyu"}],"citation-key":"wei2023a","container-title":"Journal of Biomedical Informatics","container-title-short":"J Biomed Inform","DOI":"10.1016/j.jbi.2022.104254","ISSN":"1532-0480","issued":{"date-parts":[["2023",1]]},"language":"eng","page":"104254","PMID":"36509416","source":"PubMed","title":"Machine learning based on eye-tracking data to identify Autism Spectrum Disorder: A systematic review and meta-analysis","title-short":"Machine learning based on eye-tracking data to identify Autism Spectrum Disorder","type":"article-journal","volume":"137"},
  {"id":"wei2024","abstract":"Recent research has shown that facial expressions and body gestures are two significant implications in identifying human emotions. However, these studies mainly focus on contextual information of adjacent frames, and rarely explore the spatio-temporal relationships between distant or global frames. In this paper, we revisit the facial expression and body gesture emotion recognition problems, and propose to improve the performance of video emotion recognition by extracting the spatio-temporal features via further encoding temporal information. Specifically, for facial expression, we propose a super image-based spatio-temporal convolutional model (SISTCM) and a two-stream LSTM model to capture the local spatio-temporal features and learn global temporal cues of emotion changes. For body gestures, a novel representation method and an attention-based channel-wise convolutional model (ACCM) are introduced to learn key joints features and independent characteristics of each joint. Extensive experiments on five common datasets are carried out to prove the superiority of the proposed method, and the results proved learning two visual information leads to significant improvement over the existing state-of-the-art methods.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Wei","given":"Jie"},{"family":"Hu","given":"Guanyu"},{"family":"Yang","given":"Xinyu"},{"family":"Luu","given":"Anh Tuan"},{"family":"Dong","given":"Yizhuo"}],"citation-key":"wei2024","container-title":"Expert Systems with Applications","container-title-short":"Expert Systems with Applications","DOI":"10.1016/j.eswa.2023.121419","ISSN":"0957-4174","issued":{"date-parts":[["2024",3,1]]},"page":"121419","source":"ScienceDirect","title":"Learning facial expression and body gesture visual information for video emotion recognition","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0957417423019218","volume":"237"},
  {"id":"wei2024a","abstract":"Recent research has shown that facial expressions and body gestures are two significant implications in identifying human emotions. However, these studies mainly focus on contextual information of adjacent frames, and rarely explore the spatio-temporal relationships between distant or global frames. In this paper, we revisit the facial expression and body gesture emotion recognition problems, and propose to improve the performance of video emotion recognition by extracting the spatio-temporal features via further encoding temporal information. Specifically, for facial expression, we propose a super image-based spatio-temporal convolutional model (SISTCM) and a two-stream LSTM model to capture the local spatio-temporal features and learn global temporal cues of emotion changes. For body gestures, a novel representation method and an attention-based channel-wise convolutional model (ACCM) are introduced to learn key joints features and independent characteristics of each joint. Extensive experiments on five common datasets are carried out to prove the superiority of the proposed method, and the results proved learning two visual information leads to significant improvement over the existing state-of-the-art methods.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Wei","given":"Jie"},{"family":"Hu","given":"Guanyu"},{"family":"Yang","given":"Xinyu"},{"family":"Luu","given":"Anh Tuan"},{"family":"Dong","given":"Yizhuo"}],"citation-key":"wei2024a","container-title":"Expert Systems with Applications","container-title-short":"Expert Systems with Applications","DOI":"10.1016/j.eswa.2023.121419","ISSN":"09574174","issued":{"date-parts":[["2024",3]]},"language":"en","page":"121419","source":"DOI.org (Crossref)","title":"Learning facial expression and body gesture visual information for video emotion recognition","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0957417423019218","volume":"237"},
  {"id":"wei2024b","abstract":"Background\nEarly identification of autism spectrum disorder (ASD) improves long-term outcomes, yet significant diagnostic delays persist.\nMethods\nA retrospective cohort of 449 children (ASD: 246, typically developing [TD]: 203) was used for model development. Eye-movement data were collected from the participants watching videos that featured eye-tracking paradigms for assessing social and non-social cognition. Five machine learning algorithms, namely random forest, support vector machine, logistic regression, artificial neural network, and extreme gradient boosting, were trained to classify children with ASD and TD. The best-performing algorithm was selected to build the final model which was further evaluated in a prospective cohort of 80 children. The Shapley values interpreted important eye-tracking features.\nResults\nRandom forest outperformed other algorithms during model development and achieved an area under the curve of 0.849 (< 3 years: 0.832, ≥ 3 years: 0.868) on the external validation set. Of the ten most important eye-tracking features, three measured social cognition, and the rest were related to non-social cognition. A deterioration in model performance was observed using only the social or non-social cognition-related eye-tracking features.\nLimitations\nThe sample size of this study, although larger than that of existing studies of ASD based on eye-tracking data, was still relatively small compared to the number of features.\nConclusions\nMachine learning models based on eye-tracking data have the potential to be cost- and time-efficient digital tools for the early identification of ASD. Eye-tracking phenotypes related to social and non-social cognition play an important role in distinguishing children with ASD from TD children.","accessed":{"date-parts":[["2025",1,14]]},"author":[{"family":"Wei","given":"Qiuhong"},{"family":"Dong","given":"Wenxin"},{"family":"Yu","given":"Dongchuan"},{"family":"Wang","given":"Ke"},{"family":"Yang","given":"Ting"},{"family":"Xiao","given":"Yuanjie"},{"family":"Long","given":"Dan"},{"family":"Xiong","given":"Haiyi"},{"family":"Chen","given":"Jie"},{"family":"Xu","given":"Ximing"},{"family":"Li","given":"Tingyu"}],"citation-key":"wei2024b","container-title":"Journal of Affective Disorders","container-title-short":"Journal of Affective Disorders","DOI":"10.1016/j.jad.2024.04.049","ISSN":"0165-0327","issued":{"date-parts":[["2024",8,1]]},"page":"326-334","source":"ScienceDirect","title":"Early identification of autism spectrum disorder based on machine learning with eye-tracking data","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0165032724006554","volume":"358"},
  {"id":"wen2022","abstract":"Few clinically validated biomarkers of ASD exist which can rapidly, accurately, and objectively identify autism during the first years of life and be used to support optimized treatment outcomes and advances in precision medicine. As such, the goal of the present study was to leverage both simple and computationally-advanced approaches to validate an eye-tracking measure of social attention preference, the GeoPref Test, among 1,863 ASD, delayed, or typical toddlers (12–48 months) referred from the community or general population via a primary care universal screening program. Toddlers participated in diagnostic and psychometric evaluations and the GeoPref Test: a 1-min movie containing side-by-side dynamic social and geometric images. Following testing, diagnosis was denoted as ASD, ASD features, LD, GDD, Other, typical sibling of ASD proband, or typical. Relative to other diagnostic groups, ASD toddlers exhibited the highest levels of visual attention towards geometric images and those with especially high fixation levels exhibited poor clinical profiles. Using the 69% fixation threshold, the GeoPref Test had 98% specificity, 17% sensitivity, 81% PPV, and 65% NPV. Sensitivity increased to 33% when saccades were included, with comparable validity across sex, ethnicity, or race. The GeoPref Test was also highly reliable up to 24 months following the initial test. Finally, fixation levels among twins concordant for ASD were significantly correlated, indicating that GeoPref Test performance may be genetically driven. As the GeoPref Test yields few false positives (~ 2%) and is equally valid across demographic categories, the current findings highlight the ability of the GeoPref Test to rapidly and accurately detect autism before the 2nd birthday in a subset of children and serve as a biomarker for a unique ASD subtype in clinical trials.","accessed":{"date-parts":[["2025",2,3]]},"author":[{"family":"Wen","given":"Teresa H."},{"family":"Cheng","given":"Amanda"},{"family":"Andreason","given":"Charlene"},{"family":"Zahiri","given":"Javad"},{"family":"Xiao","given":"Yaqiong"},{"family":"Xu","given":"Ronghui"},{"family":"Bao","given":"Bokan"},{"family":"Courchesne","given":"Eric"},{"family":"Barnes","given":"Cynthia Carter"},{"family":"Arias","given":"Steven J."},{"family":"Pierce","given":"Karen"}],"citation-key":"wen2022","container-title":"Scientific Reports","container-title-short":"Sci Rep","DOI":"10.1038/s41598-022-08102-6","ISSN":"2045-2322","issue":"1","issued":{"date-parts":[["2022",3,11]]},"language":"en","license":"2022 The Author(s)","page":"4253","publisher":"Nature Publishing Group","source":"www.nature.com","title":"Large scale validation of an early-age eye-tracking biomarker of an autism spectrum disorder subtype","type":"article-journal","URL":"https://www.nature.com/articles/s41598-022-08102-6","volume":"12"},
  {"id":"wienker2016","abstract":"The management of maintenance in a large industrial operation is complex and has a significant impact on the profitability of the business. Managing this process effectively without computer-based support is almost impossible, but achieving successful implementation of these systems requires a major change-management program over many years. It is not surprising then that there is a low success rate among even large organizations worldwide in implementing an effective Computerized Maintenance Management System (CMMS) to support improved reliability and performance. This paper focuses on understanding the reasons behind the low success rate achieved and outlines the essential elements that must be included to ensure a disciplined and well-resourced program that can deliver success. Emphasis is put on the need to gain and retain the support of top management to overcome the barriers to change by convincing them that such support makes good business sense.","accessed":{"date-parts":[["2025",3,7]]},"author":[{"family":"Wienker","given":"Michael"},{"family":"Henderson","given":"Ken"},{"family":"Volkerts","given":"Jacques"}],"citation-key":"wienker2016","collection-title":"SYMPHOS 2015 - 3rd International Symposium on Innovation and Technology in the Phosphate Industry","container-title":"Procedia Engineering","container-title-short":"Procedia Engineering","DOI":"10.1016/j.proeng.2016.02.100","ISSN":"1877-7058","issued":{"date-parts":[["2016",1,1]]},"page":"413-420","source":"ScienceDirect","title":"The Computerized Maintenance Management System an Essential Tool for World Class Maintenance","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S1877705816004641","volume":"138"},
  {"id":"wolf2023","abstract":"<p>Mild cognitive impairment (MCI), representing the ‘transitional zone’ between normal cognition and dementia, has become a novel topic in clinical research. Although early detection is crucial, it remains logistically challenging at the same time. While traditional pen-and-paper tests require in-depth training to ensure standardized administration and accurate interpretation of findings, significant technological advancements are leading to the development of procedures for the early detection of Alzheimer’s disease (AD) and facilitating the diagnostic process. Some of the diagnostic protocols, however, show significant limitations that hamper their widespread adoption. Concerns about the social and economic implications of the increasing incidence of AD underline the need for reliable, non-invasive, cost-effective, and timely cognitive scoring methodologies. For instance, modern clinical studies report significant oculomotor impairments among patients with MCI, who perform poorly in visual paired-comparison tasks by ascribing less attentional resources to novel stimuli. To accelerate the Global Action Plan on the Public Health Response to Dementia 2017–2025, this work provides an overview of research on saccadic and exploratory eye-movement deficits among older adults with MCI. The review protocol was drafted based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Electronic databases were systematically searched to identify peer-reviewed articles published between 2017 and 2022 that examined visual processing in older adults with MCI and reported gaze parameters as potential biomarkers. Moreover, following the contemporary trend for remote healthcare technologies, we reviewed studies that implemented non-commercial eye-tracking instrumentation in order to detect information processing impairments among the MCI population. Based on the gathered literature, eye-tracking-based paradigms may ameliorate the screening limitations of traditional cognitive assessments and contribute to early AD detection. However, in order to translate the findings pertaining to abnormal gaze behavior into clinical applications, it is imperative to conduct longitudinal investigations in both laboratory-based and ecologically valid settings.</p>","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Wolf","given":"Alexandra"},{"family":"Tripanpitak","given":"Kornkanok"},{"family":"Umeda","given":"Satoshi"},{"family":"Otake-Matsuura","given":"Mihoko"}],"citation-key":"wolf2023","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2023.1197567","ISSN":"1664-1078","issued":{"date-parts":[["2023",7,20]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Eye-tracking paradigms for the assessment of mild cognitive impairment: a systematic review","title-short":"Eye-tracking paradigms for the assessment of mild cognitive impairment","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1197567/full","volume":"14"},
  {"id":"wolfers2019","abstract":"Pattern classification and stratification approaches have increasingly been used in research on Autism Spectrum Disorder (ASD) over the last ten years with the goal of translation towards clinical applicability. Here, we present an extensive scoping literature review on those two approaches. We screened a total of 635 studies, of which 57 pattern classification and 19 stratification studies were included. We observed large variance across pattern classification studies in terms of predictive performance from about 60% to 98% accuracy, which is among other factors likely linked to sampling bias, different validation procedures across studies, the heterogeneity of ASD and differences in data quality. Stratification studies were less prevalent with only two studies reporting replications and just a few showing external validation. While some identified strata based on cognition and intelligence reappear across studies, biology as a stratification marker is clearly underexplored. In summary, mapping biological differences at the level of the individual with ASD is a major challenge for the field now. Conceptualizing those mappings and individual trajectories that lead to the diagnosis of ASD, will become a major challenge in the near future.","accessed":{"date-parts":[["2025",2,15]]},"author":[{"family":"Wolfers","given":"Thomas"},{"family":"Floris","given":"Dorothea L."},{"family":"Dinga","given":"Richard"},{"family":"Rooij","given":"Daan","non-dropping-particle":"van"},{"family":"Isakoglou","given":"Christina"},{"family":"Kia","given":"Seyed Mostafa"},{"family":"Zabihi","given":"Mariam"},{"family":"Llera","given":"Alberto"},{"family":"Chowdanayaka","given":"Rajanikanth"},{"family":"Kumar","given":"Vinod J."},{"family":"Peng","given":"Han"},{"family":"Laidi","given":"Charles"},{"family":"Batalle","given":"Dafnis"},{"family":"Dimitrova","given":"Ralica"},{"family":"Charman","given":"Tony"},{"family":"Loth","given":"Eva"},{"family":"Lai","given":"Meng-Chuan"},{"family":"Jones","given":"Emily"},{"family":"Baumeister","given":"Sarah"},{"family":"Moessnang","given":"Carolin"},{"family":"Banaschewski","given":"Tobias"},{"family":"Ecker","given":"Christine"},{"family":"Dumas","given":"Guillaume"},{"family":"O’Muircheartaigh","given":"Jonathan"},{"family":"Murphy","given":"Declan"},{"family":"Buitelaar","given":"Jan K."},{"family":"Marquand","given":"Andre F."},{"family":"Beckmann","given":"Christian F."}],"citation-key":"wolfers2019","container-title":"Neuroscience & Biobehavioral Reviews","container-title-short":"Neuroscience & Biobehavioral Reviews","DOI":"10.1016/j.neubiorev.2019.07.010","ISSN":"0149-7634","issued":{"date-parts":[["2019",9,1]]},"page":"240-254","source":"ScienceDirect","title":"From pattern classification to stratification: towards conceptualizing the heterogeneity of Autism Spectrum Disorder","title-short":"From pattern classification to stratification","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0149763419303197","volume":"104"},
  {"id":"wu2021","abstract":"Early diagnosis of Autism Spectrum Disorder (ASD) is crucial for best outcomes to interventions. In this paper, we present a machine learning (ML) approach to ASD diagnosis based on identifying specific behaviors from videos of infants of ages 6 through 36 months. The behaviors of interest include directed gaze towards faces or objects of interest, positive affect, and vocalization. The dataset consists of 2000 videos of 3-minute duration with these behaviors manually coded by expert raters. Moreover, the dataset has statistical features including duration and frequency of the above mentioned behaviors in the video collection as well as independent ASD diagnosis by clinicians. We tackle the ML problem in a two-stage approach. Firstly, we develop deep learning models for automatic identification of clinically relevant behaviors exhibited by infants in a one-on-one interaction setting with parents or expert clinicians. We report baseline results of behavior classification using two methods: (1) image based model (2) facial behavior features based model. We achieve 70% accuracy for smile, 68% accuracy for look face, 67% for look object and 53% accuracy for vocalization. Secondly, we focus on ASD diagnosis prediction by applying a feature selection process to identify the most significant statistical behavioral features and a over and under sampling process to mitigate the class imbalance, followed by developing a baseline ML classifier to achieve an accuracy of 82% for ASD diagnosis.","accessed":{"date-parts":[["2025",2,8]]},"author":[{"family":"Wu","given":"Chongruo"},{"family":"Liaqat","given":"Sidrah"},{"family":"Helvaci","given":"Halil"},{"family":"Chcung","given":"Sen-ching Samson"},{"family":"Chuah","given":"Chen-Nee"},{"family":"Ozonoff","given":"Sally"},{"family":"Young","given":"Gregory"}],"citation-key":"wu2021","container-title":"2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM)","DOI":"10.1109/HEALTHCOM49281.2021.9398924","event-title":"2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM)","issued":{"date-parts":[["2021",3]]},"page":"1-6","source":"IEEE Xplore","title":"Machine Learning Based Autism Spectrum Disorder Detection from Videos","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9398924"},
  {"id":"wu2021a","abstract":"Early diagnosis of Autism Spectrum Disorder (ASD) is crucial for best outcomes to interventions. In this paper, we present a machine learning (ML) approach to ASD diagnosis based on identifying specific behaviors from videos of infants of ages 6 through 36 months. The behaviors of interest include directed gaze towards faces or objects of interest, positive affect, and vocalization. The dataset consists of 2000 videos of 3-minute duration with these behaviors manually coded by expert raters. Moreover, the dataset has statistical features including duration and frequency of the above mentioned behaviors in the video collection as well as independent ASD diagnosis by clinicians. We tackle the ML problem in a two-stage approach. Firstly, we develop deep learning models for automatic identification of clinically relevant behaviors exhibited by infants in a one-on-one interaction setting with parents or expert clinicians. We report baseline results of behavior classification using two methods: (1) image based model (2) facial behavior features based model. We achieve 70% accuracy for smile, 68% accuracy for look face, 67% for look object and 53% accuracy for vocalization. Secondly, we focus on ASD diagnosis prediction by applying a feature selection process to identify the most significant statistical behavioral features and a over and under sampling process to mitigate the class imbalance, followed by developing a baseline ML classifier to achieve an accuracy of 82% for ASD diagnosis.","author":[{"family":"Wu","given":"Chongruo"},{"family":"Liaqat","given":"Sidrah"},{"family":"Helvaci","given":"Halil"},{"family":"Cheung","given":"Sen-Ching Samson"},{"family":"Chuah","given":"Chen-Nee"},{"family":"Ozonoff","given":"Sally"},{"family":"Young","given":"Gregory"}],"citation-key":"wu2021a","container-title":"Healthcom. International Conference on E-Health Networking, Applications and Services","container-title-short":"Healthcom","DOI":"10.1109/healthcom49281.2021.9398924","issued":{"date-parts":[["2021",3]]},"language":"eng","PMCID":"PMC8528233","PMID":"34693405","source":"PubMed","title":"Machine Learning Based Autism Spectrum Disorder Detection from Videos","type":"article-journal","volume":"2020"},
  {"id":"wu2023","abstract":"<sec><title>Introduction</title><p>Autism spectrum disorder (ASD) is a severe neurodevelopmental disorder that has become a major cause of disability in children. Digital therapeutics (DTx) delivers evidence-based therapeutic interventions to patients that are driven by software to prevent, manage, or treat a medical disorder or disease. This study objectively analyzed the current research status of global DTx in ASD from 2002 to 2022, aiming to explore the current global research status and trends in the field.</p></sec><sec><title>Methods</title><p>The Web of Science database was searched for articles about DTx in ASD from January 2002 to October 2022. CiteSpace was used to analyze the co-occurrence of keywords in literature, partnerships between authors, institutions, and countries, the sudden occurrence of keywords, clustering of keywords over time, and analysis of references, cited authors, and cited journals.</p></sec><sec><title>Results</title><p>A total of 509 articles were included. The most productive country and institution were the United States and Vanderbilt University. The largest contributing authors were Warren, Zachary, and Sarkar, Nilanjan. The most-cited journal was the <italic>Journal of Autism and Developmental Disorders</italic>. The most-cited and co-cited articles were Brian Scarselati (Robots for Use in Autism Research, 2012) and Ralph Adolphs (Abnormal processing of social information from faces in autism, 2001). “Artificial Intelligence,” “machine learning,” “Virtual Reality,” and “eye tracking” were common new and cutting-edge trends in research on DTx in ASD.</p></sec><sec><title>Discussion</title><p>The use of DTx in ASD is developing rapidly and gaining the attention of researchers worldwide. The publications in this field have increased year by year, mainly concentrated in the developed countries, especially in the United States. Both Vanderbilt University and Yale University are very important institutions in the field. The researcher from Vanderbilt University, Warren and Zachary, his dynamics or achievements in the field is also more worth our attention. The application of new technologies such as virtual reality, machine learning, and eye-tracking in this field has driven the development of DTx on ASD and is currently a popular research topic. More cross-regional and cross-disciplinary collaborations are recommended to advance the development and availability of DTx.</p></sec>","accessed":{"date-parts":[["2025",2,25]]},"author":[{"family":"Wu","given":"Xuesen"},{"family":"Deng","given":"Haiyin"},{"family":"Jian","given":"Shiyun"},{"family":"Chen","given":"Huian"},{"family":"Li","given":"Qing"},{"family":"Gong","given":"Ruiyu"},{"family":"Wu","given":"Jingsong"}],"citation-key":"wu2023","container-title":"Frontiers in Psychiatry","container-title-short":"Front. Psychiatry","DOI":"10.3389/fpsyt.2023.1126404","ISSN":"1664-0640","issued":{"date-parts":[["2023",5,15]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Global trends and hotspots in the digital therapeutics of autism spectrum disorders: a bibliometric analysis from 2002 to 2022","title-short":"Global trends and hotspots in the digital therapeutics of autism spectrum disorders","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2023.1126404/full","volume":"14"},
  {"id":"xie2023","abstract":"Facial micro-expressions indicate brief and subtle facial movements that appear during emotional communication. In comparison to macro-expressions, micro-expressions are more challenging to be analyzed due to the short span of time and the fine-grained changes. In recent years, micro-expression recognition (MER) has drawn much attention because it can benefit a wide range of applications, e.g., police interrogation, clinical diagnosis, depression analysis, and business negotiation. In this survey, we offer a fresh overview to discuss new research directions and challenges these days for MER tasks. For example, we review MER approaches from three novel aspects: macro-to-micro adaptation, recognition based on key apex frames, and recognition based on facial action units. Moreover, to mitigate the problem of limited and biased ME data, synthetic data generation is surveyed for the diversity enrichment of micro-expression data. Since micro-expression spotting can boost micro-expression analysis, the state-of-the-art spotting works are also introduced in this paper. At last, we discuss the challenges in MER research and provide potential solutions as well as possible directions for further investigation.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Xie","given":"Hong-Xia"},{"family":"Lo","given":"Ling"},{"family":"Shuai","given":"Hong-Han"},{"family":"Cheng","given":"Wen-Huang"}],"citation-key":"xie2023","container-title":"IEEE Transactions on Affective Computing","DOI":"10.1109/TAFFC.2022.3143100","ISSN":"1949-3045","issue":"3","issued":{"date-parts":[["2023",7]]},"page":"1857-1875","source":"IEEE Xplore","title":"An Overview of Facial Micro-Expression Analysis: Data, Methodology and Challenge","title-short":"An Overview of Facial Micro-Expression Analysis","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/9684697","volume":"14"},
  {"id":"xie2023a","abstract":"To our knowledge, it has been widely studied in Screen-2D modality for the six basic emotions proposed by Professor Paul Ekman, but there are only studies on their positive and negative valence in VR-3D modality. In this study, we will investigate whether the six basic emotions have stronger brain activation states in VR-3D modality than in Screen-2D modality. We designed an emotion-inducing experiment with six basic emotions (happiness, surprise, sadness, fear, anger, and disgust) to record the electroencephalogram (EEG) signals during watching VR-3D and Screen-2D videos. The power spectral density (PSD) was calculated to compare the brain activation differences between VR-3D and Screen-2D modalities during the induction of the six basic emotions. The results of statistical analysis of the relative power differences between VR-3D and Screen-2D modalities for each emotion revealed that both happiness and surprise presented greater differences in the \\alpha and \\gamma frequency bands, while sad, fear, disgust and anger all presented greater differences in the \\alpha and þeta frequency bands, which are mainly observed in the frontal and occipital regions. On the other hand, the six emotions all yielded satisfactory classification accuracy (above 85%) by classification from a subset of power feature of the brain activation states in the same emotion between the two modalities. Overall, there are significant differences in the induction of same discrete emotions in VR-3D and Screen-2D modalities, with greater brain activation in VR-3D modalities. These findings provide a better understanding about the neural activity of discrete emotional tasks assessed in VR environments.","accessed":{"date-parts":[["2024",11,25]]},"author":[{"family":"Xie","given":"Jialan"},{"family":"Lan","given":"Ping"},{"family":"Wang","given":"Shiyuan"},{"family":"Luo","given":"Yutong"},{"family":"Liu","given":"Guangyuan"}],"citation-key":"xie2023a","container-title":"IEEE Transactions on Neural Systems and Rehabilitation Engineering","DOI":"10.1109/TNSRE.2022.3229389","ISSN":"1558-0210","issued":{"date-parts":[["2023"]]},"page":"700-709","source":"IEEE Xplore","title":"Brain Activation Differences of Six Basic Emotions Between 2D Screen and Virtual Reality Modalities","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/9987528","volume":"31"},
  {"id":"xie2024","abstract":"We introduce PhysGaussian, a new method that seamlessly integrates physically grounded Newtonian dynamics within 3D Gaussians to achieve high-quality novel motion synthesis. Employing a custom Material Point Method (MPM), our approach enriches 3D Gaussian kernels with physically meaningful kinematic deformation and mechanical stress attributes, all evolved in line with continuum mechanics principles. A defining characteristic of our method is the seamless integration between physical simulation and visual rendering: both components utilize the same 3D Gaussian kernels as their discrete representations. This negates the necessity for triangle/tetrahedron meshing, marching cubes, \"cage meshes,\" or any other geometry embedding, highlighting the principle of \"what you see is what you simulate (WS$^2$).\" Our method demonstrates exceptional versatility across a wide variety of materials--including elastic entities, metals, non-Newtonian fluids, and granular materials--showcasing its strong capabilities in creating diverse visual content with novel viewpoints and movements. Our project page is at: https://xpandora.github.io/PhysGaussian/","accessed":{"date-parts":[["2024",12,11]]},"author":[{"family":"Xie","given":"Tianyi"},{"family":"Zong","given":"Zeshun"},{"family":"Qiu","given":"Yuxing"},{"family":"Li","given":"Xuan"},{"family":"Feng","given":"Yutao"},{"family":"Yang","given":"Yin"},{"family":"Jiang","given":"Chenfanfu"}],"citation-key":"xie2024","DOI":"10.48550/arXiv.2311.12198","issued":{"date-parts":[["2024",4,15]]},"number":"arXiv:2311.12198","publisher":"arXiv","source":"arXiv.org","title":"PhysGaussian: Physics-Integrated 3D Gaussians for Generative Dynamics","title-short":"PhysGaussian","type":"article","URL":"http://arxiv.org/abs/2311.12198"},
  {"id":"xu2020","abstract":"The high frame rate is a critical requirement for capturing fast human motions. In this setting, existing markerless image-based methods are constrained by the lighting requirement, the high data bandwidth and the consequent high computation overhead. In this paper, we propose EventCap - the first approach for 3D capturing of high-speed human motions using a single event camera. Our method combines model-based optimization and CNN-based human pose detection to capture high frequency motion details and to reduce the drifting in the tracking. As a result, we can capture fast motions at millisecond resolution with significantly higher data efficiency than using high frame rate videos. Experiments on our new event-based fast human motion dataset demonstrate the effectiveness and accuracy of our method, as well as its robustness to challenging lighting conditions.","accessed":{"date-parts":[["2024",6,11]]},"author":[{"family":"Xu","given":"Lan"},{"family":"Xu","given":"Weipeng"},{"family":"Golyanik","given":"Vladislav"},{"family":"Habermann","given":"Marc"},{"family":"Fang","given":"Lu"},{"family":"Theobalt","given":"Christian"}],"citation-key":"xu2020","container-title":"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","DOI":"10.1109/CVPR42600.2020.00502","event-title":"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","ISSN":"2575-7075","issued":{"date-parts":[["2020",6]]},"page":"4967-4977","source":"IEEE Xplore","title":"EventCap: Monocular 3D Capture of High-Speed Human Motions Using an Event Camera","title-short":"EventCap","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9157340"},
  {"id":"xu2021","abstract":"In this paper, we propose a new bio-inspired metric for classifying autism spectrum disorder (ASD) children and typically developed (TD) children. The model used in the Saliency4ASD Grand Challenge at ICME 2019 uses linear regression and prior probability to process distance and time data respectively. Unfortunately, this model performs unsatisfactorily because the visual attention characteristics of ASD and TD children are similar under certain circumstances. Therefore, we screen stimulus materials to select these with significant differences between eye movement distribution of ASD and TD children. We calculate the SSIM value of the ASD and TD data of each picture and conduct the subjective experiments to classify the stimulus materials into two categories: the images with the similar attention map for ASD and TD children; and the images with the dissimilar attention map for ASD and TD children. Owing to the biological property of eye, a viewing angle will be formed when people are observing a picture. Meanwhile, gazing at one point of longer time means more attention. Thus, we pick the point of the longest fixation time for each data group and extract the patch centered on this point. Three point-add strategies are afterward utilized to add points on this patch. Subsequently, a new bio-inspired metric based on graph theory is developed. Experimental results show that the new model outperforms our previous model with a classification accuracy of 72.3%.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Xu","given":"Shuning"},{"family":"Yan","given":"Junbing"},{"family":"Hu","given":"Menghan"}],"citation-key":"xu2021","container-title":"Signal Processing: Image Communication","container-title-short":"Signal Processing: Image Communication","DOI":"10.1016/j.image.2021.116171","ISSN":"0923-5965","issued":{"date-parts":[["2021",5,1]]},"page":"116171","source":"ScienceDirect","title":"A new bio-inspired metric based on eye movement data for classifying ASD and typically developing children","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0923596521000242","volume":"94"},
  {"id":"xu2023","abstract":"In this paper, we show the surprisingly good properties of plain vision transformers for body pose estimation from various aspects, namely simplicity in model structure, scalability in model size, flexibility in training paradigm, and transferability of knowledge between models, through a simple baseline model dubbed ViTPose. Specifically, ViTPose employs the plain and non-hierarchical vision transformer as an encoder to encode features and a lightweight decoder to decode body keypoints in either a top-down or a bottom-up manner. It can be scaled up from about 20M to 1B parameters by taking advantage of the scalable model capacity and high parallelism of the vision transformer, setting a new Pareto front for throughput and performance. Besides, ViTPose is very flexible regarding the attention type, input resolution, and pre-training and fine-tuning strategy. Based on the flexibility, a novel ViTPose+ model is proposed to deal with heterogeneous body keypoint categories in different types of body pose estimation tasks via knowledge factorization, i.e., adopting task-agnostic and task-specific feed-forward networks in the transformer. We also empirically demonstrate that the knowledge of large ViTPose models can be easily transferred to small ones via a simple knowledge token. Experimental results show that our ViTPose model outperforms representative methods on the challenging MS COCO Human Keypoint Detection benchmark at both top-down and bottom-up settings. Furthermore, our ViTPose+ model achieves state-of-the-art performance simultaneously on a series of body pose estimation tasks, including MS COCO, AI Challenger, OCHuman, MPII for human keypoint detection, COCO-Wholebody for whole-body keypoint detection, as well as AP-10K and APT-36K for animal keypoint detection, without sacrificing inference speed.","accessed":{"date-parts":[["2025",2,9]]},"author":[{"family":"Xu","given":"Yufei"},{"family":"Zhang","given":"Jing"},{"family":"Zhang","given":"Qiming"},{"family":"Tao","given":"Dacheng"}],"citation-key":"xu2023","DOI":"10.48550/arXiv.2212.04246","issued":{"date-parts":[["2023",12,14]]},"number":"arXiv:2212.04246","publisher":"arXiv","source":"arXiv.org","title":"ViTPose++: Vision Transformer for Generic Body Pose Estimation","title-short":"ViTPose++","type":"article","URL":"http://arxiv.org/abs/2212.04246"},
  {"id":"yan2014","abstract":"A robust automatic micro-expression recognition system would have broad applications in national safety, police interrogation, and clinical diagnosis. Developing such a system requires high quality databases with sufficient training samples which are currently not available. We reviewed the previously developed micro-expression databases and built an improved one (CASME II), with higher temporal resolution (200 fps) and spatial resolution (about 280×340 pixels on facial area). We elicited participants' facial expressions in a well-controlled laboratory environment and proper illumination (such as removing light flickering). Among nearly 3000 facial movements, 247 micro-expressions were selected for the database with action units (AUs) and emotions labeled. For baseline evaluation, LBP-TOP and SVM were employed respectively for feature extraction and classifier with the leave-one-subject-out cross-validation method. The best performance is 63.41% for 5-class classification.","author":[{"family":"Yan","given":"Wen-Jing"},{"family":"Li","given":"Xiaobai"},{"family":"Wang","given":"Su-Jing"},{"family":"Zhao","given":"Guoying"},{"family":"Liu","given":"Yong-Jin"},{"family":"Chen","given":"Yu-Hsin"},{"family":"Fu","given":"Xiaolan"}],"citation-key":"yan2014","container-title":"PloS one","container-title-short":"PloS one","DOI":"10.1371/journal.pone.0086041","issued":{"date-parts":[["2014",1,27]]},"page":"e86041","source":"ResearchGate","title":"CASME II: An Improved Spontaneous Micro-Expression Database and the Baseline Evaluation","title-short":"CASME II","type":"article-journal","volume":"9"},
  {"id":"yang2023","abstract":"Micro-expressions may occur in high-stake situations when people attempt to conceal or suppress their true feelings. Nowadays, intelligent micro-expression analysis has long been focused on videos captured under constrained laboratory conditions. This is due to the relatively small number of publicly available datasets. Moreover, micro-expression characteristics are subtle and brief, and thus very susceptible to interference from external factors and difficult to capture. In particular, head movement is unavoidable in unconstrained scenarios, making micro-expression spotting highly challenging. This paper proposes a simple yet effective method for avoiding the interference of head movement on micro-expression spotting in natural scenarios by considering three-dimensional space. In particular, based on the head pose, which can be mapped to two-dimensional vectors (translations and rotations) for representation, long and complex videos could be divided into short video segments that basically exclude head movement interference. Following that, segmented micro-expression spotting is realized based on an effective short-segment-based micro-expression spotting algorithm. Experimental results on in-the-wild databases demonstrate the effectiveness of our proposed method in avoiding head movement interference. Additionally, due to the simplicity of this method, it creates opportunities for spotting micro-expressions in real-world scenarios, possibly even in real-time. Furthermore, it helps alleviate the small sample size problem in micro-expression analysis by boosting the spotting performance in massive unlabeled videos.","accessed":{"date-parts":[["2024",7,22]]},"author":[{"family":"Yang","given":"Xingpeng"},{"family":"Yang","given":"Henian"},{"family":"Li","given":"Jingting"},{"family":"Wang","given":"Su-Jing"}],"citation-key":"yang2023","collection-title":"FME '23","container-title":"Proceedings of the 3rd Workshop on Facial Micro-Expression: Advanced Techniques for Multi-Modal Facial Expression Analysis","DOI":"10.1145/3607829.3616445","event-place":"New York, NY, USA","ISBN":"979-8-4007-0285-3","issued":{"date-parts":[["2023",10,29]]},"page":"9–16","publisher":"Association for Computing Machinery","publisher-place":"New York, NY, USA","source":"ACM Digital Library","title":"Simple but Effective In-the-wild Micro-Expression Spotting Based on Head Pose Segmentation","type":"paper-conference","URL":"https://doi.org/10.1145/3607829.3616445"},
  {"id":"yang2025","abstract":"Background: Virtual reality (VR) technology has shown significant potential in improving the social skills of children and adolescents with autism spectrum disorder (ASD). Objective: This study aimed to systematically review the evidence supporting the effectiveness of VR technology in improving the social skills of children and adolescents with ASD. Methods: The search for eligible studies encompassed 4 databases: PubMed, Web of Science, IEEE, and Scopus. Two (XY and JW) researchers independently assessed the extracted studies according to predefined criteria for inclusion and exclusion. These researchers also independently extracted information regarding gathered data on the sources, samples, measurement methods, primary results, and data related to the main results of the studies that met the inclusion criteria. The quality of the studies was further evaluated using the Physiotherapy Evidence Database scale. Results: This review analyzed 14 studies on using VR technology interventions to improve social skills in children and adolescents with ASD. Our findings indicate that VR interventions have a positive effect on improving social skills in children and adolescents with ASD. Compared with individuals with low-functioning autism (LFA), those with high-functioning autism (HFA) benefited more from the intervention. The duration and frequency of the intervention may also influence its effectiveness. In addition, immersive VR is more suitable for training complex skills in individuals with HFA. At the same time, nonimmersive VR stands out in terms of lower cost and flexibility, making it more appropriate for basic skill interventions for people with LFA. Finally, while VR technology positively enhances social skills, some studies have reported potential adverse side effects. According to the quality assessment using the Physiotherapy Evidence Database scale, of the 14 studies, 6 (43%) were classified as high quality, 4 (29%) as moderate quality, and 4 (29%) as low quality. Conclusions: This systematic review found that VR technology interventions positively impact social skills in children and adolescents with ASD, with particularly significant effects on the enhancement of complex social skills in individuals with HFA. For children and adolescents with LFA, progress was mainly observed in basic skills. Immersive VR interventions are more suitable for the development of complex skills. At the same time, nonimmersive VR, due to its lower cost and greater flexibility, also holds potential for application in specific contexts. However, the use of VR technology may lead to side effects such as dizziness, eye fatigue, and sensory overload, particularly in immersive settings. These potential issues should be carefully addressed in intervention designs to ensure user comfort and safety. Future research should focus on optimizing individualized interventions and further exploring the long-term effects of VR interventions. Clinical Trial: International Platform of Registered Systematic Review and Meta-analysis Protocols INPLASY202420079U1; https://inplasy.com/inplasy-2024-2-0079/","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Yang","given":"Xipeng"},{"family":"Wu","given":"Jinlong"},{"family":"Ma","given":"Yudan"},{"family":"Yu","given":"Jingxuan"},{"family":"Cao","given":"Hong"},{"family":"Zeng","given":"Aihua"},{"family":"Fu","given":"Rui"},{"family":"Tang","given":"Yucheng"},{"family":"Ren","given":"Zhanbing"}],"citation-key":"yang2025","container-title":"Journal of Medical Internet Research","DOI":"10.2196/60845","issue":"1","issued":{"date-parts":[["2025",2,5]]},"language":"EN","page":"e60845","publisher":"JMIR Publications Inc., Toronto, Canada","source":"www.jmir.org","title":"Effectiveness of Virtual Reality Technology Interventions in Improving the Social Skills of Children and Adolescents With Autism: Systematic Review","title-short":"Effectiveness of Virtual Reality Technology Interventions in Improving the Social Skills of Children and Adolescents With Autism","type":"article-journal","URL":"https://www.jmir.org/2025/1/e60845","volume":"27"},
  {"id":"yondjo2024","abstract":"Healthcare professionals (HPs) hold critical perspectives on the barriers and facilitating factors for the implementation of virtual reality (VR) dementia diagnosis tools in the clinical setting. This study aims to explore HP perspectives regarding the clinical implementation of dementia diagnosis tools using VR platforms.","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Yondjo","given":"Joshua"},{"family":"Siette","given":"Joyce"}],"citation-key":"yondjo2024","container-title":"BMC Medical Informatics and Decision Making","container-title-short":"BMC Med Inform Decis Mak","DOI":"10.1186/s12911-023-02413-y","ISSN":"1472-6947","issue":"1","issued":{"date-parts":[["2024",1,4]]},"language":"en","page":"9","source":"Springer Link","title":"“VR is the future”: perspectives of healthcare professionals on virtual reality as a diagnostic tool for dementia status in primary care","title-short":"“VR is the future”","type":"article-journal","URL":"https://doi.org/10.1186/s12911-023-02413-y","volume":"24"},
  {"id":"young2018","abstract":"Background\nAutism is a neurodevelopmental disorder with various clinical presentations. It has been historically considered a male disorder. An increasing number of authors stress the existence of sex/gender bias in prevalence and the need to define sex/gender differences in the clinical presentation.\nReview\nRecently, an increasing number of authors have studied the impact of sex/gender on autism's clinical presentation. The sex ratio of four boys to one girl commonly reported in literature is questioned. Sociocultural and familial influences can impact female clinical presentation as well as the way the difficulties of girls with autism are perceived. Issues of autism diagnostic instruments such as sex/gender bias are also studied since they have an impact on the access to diagnosis for girls. Clinical variability is a part of autism spectrum disorder, but some traits appear to be more specific of the female phenotype: existence of a “camouflage” phenomenon and less unusual play or restricted interests.\nDiscussion\nBetter understanding and diagnosis of females with autism is required to ensure the access to the support and treatment they need. Professionals must apprehend the sex/gender clinical differences to prevent the frequent misdiagnosis or missed diagnosis of females with autism.\nConclusion\nPursuing research on sex/gender differences seems necessary to ensure appropriate support and diagnosis of undiagnosed females.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Young","given":"H."},{"family":"Oreve","given":"M. -J."},{"family":"Speranza","given":"M."}],"citation-key":"young2018","container-title":"Archives de Pédiatrie","container-title-short":"Archives de Pédiatrie","DOI":"10.1016/j.arcped.2018.06.008","ISSN":"0929-693X","issue":"6","issued":{"date-parts":[["2018",8,1]]},"page":"399-403","source":"ScienceDirect","title":"Clinical characteristics and problems diagnosing autism spectrum disorder in girls","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0929693X18301477","volume":"25"},
  {"id":"young2021","abstract":"The image of the non-verbal child, flapping and spinning, totally absorbed in their own obsessive interests, as described by Kanner (Nerv Child 2:217–250, 1943), represents the more traditional view of Autism Spectrum Disorder (ASD) and the stereotypical behaviors that accompany this condition. However, with the revision of the Diagnostic and Statistical Manual of Mental Disorders (DSM) in 1994 (4th edition; DSM-IV; American Psychiatric Association. Diagnostic and statistical manual of mental disorders, 4th edn. Washington, DC: Author, 1994), the spectrum was expanded to include persons with a milder variant of the disorder (i.e. Asperger’s syndrome). With this came a broader interpretation of the presentation of these restricted and repetitive behaviors and interests (RRBI) in the current edition of the DSM, the DSM-5 (American Psychiatric Association. Diagnostic and statistical manual of mental disorders, 5th edn. Washington, DC: Author, 2013). As a result, the DSM-5 now includes heterogenic behaviors such as motor stereotypies, sensory-related behaviors, circumscribed interests, rituals, excessive sensitivity to change, and echolalic speech. While it is agreed that these behaviors are pervasive in this condition, and form part of the ASD diagnostic criteria, there remains a lack of consensus regarding a definition of RRBI (Leekam et al. Psychol Bull 137:562–593, 2011) and how pervasive these behaviors must be to be considered deviant and of diagnostic significance. This, therefore, creates challenges for researchers and clinicians in designing valid and reliable assessments of RRBI that are sensitive to this disorder, yet specific to ASD. The purpose of this chapter is to operationalize these behaviors and review the currently available tools so that we may determine whether these tools are valid measures of these behaviors.","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Young","given":"Robyn L."},{"family":"Lim","given":"Alliyza"}],"citation-key":"young2021","container-title":"Repetitive and Restricted Behaviors and Interests in Autism Spectrum Disorders: From Neurobiology to Behavior","DOI":"10.1007/978-3-030-66445-9_8","editor":[{"family":"Gal","given":"Eynat"},{"family":"Yirmiya","given":"Nurit"}],"event-place":"Cham","ISBN":"978-3-030-66445-9","issued":{"date-parts":[["2021"]]},"language":"en","page":"115-142","publisher":"Springer International Publishing","publisher-place":"Cham","source":"Springer Link","title":"The Measurement of Restricted and Repetitive Behaviors in Autism Spectrum Disorder","type":"chapter","URL":"https://doi.org/10.1007/978-3-030-66445-9_8"},
  {"id":"yu2024","abstract":"In this study, we present a quantitative and comprehensive analysis of social gaze in people with autism spectrum disorder (ASD). Diverging from traditional first-person camera perspectives based on eye-tracking technologies, this study utilizes a third-person perspective database from the Autism Diagnostic Observation Schedule, 2nd Edition (ADOS-2) interview videos, encompassing ASD participants and neurotypical individuals as a reference group. Employing computational models, we extracted and processed gaze-related features from the videos of both participants and examiners. The experimental samples were divided into three groups based on the presence of social gaze abnormalities and ASD diagnosis. This study quantitatively analyzed four gaze features: gaze engagement, gaze variance, gaze density map, and gaze diversion frequency. Furthermore, we developed a classifier trained on these features to identify gaze abnormalities in ASD participants. Together, we demonstrated the effectiveness of analyzing social gaze in people with ASD in naturalistic settings, showcasing the potential of third-person video perspectives in enhancing ASD diagnosis through gaze analysis.","accessed":{"date-parts":[["2025",2,3]]},"author":[{"family":"Yu","given":"Xiangxu"},{"family":"Ruan","given":"Mindi"},{"family":"Hu","given":"Chuanbo"},{"family":"Li","given":"Wenqi"},{"family":"Paul","given":"Lynn K."},{"family":"Li","given":"Xin"},{"family":"Wang","given":"Shuo"}],"citation-key":"yu2024","DOI":"10.48550/arXiv.2409.00664","issued":{"date-parts":[["2024",9,1]]},"number":"arXiv:2409.00664","publisher":"arXiv","source":"arXiv.org","title":"Video-based Analysis Reveals Atypical Social Gaze in People with Autism Spectrum Disorder","type":"article","URL":"http://arxiv.org/abs/2409.00664"},
  {"id":"zaharia2024","abstract":"Baby schema refers to physical features perceived as cute, known to trigger attention, induce positive emotions, and prompt social interactions. Given the reduced visual attention to social stimuli observed in individuals on the autism spectrum, the current study examines whether the sensitivity to baby schema is also affected. We expected that the looking time towards cute-featured stimuli would vary with symptom severity levels and would be associated with social affect. Ninety-four children (31 typically developing; 63 diagnosed with autism spectrum disorder - ASD) aged 20–83 months (M = 49.63, SD = 13.59) completed an eye-tracking visual exploration task. Autistic participants were separated into two groups based on symptom severity: children with high autism severity symptoms (HS ASD; N = 23) and low-moderate autism symptoms (LMS ASD; N = 40). Animals and neutral objects were simultaneously presented on the screen along with either human babies (condition 1) or adults (condition 2). The results indicated that visual attention oriented to cute-featured stimuli varied with autism symptom severity: only LMS and TD groups spend more time looking at cute-featured stimuli (babies; animals) than neutral objects. Moreover, children with higher severity in the social affect domain spent less time on the stimuli depicting cute than non-cute stimuli. These findings suggest that autism symptom severity and social skills are linked to variations in visual attention to cute stimuli. Implications of baby schema sensitivity are discussed in relation to the development of social competencies and play, responsiveness to robot-based interventions, as well as appraised relevance in autistic children.","accessed":{"date-parts":[["2025",2,11]]},"author":[{"family":"Zaharia","given":"Alexandra"},{"family":"Kojovic","given":"Nada"},{"family":"Rojanawisut","given":"Tara"},{"family":"Sander","given":"David"},{"family":"Schaer","given":"Marie"},{"family":"Samson","given":"Andrea C."}],"citation-key":"zaharia2024","container-title":"Journal of Autism and Developmental Disorders","container-title-short":"J Autism Dev Disord","DOI":"10.1007/s10803-024-06504-1","ISSN":"1573-3432","issued":{"date-parts":[["2024",8,22]]},"language":"en","source":"Springer Link","title":"Examining the Link Between Social Affect and Visual Exploration of Cute Stimuli in Autistic Children","type":"article-journal","URL":"https://doi.org/10.1007/s10803-024-06504-1"},
  {"id":"zammarchi2021","abstract":"Eye tracking provides a quantitative measure of eye movements during different activities. We report the results from a bibliometric analysis to investigate trends in eye tracking research applied to the study of different medical conditions. We conducted a search on the Web of Science Core Collection (WoS) database and analyzed the dataset of 2456 retrieved articles using VOSviewer and the Bibliometrix R package. The most represented area was psychiatry (503, 20.5%) followed by neuroscience (465, 18.9%) and psychology developmental (337, 13.7%). The annual scientific production growth was 11.14% and showed exponential growth with three main peaks in 2011, 2015 and 2017. Extensive collaboration networks were identified between the three countries with the highest scientific production, the USA (35.3%), the UK (9.5%) and Germany (7.3%). Based on term co-occurrence maps and analyses of sources of articles, we identified autism spectrum disorders as the most investigated condition and conducted specific analyses on 638 articles related to this topic which showed an annual scientific production growth of 16.52%. The majority of studies focused on autism used eye tracking to investigate gaze patterns with regards to stimuli related to social interaction. Our analysis highlights the widespread and increasing use of eye tracking in the study of different neurological and psychiatric conditions.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Zammarchi","given":"Gianpaolo"},{"family":"Conversano","given":"Claudio"}],"citation-key":"zammarchi2021","container-title":"Vision","container-title-short":"Vision (Basel)","DOI":"10.3390/vision5040056","ISSN":"2411-5150","issue":"4","issued":{"date-parts":[["2021",11,11]]},"page":"56","PMCID":"PMC8628933","PMID":"34842855","source":"PubMed Central","title":"Application of Eye Tracking Technology in Medicine: A Bibliometric Analysis","title-short":"Application of Eye Tracking Technology in Medicine","type":"article-journal","URL":"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8628933/","volume":"5"},
  {"id":"zaouiseghroucheni2025","abstract":"Tacit knowledge, often implicit and deeply embedded within individuals and organizational practices, is critical for fostering innovation and decision-making in knowledge management systems (KMS). Converting tacit knowledge into explicit forms enhances organizational effectiveness by making this knowledge accessible and reusable. This paper presents a comparative analysis of natural language processing (NLP) algorithms used for document and report mining to facilitate tacit knowledge conversion. This study focuses on algorithms that extract insights from semi-structured and document-based natural language representations, commonly found in organizational knowledge artifacts. Key NLP strategies, including text mining, information extraction, sentiment analysis, clustering, classification, recommendation systems, and affective computing, are evaluated for their effectiveness in identifying and externalizing tacit knowledge. The findings highlight the relative strengths and limitations of these techniques, offering practical guidance for selecting suitable algorithms based on organizational needs. Additionally, this paper identifies challenges and emerging opportunities for advancing NLP-driven tacit knowledge conversion, providing actionable insights for researchers and practitioners aiming to enhance KMS capabilities.","accessed":{"date-parts":[["2025",3,5]]},"author":[{"family":"Zaoui Seghroucheni","given":"Ouissale"},{"family":"Lazaar","given":"Mohamed"},{"family":"Al Achhab","given":"Mohammed"}],"citation-key":"zaouiseghroucheni2025","container-title":"Technologies","DOI":"10.3390/technologies13020087","ISSN":"2227-7080","issue":"2","issued":{"date-parts":[["2025",2]]},"language":"en","license":"http://creativecommons.org/licenses/by/3.0/","number":"2","page":"87","publisher":"Multidisciplinary Digital Publishing Institute","source":"www.mdpi.com","title":"Using AI and NLP for Tacit Knowledge Conversion in Knowledge Management Systems: A Comparative Analysis","title-short":"Using AI and NLP for Tacit Knowledge Conversion in Knowledge Management Systems","type":"article-journal","URL":"https://www.mdpi.com/2227-7080/13/2/87","volume":"13"},
  {"id":"zeng2009","abstract":"Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.","author":[{"family":"Zeng","given":"Zhihong"},{"family":"Pantic","given":"Maja"},{"family":"Roisman","given":"Glenn I."},{"family":"Huang","given":"Thomas S."}],"citation-key":"zeng2009","container-title":"IEEE transactions on pattern analysis and machine intelligence","container-title-short":"IEEE Trans Pattern Anal Mach Intell","DOI":"10.1109/TPAMI.2008.52","ISSN":"0162-8828","issue":"1","issued":{"date-parts":[["2009",1]]},"language":"eng","page":"39-58","PMID":"19029545","source":"PubMed","title":"A survey of affect recognition methods: audio, visual, and spontaneous expressions","title-short":"A survey of affect recognition methods","type":"article-journal","volume":"31"},
  {"id":"zhang2015","abstract":"Title: Classification of Evoked Emotions Using an Artificial Neural Network Based on Single, Short-Term Physiological Signals | Keywords: emotional recognition, ANN, automatic recognition, ECG, GSR | Author: Shanbin Zhang, Guangyuan Liu, and Xiangwei Lai","accessed":{"date-parts":[["2024",7,24]]},"author":[{"family":"Zhang","given":"Shanbin"},{"family":"Liu","given":"Guangyuan"},{"family":"Lai","given":"Xiangwei"}],"citation-key":"zhang2015","container-title":"Journal of Advanced Computational Intelligence and Intelligent Informatics","DOI":"10.20965/jaciii.2015.p0118","issue":"1","issued":{"date-parts":[["2015",1,20]]},"page":"118-126","publisher":"Fuji Technology Press Ltd.","source":"www.fujipress.jp","title":"Classification of Evoked Emotions Using an Artificial Neural Network Based on Single, Short-Term Physiological Signals","type":"article-journal","URL":"https://www.fujipress.jp/jaciii/jc/jacii001900010118/","volume":"19"},
  {"id":"zhang2023","abstract":"<p>This study delved into the realm of facial emotion recognition within virtual reality (VR) environments. Using a novel system with MobileNet V2, a lightweight convolutional neural network, we tested emotion detection on 15 university students. High recognition rates were observed for emotions like “Neutral”, “Happiness”, “Sadness”, and “Surprise”. However, the model struggled with 'Anger' and 'Fear', often confusing them with “neutral”. These discrepancies might be attributed to overlapping facial indicators, limited training samples, and the precision of the devices used. Nonetheless, our research underscores the viability of using facial emotion recognition technology in VR and recommends model improvements, the adoption of advanced devices, and a more holistic approach to foster the future development of VR emotion recognition.</p>","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Zhang","given":"Zhihui"},{"family":"Fort","given":"Josep M."},{"family":"Giménez Mateu","given":"Lluis"}],"citation-key":"zhang2023","container-title":"Frontiers in Psychology","container-title-short":"Front. Psychol.","DOI":"10.3389/fpsyg.2023.1280136","ISSN":"1664-1078","issued":{"date-parts":[["2023",10,11]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Facial expression recognition in virtual reality environments: challenges and opportunities","title-short":"Facial expression recognition in virtual reality environments","type":"article-journal","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2023.1280136/full","volume":"14"},
  {"id":"zhang2023a","abstract":"Technology-mediated dance experiences, as a medium of entertainment, are a key element in both traditional and virtual reality-based gaming platforms. These platforms predominantly depend on unobtrusive and continuous human pose estimation as a means of capturing input. Current solutions primarily employ RGB or RGB-Depth cameras for dance gaming applications; however, the former is hindered by low-light conditions due to motion blur and reduced sensitivity, while the latter exhibits excessive power consumption, diminished frame rates, and restricted operational distance. Boasting ultra-low latency, energy efficiency, and a wide dynamic range, neuromorphic cameras present a viable solution to surmount these limitations. Here, we introduce YeLan, a neuromorphic camera-driven, three-dimensional, high-frequency human pose estimation (HPE) system capable of withstanding low-light environments and dynamic backgrounds. We have compiled the first-ever neuromorphic camera dance HPE dataset and devised a fully adaptable motion-to-event, physics-conscious simulator. YeLan surpasses baseline models under strenuous conditions and exhibits resilience against varying clothing types, background motion, viewing angles, occlusions, and lighting fluctuations.","accessed":{"date-parts":[["2024",6,11]]},"author":[{"family":"Zhang","given":"Zhongyang"},{"family":"Chai","given":"Kaidong"},{"family":"Yu","given":"Haowen"},{"family":"Majaj","given":"Ramzi"},{"family":"Walsh","given":"Francesca"},{"family":"Wang","given":"Edward"},{"family":"Mahbub","given":"Upal"},{"family":"Siegelmann","given":"Hava"},{"family":"Kim","given":"Donghyun"},{"family":"Rahman","given":"Tauhidur"}],"citation-key":"zhang2023a","container-title":"Neurocomputing","container-title-short":"Neurocomput.","DOI":"10.1016/j.neucom.2023.126388","ISSN":"0925-2312","issue":"C","issued":{"date-parts":[["2023",8,28]]},"source":"ACM Digital Library","title":"Neuromorphic high-frequency 3D dancing pose estimation in dynamic environment","type":"article-journal","URL":"https://doi.org/10.1016/j.neucom.2023.126388","volume":"547"},
  {"id":"zhang2023b","abstract":"We present Video-LLaMA a multi-modal framework that empowers Large Language Models (LLMs) with the capability of understanding both visual and auditory content in the video. Video-LLaMA bootstraps cross-modal training from the frozen pre-trained visual and audio encoders and the frozen LLMs. Unlike previous works that complement LLMs to process the visual or audio signals only, Video-LLaMA enables video comprehension by tackling two challenges: (1) capturing the temporal changes in visual scenes, (2) integrating audio-visual signals. To counter the first challenge, we propose a Video Q-former to assemble a pre-trained image encoder into our video encoder and introduce a video-to-text generation task to learn video-language correspondence. For the second challenge, we leverage ImageBind, a universal embedding model aligning multiple modalities, as the pre-trained audio encoder and introduce an Audio Q-former on top of ImageBind to learn reasonable auditory query embeddings for the LLM module. To align the output of both visual and audio encoders with LLM's embedding space, we first train Video-LLaMA on massive video/image-caption pairs and then tune our model with visual-instruction datasets of moderate amount but higher quality. We found Video-LLaMA shows the ability to perceive and comprehend video content and generate meaningful responses grounded in the visual and auditory information presented in the videos.","accessed":{"date-parts":[["2024",10,16]]},"author":[{"family":"Zhang","given":"Hang"},{"family":"Li","given":"Xin"},{"family":"Bing","given":"Lidong"}],"citation-key":"zhang2023b","issued":{"date-parts":[["2023",10,25]]},"number":"arXiv:2306.02858","publisher":"arXiv","source":"arXiv.org","title":"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding","title-short":"Video-LLaMA","type":"article","URL":"http://arxiv.org/abs/2306.02858"},
  {"id":"zhang2024","abstract":"Eye tracking has shown great promise in many scientific fields and daily applications, ranging from the early detection of mental health disorders to foveated rendering in virtual reality (VR). These applications all call for a robust system for high-frequency near-eye movement sensing and analysis in high precision, which cannot be guaranteed by the existing eye tracking solutions with CCD/CMOS cameras. To bridge the gap, in this paper, we propose Swift-Eye, an offline precise and robust pupil estimation and tracking framework to support high-frequency near-eye movement analysis, especially when the pupil region is partially occluded. Swift-Eye is built upon the emerging event cameras to capture the high-speed movement of eyes in high temporal resolution. Then, a series of bespoke components are designed to generate high-quality near-eye movement video at a high frame rate over kilohertz and deal with the occlusion over the pupil caused by involuntary eye blinks. According to our extensive evaluations on EV-Eye, a large-scale public dataset for eye tracking using event cameras, Swift-Eye shows high robustness against significant occlusion. It can improve the IoU and F1-score of the pupil estimation by 20% and 12.5% respectively, compared with the second-best competing approach, when over 80% of the pupil region is occluded by the eyelid. Lastly, it provides continuous and smooth traces of pupils in extremely high temporal resolution and can support high-frequency eye movement analysis and a number of potential applications, such as mental health diagnosis, behaviour-brain association, etc. The implementation details and source codes can be found at https://github.com/ztysdu/Swift-Eye.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Zhang","given":"Tongyu"},{"family":"Shen","given":"Yiran"},{"family":"Zhao","given":"Guangrong"},{"family":"Wang","given":"Lin"},{"family":"Chen","given":"Xiaoming"},{"family":"Bai","given":"Lu"},{"family":"Zhou","given":"Yuanfeng"}],"citation-key":"zhang2024","container-title":"IEEE Transactions on Visualization and Computer Graphics","DOI":"10.1109/TVCG.2024.3372039","ISSN":"1941-0506","issue":"5","issued":{"date-parts":[["2024",5]]},"page":"2077-2086","source":"IEEE Xplore","title":"Swift-Eye: Towards Anti-blink Pupil Tracking for Precise and Robust High-Frequency Near-Eye Movement Analysis with Event Cameras","title-short":"Swift-Eye","type":"article-journal","URL":"https://ieeexplore.ieee.org/document/10458392","volume":"30"},
  {"id":"zhang2024a","abstract":"Emotion recognition has recently attracted extensive interest due to its significant applications to human–computer interaction. The expression of human emotion depends on various verbal and non-verbal languages like audio, visual, text, etc. Emotion recognition is thus well suited as a multimodal rather than single-modal learning problem. Owing to the powerful feature learning capability, extensive deep learning methods have been recently leveraged to capture high-level emotional feature representations for multimodal emotion recognition (MER). Therefore, this paper makes the first effort in comprehensively summarize recent advances in deep learning-based multimodal emotion recognition (DL-MER) involved in audio, visual, and text modalities. We focus on: (1) MER milestones are given to summarize the development tendency of MER, and conventional multimodal emotional datasets are provided; (2) The core principles of typical deep learning models and its recent advancements are overviewed; (3) A systematic survey and taxonomy is provided to cover the state-of-the-art methods related to two key steps in a MER system, including feature extraction and multimodal information fusion; (4) The research challenges and open issues in this field are discussed, and promising future directions are given.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Zhang","given":"Shiqing"},{"family":"Yang","given":"Yijiao"},{"family":"Chen","given":"Chen"},{"family":"Zhang","given":"Xingnan"},{"family":"Leng","given":"Qingming"},{"family":"Zhao","given":"Xiaoming"}],"citation-key":"zhang2024a","container-title":"Expert Systems with Applications","container-title-short":"Expert Systems with Applications","DOI":"10.1016/j.eswa.2023.121692","ISSN":"0957-4174","issued":{"date-parts":[["2024",3,1]]},"page":"121692","source":"ScienceDirect","title":"Deep learning-based multimodal emotion recognition from audio, visual, and text modalities: A systematic review of recent advancements and future prospects","title-short":"Deep learning-based multimodal emotion recognition from audio, visual, and text modalities","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0957417423021942","volume":"237"},
  {"id":"zhang2024b","abstract":"Emotion recognition has recently attracted extensive interest due to its significant applications to human–computer interaction. The expression of human emotion depends on various verbal and non-verbal languages like audio, visual, text, etc. Emotion recognition is thus well suited as a multimodal rather than single-modal learning problem. Owing to the powerful feature learning capability, extensive deep learning methods have been recently leveraged to capture high-level emotional feature representations for multimodal emotion recognition (MER). Therefore, this paper makes the first effort in comprehensively summarize recent advances in deep learning-based multimodal emotion recognition (DL-MER) involved in audio, visual, and text modalities. We focus on: (1) MER milestones are given to summarize the development tendency of MER, and conventional multimodal emotional datasets are provided; (2) The core principles of typical deep learning models and its recent advancements are overviewed; (3) A systematic survey and taxonomy is provided to cover the state-of-theart methods related to two key steps in a MER system, including feature extraction and multimodal information fusion; (4) The research challenges and open issues in this field are discussed, and promising future directions are given.","accessed":{"date-parts":[["2024",10,24]]},"author":[{"family":"Zhang","given":"Shiqing"},{"family":"Yang","given":"Yijiao"},{"family":"Chen","given":"Chen"},{"family":"Zhang","given":"Xingnan"},{"family":"Leng","given":"Qingming"},{"family":"Zhao","given":"Xiaoming"}],"citation-key":"zhang2024b","container-title":"Expert Systems with Applications","container-title-short":"Expert Systems with Applications","DOI":"10.1016/j.eswa.2023.121692","ISSN":"09574174","issued":{"date-parts":[["2024",3]]},"language":"en","page":"121692","source":"DOI.org (Crossref)","title":"Deep learning-based multimodal emotion recognition from audio, visual, and text modalities: A systematic review of recent advancements and future prospects","title-short":"Deep learning-based multimodal emotion recognition from audio, visual, and text modalities","type":"article-journal","URL":"https://linkinghub.elsevier.com/retrieve/pii/S0957417423021942","volume":"237"},
  {"id":"zhang2024c","abstract":"This paper proposes a novel framework for large-scale scene reconstruction based on 3D Gaussian splatting (3DGS) and aims to address the scalability and accuracy challenges faced by existing methods. For tackling the scalability issue, we split the large scene into multiple cells, and the candidate point-cloud and camera views of each cell are correlated through a visibility-based camera selection and a progressive point-cloud extension. To reinforce the rendering quality, three highlighted improvements are made in comparison with vanilla 3DGS, which are a strategy of the ray-Gaussian intersection and the novel Gaussians density control for learning efficiency, an appearance decoupling module based on ConvKAN network to solve uneven lighting conditions in large-scale scenes, and a refined final loss with the color loss, the depth distortion loss, and the normal consistency loss. Finally, the seamless stitching procedure is executed to merge the individual Gaussian radiance field for novel view synthesis across different cells. Evaluation of Mill19, Urban3D, and MatrixCity datasets shows that our method consistently generates more high-fidelity rendering results than state-of-the-art methods of large-scale scene reconstruction. We further validate the generalizability of the proposed approach by rendering on self-collected video clips recorded by a commercial drone.","accessed":{"date-parts":[["2024",12,18]]},"author":[{"family":"Zhang","given":"Hanyue"},{"family":"Yang","given":"Zhiliu"},{"family":"Zuo","given":"Xinhe"},{"family":"Tong","given":"Yuxin"},{"family":"Long","given":"Ying"},{"family":"Liu","given":"Chen"}],"citation-key":"zhang2024c","DOI":"10.48550/arXiv.2409.12774","issued":{"date-parts":[["2024",9,24]]},"number":"arXiv:2409.12774","publisher":"arXiv","source":"arXiv.org","title":"GaRField++: Reinforced Gaussian Radiance Fields for Large-Scale 3D Scene Reconstruction","title-short":"GaRField++","type":"article","URL":"http://arxiv.org/abs/2409.12774"},
  {"id":"zhang2025","abstract":"Industrial time series data provides real-time information about the operational status of equipment and helps identify anomalies. Data-driven and knowledge-guided methods have become predominant in this field. However, these methods depend on industrial domain knowledge and high-quality industrial data which can lead to issues such as unclear diagnostic results and lengthy development cycles. This paper introduces a novel human-in-the-loop task-driven approach to reduce reliance on manually annotated data and improve the interpretability of diagnostic outcomes. This approach utilises a large language model for fault detection, fostering process autonomy and enhancing human–machine collaboration. Furthermore, this paper explores four key roles of the large language model: managing the data pipeline, correcting causality, controlling model management, and making decisions about diagnostic results. Additionally, it presents a prompt structure designed for fault diagnosis of time series data, enabling the large language model to realize task-driven. Finally, the paper validates the proposed framework through a case study in the context of steel metallurgy.","accessed":{"date-parts":[["2025",1,10]]},"author":[{"family":"Zhang","given":"Qi"},{"family":"Xu","given":"Chao"},{"family":"Li","given":"Jie"},{"family":"Sun","given":"Yicheng"},{"family":"Bao","given":"Jinsong"},{"family":"Zhang","given":"Dan"}],"citation-key":"zhang2025","container-title":"Expert Systems with Applications","container-title-short":"Expert Systems with Applications","DOI":"10.1016/j.eswa.2024.125861","ISSN":"0957-4174","issued":{"date-parts":[["2025",3,10]]},"page":"125861","source":"ScienceDirect","title":"LLM-TSFD: An industrial time series human-in-the-loop fault diagnosis method based on a large language model","title-short":"LLM-TSFD","type":"article-journal","URL":"https://www.sciencedirect.com/science/article/pii/S0957417424027283","volume":"264"},
  {"id":"zhang2025a","abstract":"Cognitive assessment can reveal a person's cognitive processing and behavioral patterns, making it an indispensable component of autism intervention and prognosis. Existing machine-assisted cognitive assessment methods primarily focus on children's performance outcomes, overlooking distinctive behavioral models, particularly characteristics of eye movement behavior, which have been demonstrated as the most direct indicators of cognitive abilities. In this study, we explore eye-tracking biomarkers for assisting cognitive assessment through a series of meticulously designed multi-level human-computer interaction protocols, encompassing three cognitive abilities: pairing and categorization, emotion recognition, and social interaction. A platform embedded with an eye-tracking module has been developed to reliably collect and analyze eye movement data, even in the presence of unrestricted large head movements in children. Experimental results indicate that there are significant group differences between autism and typically developing children in the eye-tracking features of total fixation duration, response latency, time to first fixation, mean fixation duration, and visit count in the absence of significant intergroup differences in the Wechsler Preschool and Primary Scale of Intelligence (WPPSI) and Wechsler Intelligence Scale for Children (WISC) assessment results. In addition, certain eye movement features in each group are correlated with WPPSI/WISC scale scores, enabling clinical cognitive assessments within each group based on these eye movement features. This study suggests that using eye-tracking features as biomarkers to assist detailed cognitive assessments holds significant potential for the intervention and prognosis of autism.","accessed":{"date-parts":[["2025",1,28]]},"author":[{"family":"Zhang","given":"Hanlin"},{"family":"Hu","given":"Chunchun"},{"family":"Wang","given":"Zhiyong"},{"family":"Zhou","given":"Bingrui"},{"family":"Wang","given":"Xinming"},{"family":"Nie","given":"Wei"},{"family":"Ye","given":"Qinyi"},{"family":"Lin","given":"Ruihan"},{"family":"Xu","given":"Xiu"},{"family":"Liu","given":"Honghai"}],"citation-key":"zhang2025a","container-title":"IEEE Journal of Biomedical and Health Informatics","DOI":"10.1109/JBHI.2025.3531421","ISSN":"2168-2208","issued":{"date-parts":[["2025"]]},"page":"1-14","source":"IEEE Xplore","title":"Exploring Eye-tracking based Biomarkers to Assess Cognitive Abilities in Autistic Children: A Feasibility Study","title-short":"Exploring Eye-tracking based Biomarkers to Assess Cognitive Abilities in Autistic Children","type":"article-journal","URL":"https://ieeexplore.ieee.org/abstract/document/10845174"},
  {"id":"zhao2022","abstract":"<sec><title>Objective</title><p>We aimed to explore the impact of using virtual reality technology to intervene in and encourage the developmental behavior areas of cognition, imitation, and social interaction in children with autism spectrum disorder.</p></sec><sec><title>Methods</title><p>Forty-four children with autism spectrum disorder were divided randomly into an intervention group and a control group, with each group consisting of 22 participants. Incorporating conventional rehabilitation strategies, virtual reality technology was used with the intervention group to conduct rehabilitation training in areas including cognition, imitation, and social interaction. The control group was provided conventional/routine clinical rehabilitation training. The children's cognitive development was evaluated before and 3 months after intervention.</p></sec><sec><title>Results</title><p>After intervention, the developmental abilities of both groups of children in the areas of cognition, imitation, and social interaction were improved over their abilities measured before the intervention (<italic>P</italic> &lt; 0.05). However, post-intervention score differences between the two groups demonstrated that the intervention group levels were better than the control group levels only in the areas of cognition and social interaction (<italic>P</italic> &lt; 0.05).</p></sec><sec><title>Conclusion</title><p>Combining virtual reality with conventional rehabilitation training improved the cognitive and social development of children with autism spectrum disorder and supported the goal of improving the rehabilitation effect.</p></sec>","accessed":{"date-parts":[["2025",2,14]]},"author":[{"family":"Zhao","given":"Junqiang"},{"family":"Zhang","given":"Xinxin"},{"family":"Lu","given":"Yi"},{"family":"Wu","given":"Xingyang"},{"family":"Zhou","given":"Fujun"},{"family":"Yang","given":"Shichang"},{"family":"Wang","given":"Luping"},{"family":"Wu","given":"Xiaoyan"},{"family":"Fei","given":"Fangrong"}],"citation-key":"zhao2022","container-title":"Frontiers in Public Health","container-title-short":"Front. Public Health","DOI":"10.3389/fpubh.2022.1029392","ISSN":"2296-2565","issued":{"date-parts":[["2022",10,6]]},"language":"English","publisher":"Frontiers","source":"Frontiers","title":"Virtual reality technology enhances the cognitive and social communication of children with autism spectrum disorder","type":"article-journal","URL":"https://www.frontiersin.org/journals/public-health/articles/10.3389/fpubh.2022.1029392/full","volume":"10"},
  {"id":"zhao2023","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Zhao","given":"Guangrong"},{"family":"Yang","given":"Yurun"},{"family":"Liu","given":"Jingwei"},{"family":"Chen","given":"Ning"},{"family":"Shen","given":"Yiran"},{"family":"Wen","given":"Hongkai"},{"family":"Lan","given":"Guohao"}],"citation-key":"zhao2023","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2023",12,15]]},"language":"en","page":"62169-62182","source":"papers.nips.cc","title":"EV-Eye: Rethinking High-frequency Eye Tracking through the Lenses of Event Cameras","title-short":"EV-Eye","type":"article-journal","URL":"https://papers.nips.cc/paper_files/paper/2023/hash/c41b5d8c1ba15b2aa83e4fa1541f02c8-Abstract-Datasets_and_Benchmarks.html","volume":"36"},
  {"id":"zhu2024","abstract":"Recent years have witnessed the resurgence of knowledge engineering which is featured by the fast growth of knowledge graphs. However, most of existing knowledge graphs are represented with pure symbols, which hurts the machine's capability to understand the real world. The multi-modalization of knowledge graphs is an inevitable key step towards the realization of human-level machine intelligence. The results of this endeavor are Multi-modal Knowledge Graphs (MMKGs). In this survey on MMKGs constructed by texts and images, we first give definitions of MMKGs, followed with the preliminaries on multi-modal tasks and techniques. We then systematically review the challenges, progresses and opportunities on the construction and application of MMKGs respectively, with detailed analyses of the strength and weakness of different solutions. We finalize this survey with open research problems relevant to MMKGs.","accessed":{"date-parts":[["2025",1,10]]},"author":[{"family":"Zhu","given":"Xiangru"},{"family":"Li","given":"Zhixu"},{"family":"Wang","given":"Xiaodan"},{"family":"Jiang","given":"Xueyao"},{"family":"Sun","given":"Penglei"},{"family":"Wang","given":"Xuwu"},{"family":"Xiao","given":"Yanghua"},{"family":"Yuan","given":"Nicholas Jing"}],"citation-key":"zhu2024","container-title":"IEEE Transactions on Knowledge and Data Engineering","container-title-short":"IEEE Trans. Knowl. Data Eng.","DOI":"10.1109/TKDE.2022.3224228","ISSN":"1041-4347, 1558-2191, 2326-3865","issue":"2","issued":{"date-parts":[["2024",2]]},"page":"715-735","source":"arXiv.org","title":"Multi-Modal Knowledge Graph Construction and Application: A Survey","title-short":"Multi-Modal Knowledge Graph Construction and Application","type":"article-journal","URL":"http://arxiv.org/abs/2202.05786","volume":"36"},
  {"id":"zia2023","abstract":"This article aims to explore the connections between tacit knowledge management and the capacity to create new products and services for stimulating organizational performance.,This research utilizes a questionnaire-based study and 378 questionnaires gathered from different provinces of China between August and October 2022. The SmartPLS technique was used to evaluate the regression and mediation analysis on lower-order and higher-order components of the research hypotheses behind the model.,This investigation's results indicate that the tacit knowledge management process (TKMP) significantly drives product and service innovation and impacts organizational performance (ORP). According to the results, TKMP did not directly influence ORP and product innovation to mediate between Tacit knowledge and organizational performance.,Future research should concentrate on different combinations of influences on innovation and other consequences of introducing innovation into businesses. Moreover, researchers may add moderators to innovation and organizational performance.,This study assists managers in how tacit knowledge management affects organisational performance by examining product/service innovation capabilities. Product innovation also mediates between tacit knowledge and organizational performance. Service innovation improves organizational performance, prioritizing knowledge creation, sharing and retention to increase innovation and organizational success.,This study contributes to the literature on tacit knowledge management, innovation capability and organizational performance by concentrating on the tacit knowledge process and using the resource-based view. This study gives a solid theoretical and practical basis for understanding the component interactions.","accessed":{"date-parts":[["2025",3,5]]},"archive_location":"world","author":[{"family":"Zia","given":"Umair"},{"family":"Zhang","given":"Jianhua"},{"family":"Alam","given":"Sajjad"}],"citation-key":"zia2023","container-title":"Kybernetes","DOI":"10.1108/K-03-2023-0444","ISSN":"0368-492X","issue":"11","issued":{"date-parts":[["2023",8,3]]},"language":"en","page":"4976-5000","publisher":"Emerald Publishing Limited","source":"www.emerald.com","title":"Role of tacit knowledge management process and innovation capability for stimulating organizational performance: empirical analysis, PLS-SEM approach","title-short":"Role of tacit knowledge management process and innovation capability for stimulating organizational performance","type":"article-journal","URL":"https://www.emerald.com/insight/content/doi/10.1108/k-03-2023-0444/full/html","volume":"53"},
  {"id":"zotero-1798","abstract":"Avec la montée en puissance des technologies, c'est le bon moment pour de nombreuses entreprises de commencer ou d'accélérer l’usage de la VR. De nouvelles opportunités se créent en matière de perfectionnement et de collaboration basées sur la réalité virtuelle.","accessed":{"date-parts":[["2024",7,24]]},"citation-key":"zotero-1798","language":"fr","title":"Les nouvelles technologies au service de la formation - PwC Store France","type":"webpage","URL":"https://store.pwc.fr/fr/nouvelles-technologies-pour-formation"},
  {"id":"zotero-1976","accessed":{"date-parts":[["2024",9,15]]},"citation-key":"zotero-1976","title":"VECTRA M3 3D Imaging System | Canfield Scientific","type":"webpage","URL":"https://www.canfieldsci.com/imaging-systems/vectra-m3-3d-imaging-system/"},
  {"id":"zotero-1982","accessed":{"date-parts":[["2024",9,15]]},"citation-key":"zotero-1982","title":"VISIA Skin Analysis | Canfield Scientific","type":"webpage","URL":"https://www.canfieldsci.com/imaging-systems/visia-complexion-analysis/"},
  {"id":"zotero-5033","abstract":"Background: Autism spectrum disorder (ASD) is a complex neurodevelopmental disorder that affects a significant proportion of the world's population, particularly children and adolescents. The sensory processing issues can be an evidence-based target for therapeutic/corrective interventions by controlling the intensity and targeted replacement of maladaptive sensory stimuli with neutral stimuli using virtual reality or augmented reality. Subjects and methods: We searched for articles on Pubmed. The search query included ((VR or virtual reality) or (AR or augmented reality)) and (children or adolescents) and (ASD or autism spectrum disorder or autism).\nResults: Our criteria were met by 25 articles. 19 articles used VR, 5 articles used AR and 1 article used MR. Most interventions offer children and adolescents with ASD individualized tasks. Immersive VR games developed collaborative skills. Other systems encourage and teach directed facial gaze. Evaluation of the effectiveness of learning in VR/AR environment is carried out by means of different scales, qualitative analysis of surveys, questionnaires and interviews, studying the number and duration of eye contacts between the participant and the avatar. It should be noted that almost all studies were conducted on small samples, so their results allow us to draw only preliminary conclusions about the effectiveness of VR /AR.\nConclusions: The following key areas of VR/AR technologies for children and adolescents with high-functioning ASD can be identified: communicating with an avatar, including answering its questions, tracking the child's gaze and encouraging the child to look at the face, placing it in social situations close to real life, practicing common everyday situations, learning to recognize emotions. A VR/AR-based therapy approach may help children with autism spectrum disorder without cognitive impairment to develop higher levels of adaptation in terms of social and communication skills. However, more research is needed to evaluate the effectiveness of different methods.","citation-key":"zotero-5033","container-title":"VIRTUAL REALITY","language":"en","source":"Zotero","title":"PSYCHIATRIA DANUBINA","type":"article-journal","volume":"36"},
  {"id":"zotero-5946","accessed":{"date-parts":[["2025",3,11]]},"citation-key":"zotero-5946","title":"Frontiers | Characterization of Clinical Manifestations in the Co-occurring Phenotype of Attention Deficit/Hyperactivity Disorder and Autism Spectrum Disorder","type":"webpage","URL":"https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.00861/full"},
  {"id":"zou2021","abstract":"Event camera is an emerging imaging sensor for capturing dynamics of moving objects as events, which motivates our work in estimating 3D human pose and shape from the event signals. Events, on the other hand, have their unique challenges: rather than capturing static body postures, the event signals are best at capturing local motions. This leads us to propose a two-stage deep learning approach, called EventHPE. The first-stage, FlowNet, is trained by unsupervised learning to infer optical flow from events. Both events and optical flow are closely related to human body dynamics, which are fed as input to the ShapeNet in the second stage, to estimate 3D human shapes. To mitigate the discrepancy between image-based flow (optical flow) and shape-based flow (vertices movement of human body shape), a novel flow coherence loss is introduced by exploiting the fact that both flows are originated from the identical human motion. An in-house event-based 3D human dataset is curated that comes with 3D pose and shape annotations, which is by far the largest one to our knowledge. Empirical evaluations on DHP19 dataset and our in-house dataset demonstrate the effectiveness of our approach.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Zou","given":"Shihao"},{"family":"Guo","given":"Chuan"},{"family":"Zuo","given":"Xinxin"},{"family":"Wang","given":"Sen"},{"family":"Wang","given":"Pengyu"},{"family":"Hu","given":"Xiaoqin"},{"family":"Chen","given":"Shoushun"},{"family":"Gong","given":"Minglun"},{"family":"Cheng","given":"Li"}],"citation-key":"zou2021","container-title":"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","DOI":"10.1109/ICCV48922.2021.01081","event-title":"2021 IEEE/CVF International Conference on Computer Vision (ICCV)","ISSN":"2380-7504","issued":{"date-parts":[["2021",10]]},"page":"10976-10985","source":"IEEE Xplore","title":"EventHPE: Event-based 3D Human Pose and Shape Estimation","title-short":"EventHPE","type":"paper-conference","URL":"https://ieeexplore.ieee.org/document/9710646"},
  {"id":"zou2023","abstract":"Event camera, as an emerging biologically-inspired vision sensor for capturing motion dynamics, presents new potential for 3D human pose tracking, or video-based 3D human pose estimation. However, existing works in pose tracking either require the presence of additional gray-scale images to establish a solid starting pose, or ignore the temporal dependencies all together by collapsing segments of event streams to form static event frames. Meanwhile, although the effectiveness of Artificial Neural Networks (ANNs, a.k.a. dense deep learning) has been showcased in many event-based tasks, the use of ANNs tends to neglect the fact that compared to the dense frame-based image sequences, the occurrence of events from an event camera is spatiotemporally much sparser. Motivated by the above mentioned issues, we present in this paper a dedicated end-to-end sparse deep learning approach for event-based pose tracking: 1) to our knowledge this is the first time that 3D human pose tracking is obtained from events only, thus eliminating the need of accessing to any frame-based images as part of input; 2) our approach is based entirely upon the framework of Spiking Neural Networks (SNNs), which consists of Spike-Element-Wise (SEW) ResNet and a novel Spiking Spatiotemporal Transformer; 3) a large-scale synthetic dataset is constructed that features a broad and diverse set of annotated 3D human motions, as well as longer hours of event stream data, named SynEventHPD. Empirical experiments demonstrate that, with superior performance over the state-of-the-art (SOTA) ANNs counterparts, our approach also achieves a significant computation reduction of 80% in FLOPS. Furthermore, our proposed method also outperforms SOTA SNNs in the regression task of human pose tracking. Our implementation is available at https://github.com/JimmyZou/HumanPoseTracking_SNN and dataset will be released upon paper acceptance.","accessed":{"date-parts":[["2024",6,5]]},"author":[{"family":"Zou","given":"Shihao"},{"family":"Mu","given":"Yuxuan"},{"family":"Zuo","given":"Xinxin"},{"family":"Wang","given":"Sen"},{"family":"Cheng","given":"Li"}],"citation-key":"zou2023","DOI":"10.48550/arXiv.2303.09681","issued":{"date-parts":[["2023",9,6]]},"number":"arXiv:2303.09681","publisher":"arXiv","source":"arXiv.org","title":"Event-based Human Pose Tracking by Spiking Spatiotemporal Transformer","type":"article","URL":"http://arxiv.org/abs/2303.09681"}
]
