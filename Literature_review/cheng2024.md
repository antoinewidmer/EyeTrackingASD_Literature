---
title: Appearance-based Gaze Estimation With Deep Learning A Review and Benchmark
authors: Yihua Cheng, Haofei Wang, Yiwei Bao, Feng Lu
published: 2024
citekey: cheng2024
journal: 
Paper_type: 
DOI: https://www.doi.org/10.48550/arXiv.2104.12668
PdfZoteroLink : zotero://select/library/items/E3JU7Y7Y
tags: Computer Science - Computer Vision and Pattern Recognition
category:
  main: 
  sub: 
device:
  Type: 
  sampling_rate: 
Participants:
  Total: 
  ASD_boys: 
  ASD_girls: 
  TD_boys: 
  TD_girls: 
cited_papers:
citing_papers: 
other_connected_paper: 
read_on: 
code_repo: 
dataset:
---

## Appearance-based Gaze Estimation With Deep Learning: A Review and Benchmark

> [!Cite]
> Cheng, Y., Wang, H., Bao, Y., & Lu, F. (2024). _Appearance-based Gaze Estimation With Deep Learning: A Review and Benchmark_ (No. arXiv:2104.12668). arXiv. [https://doi.org/10.48550/arXiv.2104.12668](https://doi.org/10.48550/arXiv.2104.12668)

## ðŸ“Œ Summary


## ðŸ”¬ Methods 


### Summary of Common Gaze Estimation Datasets

|**Dataset**|**Subjects**|**Total Annotations**|**Full Face**|**2D Gaze**|**3D Gaze**|**Brief Introduction**|**Links**|
|---|---|---|---|---|---|---|---|
|**Columbia** [184] (2013)|58|6K images|âœ“|Ã—|âœ“|Collected in laboratory; 5 head poses and 21 gaze directions per head pose.|[Link](https://cs.columbia.edu/CAVE/databases/columbia_gaze)|
|**UTMultiview** [37] (2014)|50|1.1M images|Ã—|âœ“|âœ“|Collected in laboratory; Fixed head pose; Multiview eye images; Synthesis eye images.|[Link](https://ut-vision.org/datasets)|
|**EyeDiap** [185] (2014)|16|94 videos|âœ“|âœ“|âœ“|Collected in laboratory; Free head pose; Additional depth videos.|[Link](https://idiap.ch/dataset/eyediap)|
|**MPIIGaze** [49] (2015)|15|213K images|Ã—|âœ“|âœ“|Collected by laptops in daily life; Free head pose and illumination.|[Link](https://mpi-inf.mpg.de/mpiigaze)|
|**GazeCapture** [42] (2016)|1,474|2.4M images|âœ“|âœ“|Ã—|Collected by mobile devices in daily life; Variable lighting condition and head motion.|[Link](https://gazecapture.csail.mit.edu)|
|**MPIIFaceGaze** [50] (2017)|15|~45K images|âœ“|âœ“|âœ“|Collected by laptops in daily life; Free head pose and illumination.|[Link](https://mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/research/gaze-based-human-computer-interaction/its-written-all-over-your-face-full-face-appearance-based-gaze-estimation)|
|**InvisibleEye** [147] (2017)|17|280K images|Ã—|âœ“|Ã—|Collected in laboratory; Multiple near-eye cameras; Low-resolution cameras.|[Link](https://mpi-inf.mpg.de/invisibleeye)|
|**TabletGaze** [186] (2017)|51|816 videos|âœ“|âœ“|Ã—|Collected by tablets in laboratory; Four postures to hold tablets; Free head pose.|Link|
|**RT-Gene** [54] (2018)|15|123K images|âœ“|Ã—|âœ“|Collected in laboratory; Free head pose; Annotated with mobile eye tracker; Use GAN to remove eye tracker in face images.|[Link](https://github.com/Tobias-Fischer/rt_gene)|
|**Gaze360** [43] (2019)|238|172K images|âœ“|Ã—|âœ“|Collected in indoor and outdoor environments; A wide range of head poses and distances.|[Link](https://gaze360.csail.mit.edu)|
|**NVGaze** [149] (2019)|30|4.5M images|Ã—|âœ“|Ã—|Collected in laboratory; Near-eye images; Infrared illumination.|[Link](https://sites.google.com/nvidia.com/nvgaze)|
|**ShanghaiTechGaze** [121] (2019)|137|224K images|âœ“|âœ“|Ã—|Collected in laboratory; Free head pose; Multiview gaze dataset.|[Link](https://github.com/dongzelian/multi-view-gaze)|
|**ETH-XGaze** [66] (2020)|110|1.1M images|âœ“|âœ“|âœ“|Collected in laboratory; High-resolution images; Extreme head poses; 16 illumination conditions.|[Link](https://ait.ethz.ch/projects/2020/ETH-XGaze)|
|**EVE** [67] (2020)|54|~4.2K videos|âœ“|âœ“|âœ“|Collected in laboratory; Free head pose; Free view; Annotated with desktop eye tracker; Pupil size annotation.|[Link](https://ait.ethz.ch/projects/2020/EVE/)|